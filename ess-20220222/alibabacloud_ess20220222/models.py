# -*- coding: utf-8 -*-
# This file is auto-generated, don't edit it. Thanks.
from Tea.model import TeaModel


class ApplyEciScalingConfigurationRequest(TeaModel):
    def __init__(self, content=None, format=None, region_id=None, scaling_configuration_id=None,
                 scaling_group_id=None):
        self.content = content  # type: str
        self.format = format  # type: str
        self.region_id = region_id  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ApplyEciScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.format is not None:
            result['Format'] = self.format
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Format') is not None:
            self.format = m.get('Format')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ApplyEciScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_configuration_id=None):
        self.request_id = request_id  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ApplyEciScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        return self


class ApplyEciScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ApplyEciScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ApplyEciScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ApplyEciScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ApplyScalingGroupRequest(TeaModel):
    def __init__(self, content=None, format=None, region_id=None):
        self.content = content  # type: str
        self.format = format  # type: str
        self.region_id = region_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ApplyScalingGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.format is not None:
            result['Format'] = self.format
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Format') is not None:
            self.format = m.get('Format')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ApplyScalingGroupResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_group_id=None):
        self.request_id = request_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ApplyScalingGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ApplyScalingGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ApplyScalingGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ApplyScalingGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ApplyScalingGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachAlbServerGroupsRequestAlbServerGroups(TeaModel):
    def __init__(self, alb_server_group_id=None, port=None, weight=None):
        # The ID of the ALB server group.
        # 
        # You can associate only a limited number of ALB server groups with a scaling group. To view the quota or manually request a quota increase, go to [Quota Center](https://quotas.console.aliyun.com/products/ess/quotas).
        self.alb_server_group_id = alb_server_group_id  # type: str
        # The port number used by the ECS instance after the ECS instance is added to the ALB server group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The weight of the ECS instance as a backend server after the instance is added to the ALB server group.
        # 
        # If you increase the weight of an ECS instance in an ALB server group, the number of access requests that are forwarded to the ECS instance increases. If you set the Weight parameter for an ECS instance to 0, no access requests are forwarded to the ECS instance. Valid values: 0 to 100.
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachAlbServerGroupsRequestAlbServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alb_server_group_id is not None:
            result['AlbServerGroupId'] = self.alb_server_group_id
        if self.port is not None:
            result['Port'] = self.port
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlbServerGroupId') is not None:
            self.alb_server_group_id = m.get('AlbServerGroupId')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class AttachAlbServerGroupsRequest(TeaModel):
    def __init__(self, alb_server_groups=None, client_token=None, force_attach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # Details of the ALB server group.
        self.alb_server_groups = alb_server_groups  # type: list[AttachAlbServerGroupsRequestAlbServerGroups]
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests. The token can only contain ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure the idempotence of a request](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to add the ECS instances in the scaling group to the ALB server group. Valid values:
        # 
        # *   true: adds the ECS instances to the ALB server group and returns the value of the `ScalingActivityId` parameter. You can check whether the ECS instances are added to the ALB server group by using the ID of the scaling activity.
        # *   false: does not add the ECS instances to the ALB server group.
        # 
        # Default value: false.
        self.force_attach = force_attach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group, such as cn-hangzhou and cn-shanghai. For more information, see [Regions and zones](~~40654~~).
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        if self.alb_server_groups:
            for k in self.alb_server_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(AttachAlbServerGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AlbServerGroups'] = []
        if self.alb_server_groups is not None:
            for k in self.alb_server_groups:
                result['AlbServerGroups'].append(k.to_map() if k else None)
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_attach is not None:
            result['ForceAttach'] = self.force_attach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.alb_server_groups = []
        if m.get('AlbServerGroups') is not None:
            for k in m.get('AlbServerGroups'):
                temp_model = AttachAlbServerGroupsRequestAlbServerGroups()
                self.alb_server_groups.append(temp_model.from_map(k))
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceAttach') is not None:
            self.force_attach = m.get('ForceAttach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class AttachAlbServerGroupsResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity in which Auto Scaling associates the ALB server group with the scaling group and adds ECS instances in the scaling group to the ALB server group. This parameter is returned only if you set the `ForceAttach` parameter to `true`.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachAlbServerGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class AttachAlbServerGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: AttachAlbServerGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(AttachAlbServerGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachAlbServerGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachDBInstancesRequest(TeaModel):
    def __init__(self, client_token=None, dbinstances=None, force_attach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can only contain ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure the idempotence of a request](~~25965~~).
        self.client_token = client_token  # type: str
        # The ID of the ApsaraDB RDS instance.
        self.dbinstances = dbinstances  # type: list[str]
        # Specifies whether to add the private IP addresses of all instances in the scaling group to the IP address whitelist of the ApsaraDB RDS instance. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_attach = force_attach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachDBInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.dbinstances is not None:
            result['DBInstances'] = self.dbinstances
        if self.force_attach is not None:
            result['ForceAttach'] = self.force_attach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('DBInstances') is not None:
            self.dbinstances = m.get('DBInstances')
        if m.get('ForceAttach') is not None:
            self.force_attach = m.get('ForceAttach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class AttachDBInstancesResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachDBInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class AttachDBInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: AttachDBInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(AttachDBInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachDBInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachInstancesRequest(TeaModel):
    def __init__(self, client_token=None, entrusted=None, instance_ids=None, lifecycle_hook=None,
                 load_balancer_weights=None, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 resource_owner_id=None, scaling_group_id=None):
        # 保证请求幂等性。从您的客户端生成一个参数值，确保不同请求间该参数值唯一。只支持ASCII字符，且不能超过64个字符。更多信息，请参见[如何保证幂等性](~~25965~~)。
        self.client_token = client_token  # type: str
        # Specifies whether the scaling group manages the lifecycles of instances that are manually added to the scaling group. Valid values:
        # 
        # *   true: The scaling group manages the lifecycles of instances that are manually added in a similar manner in which the scaling group manages the lifecycles of automatically created instances. After Auto Scaling removes instances from the scaling group, Auto Scaling releases the instances. After you call the DetachInstances operation to remove instances from the scaling group, Auto Scaling does not release the instances.
        # *   false: The scaling group does not manage the lifecycles of instances that are manually added. After Auto Scaling removes instances from the scaling group, Auto Scaling does not release the instances.
        # 
        # > You cannot specify this parameter for subscription instances.
        # 
        # Default value: false.
        self.entrusted = entrusted  # type: bool
        # The IDs of the ECS instances or elastic container instances that you want to add.
        self.instance_ids = instance_ids  # type: list[str]
        # Specifies whether to trigger a lifecycle hook for a scale-out activity. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.lifecycle_hook = lifecycle_hook  # type: bool
        # The weights of the ECS instances or elastic container instances as the backend servers of the associated Classic Load Balancer (CLB) instance.
        self.load_balancer_weights = load_balancer_weights  # type: list[int]
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.entrusted is not None:
            result['Entrusted'] = self.entrusted
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.lifecycle_hook is not None:
            result['LifecycleHook'] = self.lifecycle_hook
        if self.load_balancer_weights is not None:
            result['LoadBalancerWeights'] = self.load_balancer_weights
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('Entrusted') is not None:
            self.entrusted = m.get('Entrusted')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('LifecycleHook') is not None:
            self.lifecycle_hook = m.get('LifecycleHook')
        if m.get('LoadBalancerWeights') is not None:
            self.load_balancer_weights = m.get('LoadBalancerWeights')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class AttachInstancesResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class AttachInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: AttachInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(AttachInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachLoadBalancersRequestLoadBalancerConfigs(TeaModel):
    def __init__(self, load_balancer_id=None, weight=None):
        # 负载均衡CLB（原SLB）实例的ID。
        self.load_balancer_id = load_balancer_id  # type: str
        # 弹性伸缩将ECS实例添加到SLB服务器组后，ECS实例作为后端服务器的权重。权重越高，ECS实例将被分配到越多的访问请求。如果权重为0，则ECS实例不会收到访问请求。取值范围：0~100。
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachLoadBalancersRequestLoadBalancerConfigs, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class AttachLoadBalancersRequest(TeaModel):
    def __init__(self, async=None, client_token=None, force_attach=None, load_balancer_configs=None,
                 load_balancers=None, owner_id=None, resource_owner_account=None, scaling_group_id=None):
        # Specifies whether to attach the CLB instance to the scaling group in an asynchronous manner. If you attach the CLB instance from the scaling group in an asynchronous manner, the call is successful only after all operations are successful. If a specific operation fails, the call fails. We recommend that you set this parameter to true. Valid values:
        # 
        # *   true: attaches the CLB instance to the scaling group in an asynchronous manner. In this case, the ID of the scaling activity is returned.
        # *   false: does not attach the CLB instance to the scaling group in an asynchronous manner.
        # 
        # Default value: false.
        self.async = async  # type: bool
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to add all instances in the scaling group to the vServer groups of the CLB instance. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_attach = force_attach  # type: bool
        # 负载均衡配置列表。
        self.load_balancer_configs = load_balancer_configs  # type: list[AttachLoadBalancersRequestLoadBalancerConfigs]
        # The IDs of the CLB instances.
        self.load_balancers = load_balancers  # type: list[str]
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        if self.load_balancer_configs:
            for k in self.load_balancer_configs:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(AttachLoadBalancersRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.async is not None:
            result['Async'] = self.async
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_attach is not None:
            result['ForceAttach'] = self.force_attach
        result['LoadBalancerConfigs'] = []
        if self.load_balancer_configs is not None:
            for k in self.load_balancer_configs:
                result['LoadBalancerConfigs'].append(k.to_map() if k else None)
        if self.load_balancers is not None:
            result['LoadBalancers'] = self.load_balancers
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Async') is not None:
            self.async = m.get('Async')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceAttach') is not None:
            self.force_attach = m.get('ForceAttach')
        self.load_balancer_configs = []
        if m.get('LoadBalancerConfigs') is not None:
            for k in m.get('LoadBalancerConfigs'):
                temp_model = AttachLoadBalancersRequestLoadBalancerConfigs()
                self.load_balancer_configs.append(temp_model.from_map(k))
        if m.get('LoadBalancers') is not None:
            self.load_balancers = m.get('LoadBalancers')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class AttachLoadBalancersResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        # 
        # The value of this parameter is returned only after you set the Async parameter to true. You can call the DescribeScalingActivities operation to query all scaling activity IDs and use the scaling activity IDs to check the status of the scaling activities.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachLoadBalancersResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class AttachLoadBalancersResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: AttachLoadBalancersResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(AttachLoadBalancersResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachLoadBalancersResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachServerGroupsRequestServerGroups(TeaModel):
    def __init__(self, port=None, server_group_id=None, type=None, weight=None):
        # The port number that is used by an ECS instance after Auto Scaling adds the ECS instance to the server group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The ID of the server group.
        self.server_group_id = server_group_id  # type: str
        # The type of the server group. Valid values:
        # 
        # *   ALB
        # *   NLB
        self.type = type  # type: str
        # The weight of an ECS instance after Auto Scaling adds the ECS instance to the server group as a backend server.
        # 
        # A higher weight specifies that a larger number of requests are forwarded to the ECS instance. If you set the Weight parameter for an ECS instance in the server group to 0, no access requests are forwarded to the ECS instance. Valid values: 0 to 100.
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachServerGroupsRequestServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.server_group_id is not None:
            result['ServerGroupId'] = self.server_group_id
        if self.type is not None:
            result['Type'] = self.type
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ServerGroupId') is not None:
            self.server_group_id = m.get('ServerGroupId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class AttachServerGroupsRequest(TeaModel):
    def __init__(self, client_token=None, force_attach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None, server_groups=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the token, but you must make sure that the token is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [Ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to add the Elastic Compute Service (ECS) instances in the scaling group to the new server group.
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_attach = force_attach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # Details of the server groups.
        self.server_groups = server_groups  # type: list[AttachServerGroupsRequestServerGroups]

    def validate(self):
        if self.server_groups:
            for k in self.server_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(AttachServerGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_attach is not None:
            result['ForceAttach'] = self.force_attach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['ServerGroups'] = []
        if self.server_groups is not None:
            for k in self.server_groups:
                result['ServerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceAttach') is not None:
            self.force_attach = m.get('ForceAttach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.server_groups = []
        if m.get('ServerGroups') is not None:
            for k in m.get('ServerGroups'):
                temp_model = AttachServerGroupsRequestServerGroups()
                self.server_groups.append(temp_model.from_map(k))
        return self


class AttachServerGroupsResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity in which you attach the server group to the scaling group and Auto Scaling adds the ECS instances in the scaling group to the server group.
        # 
        # > This parameter is returned only if you set the ForceAttach parameter to true.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachServerGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class AttachServerGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: AttachServerGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(AttachServerGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachServerGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class AttachVServerGroupsRequestVServerGroupsVServerGroupAttributes(TeaModel):
    def __init__(self, port=None, vserver_group_id=None, weight=None):
        # The port number that is used when Auto Scaling adds ECS instances to the vServer group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The ID of the vServer group.
        self.vserver_group_id = vserver_group_id  # type: str
        # The weight of an ECS instance as a backend server in the vServer group. Valid values: 0 to 100.
        # 
        # Default value: 50.
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachVServerGroupsRequestVServerGroupsVServerGroupAttributes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.vserver_group_id is not None:
            result['VServerGroupId'] = self.vserver_group_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('VServerGroupId') is not None:
            self.vserver_group_id = m.get('VServerGroupId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class AttachVServerGroupsRequestVServerGroups(TeaModel):
    def __init__(self, load_balancer_id=None, vserver_group_attributes=None):
        # The ID of the CLB instance to which the vServer group belongs.
        self.load_balancer_id = load_balancer_id  # type: str
        # Details of the vServer group attributes.
        self.vserver_group_attributes = vserver_group_attributes  # type: list[AttachVServerGroupsRequestVServerGroupsVServerGroupAttributes]

    def validate(self):
        if self.vserver_group_attributes:
            for k in self.vserver_group_attributes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(AttachVServerGroupsRequestVServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        result['VServerGroupAttributes'] = []
        if self.vserver_group_attributes is not None:
            for k in self.vserver_group_attributes:
                result['VServerGroupAttributes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        self.vserver_group_attributes = []
        if m.get('VServerGroupAttributes') is not None:
            for k in m.get('VServerGroupAttributes'):
                temp_model = AttachVServerGroupsRequestVServerGroupsVServerGroupAttributes()
                self.vserver_group_attributes.append(temp_model.from_map(k))
        return self


class AttachVServerGroupsRequest(TeaModel):
    def __init__(self, client_token=None, force_attach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None, vserver_groups=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure the idempotence of a request](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to add Elastic Compute Service (ECS) instances in the scaling group to the vServer group. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_attach = force_attach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group. Examples: cn-hangzhou and cn-shanghai.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # Details of the vServer groups.
        self.vserver_groups = vserver_groups  # type: list[AttachVServerGroupsRequestVServerGroups]

    def validate(self):
        if self.vserver_groups:
            for k in self.vserver_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(AttachVServerGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_attach is not None:
            result['ForceAttach'] = self.force_attach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['VServerGroups'] = []
        if self.vserver_groups is not None:
            for k in self.vserver_groups:
                result['VServerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceAttach') is not None:
            self.force_attach = m.get('ForceAttach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.vserver_groups = []
        if m.get('VServerGroups') is not None:
            for k in m.get('VServerGroups'):
                temp_model = AttachVServerGroupsRequestVServerGroups()
                self.vserver_groups.append(temp_model.from_map(k))
        return self


class AttachVServerGroupsResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(AttachVServerGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class AttachVServerGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: AttachVServerGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(AttachVServerGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = AttachVServerGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ChangeResourceGroupRequest(TeaModel):
    def __init__(self, new_resource_group_id=None, owner_id=None, region_id=None, resource_id=None,
                 resource_owner_account=None, resource_type=None):
        self.new_resource_group_id = new_resource_group_id  # type: str
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.resource_id = resource_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_type = resource_type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ChangeResourceGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.new_resource_group_id is not None:
            result['NewResourceGroupId'] = self.new_resource_group_id
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_id is not None:
            result['ResourceId'] = self.resource_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NewResourceGroupId') is not None:
            self.new_resource_group_id = m.get('NewResourceGroupId')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceId') is not None:
            self.resource_id = m.get('ResourceId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        return self


class ChangeResourceGroupResponseBody(TeaModel):
    def __init__(self, request_id=None):
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ChangeResourceGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ChangeResourceGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ChangeResourceGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ChangeResourceGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ChangeResourceGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CompleteLifecycleActionRequest(TeaModel):
    def __init__(self, client_token=None, lifecycle_action_result=None, lifecycle_action_token=None,
                 lifecycle_hook_id=None, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the token, but you must make sure that the token is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # The action that you want Auto Scaling to perform after the lifecycle hook times out. Valid values:
        # 
        # *   CONTINUE: Auto Scaling continues to respond to a scale-in or scale-out request.
        # *   ABANDON: Auto Scaling releases Elastic Compute Service (ECS) instances that are created during scale-out activities or removes ECS instances from the scaling group during scale-in activities.
        # *   ROLLBACK: For scale-in activities, Auto Scaling rejects the requests to release ECS instances but rolls back ECS instances. For scale-out activities, the ROLLBACK setting has the same effect as the ABANDON setting.
        # 
        # If you do not specify this parameter, Auto Scaling performs the action that is specified by the `DefaultResult` parameter after the lifecycle hook times out.
        # 
        # If multiple lifecycle hooks exist in a scaling group and the lifecycle hooks are triggered at the same time, the following rules apply:
        # 
        # *   For scale-in activities, when lifecycle hooks whose LifecycleActionResult parameter is set to ABANDON or ROLLBACK time out, other lifecycle hooks time out ahead of schedule.
        # *   For scale-in and scale-out activities, if you set the LifecycleActionResult parameter for all lifecycle hooks to CONTINUE, Auto Scaling performs the next action only after the last lifecycle hook times out. The action that Auto Scaling performs varies based on the value that you specify for the LifecycleActionResult parameter of the lifecycle hook that last times out.
        self.lifecycle_action_result = lifecycle_action_result  # type: str
        # The token of the lifecycle hook. You can obtain this token by using a Message Service (MNS) queue or an MNS topic that is specified for the lifecycle hook.
        self.lifecycle_action_token = lifecycle_action_token  # type: str
        # The ID of the lifecycle hook.
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CompleteLifecycleActionRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.lifecycle_action_result is not None:
            result['LifecycleActionResult'] = self.lifecycle_action_result
        if self.lifecycle_action_token is not None:
            result['LifecycleActionToken'] = self.lifecycle_action_token
        if self.lifecycle_hook_id is not None:
            result['LifecycleHookId'] = self.lifecycle_hook_id
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('LifecycleActionResult') is not None:
            self.lifecycle_action_result = m.get('LifecycleActionResult')
        if m.get('LifecycleActionToken') is not None:
            self.lifecycle_action_token = m.get('LifecycleActionToken')
        if m.get('LifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('LifecycleHookId')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class CompleteLifecycleActionResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CompleteLifecycleActionResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CompleteLifecycleActionResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CompleteLifecycleActionResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CompleteLifecycleActionResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CompleteLifecycleActionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateAlarmRequestDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        self.dimension_key = dimension_key  # type: str
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateAlarmRequestDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class CreateAlarmRequestExpressions(TeaModel):
    def __init__(self, comparison_operator=None, metric_name=None, period=None, statistics=None, threshold=None):
        self.comparison_operator = comparison_operator  # type: str
        self.metric_name = metric_name  # type: str
        self.period = period  # type: int
        self.statistics = statistics  # type: str
        self.threshold = threshold  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateAlarmRequestExpressions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.period is not None:
            result['Period'] = self.period
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class CreateAlarmRequest(TeaModel):
    def __init__(self, alarm_actions=None, comparison_operator=None, description=None, dimensions=None,
                 effective=None, evaluation_count=None, expressions=None, expressions_logic_operator=None, group_id=None,
                 metric_name=None, metric_type=None, name=None, owner_id=None, period=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None, statistics=None, threshold=None):
        self.alarm_actions = alarm_actions  # type: list[str]
        self.comparison_operator = comparison_operator  # type: str
        self.description = description  # type: str
        self.dimensions = dimensions  # type: list[CreateAlarmRequestDimensions]
        self.effective = effective  # type: str
        self.evaluation_count = evaluation_count  # type: int
        self.expressions = expressions  # type: list[CreateAlarmRequestExpressions]
        self.expressions_logic_operator = expressions_logic_operator  # type: str
        self.group_id = group_id  # type: int
        self.metric_name = metric_name  # type: str
        self.metric_type = metric_type  # type: str
        self.name = name  # type: str
        self.owner_id = owner_id  # type: long
        self.period = period  # type: int
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.statistics = statistics  # type: str
        self.threshold = threshold  # type: float

    def validate(self):
        if self.dimensions:
            for k in self.dimensions:
                if k:
                    k.validate()
        if self.expressions:
            for k in self.expressions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateAlarmRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_actions is not None:
            result['AlarmActions'] = self.alarm_actions
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        if self.description is not None:
            result['Description'] = self.description
        result['Dimensions'] = []
        if self.dimensions is not None:
            for k in self.dimensions:
                result['Dimensions'].append(k.to_map() if k else None)
        if self.effective is not None:
            result['Effective'] = self.effective
        if self.evaluation_count is not None:
            result['EvaluationCount'] = self.evaluation_count
        result['Expressions'] = []
        if self.expressions is not None:
            for k in self.expressions:
                result['Expressions'].append(k.to_map() if k else None)
        if self.expressions_logic_operator is not None:
            result['ExpressionsLogicOperator'] = self.expressions_logic_operator
        if self.group_id is not None:
            result['GroupId'] = self.group_id
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.metric_type is not None:
            result['MetricType'] = self.metric_type
        if self.name is not None:
            result['Name'] = self.name
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.period is not None:
            result['Period'] = self.period
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmActions') is not None:
            self.alarm_actions = m.get('AlarmActions')
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        self.dimensions = []
        if m.get('Dimensions') is not None:
            for k in m.get('Dimensions'):
                temp_model = CreateAlarmRequestDimensions()
                self.dimensions.append(temp_model.from_map(k))
        if m.get('Effective') is not None:
            self.effective = m.get('Effective')
        if m.get('EvaluationCount') is not None:
            self.evaluation_count = m.get('EvaluationCount')
        self.expressions = []
        if m.get('Expressions') is not None:
            for k in m.get('Expressions'):
                temp_model = CreateAlarmRequestExpressions()
                self.expressions.append(temp_model.from_map(k))
        if m.get('ExpressionsLogicOperator') is not None:
            self.expressions_logic_operator = m.get('ExpressionsLogicOperator')
        if m.get('GroupId') is not None:
            self.group_id = m.get('GroupId')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MetricType') is not None:
            self.metric_type = m.get('MetricType')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class CreateAlarmResponseBody(TeaModel):
    def __init__(self, alarm_task_id=None, request_id=None):
        self.alarm_task_id = alarm_task_id  # type: str
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateAlarmResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateAlarmResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateAlarmResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateAlarmResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateAlarmResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateEciScalingConfigurationRequestAcrRegistryInfos(TeaModel):
    def __init__(self, domains=None, instance_id=None, instance_name=None, region_id=None):
        # The domain names of the Container Registry Enterprise Edition instances. By default, all domain names of the Container Registry Enterprise Edition instances are displayed. You can specify one or more domain names. Separate multiple domain names with commas (,).
        self.domains = domains  # type: list[str]
        # The ID of the Container Registry Enterprise Edition instance.
        self.instance_id = instance_id  # type: str
        # The name of the Container Registry Enterprise Edition instance.
        self.instance_name = instance_name  # type: str
        # The region ID of the Container Registry Enterprise Edition instance.
        self.region_id = region_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestAcrRegistryInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.domains is not None:
            result['Domains'] = self.domains
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Domains') is not None:
            self.domains = m.get('Domains')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class CreateEciScalingConfigurationRequestContainersLivenessProbeExec(TeaModel):
    def __init__(self, commands=None):
        self.commands = commands  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersLivenessProbeExec, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.commands is not None:
            result['Commands'] = self.commands
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        return self


class CreateEciScalingConfigurationRequestContainersLivenessProbeHttpGet(TeaModel):
    def __init__(self, path=None, port=None, scheme=None):
        self.path = path  # type: str
        self.port = port  # type: int
        self.scheme = scheme  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersLivenessProbeHttpGet, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.port is not None:
            result['Port'] = self.port
        if self.scheme is not None:
            result['Scheme'] = self.scheme
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Scheme') is not None:
            self.scheme = m.get('Scheme')
        return self


class CreateEciScalingConfigurationRequestContainersLivenessProbeTcpSocket(TeaModel):
    def __init__(self, port=None):
        self.port = port  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersLivenessProbeTcpSocket, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        return self


class CreateEciScalingConfigurationRequestContainersLivenessProbe(TeaModel):
    def __init__(self, exec_=None, failure_threshold=None, http_get=None, initial_delay_seconds=None,
                 period_seconds=None, success_threshold=None, tcp_socket=None, timeout_seconds=None):
        self.exec_ = exec_  # type: CreateEciScalingConfigurationRequestContainersLivenessProbeExec
        self.failure_threshold = failure_threshold  # type: int
        self.http_get = http_get  # type: CreateEciScalingConfigurationRequestContainersLivenessProbeHttpGet
        self.initial_delay_seconds = initial_delay_seconds  # type: int
        self.period_seconds = period_seconds  # type: int
        self.success_threshold = success_threshold  # type: int
        self.tcp_socket = tcp_socket  # type: CreateEciScalingConfigurationRequestContainersLivenessProbeTcpSocket
        self.timeout_seconds = timeout_seconds  # type: int

    def validate(self):
        if self.exec_:
            self.exec_.validate()
        if self.http_get:
            self.http_get.validate()
        if self.tcp_socket:
            self.tcp_socket.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersLivenessProbe, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.exec_ is not None:
            result['Exec'] = self.exec_.to_map()
        if self.failure_threshold is not None:
            result['FailureThreshold'] = self.failure_threshold
        if self.http_get is not None:
            result['HttpGet'] = self.http_get.to_map()
        if self.initial_delay_seconds is not None:
            result['InitialDelaySeconds'] = self.initial_delay_seconds
        if self.period_seconds is not None:
            result['PeriodSeconds'] = self.period_seconds
        if self.success_threshold is not None:
            result['SuccessThreshold'] = self.success_threshold
        if self.tcp_socket is not None:
            result['TcpSocket'] = self.tcp_socket.to_map()
        if self.timeout_seconds is not None:
            result['TimeoutSeconds'] = self.timeout_seconds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Exec') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersLivenessProbeExec()
            self.exec_ = temp_model.from_map(m['Exec'])
        if m.get('FailureThreshold') is not None:
            self.failure_threshold = m.get('FailureThreshold')
        if m.get('HttpGet') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersLivenessProbeHttpGet()
            self.http_get = temp_model.from_map(m['HttpGet'])
        if m.get('InitialDelaySeconds') is not None:
            self.initial_delay_seconds = m.get('InitialDelaySeconds')
        if m.get('PeriodSeconds') is not None:
            self.period_seconds = m.get('PeriodSeconds')
        if m.get('SuccessThreshold') is not None:
            self.success_threshold = m.get('SuccessThreshold')
        if m.get('TcpSocket') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersLivenessProbeTcpSocket()
            self.tcp_socket = temp_model.from_map(m['TcpSocket'])
        if m.get('TimeoutSeconds') is not None:
            self.timeout_seconds = m.get('TimeoutSeconds')
        return self


class CreateEciScalingConfigurationRequestContainersReadinessProbeExec(TeaModel):
    def __init__(self, commands=None):
        self.commands = commands  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersReadinessProbeExec, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.commands is not None:
            result['Commands'] = self.commands
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        return self


class CreateEciScalingConfigurationRequestContainersReadinessProbeHttpGet(TeaModel):
    def __init__(self, path=None, port=None, scheme=None):
        self.path = path  # type: str
        self.port = port  # type: int
        self.scheme = scheme  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersReadinessProbeHttpGet, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.port is not None:
            result['Port'] = self.port
        if self.scheme is not None:
            result['Scheme'] = self.scheme
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Scheme') is not None:
            self.scheme = m.get('Scheme')
        return self


class CreateEciScalingConfigurationRequestContainersReadinessProbeTcpSocket(TeaModel):
    def __init__(self, port=None):
        self.port = port  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersReadinessProbeTcpSocket, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        return self


class CreateEciScalingConfigurationRequestContainersReadinessProbe(TeaModel):
    def __init__(self, exec_=None, failure_threshold=None, http_get=None, initial_delay_seconds=None,
                 period_seconds=None, success_threshold=None, tcp_socket=None, timeout_seconds=None):
        self.exec_ = exec_  # type: CreateEciScalingConfigurationRequestContainersReadinessProbeExec
        self.failure_threshold = failure_threshold  # type: int
        self.http_get = http_get  # type: CreateEciScalingConfigurationRequestContainersReadinessProbeHttpGet
        self.initial_delay_seconds = initial_delay_seconds  # type: int
        self.period_seconds = period_seconds  # type: int
        self.success_threshold = success_threshold  # type: int
        self.tcp_socket = tcp_socket  # type: CreateEciScalingConfigurationRequestContainersReadinessProbeTcpSocket
        self.timeout_seconds = timeout_seconds  # type: int

    def validate(self):
        if self.exec_:
            self.exec_.validate()
        if self.http_get:
            self.http_get.validate()
        if self.tcp_socket:
            self.tcp_socket.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersReadinessProbe, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.exec_ is not None:
            result['Exec'] = self.exec_.to_map()
        if self.failure_threshold is not None:
            result['FailureThreshold'] = self.failure_threshold
        if self.http_get is not None:
            result['HttpGet'] = self.http_get.to_map()
        if self.initial_delay_seconds is not None:
            result['InitialDelaySeconds'] = self.initial_delay_seconds
        if self.period_seconds is not None:
            result['PeriodSeconds'] = self.period_seconds
        if self.success_threshold is not None:
            result['SuccessThreshold'] = self.success_threshold
        if self.tcp_socket is not None:
            result['TcpSocket'] = self.tcp_socket.to_map()
        if self.timeout_seconds is not None:
            result['TimeoutSeconds'] = self.timeout_seconds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Exec') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersReadinessProbeExec()
            self.exec_ = temp_model.from_map(m['Exec'])
        if m.get('FailureThreshold') is not None:
            self.failure_threshold = m.get('FailureThreshold')
        if m.get('HttpGet') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersReadinessProbeHttpGet()
            self.http_get = temp_model.from_map(m['HttpGet'])
        if m.get('InitialDelaySeconds') is not None:
            self.initial_delay_seconds = m.get('InitialDelaySeconds')
        if m.get('PeriodSeconds') is not None:
            self.period_seconds = m.get('PeriodSeconds')
        if m.get('SuccessThreshold') is not None:
            self.success_threshold = m.get('SuccessThreshold')
        if m.get('TcpSocket') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersReadinessProbeTcpSocket()
            self.tcp_socket = temp_model.from_map(m['TcpSocket'])
        if m.get('TimeoutSeconds') is not None:
            self.timeout_seconds = m.get('TimeoutSeconds')
        return self


class CreateEciScalingConfigurationRequestContainersSecurityContextCapability(TeaModel):
    def __init__(self, add=None):
        self.add = add  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersSecurityContextCapability, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.add is not None:
            result['Add'] = self.add
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Add') is not None:
            self.add = m.get('Add')
        return self


class CreateEciScalingConfigurationRequestContainersSecurityContext(TeaModel):
    def __init__(self, capability=None, read_only_root_filesystem=None, run_as_user=None):
        self.capability = capability  # type: CreateEciScalingConfigurationRequestContainersSecurityContextCapability
        self.read_only_root_filesystem = read_only_root_filesystem  # type: bool
        self.run_as_user = run_as_user  # type: long

    def validate(self):
        if self.capability:
            self.capability.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersSecurityContext, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capability is not None:
            result['Capability'] = self.capability.to_map()
        if self.read_only_root_filesystem is not None:
            result['ReadOnlyRootFilesystem'] = self.read_only_root_filesystem
        if self.run_as_user is not None:
            result['RunAsUser'] = self.run_as_user
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Capability') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersSecurityContextCapability()
            self.capability = temp_model.from_map(m['Capability'])
        if m.get('ReadOnlyRootFilesystem') is not None:
            self.read_only_root_filesystem = m.get('ReadOnlyRootFilesystem')
        if m.get('RunAsUser') is not None:
            self.run_as_user = m.get('RunAsUser')
        return self


class CreateEciScalingConfigurationRequestContainersEnvironmentVars(TeaModel):
    def __init__(self, field_ref_field_path=None, key=None, value=None):
        # > This parameter is unavailable.
        self.field_ref_field_path = field_ref_field_path  # type: str
        # The name of the environment variable. The name must be 1 to 128 characters in length and can contain letters, digits, and underscores (\_). The name cannot start with a digit. Specify the name in the \[0-9a-zA-Z] format.
        self.key = key  # type: str
        # The value of the environment variable. The value must be 0 to 256 characters in length.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref_field_path is not None:
            result['FieldRefFieldPath'] = self.field_ref_field_path
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRefFieldPath') is not None:
            self.field_ref_field_path = m.get('FieldRefFieldPath')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateEciScalingConfigurationRequestContainersPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        # The port number. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The type of the protocol. Valid values:
        # 
        # *   TCP
        # *   UDP
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class CreateEciScalingConfigurationRequestContainersVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        # The directory on which the container mounts the volume.
        # 
        # > Data in this directory is overwritten by the data on the volume.
        self.mount_path = mount_path  # type: str
        # The mount propagation settings of the volume. Mount propagation allows volumes that are mounted on one container to be shared with other containers in the same pod, or even with other pods on the same node. Valid values:
        # 
        # *   None: The volume mount does not receive subsequent mounts that are mounted to this volume or its subdirectories.
        # *   HostToCotainer: The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories.
        # *   Bidirectional: This value is similar to HostToCotainer. The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories. In addition, all volume mounts that are created by the container are propagated back to the instance and to all containers of all pods that use the same volume.
        # 
        # Default value: None.
        self.mount_propagation = mount_propagation  # type: str
        # The name of the volume. The value of this parameter is the same as the value of the VolumeName parameter.
        self.name = name  # type: str
        # Specifies whether the volume is read-only. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.read_only = read_only  # type: bool
        # The subdirectory of the volume.
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainersVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class CreateEciScalingConfigurationRequestContainers(TeaModel):
    def __init__(self, liveness_probe=None, readiness_probe=None, security_context=None, args=None, commands=None,
                 cpu=None, environment_vars=None, gpu=None, image=None, image_pull_policy=None,
                 lifecycle_post_start_handler_execs=None, lifecycle_post_start_handler_http_get_host=None,
                 lifecycle_post_start_handler_http_get_path=None, lifecycle_post_start_handler_http_get_port=None,
                 lifecycle_post_start_handler_http_get_scheme=None, lifecycle_post_start_handler_tcp_socket_host=None,
                 lifecycle_post_start_handler_tcp_socket_port=None, lifecycle_pre_stop_handler_execs=None, lifecycle_pre_stop_handler_http_get_host=None,
                 lifecycle_pre_stop_handler_http_get_path=None, lifecycle_pre_stop_handler_http_get_port=None,
                 lifecycle_pre_stop_handler_http_get_scheme=None, lifecycle_pre_stop_handler_tcp_socket_host=None,
                 lifecycle_pre_stop_handler_tcp_socket_port=None, memory=None, name=None, ports=None, stdin=None, stdin_once=None, tty=None, volume_mounts=None,
                 working_dir=None):
        self.liveness_probe = liveness_probe  # type: CreateEciScalingConfigurationRequestContainersLivenessProbe
        self.readiness_probe = readiness_probe  # type: CreateEciScalingConfigurationRequestContainersReadinessProbe
        self.security_context = security_context  # type: CreateEciScalingConfigurationRequestContainersSecurityContext
        # The arguments that correspond to the startup commands of the container. You can specify up to 10 arguments.
        self.args = args  # type: list[str]
        # The commands that you want to run in the container when you use the CLI to perform probes.
        self.commands = commands  # type: list[str]
        # The number of CPU cores in the container.
        self.cpu = cpu  # type: float
        # Information about environment variables.
        self.environment_vars = environment_vars  # type: list[CreateEciScalingConfigurationRequestContainersEnvironmentVars]
        # The number of GPUs that you want to allocate to the container.
        self.gpu = gpu  # type: int
        # The image of the container.
        self.image = image  # type: str
        # The image pulling policy. Valid values:
        # 
        # *   Always: pulls images each time.
        # *   IfNotPresent: pulls images only if no on-premises images are available. On-premises images are preferentially used. If no on-premises images are available, image pulling is performed.
        # *   Never: never pulls images. On-premises images are always used.
        self.image_pull_policy = image_pull_policy  # type: str
        self.lifecycle_post_start_handler_execs = lifecycle_post_start_handler_execs  # type: list[str]
        self.lifecycle_post_start_handler_http_get_host = lifecycle_post_start_handler_http_get_host  # type: str
        self.lifecycle_post_start_handler_http_get_path = lifecycle_post_start_handler_http_get_path  # type: str
        self.lifecycle_post_start_handler_http_get_port = lifecycle_post_start_handler_http_get_port  # type: int
        self.lifecycle_post_start_handler_http_get_scheme = lifecycle_post_start_handler_http_get_scheme  # type: str
        self.lifecycle_post_start_handler_tcp_socket_host = lifecycle_post_start_handler_tcp_socket_host  # type: str
        self.lifecycle_post_start_handler_tcp_socket_port = lifecycle_post_start_handler_tcp_socket_port  # type: int
        self.lifecycle_pre_stop_handler_execs = lifecycle_pre_stop_handler_execs  # type: list[str]
        self.lifecycle_pre_stop_handler_http_get_host = lifecycle_pre_stop_handler_http_get_host  # type: str
        self.lifecycle_pre_stop_handler_http_get_path = lifecycle_pre_stop_handler_http_get_path  # type: str
        self.lifecycle_pre_stop_handler_http_get_port = lifecycle_pre_stop_handler_http_get_port  # type: int
        self.lifecycle_pre_stop_handler_http_get_scheme = lifecycle_pre_stop_handler_http_get_scheme  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_host = lifecycle_pre_stop_handler_tcp_socket_host  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_port = lifecycle_pre_stop_handler_tcp_socket_port  # type: int
        # The memory size of the container. Unit: GiB.
        self.memory = memory  # type: float
        # The name of the container image.
        self.name = name  # type: str
        # The ports.
        self.ports = ports  # type: list[CreateEciScalingConfigurationRequestContainersPorts]
        # Specifies whether the container allocates buffer resources to standard input streams when the container is running. If you do not specify this parameter, an end-of-file (EOF) error may occur.
        # 
        # Default value: false.
        self.stdin = stdin  # type: bool
        # Specifies whether to disconnect standard input streams after a client is disconnected.
        # 
        # If you set the StdinOnce parameter to true, standard input streams are connected after the container is started, and remain idle until a client is connected to receive data. After the client is disconnected, streams are also disconnected, and remain disconnected until the container is started again.
        self.stdin_once = stdin_once  # type: bool
        # Specifies whether to enable interaction. Valid values:
        # 
        # *   true
        # *   false
        # 
        # If the value of the Command parameter is /bin/bash, you must set this parameter to true.
        # 
        # Default value: false.
        self.tty = tty  # type: bool
        # Information about the volume mount of the container.
        self.volume_mounts = volume_mounts  # type: list[CreateEciScalingConfigurationRequestContainersVolumeMounts]
        # The working directory of the container.
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.liveness_probe:
            self.liveness_probe.validate()
        if self.readiness_probe:
            self.readiness_probe.validate()
        if self.security_context:
            self.security_context.validate()
        if self.environment_vars:
            for k in self.environment_vars:
                if k:
                    k.validate()
        if self.ports:
            for k in self.ports:
                if k:
                    k.validate()
        if self.volume_mounts:
            for k in self.volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.liveness_probe is not None:
            result['LivenessProbe'] = self.liveness_probe.to_map()
        if self.readiness_probe is not None:
            result['ReadinessProbe'] = self.readiness_probe.to_map()
        if self.security_context is not None:
            result['SecurityContext'] = self.security_context.to_map()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        result['EnvironmentVars'] = []
        if self.environment_vars is not None:
            for k in self.environment_vars:
                result['EnvironmentVars'].append(k.to_map() if k else None)
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        if self.lifecycle_post_start_handler_execs is not None:
            result['LifecyclePostStartHandlerExecs'] = self.lifecycle_post_start_handler_execs
        if self.lifecycle_post_start_handler_http_get_host is not None:
            result['LifecyclePostStartHandlerHttpGetHost'] = self.lifecycle_post_start_handler_http_get_host
        if self.lifecycle_post_start_handler_http_get_path is not None:
            result['LifecyclePostStartHandlerHttpGetPath'] = self.lifecycle_post_start_handler_http_get_path
        if self.lifecycle_post_start_handler_http_get_port is not None:
            result['LifecyclePostStartHandlerHttpGetPort'] = self.lifecycle_post_start_handler_http_get_port
        if self.lifecycle_post_start_handler_http_get_scheme is not None:
            result['LifecyclePostStartHandlerHttpGetScheme'] = self.lifecycle_post_start_handler_http_get_scheme
        if self.lifecycle_post_start_handler_tcp_socket_host is not None:
            result['LifecyclePostStartHandlerTcpSocketHost'] = self.lifecycle_post_start_handler_tcp_socket_host
        if self.lifecycle_post_start_handler_tcp_socket_port is not None:
            result['LifecyclePostStartHandlerTcpSocketPort'] = self.lifecycle_post_start_handler_tcp_socket_port
        if self.lifecycle_pre_stop_handler_execs is not None:
            result['LifecyclePreStopHandlerExecs'] = self.lifecycle_pre_stop_handler_execs
        if self.lifecycle_pre_stop_handler_http_get_host is not None:
            result['LifecyclePreStopHandlerHttpGetHost'] = self.lifecycle_pre_stop_handler_http_get_host
        if self.lifecycle_pre_stop_handler_http_get_path is not None:
            result['LifecyclePreStopHandlerHttpGetPath'] = self.lifecycle_pre_stop_handler_http_get_path
        if self.lifecycle_pre_stop_handler_http_get_port is not None:
            result['LifecyclePreStopHandlerHttpGetPort'] = self.lifecycle_pre_stop_handler_http_get_port
        if self.lifecycle_pre_stop_handler_http_get_scheme is not None:
            result['LifecyclePreStopHandlerHttpGetScheme'] = self.lifecycle_pre_stop_handler_http_get_scheme
        if self.lifecycle_pre_stop_handler_tcp_socket_host is not None:
            result['LifecyclePreStopHandlerTcpSocketHost'] = self.lifecycle_pre_stop_handler_tcp_socket_host
        if self.lifecycle_pre_stop_handler_tcp_socket_port is not None:
            result['LifecyclePreStopHandlerTcpSocketPort'] = self.lifecycle_pre_stop_handler_tcp_socket_port
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        result['Ports'] = []
        if self.ports is not None:
            for k in self.ports:
                result['Ports'].append(k.to_map() if k else None)
        if self.stdin is not None:
            result['Stdin'] = self.stdin
        if self.stdin_once is not None:
            result['StdinOnce'] = self.stdin_once
        if self.tty is not None:
            result['Tty'] = self.tty
        result['VolumeMounts'] = []
        if self.volume_mounts is not None:
            for k in self.volume_mounts:
                result['VolumeMounts'].append(k.to_map() if k else None)
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LivenessProbe') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersLivenessProbe()
            self.liveness_probe = temp_model.from_map(m['LivenessProbe'])
        if m.get('ReadinessProbe') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersReadinessProbe()
            self.readiness_probe = temp_model.from_map(m['ReadinessProbe'])
        if m.get('SecurityContext') is not None:
            temp_model = CreateEciScalingConfigurationRequestContainersSecurityContext()
            self.security_context = temp_model.from_map(m['SecurityContext'])
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        self.environment_vars = []
        if m.get('EnvironmentVars') is not None:
            for k in m.get('EnvironmentVars'):
                temp_model = CreateEciScalingConfigurationRequestContainersEnvironmentVars()
                self.environment_vars.append(temp_model.from_map(k))
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        if m.get('LifecyclePostStartHandlerExecs') is not None:
            self.lifecycle_post_start_handler_execs = m.get('LifecyclePostStartHandlerExecs')
        if m.get('LifecyclePostStartHandlerHttpGetHost') is not None:
            self.lifecycle_post_start_handler_http_get_host = m.get('LifecyclePostStartHandlerHttpGetHost')
        if m.get('LifecyclePostStartHandlerHttpGetPath') is not None:
            self.lifecycle_post_start_handler_http_get_path = m.get('LifecyclePostStartHandlerHttpGetPath')
        if m.get('LifecyclePostStartHandlerHttpGetPort') is not None:
            self.lifecycle_post_start_handler_http_get_port = m.get('LifecyclePostStartHandlerHttpGetPort')
        if m.get('LifecyclePostStartHandlerHttpGetScheme') is not None:
            self.lifecycle_post_start_handler_http_get_scheme = m.get('LifecyclePostStartHandlerHttpGetScheme')
        if m.get('LifecyclePostStartHandlerTcpSocketHost') is not None:
            self.lifecycle_post_start_handler_tcp_socket_host = m.get('LifecyclePostStartHandlerTcpSocketHost')
        if m.get('LifecyclePostStartHandlerTcpSocketPort') is not None:
            self.lifecycle_post_start_handler_tcp_socket_port = m.get('LifecyclePostStartHandlerTcpSocketPort')
        if m.get('LifecyclePreStopHandlerExecs') is not None:
            self.lifecycle_pre_stop_handler_execs = m.get('LifecyclePreStopHandlerExecs')
        if m.get('LifecyclePreStopHandlerHttpGetHost') is not None:
            self.lifecycle_pre_stop_handler_http_get_host = m.get('LifecyclePreStopHandlerHttpGetHost')
        if m.get('LifecyclePreStopHandlerHttpGetPath') is not None:
            self.lifecycle_pre_stop_handler_http_get_path = m.get('LifecyclePreStopHandlerHttpGetPath')
        if m.get('LifecyclePreStopHandlerHttpGetPort') is not None:
            self.lifecycle_pre_stop_handler_http_get_port = m.get('LifecyclePreStopHandlerHttpGetPort')
        if m.get('LifecyclePreStopHandlerHttpGetScheme') is not None:
            self.lifecycle_pre_stop_handler_http_get_scheme = m.get('LifecyclePreStopHandlerHttpGetScheme')
        if m.get('LifecyclePreStopHandlerTcpSocketHost') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_host = m.get('LifecyclePreStopHandlerTcpSocketHost')
        if m.get('LifecyclePreStopHandlerTcpSocketPort') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_port = m.get('LifecyclePreStopHandlerTcpSocketPort')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        self.ports = []
        if m.get('Ports') is not None:
            for k in m.get('Ports'):
                temp_model = CreateEciScalingConfigurationRequestContainersPorts()
                self.ports.append(temp_model.from_map(k))
        if m.get('Stdin') is not None:
            self.stdin = m.get('Stdin')
        if m.get('StdinOnce') is not None:
            self.stdin_once = m.get('StdinOnce')
        if m.get('Tty') is not None:
            self.tty = m.get('Tty')
        self.volume_mounts = []
        if m.get('VolumeMounts') is not None:
            for k in m.get('VolumeMounts'):
                temp_model = CreateEciScalingConfigurationRequestContainersVolumeMounts()
                self.volume_mounts.append(temp_model.from_map(k))
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class CreateEciScalingConfigurationRequestDnsConfigOptions(TeaModel):
    def __init__(self, name=None, value=None):
        # The variable name of the option.
        self.name = name  # type: str
        # The variable value of the option.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestDnsConfigOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateEciScalingConfigurationRequestHostAliases(TeaModel):
    def __init__(self, hostnames=None, ip=None):
        # The hostname that you want to add.
        self.hostnames = hostnames  # type: list[str]
        # The IP address that you want to add.
        self.ip = ip  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestHostAliases, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.hostnames is not None:
            result['Hostnames'] = self.hostnames
        if self.ip is not None:
            result['Ip'] = self.ip
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Hostnames') is not None:
            self.hostnames = m.get('Hostnames')
        if m.get('Ip') is not None:
            self.ip = m.get('Ip')
        return self


class CreateEciScalingConfigurationRequestImageRegistryCredentials(TeaModel):
    def __init__(self, password=None, server=None, user_name=None):
        # The password that is used to access the image repository.
        self.password = password  # type: str
        # The domain name of the image repository.
        self.server = server  # type: str
        # The username that is used to access the image repository.
        self.user_name = user_name  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestImageRegistryCredentials, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.password is not None:
            result['Password'] = self.password
        if self.server is not None:
            result['Server'] = self.server
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('Server') is not None:
            self.server = m.get('Server')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class CreateEciScalingConfigurationRequestInitContainersSecurityContextCapability(TeaModel):
    def __init__(self, adds=None):
        self.adds = adds  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestInitContainersSecurityContextCapability, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.adds is not None:
            result['Adds'] = self.adds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Adds') is not None:
            self.adds = m.get('Adds')
        return self


class CreateEciScalingConfigurationRequestInitContainersSecurityContext(TeaModel):
    def __init__(self, capability=None, read_only_root_filesystem=None, run_as_user=None):
        self.capability = capability  # type: CreateEciScalingConfigurationRequestInitContainersSecurityContextCapability
        self.read_only_root_filesystem = read_only_root_filesystem  # type: bool
        self.run_as_user = run_as_user  # type: long

    def validate(self):
        if self.capability:
            self.capability.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestInitContainersSecurityContext, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capability is not None:
            result['Capability'] = self.capability.to_map()
        if self.read_only_root_filesystem is not None:
            result['ReadOnlyRootFilesystem'] = self.read_only_root_filesystem
        if self.run_as_user is not None:
            result['RunAsUser'] = self.run_as_user
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Capability') is not None:
            temp_model = CreateEciScalingConfigurationRequestInitContainersSecurityContextCapability()
            self.capability = temp_model.from_map(m['Capability'])
        if m.get('ReadOnlyRootFilesystem') is not None:
            self.read_only_root_filesystem = m.get('ReadOnlyRootFilesystem')
        if m.get('RunAsUser') is not None:
            self.run_as_user = m.get('RunAsUser')
        return self


class CreateEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars(TeaModel):
    def __init__(self, field_ref_field_path=None, key=None, value=None):
        # > This parameter is unavailable.
        self.field_ref_field_path = field_ref_field_path  # type: str
        # The key of the environment variable. Specify the key in the `[0-9a-zA-Z]` format. The key must be 1 to 128 characters in length. The key can contain underscores (\_) and cannot start with a digit.
        self.key = key  # type: str
        # The value of the environment variable. The value must be 0 to 256 characters in length.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref_field_path is not None:
            result['FieldRefFieldPath'] = self.field_ref_field_path
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRefFieldPath') is not None:
            self.field_ref_field_path = m.get('FieldRefFieldPath')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateEciScalingConfigurationRequestInitContainersInitContainerPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        # The port number. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The type of the protocol. Valid values:
        # 
        # *   TCP
        # *   UDP
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestInitContainersInitContainerPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class CreateEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        # The path to which the volume is mounted. Data under this path is overwritten by the data on the volume.
        self.mount_path = mount_path  # type: str
        # The mount propagation settings of the volume . Mount propagation allows volumes that are mounted on one container to be shared with other containers in the same pod, or even with other pods on the same node. Valid values:
        # 
        # *   None: The volume mount does not receive subsequent mounts that are mounted to this volume or its subdirectories.
        # *   HostToCotainer: The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories.
        # *   Bidirectional: This value is similar to HostToCotainer. The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories. In addition, all volume mounts that are created by the container are propagated back to the instance and to all containers of all pods that use the same volume.
        self.mount_propagation = mount_propagation  # type: str
        # The name of the volume.
        self.name = name  # type: str
        # Specifies whether the mount path is read-only.
        # 
        # Default value: false.
        self.read_only = read_only  # type: bool
        # The subdirectory of the volume. The elastic container instance can mount different directories of the same volume to different subdirectories of containers.
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class CreateEciScalingConfigurationRequestInitContainers(TeaModel):
    def __init__(self, security_context=None, args=None, commands=None, cpu=None, gpu=None, image=None,
                 image_pull_policy=None, init_container_environment_vars=None, init_container_ports=None,
                 init_container_volume_mounts=None, memory=None, name=None, working_dir=None):
        self.security_context = security_context  # type: CreateEciScalingConfigurationRequestInitContainersSecurityContext
        # The arguments that correspond to the startup commands of the container. You can specify up to 10 arguments.
        self.args = args  # type: list[str]
        # The list of commands that you want to run to start the container.
        self.commands = commands  # type: list[str]
        # The number of vCPUs that you want to allocate to the container.
        self.cpu = cpu  # type: float
        # The number of GPUs that you want to allocate to the container.
        self.gpu = gpu  # type: int
        # The container image.
        self.image = image  # type: str
        # The image pulling policy.
        self.image_pull_policy = image_pull_policy  # type: str
        # The environment variables of the init container.
        self.init_container_environment_vars = init_container_environment_vars  # type: list[CreateEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars]
        # The ports of the init container.
        self.init_container_ports = init_container_ports  # type: list[CreateEciScalingConfigurationRequestInitContainersInitContainerPorts]
        # Information about the volume mounts of the init container.
        self.init_container_volume_mounts = init_container_volume_mounts  # type: list[CreateEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts]
        # The size of the memory. Unit: GiB.
        self.memory = memory  # type: float
        # The name of the container.
        self.name = name  # type: str
        # The working directory.
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.security_context:
            self.security_context.validate()
        if self.init_container_environment_vars:
            for k in self.init_container_environment_vars:
                if k:
                    k.validate()
        if self.init_container_ports:
            for k in self.init_container_ports:
                if k:
                    k.validate()
        if self.init_container_volume_mounts:
            for k in self.init_container_volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestInitContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.security_context is not None:
            result['SecurityContext'] = self.security_context.to_map()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        result['InitContainerEnvironmentVars'] = []
        if self.init_container_environment_vars is not None:
            for k in self.init_container_environment_vars:
                result['InitContainerEnvironmentVars'].append(k.to_map() if k else None)
        result['InitContainerPorts'] = []
        if self.init_container_ports is not None:
            for k in self.init_container_ports:
                result['InitContainerPorts'].append(k.to_map() if k else None)
        result['InitContainerVolumeMounts'] = []
        if self.init_container_volume_mounts is not None:
            for k in self.init_container_volume_mounts:
                result['InitContainerVolumeMounts'].append(k.to_map() if k else None)
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('SecurityContext') is not None:
            temp_model = CreateEciScalingConfigurationRequestInitContainersSecurityContext()
            self.security_context = temp_model.from_map(m['SecurityContext'])
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        self.init_container_environment_vars = []
        if m.get('InitContainerEnvironmentVars') is not None:
            for k in m.get('InitContainerEnvironmentVars'):
                temp_model = CreateEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars()
                self.init_container_environment_vars.append(temp_model.from_map(k))
        self.init_container_ports = []
        if m.get('InitContainerPorts') is not None:
            for k in m.get('InitContainerPorts'):
                temp_model = CreateEciScalingConfigurationRequestInitContainersInitContainerPorts()
                self.init_container_ports.append(temp_model.from_map(k))
        self.init_container_volume_mounts = []
        if m.get('InitContainerVolumeMounts') is not None:
            for k in m.get('InitContainerVolumeMounts'):
                temp_model = CreateEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts()
                self.init_container_volume_mounts.append(temp_model.from_map(k))
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class CreateEciScalingConfigurationRequestSecurityContextSysctls(TeaModel):
    def __init__(self, name=None, value=None):
        # The variable name of the security context in which the elastic container instance runs.
        self.name = name  # type: str
        # The variable value of the security context in which the elastic container instance runs.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestSecurityContextSysctls, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateEciScalingConfigurationRequestTags(TeaModel):
    def __init__(self, key=None, value=None):
        # The tag key of the elastic container instance. You can specify 1 to 20 tags.
        # 
        # You cannot specify an empty string as a tag key. The tag key can be up to 128 characters in length and cannot start with `acs:` or `aliyun`. It cannot contain `http://` or `https://`.
        self.key = key  # type: str
        # The tag value of the elastic container instance. You can specify 1 to 20 tags.
        # 
        # You can specify an empty string as a tag value. The tag value can be up to 128 characters in length and cannot start with `acs:`. It cannot contain `http://` or `https://`.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateEciScalingConfigurationRequestVolumesDiskVolume(TeaModel):
    def __init__(self, disk_id=None, disk_size=None, fs_type=None):
        self.disk_id = disk_id  # type: str
        self.disk_size = disk_size  # type: int
        self.fs_type = fs_type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumesDiskVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disk_id is not None:
            result['DiskId'] = self.disk_id
        if self.disk_size is not None:
            result['DiskSize'] = self.disk_size
        if self.fs_type is not None:
            result['FsType'] = self.fs_type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DiskId') is not None:
            self.disk_id = m.get('DiskId')
        if m.get('DiskSize') is not None:
            self.disk_size = m.get('DiskSize')
        if m.get('FsType') is not None:
            self.fs_type = m.get('FsType')
        return self


class CreateEciScalingConfigurationRequestVolumesEmptyDirVolume(TeaModel):
    def __init__(self, medium=None, size_limit=None):
        self.medium = medium  # type: str
        self.size_limit = size_limit  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumesEmptyDirVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.medium is not None:
            result['Medium'] = self.medium
        if self.size_limit is not None:
            result['SizeLimit'] = self.size_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Medium') is not None:
            self.medium = m.get('Medium')
        if m.get('SizeLimit') is not None:
            self.size_limit = m.get('SizeLimit')
        return self


class CreateEciScalingConfigurationRequestVolumesFlexVolume(TeaModel):
    def __init__(self, driver=None, fs_type=None, options=None):
        self.driver = driver  # type: str
        self.fs_type = fs_type  # type: str
        self.options = options  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumesFlexVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.driver is not None:
            result['Driver'] = self.driver
        if self.fs_type is not None:
            result['FsType'] = self.fs_type
        if self.options is not None:
            result['Options'] = self.options
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Driver') is not None:
            self.driver = m.get('Driver')
        if m.get('FsType') is not None:
            self.fs_type = m.get('FsType')
        if m.get('Options') is not None:
            self.options = m.get('Options')
        return self


class CreateEciScalingConfigurationRequestVolumesHostPathVolume(TeaModel):
    def __init__(self, path=None, type=None):
        self.path = path  # type: str
        self.type = type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumesHostPathVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class CreateEciScalingConfigurationRequestVolumesNFSVolume(TeaModel):
    def __init__(self, path=None, read_only=None, server=None):
        self.path = path  # type: str
        self.read_only = read_only  # type: bool
        self.server = server  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumesNFSVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.server is not None:
            result['Server'] = self.server
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('Server') is not None:
            self.server = m.get('Server')
        return self


class CreateEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPaths(TeaModel):
    def __init__(self, content=None, mode=None, path=None):
        # The content of the configuration file, which can be up to 32 KB in size.
        self.content = content  # type: str
        # The permissions on ConfigFileVolume.
        self.mode = mode  # type: int
        # The name of the environment variable. The name must be 1 to 128 characters in length. Specify the name in the `[0-9a-zA-Z]` format. The name can contain underscores and cannot start with a digit.
        self.path = path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPaths, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.path is not None:
            result['Path'] = self.path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('Path') is not None:
            self.path = m.get('Path')
        return self


class CreateEciScalingConfigurationRequestVolumes(TeaModel):
    def __init__(self, disk_volume=None, empty_dir_volume=None, flex_volume=None, host_path_volume=None,
                 nfsvolume=None, config_file_volume_config_file_to_paths=None, config_file_volume_default_mode=None,
                 name=None, type=None):
        self.disk_volume = disk_volume  # type: CreateEciScalingConfigurationRequestVolumesDiskVolume
        self.empty_dir_volume = empty_dir_volume  # type: CreateEciScalingConfigurationRequestVolumesEmptyDirVolume
        self.flex_volume = flex_volume  # type: CreateEciScalingConfigurationRequestVolumesFlexVolume
        self.host_path_volume = host_path_volume  # type: CreateEciScalingConfigurationRequestVolumesHostPathVolume
        self.nfsvolume = nfsvolume  # type: CreateEciScalingConfigurationRequestVolumesNFSVolume
        # The paths to the configuration files.
        self.config_file_volume_config_file_to_paths = config_file_volume_config_file_to_paths  # type: list[CreateEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPaths]
        # The default permissions on the ConfigFile volume.
        self.config_file_volume_default_mode = config_file_volume_default_mode  # type: int
        # The name of the volume.
        self.name = name  # type: str
        # The type of the Host file or path. Examples: File, Directory, and Socket.
        self.type = type  # type: str

    def validate(self):
        if self.disk_volume:
            self.disk_volume.validate()
        if self.empty_dir_volume:
            self.empty_dir_volume.validate()
        if self.flex_volume:
            self.flex_volume.validate()
        if self.host_path_volume:
            self.host_path_volume.validate()
        if self.nfsvolume:
            self.nfsvolume.validate()
        if self.config_file_volume_config_file_to_paths:
            for k in self.config_file_volume_config_file_to_paths:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequestVolumes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disk_volume is not None:
            result['DiskVolume'] = self.disk_volume.to_map()
        if self.empty_dir_volume is not None:
            result['EmptyDirVolume'] = self.empty_dir_volume.to_map()
        if self.flex_volume is not None:
            result['FlexVolume'] = self.flex_volume.to_map()
        if self.host_path_volume is not None:
            result['HostPathVolume'] = self.host_path_volume.to_map()
        if self.nfsvolume is not None:
            result['NFSVolume'] = self.nfsvolume.to_map()
        result['ConfigFileVolumeConfigFileToPaths'] = []
        if self.config_file_volume_config_file_to_paths is not None:
            for k in self.config_file_volume_config_file_to_paths:
                result['ConfigFileVolumeConfigFileToPaths'].append(k.to_map() if k else None)
        if self.config_file_volume_default_mode is not None:
            result['ConfigFileVolumeDefaultMode'] = self.config_file_volume_default_mode
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DiskVolume') is not None:
            temp_model = CreateEciScalingConfigurationRequestVolumesDiskVolume()
            self.disk_volume = temp_model.from_map(m['DiskVolume'])
        if m.get('EmptyDirVolume') is not None:
            temp_model = CreateEciScalingConfigurationRequestVolumesEmptyDirVolume()
            self.empty_dir_volume = temp_model.from_map(m['EmptyDirVolume'])
        if m.get('FlexVolume') is not None:
            temp_model = CreateEciScalingConfigurationRequestVolumesFlexVolume()
            self.flex_volume = temp_model.from_map(m['FlexVolume'])
        if m.get('HostPathVolume') is not None:
            temp_model = CreateEciScalingConfigurationRequestVolumesHostPathVolume()
            self.host_path_volume = temp_model.from_map(m['HostPathVolume'])
        if m.get('NFSVolume') is not None:
            temp_model = CreateEciScalingConfigurationRequestVolumesNFSVolume()
            self.nfsvolume = temp_model.from_map(m['NFSVolume'])
        self.config_file_volume_config_file_to_paths = []
        if m.get('ConfigFileVolumeConfigFileToPaths') is not None:
            for k in m.get('ConfigFileVolumeConfigFileToPaths'):
                temp_model = CreateEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPaths()
                self.config_file_volume_config_file_to_paths.append(temp_model.from_map(k))
        if m.get('ConfigFileVolumeDefaultMode') is not None:
            self.config_file_volume_default_mode = m.get('ConfigFileVolumeDefaultMode')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class CreateEciScalingConfigurationRequest(TeaModel):
    def __init__(self, acr_registry_infos=None, active_deadline_seconds=None, auto_create_eip=None,
                 auto_match_image_cache=None, container_group_name=None, containers=None, cost_optimization=None, cpu=None,
                 cpu_options_core=None, cpu_options_threads_per_core=None, data_cache_bucket=None,
                 data_cache_bursting_enabled=None, data_cache_pl=None, data_cache_provisioned_iops=None, description=None,
                 dns_config_name_servers=None, dns_config_options=None, dns_config_searchs=None, dns_policy=None, egress_bandwidth=None,
                 eip_bandwidth=None, enable_sls=None, ephemeral_storage=None, host_aliases=None, host_name=None,
                 image_registry_credentials=None, image_snapshot_id=None, ingress_bandwidth=None, init_containers=None,
                 instance_family_level=None, instance_types=None, ipv_6address_count=None, load_balancer_weight=None, memory=None,
                 ntp_servers=None, owner_id=None, ram_role_name=None, resource_group_id=None, resource_owner_account=None,
                 restart_policy=None, scaling_configuration_name=None, scaling_group_id=None, security_context_sysctls=None,
                 security_group_id=None, spot_price_limit=None, spot_strategy=None, tags=None, termination_grace_period_seconds=None,
                 volumes=None):
        # Information about the Container Registry Enterprise Edition instance.
        self.acr_registry_infos = acr_registry_infos  # type: list[CreateEciScalingConfigurationRequestAcrRegistryInfos]
        # The validity period. Unit: seconds.
        self.active_deadline_seconds = active_deadline_seconds  # type: long
        # Specifies whether to automatically create an elastic IP address (EIP) and bind the EIP to the elastic container instance.
        self.auto_create_eip = auto_create_eip  # type: bool
        # Specifies whether to automatically match the image cache. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.auto_match_image_cache = auto_match_image_cache  # type: bool
        # The name of the elastic container instance.
        self.container_group_name = container_group_name  # type: str
        # The containers in the elastic container instance.
        self.containers = containers  # type: list[CreateEciScalingConfigurationRequestContainers]
        # Specifies whether to enable the cost optimization feature. Valid values:
        # 
        # *   true
        # *   false
        self.cost_optimization = cost_optimization  # type: bool
        # The number of vCPUs of the elastic container instance.
        self.cpu = cpu  # type: float
        # Number of physical CPU cores This parameter is not available for all instance types. For more information, see [Specify custom CPU options](~~197781~~).
        self.cpu_options_core = cpu_options_core  # type: int
        # The number of threads per core. This parameter is not available for all instance types. A value of 1 indicates that Hyper-Threading is disabled. For more information, see [Specify custom CPU options](~~197781~~).
        self.cpu_options_threads_per_core = cpu_options_threads_per_core  # type: int
        self.data_cache_bucket = data_cache_bucket  # type: str
        self.data_cache_bursting_enabled = data_cache_bursting_enabled  # type: bool
        self.data_cache_pl = data_cache_pl  # type: str
        self.data_cache_provisioned_iops = data_cache_provisioned_iops  # type: int
        # > This parameter is unavailable.
        self.description = description  # type: str
        # The IP addresses of the DNS servers.
        self.dns_config_name_servers = dns_config_name_servers  # type: list[str]
        # The options. Each option is in the name-value pair format. The value in the name-value pair is optional.
        self.dns_config_options = dns_config_options  # type: list[CreateEciScalingConfigurationRequestDnsConfigOptions]
        # The DNS lookup domains.
        self.dns_config_searchs = dns_config_searchs  # type: list[str]
        # The Domain Name System (DNS) policy. Valid values:
        # 
        # *   None: uses the DNS that is set for the DnsConfig field.
        # *   Default: use the DNS that is set for the runtime environment.
        self.dns_policy = dns_policy  # type: str
        # The maximum outbound bandwidth. Unit: bytes.
        self.egress_bandwidth = egress_bandwidth  # type: long
        # The bandwidth of the EIP. Default value: 5 Mbit/s.
        self.eip_bandwidth = eip_bandwidth  # type: int
        # > This parameter is unavailable.
        self.enable_sls = enable_sls  # type: bool
        # The size of the temporary storage space. By default, an ESSD of the PL1 type is used. Unit: GiB.
        self.ephemeral_storage = ephemeral_storage  # type: int
        # The hostnames and IP addresses of a container that you want to add to the hosts file of the elastic container instance.
        self.host_aliases = host_aliases  # type: list[CreateEciScalingConfigurationRequestHostAliases]
        # The name of the elastic container instance.
        self.host_name = host_name  # type: str
        # Information about the image repository.
        self.image_registry_credentials = image_registry_credentials  # type: list[CreateEciScalingConfigurationRequestImageRegistryCredentials]
        # The ID of the image cache.
        self.image_snapshot_id = image_snapshot_id  # type: str
        # The maximum inbound bandwidth. Unit: bit/s.
        self.ingress_bandwidth = ingress_bandwidth  # type: long
        # The init containers.
        self.init_containers = init_containers  # type: list[CreateEciScalingConfigurationRequestInitContainers]
        # The level of the instance type, which is used to filter the instance types that meet the specified criteria. This parameter takes effect only if you set the `CostOptimization` parameter to true. Valid values:
        # 
        # *   EntryLevel: shared instance type. Instances of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instances of this level are suitable for business scenarios in which the CPU utilization is low. For more information, see [Shared instance families](~~108489~~).
        # *   EnterpriseLevel: Instances of this level provide stable performance and dedicated resources, and are suitable for business scenarios that require high stability. For more information, see [Instance family](~~25378~~).
        # *   CreditEntryLevel: This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instances of this level are suitable for scenarios in which the CPU utilization is low but may fluctuate in specific cases. For more information, see the [Overview](~~59977~~) topic of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        self.instance_types = instance_types  # type: list[str]
        # The number of IPv6 addresses.
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The weight of the elastic container instance as a backend server. Valid values: 1 to 100.
        # 
        # Default value: 50.
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size of the elastic container instance. Unit: GiB.
        self.memory = memory  # type: float
        # The domain name of the Network Time Protocol (NTP) server.
        self.ntp_servers = ntp_servers  # type: list[str]
        self.owner_id = owner_id  # type: long
        # The name of the RAM role for the elastic container instance. You can use an instance RAM role to access both elastic container instances and Elastic Compute Service (ECS) instances. For more information, see [Use an instance RAM role by calling API operations](~~61178~~).
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The restart policy of the elastic container instance. Valid values:
        # 
        # *   Always: always restarts the elastic container instance.
        # *   Never: never restarts the elastic container instance.
        # *   OnFailure: restarts the elastic container instance upon failures.
        # 
        # Default value: Always.
        self.restart_policy = restart_policy  # type: str
        # The name of the scaling configuration. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # The name of the scaling configuration must be unique within a scaling group in a region. If you do not specify this parameter, the value of the ScalingConfigurationId parameter is used.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The ID of the scaling group in which you want to create the scaling configuration.
        self.scaling_group_id = scaling_group_id  # type: str
        # The system information of the security context in which the elastic container instance runs.
        self.security_context_sysctls = security_context_sysctls  # type: list[CreateEciScalingConfigurationRequestSecurityContextSysctls]
        # The ID of the security group with which you want to associate the elastic container instance. Elastic container instances that are associated with the same security group can access each other.
        # 
        # If you do not specify a security group, the system uses the default security group in the region that you selected. Make sure that the inbound rules of the security group contain the protocols and the port numbers of the containers that you want to expose. If you do not have a default security group in the region, the system creates a default security group, and then adds the declared container protocols and port numbers to the inbound rules of the security group.
        self.security_group_id = security_group_id  # type: str
        # The maximum hourly price of the preemptible elastic container instance. The value can be accurate to three decimal places.
        # 
        # If you set the SpotStrategy parameter to SpotWithPriceLimit, you must also specify the SpotPriceLimit parameter.
        self.spot_price_limit = spot_price_limit  # type: float
        # The bidding policy for the elastic container instance. Valid values:
        # 
        # *   NoSpot: The instance is a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance with a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is a preemptible instance for which the market price at the time of purchase is used as the bid price.
        # 
        # Default value: NoSpot.
        self.spot_strategy = spot_strategy  # type: str
        # The tags of the elastic container instance. The tags must be specified in the key-value pair format. You can specify up to 20 tags. When you specify tag keys and tag values, take note of the following items:
        # 
        # *   A tag key can be up to 64 characters in length. The key cannot start with acs: or aliyun and cannot contain `http://` or `https://`. You cannot specify an empty string as a tag key.
        # *   A tag value can be up to 128 characters in length. The value cannot start with acs: or aliyun and cannot contain `http://` or `https://`. You can specify an empty string as a tag value.
        self.tags = tags  # type: list[CreateEciScalingConfigurationRequestTags]
        # The buffer time in which the program handles operations before the program is stopped. Unit: seconds.
        self.termination_grace_period_seconds = termination_grace_period_seconds  # type: long
        # Information about the volumes.
        self.volumes = volumes  # type: list[CreateEciScalingConfigurationRequestVolumes]

    def validate(self):
        if self.acr_registry_infos:
            for k in self.acr_registry_infos:
                if k:
                    k.validate()
        if self.containers:
            for k in self.containers:
                if k:
                    k.validate()
        if self.dns_config_options:
            for k in self.dns_config_options:
                if k:
                    k.validate()
        if self.host_aliases:
            for k in self.host_aliases:
                if k:
                    k.validate()
        if self.image_registry_credentials:
            for k in self.image_registry_credentials:
                if k:
                    k.validate()
        if self.init_containers:
            for k in self.init_containers:
                if k:
                    k.validate()
        if self.security_context_sysctls:
            for k in self.security_context_sysctls:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.volumes:
            for k in self.volumes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcrRegistryInfos'] = []
        if self.acr_registry_infos is not None:
            for k in self.acr_registry_infos:
                result['AcrRegistryInfos'].append(k.to_map() if k else None)
        if self.active_deadline_seconds is not None:
            result['ActiveDeadlineSeconds'] = self.active_deadline_seconds
        if self.auto_create_eip is not None:
            result['AutoCreateEip'] = self.auto_create_eip
        if self.auto_match_image_cache is not None:
            result['AutoMatchImageCache'] = self.auto_match_image_cache
        if self.container_group_name is not None:
            result['ContainerGroupName'] = self.container_group_name
        result['Containers'] = []
        if self.containers is not None:
            for k in self.containers:
                result['Containers'].append(k.to_map() if k else None)
        if self.cost_optimization is not None:
            result['CostOptimization'] = self.cost_optimization
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.cpu_options_core is not None:
            result['CpuOptionsCore'] = self.cpu_options_core
        if self.cpu_options_threads_per_core is not None:
            result['CpuOptionsThreadsPerCore'] = self.cpu_options_threads_per_core
        if self.data_cache_bucket is not None:
            result['DataCacheBucket'] = self.data_cache_bucket
        if self.data_cache_bursting_enabled is not None:
            result['DataCacheBurstingEnabled'] = self.data_cache_bursting_enabled
        if self.data_cache_pl is not None:
            result['DataCachePL'] = self.data_cache_pl
        if self.data_cache_provisioned_iops is not None:
            result['DataCacheProvisionedIops'] = self.data_cache_provisioned_iops
        if self.description is not None:
            result['Description'] = self.description
        if self.dns_config_name_servers is not None:
            result['DnsConfigNameServers'] = self.dns_config_name_servers
        result['DnsConfigOptions'] = []
        if self.dns_config_options is not None:
            for k in self.dns_config_options:
                result['DnsConfigOptions'].append(k.to_map() if k else None)
        if self.dns_config_searchs is not None:
            result['DnsConfigSearchs'] = self.dns_config_searchs
        if self.dns_policy is not None:
            result['DnsPolicy'] = self.dns_policy
        if self.egress_bandwidth is not None:
            result['EgressBandwidth'] = self.egress_bandwidth
        if self.eip_bandwidth is not None:
            result['EipBandwidth'] = self.eip_bandwidth
        if self.enable_sls is not None:
            result['EnableSls'] = self.enable_sls
        if self.ephemeral_storage is not None:
            result['EphemeralStorage'] = self.ephemeral_storage
        result['HostAliases'] = []
        if self.host_aliases is not None:
            for k in self.host_aliases:
                result['HostAliases'].append(k.to_map() if k else None)
        if self.host_name is not None:
            result['HostName'] = self.host_name
        result['ImageRegistryCredentials'] = []
        if self.image_registry_credentials is not None:
            for k in self.image_registry_credentials:
                result['ImageRegistryCredentials'].append(k.to_map() if k else None)
        if self.image_snapshot_id is not None:
            result['ImageSnapshotId'] = self.image_snapshot_id
        if self.ingress_bandwidth is not None:
            result['IngressBandwidth'] = self.ingress_bandwidth
        result['InitContainers'] = []
        if self.init_containers is not None:
            for k in self.init_containers:
                result['InitContainers'].append(k.to_map() if k else None)
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.ntp_servers is not None:
            result['NtpServers'] = self.ntp_servers
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.restart_policy is not None:
            result['RestartPolicy'] = self.restart_policy
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['SecurityContextSysctls'] = []
        if self.security_context_sysctls is not None:
            for k in self.security_context_sysctls:
                result['SecurityContextSysctls'].append(k.to_map() if k else None)
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.termination_grace_period_seconds is not None:
            result['TerminationGracePeriodSeconds'] = self.termination_grace_period_seconds
        result['Volumes'] = []
        if self.volumes is not None:
            for k in self.volumes:
                result['Volumes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.acr_registry_infos = []
        if m.get('AcrRegistryInfos') is not None:
            for k in m.get('AcrRegistryInfos'):
                temp_model = CreateEciScalingConfigurationRequestAcrRegistryInfos()
                self.acr_registry_infos.append(temp_model.from_map(k))
        if m.get('ActiveDeadlineSeconds') is not None:
            self.active_deadline_seconds = m.get('ActiveDeadlineSeconds')
        if m.get('AutoCreateEip') is not None:
            self.auto_create_eip = m.get('AutoCreateEip')
        if m.get('AutoMatchImageCache') is not None:
            self.auto_match_image_cache = m.get('AutoMatchImageCache')
        if m.get('ContainerGroupName') is not None:
            self.container_group_name = m.get('ContainerGroupName')
        self.containers = []
        if m.get('Containers') is not None:
            for k in m.get('Containers'):
                temp_model = CreateEciScalingConfigurationRequestContainers()
                self.containers.append(temp_model.from_map(k))
        if m.get('CostOptimization') is not None:
            self.cost_optimization = m.get('CostOptimization')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CpuOptionsCore') is not None:
            self.cpu_options_core = m.get('CpuOptionsCore')
        if m.get('CpuOptionsThreadsPerCore') is not None:
            self.cpu_options_threads_per_core = m.get('CpuOptionsThreadsPerCore')
        if m.get('DataCacheBucket') is not None:
            self.data_cache_bucket = m.get('DataCacheBucket')
        if m.get('DataCacheBurstingEnabled') is not None:
            self.data_cache_bursting_enabled = m.get('DataCacheBurstingEnabled')
        if m.get('DataCachePL') is not None:
            self.data_cache_pl = m.get('DataCachePL')
        if m.get('DataCacheProvisionedIops') is not None:
            self.data_cache_provisioned_iops = m.get('DataCacheProvisionedIops')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DnsConfigNameServers') is not None:
            self.dns_config_name_servers = m.get('DnsConfigNameServers')
        self.dns_config_options = []
        if m.get('DnsConfigOptions') is not None:
            for k in m.get('DnsConfigOptions'):
                temp_model = CreateEciScalingConfigurationRequestDnsConfigOptions()
                self.dns_config_options.append(temp_model.from_map(k))
        if m.get('DnsConfigSearchs') is not None:
            self.dns_config_searchs = m.get('DnsConfigSearchs')
        if m.get('DnsPolicy') is not None:
            self.dns_policy = m.get('DnsPolicy')
        if m.get('EgressBandwidth') is not None:
            self.egress_bandwidth = m.get('EgressBandwidth')
        if m.get('EipBandwidth') is not None:
            self.eip_bandwidth = m.get('EipBandwidth')
        if m.get('EnableSls') is not None:
            self.enable_sls = m.get('EnableSls')
        if m.get('EphemeralStorage') is not None:
            self.ephemeral_storage = m.get('EphemeralStorage')
        self.host_aliases = []
        if m.get('HostAliases') is not None:
            for k in m.get('HostAliases'):
                temp_model = CreateEciScalingConfigurationRequestHostAliases()
                self.host_aliases.append(temp_model.from_map(k))
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        self.image_registry_credentials = []
        if m.get('ImageRegistryCredentials') is not None:
            for k in m.get('ImageRegistryCredentials'):
                temp_model = CreateEciScalingConfigurationRequestImageRegistryCredentials()
                self.image_registry_credentials.append(temp_model.from_map(k))
        if m.get('ImageSnapshotId') is not None:
            self.image_snapshot_id = m.get('ImageSnapshotId')
        if m.get('IngressBandwidth') is not None:
            self.ingress_bandwidth = m.get('IngressBandwidth')
        self.init_containers = []
        if m.get('InitContainers') is not None:
            for k in m.get('InitContainers'):
                temp_model = CreateEciScalingConfigurationRequestInitContainers()
                self.init_containers.append(temp_model.from_map(k))
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('NtpServers') is not None:
            self.ntp_servers = m.get('NtpServers')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('RestartPolicy') is not None:
            self.restart_policy = m.get('RestartPolicy')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.security_context_sysctls = []
        if m.get('SecurityContextSysctls') is not None:
            for k in m.get('SecurityContextSysctls'):
                temp_model = CreateEciScalingConfigurationRequestSecurityContextSysctls()
                self.security_context_sysctls.append(temp_model.from_map(k))
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = CreateEciScalingConfigurationRequestTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('TerminationGracePeriodSeconds') is not None:
            self.termination_grace_period_seconds = m.get('TerminationGracePeriodSeconds')
        self.volumes = []
        if m.get('Volumes') is not None:
            for k in m.get('Volumes'):
                temp_model = CreateEciScalingConfigurationRequestVolumes()
                self.volumes.append(temp_model.from_map(k))
        return self


class CreateEciScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_configuration_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the elastic container instance.
        self.scaling_configuration_id = scaling_configuration_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateEciScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        return self


class CreateEciScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateEciScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateEciScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateEciScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateLifecycleHookRequest(TeaModel):
    def __init__(self, default_result=None, heartbeat_timeout=None, lifecycle_hook_name=None,
                 lifecycle_transition=None, notification_arn=None, notification_metadata=None, owner_account=None, owner_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The action that you want Auto Scaling to perform after the lifecycle hook times out. Valid values:
        # 
        # *   CONTINUE: Auto Scaling continues to respond to scale-in or scale-out requests.
        # *   ABANDON: Auto Scaling releases ECS instances that are created during scale-out activities or removes ECS instances from the scaling group during scale-in activities.
        # *   ROLLBACK: For scale-in activities, Auto Scaling rejects the requests to release ECS instances but rolls back ECS instances. For scale-out activities, the ROLLBACK setting has the same effect as the ABANDON setting.
        # 
        # If a scaling group has multiple lifecycle hooks in effect and you set the DefaultResult parameter for one of the lifecycle hooks to ABANDON or ROLLBACK, the following rule applies to scale-in activities: When the lifecycle hook whose DefaultResult parameter is set to ABANDON or ROLLBACK times out, other lifecycle hooks time out ahead of schedule. In other cases, Auto Scaling performs the action only after all lifecycle hooks time out. The action that Auto Scaling performs is specified by the DefaultResult parameter of the last lifecycle hook that times out.
        # 
        # Default value: CONTINUE.
        self.default_result = default_result  # type: str
        # The period of time before the lifecycle hook times out. When the lifecycle hook times out, Auto Scaling performs the action specified by the DefaultResult parameter. Valid values: 30 to 21600. Unit: seconds.
        # 
        # After you create a lifecycle hook, you can call the RecordLifecycleActionHeartbeat operation to extend the timeout period of the lifecycle hook. You can also call the CompleteLifecycleAction operation to end the timeout period ahead of schedule.
        # 
        # Default value: 600.
        self.heartbeat_timeout = heartbeat_timeout  # type: int
        # The name of the lifecycle hook. Each lifecycle hook name must be unique within a scaling group. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # If you do not specify this parameter, the value of the LifecycleHookId parameter is used.
        self.lifecycle_hook_name = lifecycle_hook_name  # type: str
        # The type of the scaling activity to which you want to apply the lifecycle hook. Valid values:
        # 
        # *   SCALE_OUT: scale-out activity.
        # *   SCALE_IN: scale-in activity.
        self.lifecycle_transition = lifecycle_transition  # type: str
        # The Alibaba Cloud Resource Name (ARN) of the notification method. If you do not specify this parameter, no notification is sent when the lifecycle hook takes effect. If you specify this parameter, the following rules apply:
        # 
        # *   If you use a Message Service (MNS) queue as the notification method, specify the value in the acs:mns:{region-id}:{account-id}:queue/{queuename} format.
        # *   If you use an MNS topic as the notification method, specify the value in the acs:mns:{region-id}:{account-id}:topic/{topicname} format.
        # *   If you use an OOS template as the notification method, specify the value in the acs:oos:{region-id}:{account-id}:template/{templatename} format.
        # 
        # The variables in the preceding formats have the following meanings:
        # 
        # *   region-id: the region ID of the scaling group.
        # *   account-id: the ID of the Alibaba Cloud account. The ID of a RAM user is not supported.
        # *   queuename: the name of the MNS queue.
        # *   topicname: the name of the MNS topic.
        # *   templatename: the name of the OOS template.
        self.notification_arn = notification_arn  # type: str
        # The notification metadata that is sent when the lifecycle hook takes effect. This helps you manage and categorize notifications in an efficient manner. If you specify this parameter, you must also specify the NotificationArn parameter. The value of this parameter cannot exceed 4,096 characters in length.
        # 
        # The fixed string that is included in a notification that Auto Scaling sends when the lifecycle hook takes effect. Auto Scaling sends the value of the NotificationMetadata parameter together with the notification. This helps you categorize your notifications. For example, your OOS template includes the following parameters: `{"dbInstanceId": "dds-bp17661e0135****", "modifyMode": "Append"}`, `dbInstanceId`, and `modifyMode`. Specific parameters that are defined in your OOS template have default values. When you specify the NotificationMetadata parameter, specify parameters that do not have default values. If you specify parameters that have default values, the default values are overwritten. The default values of the following parameters must be retained to obtain information about scaling activities that are in progress:
        # 
        # *   `regionId`: the region ID of the scaling activity that is in progress. Default value: ${regionId}.
        # *   `instanceIds`: the IDs of ECS instances that are scaled in the scaling activity. Default value: ${instanceIds}.
        # *   `lifecycleHookId`: the ID of the lifecycle hook. Default value: ${lifecycleHookId}.
        # *   `lifecycleActionToken`: the token of the lifecycle hook. You can use the token to end the timeout period of the lifecycle hook ahead of schedule. Default value: ${lifecycleActionToken}
        # *   `scalingGroupId`: the ID of the scaling group in which the scaling activity is executed. Default value: ${scalingGroupId}.
        # *   `lifecycleActionResult`: the action that Auto Scaling performs after the lifecycle hook times out. If the OOS template fails to be executed, the lifecycle hook times out ahead of schedule. If you set the DefalutResult parameter to ROLLBACK, the default value of this parameter is ROLLBACK. If you set the DefaultResult parameter to other values, the default value of this parameter is ABANDON.
        # 
        # > 
        # 
        # *   You can specify a value for the lifecycleActionResult parameter to overwrite the default value. Valid values: ABANDON, CONTINUE, ROLLBACK, and ${lifecycleActionResult}.
        # 
        # A value of ${lifecycleActionResult} specifies that the value of the lifecycleActionResult parameter is the same as the value of the DefaultResult parameter.
        # 
        # *   You can view the details of the OOS template that you specify in the [OOS](https://oos.console.aliyun.com/) console.
        self.notification_metadata = notification_metadata  # type: str
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateLifecycleHookRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.default_result is not None:
            result['DefaultResult'] = self.default_result
        if self.heartbeat_timeout is not None:
            result['HeartbeatTimeout'] = self.heartbeat_timeout
        if self.lifecycle_hook_name is not None:
            result['LifecycleHookName'] = self.lifecycle_hook_name
        if self.lifecycle_transition is not None:
            result['LifecycleTransition'] = self.lifecycle_transition
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_metadata is not None:
            result['NotificationMetadata'] = self.notification_metadata
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DefaultResult') is not None:
            self.default_result = m.get('DefaultResult')
        if m.get('HeartbeatTimeout') is not None:
            self.heartbeat_timeout = m.get('HeartbeatTimeout')
        if m.get('LifecycleHookName') is not None:
            self.lifecycle_hook_name = m.get('LifecycleHookName')
        if m.get('LifecycleTransition') is not None:
            self.lifecycle_transition = m.get('LifecycleTransition')
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationMetadata') is not None:
            self.notification_metadata = m.get('NotificationMetadata')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class CreateLifecycleHookResponseBody(TeaModel):
    def __init__(self, lifecycle_hook_id=None, request_id=None):
        # The ID of the lifecycle hook.
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateLifecycleHookResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.lifecycle_hook_id is not None:
            result['LifecycleHookId'] = self.lifecycle_hook_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('LifecycleHookId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateLifecycleHookResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateLifecycleHookResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateLifecycleHookResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateLifecycleHookResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateNotificationConfigurationRequest(TeaModel):
    def __init__(self, notification_arn=None, notification_types=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The Alibaba Cloud Resource Name (ARN) of the notification method. The following list describes the value formats of this parameter:
        # 
        # *   If you use CloudMonitor as the notification method, the value format of this parameter is acs:ess:{region-id}:{account-id}:cloudmonitor.
        # *   If you use an MNS queue as the notification method, the value format of this parameter is acs:mns:{region-id}:{account-id}:queue/{queuename}.
        # *   If you use an MNS topic as the notification method, the value format of this parameter is acs:mns:{region-id}:{account-id}:topic/{topicname}.
        # 
        # The variables in the preceding formats have the following meanings:
        # 
        # *   region-id: the region ID of the scaling group.
        # *   account-id: the ID of the Alibaba Cloud account.
        # *   queuename: the name of the MNS queue.
        # *   topicname: the name of the MNS topic.
        self.notification_arn = notification_arn  # type: str
        # The types of the notifications that you want to create. You can create one to eight notifications. Specify multiple values in the repeated list form.
        # 
        # You can call the DescribeNotificationTypes operation to query the values of this parameter.
        self.notification_types = notification_types  # type: list[str]
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateNotificationConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_types is not None:
            result['NotificationTypes'] = self.notification_types
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationTypes') is not None:
            self.notification_types = m.get('NotificationTypes')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class CreateNotificationConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateNotificationConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class CreateNotificationConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateNotificationConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateNotificationConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateNotificationConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateScalingConfigurationRequestImageOptions(TeaModel):
    def __init__(self, login_as_non_root=None):
        self.login_as_non_root = login_as_non_root  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestImageOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.login_as_non_root is not None:
            result['LoginAsNonRoot'] = self.login_as_non_root
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoginAsNonRoot') is not None:
            self.login_as_non_root = m.get('LoginAsNonRoot')
        return self


class CreateScalingConfigurationRequestPrivatePoolOptions(TeaModel):
    def __init__(self, id=None, match_criteria=None):
        # The ID of the private pool. The ID of a private pool is the same as the ID of the elasticity assurance or capacity reservation for which the private pool is generated.
        self.id = id  # type: str
        # The type of the private pool that you want to use to start ECS instances. A private pool is generated when an elasticity assurance or a capacity reservation takes effect. You can select a private pool to create ECS instances. Valid values:
        # 
        # *   Open: open private pool. Auto Scaling selects a matching open private pool to start instances. If no matching open private pools are found, Auto Scaling uses the resources in the public pool to start instances. In this case, you do not need to specify PrivatePoolOptions.Id.
        # *   Target: specified private pool. Auto Scaling uses the resources in the specified private pool to start ECS instances. If the specified private pool is unavailable, Auto Scaling cannot start ECS instances. If you set this parameter to Target, you must specify PrivatePoolOptions.Id.
        # *   None: no private pool. Auto Scaling does not use the resources in private pools to start ECS instances.
        self.match_criteria = match_criteria  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestPrivatePoolOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.id is not None:
            result['Id'] = self.id
        if self.match_criteria is not None:
            result['MatchCriteria'] = self.match_criteria
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('MatchCriteria') is not None:
            self.match_criteria = m.get('MatchCriteria')
        return self


class CreateScalingConfigurationRequestSystemDisk(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, category=None, description=None,
                 disk_name=None, encrypt_algorithm=None, encrypted=None, kmskey_id=None, performance_level=None,
                 provisioned_iops=None, size=None):
        # The ID of the automatic snapshot policy that you want to apply to the system disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The category of the system disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   ephemeral_ssd: local SSD
        # *   cloud_essd: enhanced SSD (ESSD)
        # *   cloud_auto: ESSD AutoPL disk
        # 
        # If you specify SystemDisk.Category, you cannot specify `SystemDiskCategories`. If you do not specify SystemDisk.Category or `SystemDiskCategories`, the default value of SystemDisk.Category is used.
        # 
        # *   For I/O optimized instances, the default value is cloud_efficiency.
        # *   For non-I/O optimized instances, the default value is cloud.
        self.category = category  # type: str
        # The description of the system disk. The description must be 2 to 256 characters in length. The description can contain letters and cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length. The name can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with `http://` or `https://`.
        self.disk_name = disk_name  # type: str
        # The encryption algorithm that you want to use to encrypt the system disk. Valid values:
        # 
        # *   AES-256
        # *   SM4-128
        # 
        # Default value: AES-256
        self.encrypt_algorithm = encrypt_algorithm  # type: str
        # Specifies whether to encrypt the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false
        self.encrypted = encrypted  # type: bool
        # The ID of the KMS key that you want to use to encrypt the system disk.
        self.kmskey_id = kmskey_id  # type: str
        # The performance level (PL) of the system disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # Default value: PL0
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the system disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the system disk. Unit: GiB.
        # 
        # *   If you set SystemDisk.Category cloud: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_efficiency: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_ssd: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_essd: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_essd: 20 to 500.
        # 
        # The value of SystemDisk.Size must be greater than or equal to the value of max{20, ImageSize}.
        # 
        # Default value: 40 or the size of the image, whichever is greater.
        self.size = size  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestSystemDisk, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.category is not None:
            result['Category'] = self.category
        if self.description is not None:
            result['Description'] = self.description
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypt_algorithm is not None:
            result['EncryptAlgorithm'] = self.encrypt_algorithm
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('EncryptAlgorithm') is not None:
            self.encrypt_algorithm = m.get('EncryptAlgorithm')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        return self


class CreateScalingConfigurationRequestCustomPriorities(TeaModel):
    def __init__(self, instance_type=None, vswitch_id=None):
        self.instance_type = instance_type  # type: str
        self.vswitch_id = vswitch_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestCustomPriorities, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.vswitch_id is not None:
            result['VswitchId'] = self.vswitch_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('VswitchId') is not None:
            self.vswitch_id = m.get('VswitchId')
        return self


class CreateScalingConfigurationRequestDataDisks(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, categories=None, category=None,
                 delete_with_instance=None, description=None, device=None, disk_name=None, encrypted=None, kmskey_id=None,
                 performance_level=None, provisioned_iops=None, size=None, snapshot_id=None):
        # The ID of the automatic snapshot policy that you want to apply to the data disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The categories of the data disks. If Auto Scaling cannot create instances by using the disk category that has the highest priority, Auto Scaling creates instances by using the disk category that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk. For a basic disk that is created together with the instance, DeleteWithInstance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   cloud_essd: ESSD.
        # 
        # > If you specify Categories, you cannot specify `DataDisks.Category`.
        self.categories = categories  # type: list[str]
        # The category of the data disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        # *   ephemeral_ssd: local SSD
        # *   cloud_auto: ESSD AutoPL disk
        # 
        # If you specify this parameter, you cannot specify Categories. If you do not specify Category or Categories, the default value of Category is used.
        # 
        # *   For I/O optimized instances, the default value is cloud_efficiency.
        # *   For non-I/O optimized instances, the default value is cloud.
        self.category = category  # type: str
        # Specifies whether to release the data disk when the instance to which the data disk is attached is released. Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is available only for independent disks whose value of Category is set to cloud, cloud_efficiency, cloud_ssd, or cloud_essd. If you specify this parameter for other disks, an error is reported.
        # 
        # Default value: true
        self.delete_with_instance = delete_with_instance  # type: bool
        # The description of the data disk. The description must be 2 to 256 characters in length. The description can contain letters and cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The mount target of the data disk. If you do not specify Device, a mount target is automatically assigned when Auto Scaling creates ECS instances. The names of mount targets range from /dev/xvdb to /dev/xvdz.
        self.device = device  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length and can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with `http://` or `https://`.
        self.disk_name = disk_name  # type: str
        # Specifies whether to encrypt the data disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false
        self.encrypted = encrypted  # type: str
        # The ID of the KMS key that you want to use to encrypt the data disk.
        self.kmskey_id = kmskey_id  # type: str
        # The PL of the data disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # > For more information about how to select ESSD PLs, see [ESSD](~~122389~~).
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the data disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the data disk. Unit: GiB. Valid values:
        # 
        # *   If you set Categories to cloud: 5 to 2000.
        # *   If you set Categories to cloud_efficiency: 20 to 32768.
        # *   If you set Categories to cloud_essd: 20 to 32768.
        # *   If you set Categories to ephemeral_ssd: 5 to 800.
        # 
        # The size of the data disk must be greater than or equal to the size of the snapshot that is specified by SnapshotId.
        self.size = size  # type: int
        # The ID of the snapshot that you want to use to create data disks. If you specify this parameter, DataDisks.Size is ignored. The size of the data disk is the same as the size of the specified snapshot.
        # 
        # If you specify a snapshot that is created on or before July 15, 2013, the operation fails and the system returns InvalidSnapshot.TooOld.
        self.snapshot_id = snapshot_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestDataDisks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.categories is not None:
            result['Categories'] = self.categories
        if self.category is not None:
            result['Category'] = self.category
        if self.delete_with_instance is not None:
            result['DeleteWithInstance'] = self.delete_with_instance
        if self.description is not None:
            result['Description'] = self.description
        if self.device is not None:
            result['Device'] = self.device
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        if self.snapshot_id is not None:
            result['SnapshotId'] = self.snapshot_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Categories') is not None:
            self.categories = m.get('Categories')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('DeleteWithInstance') is not None:
            self.delete_with_instance = m.get('DeleteWithInstance')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Device') is not None:
            self.device = m.get('Device')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        if m.get('SnapshotId') is not None:
            self.snapshot_id = m.get('SnapshotId')
        return self


class CreateScalingConfigurationRequestInstancePatternInfos(TeaModel):
    def __init__(self, architectures=None, burstable_performance=None, cores=None, excluded_instance_types=None,
                 instance_family_level=None, max_price=None, memory=None):
        # The architectures of the instance types. Valid values:
        # 
        # *   X86: x86 architecture.
        # *   Heterogeneous: heterogeneous architecture, such as GPUs and FPGAs.
        # *   BareMetal: ECS Bare Metal Instance architecture.
        # *   Arm: ARM architecture.
        # *   SuperComputeCluster: Super Computing Cluster architecture.
        # 
        # By default, all values are included.
        self.architectures = architectures  # type: list[str]
        # Specifies whether to include burstable instance types. Valid values:
        # 
        # *   Exclude: does not include burstable instance types.
        # *   Include: includes burstable instance types.
        # *   Required: includes only burstable instance types.
        # 
        # Default value: Include
        self.burstable_performance = burstable_performance  # type: str
        # The number of vCPUs that you want to allocate to an instance type in intelligent configuration mode. This parameter is used to filter the available instance types that meet the specified criteria. For more information, see the "[Instance families](~~25378~~)" topic.
        # 
        # Take note of the following items when you specify Cores:
        # 
        # *   InstancePatternInfos is available only for scaling groups that reside in VPCs.
        # *   If you specify InstancePatternInfos, you must specify Cores and Memory.
        # *   If you specify an instance type by using InstanceType or InstanceTypes, Auto Scaling preferentially uses the instance type that is specified by InstanceType or InstanceTypes for scale-outs. If the specified instance type does not have sufficient inventory, Auto Scaling creates instances by using the lowest-priced instance type that is specified by InstancePatternInfos.
        self.cores = cores  # type: int
        # The instance types that you want to exclude. You can use wildcard characters, such as asterisks (\*), to exclude an instance type or an instance family. Examples:
        # 
        # *   ecs.c6.large: excludes the ecs.c6.large instance type.
        # *   ecs.c6.\*: excludes the c6 instance family.
        self.excluded_instance_types = excluded_instance_types  # type: list[str]
        # The level of the instance type, which is used to filter instance types that meet the specified criteria. This parameter takes effect only if you set `CostOptimization` to true. Valid values:
        # 
        # *   EntryLevel: entry level (shared instance type). Instance types of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instance types of this level are suitable for business scenarios in which the CPU utilization is low. For more information, see the "[Shared instance families](~~108489~~)" topic.
        # *   EnterpriseLevel: enterprise level. Instance types of this level provide stable performance and dedicated resources and are suitable for business scenarios that require high stability. For more information, see the "[Instance families](~~25378~~)" topic.
        # *   CreditEntryLevel: credit entry level. This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instance types of this level are suitable for business scenarios in which the CPU utilization is low but may fluctuate in specific cases. For more information, see the "[Overview](~~59977~~)" topic of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        # The maximum hourly price of a pay-as-you-go or preemptible instance in intelligent configuration mode. This parameter is used to filter the available instance types that meet the specified criteria.
        # 
        # > If you set SpotStrategy to SpotWithPriceLimit, you must specify MaxPrice. In other cases, MaxPrice is optional.
        self.max_price = max_price  # type: float
        # The memory size that you want to allocate to an instance type in intelligent configuration mode. Unit: GiB. This parameter is used to filter the available instance types that meet the specified criteria.
        self.memory = memory  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestInstancePatternInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.architectures is not None:
            result['Architectures'] = self.architectures
        if self.burstable_performance is not None:
            result['BurstablePerformance'] = self.burstable_performance
        if self.cores is not None:
            result['Cores'] = self.cores
        if self.excluded_instance_types is not None:
            result['ExcludedInstanceTypes'] = self.excluded_instance_types
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.max_price is not None:
            result['MaxPrice'] = self.max_price
        if self.memory is not None:
            result['Memory'] = self.memory
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Architectures') is not None:
            self.architectures = m.get('Architectures')
        if m.get('BurstablePerformance') is not None:
            self.burstable_performance = m.get('BurstablePerformance')
        if m.get('Cores') is not None:
            self.cores = m.get('Cores')
        if m.get('ExcludedInstanceTypes') is not None:
            self.excluded_instance_types = m.get('ExcludedInstanceTypes')
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('MaxPrice') is not None:
            self.max_price = m.get('MaxPrice')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        return self


class CreateScalingConfigurationRequestInstanceTypeOverrides(TeaModel):
    def __init__(self, instance_type=None, weighted_capacity=None):
        # Instance type N that you want to use to override the instance type that is specified in the launch template.
        # 
        # If you want to trigger scale-outs based on the weighted capacities of instances, specify InstanceType and WeightedCapacity at the same time. You can specify N instance types by using the Extended Configurations feature. Valid values of N: 1 to 10.
        # 
        # > This parameter takes effect only if you specify LaunchTemplateId.
        # 
        # You can specify an instance type that is available for purchase as the value of InstanceType.
        self.instance_type = instance_type  # type: str
        # The weight of instance type N. If you want to trigger scale-outs based on the weighted capacities of instances, you must specify WeightedCapacity after you specify InstanceType.
        # 
        # The weight of an instance type specifies the capacity of an instance of the instance type in the scaling group. A higher weight specifies that a smaller number of instances of the specified instance type is required to meet the expected capacity requirement.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by MaxSize and the maximum weight of the instance types.
        # 
        # Valid values of WeightedCapacity: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestInstanceTypeOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class CreateScalingConfigurationRequestSpotPriceLimits(TeaModel):
    def __init__(self, instance_type=None, price_limit=None):
        # The instance type of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.instance_type = instance_type  # type: str
        # The price limit of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.price_limit = price_limit  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationRequestSpotPriceLimits, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.price_limit is not None:
            result['PriceLimit'] = self.price_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('PriceLimit') is not None:
            self.price_limit = m.get('PriceLimit')
        return self


class CreateScalingConfigurationRequest(TeaModel):
    def __init__(self, image_options=None, private_pool_options=None, system_disk=None, affinity=None,
                 client_token=None, cpu=None, credit_specification=None, custom_priorities=None, data_disks=None,
                 dedicated_host_id=None, deletion_protection=None, deployment_set_id=None, host_name=None, hpc_cluster_id=None,
                 image_family=None, image_id=None, image_name=None, instance_description=None, instance_name=None,
                 instance_pattern_infos=None, instance_type=None, instance_type_overrides=None, instance_types=None,
                 internet_charge_type=None, internet_max_bandwidth_in=None, internet_max_bandwidth_out=None, io_optimized=None,
                 ipv_6address_count=None, key_pair_name=None, load_balancer_weight=None, memory=None, owner_account=None,
                 owner_id=None, password=None, password_inherit=None, ram_role_name=None, resource_group_id=None,
                 resource_owner_account=None, scaling_configuration_name=None, scaling_group_id=None, scheduler_options=None,
                 security_enhancement_strategy=None, security_group_id=None, security_group_ids=None, spot_duration=None,
                 spot_interruption_behavior=None, spot_price_limits=None, spot_strategy=None, storage_set_id=None,
                 storage_set_partition_number=None, system_disk_categories=None, tags=None, tenancy=None, user_data=None, zone_id=None):
        self.image_options = image_options  # type: CreateScalingConfigurationRequestImageOptions
        self.private_pool_options = private_pool_options  # type: CreateScalingConfigurationRequestPrivatePoolOptions
        self.system_disk = system_disk  # type: CreateScalingConfigurationRequestSystemDisk
        # Specifies whether to associate an ECS instance on a dedicated host with the dedicated host. Valid values:
        # 
        # *   default: does not associate the ECS instance with the dedicated host. If you start an ECS instance that was stopped in economical mode and the original dedicated host has insufficient resources, the ECS instance is automatically deployed to another dedicated host in the automatic deployment resource pool.
        # *   host: associates the ECS instance with the dedicated host. If you start an ECS instance that was stopped in economical mode, the instance remains on the original dedicated host. If the original dedicated host has insufficient resources, the ECS instance fails to start.
        # 
        # Default value: default
        self.affinity = affinity  # type: str
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the token, but you must make sure that the token is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see the "[How to ensure the idempotence of a request](~~25693~~)" topic.
        self.client_token = client_token  # type: str
        # The number of vCPUs.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set CPU to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify Cpu and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify instance types in the scaling configuration.
        self.cpu = cpu  # type: int
        # The performance mode of the burstable instance. Valid values:
        # 
        # *   Standard: standard mode
        # *   Unlimited: unlimited mode
        # 
        # For more information, see the "Performance modes" section in the "[Overview](~~59977~~)" topic.
        self.credit_specification = credit_specification  # type: str
        self.custom_priorities = custom_priorities  # type: list[CreateScalingConfigurationRequestCustomPriorities]
        # The data disks.
        self.data_disks = data_disks  # type: list[CreateScalingConfigurationRequestDataDisks]
        # The ID of the dedicated host on which you want to create an ECS instance. You cannot create preemptible instances on dedicated hosts. If you specify DedicatedHostId, SpotStrategy and SpotPriceLimit are ignored.
        # 
        # You can call the DescribeDedicatedHosts operation to query dedicated host IDs.
        self.dedicated_host_id = dedicated_host_id  # type: str
        self.deletion_protection = deletion_protection  # type: bool
        # The ID of the deployment set of the ECS instances that are created by using the scaling configuration.
        self.deployment_set_id = deployment_set_id  # type: str
        # The hostname of the ECS instance. The hostname cannot start or end with a period (.) or a hyphen (-). The hostname cannot contain consecutive periods (.) or hyphens (-). Naming conventions for different types of instances:
        # 
        # *   Windows instances: The hostname must be 2 to 15 characters in length and can contain letters, digits, and hyphens (-). The hostname cannot contain periods (.) or contain only digits.
        # *   Other instances, such as Linux instances: The hostname must be 2 to 64 characters in length. You can use periods (.) to separate a hostname into multiple segments. Each segment can contain letters, digits, and hyphens (-).
        self.host_name = host_name  # type: str
        # The ID of the Elastic High Performance Computing (E-HPC) cluster to which the ECS instances that are created by using the scaling configuration belong.
        self.hpc_cluster_id = hpc_cluster_id  # type: str
        # The name of the image family. If you specify this parameter, the most recent custom images that are available in the specified image family are returned. You can use the images to create instances. If you specify ImageId, you cannot specify ImageFamily.
        self.image_family = image_family  # type: str
        # The ID of the image that Auto Scaling uses to automatically create ECS instances.
        self.image_id = image_id  # type: str
        # The name of the image. Each image name must be unique in a region. If you specify ImageId, ImageName is ignored.
        # 
        # You cannot use ImageName to specify images that are purchased from Alibaba Cloud Marketplace.
        self.image_name = image_name  # type: str
        # The description of the ECS instance. The description must be 2 to 256 characters in length. The description can contain letters and cannot start with `http://` or `https://`.
        self.instance_description = instance_description  # type: str
        # The name of the ECS instance that Auto Scaling creates based on the scaling configuration.
        self.instance_name = instance_name  # type: str
        # Details of the intelligent configuration settings that determine the range of instance types that meet the specified criteria.
        self.instance_pattern_infos = instance_pattern_infos  # type: list[CreateScalingConfigurationRequestInstancePatternInfos]
        # The instance type of the ECS instance. For more information, see the "Instance families" topic.
        self.instance_type = instance_type  # type: str
        # The instance types.
        self.instance_type_overrides = instance_type_overrides  # type: list[CreateScalingConfigurationRequestInstanceTypeOverrides]
        # The instance types. If you specify InstanceTypes, InstanceType is ignored.
        # 
        # Auto Scaling creates instances based on the priorities of the instance types. If Auto Scaling cannot create instances by using the instance type that has the highest priority, Auto Scaling creates instances by using the instance type that has the next highest priority.
        self.instance_types = instance_types  # type: list[str]
        # The metering method for network usage. Valid values:
        # 
        # *   PayByBandwidth: You are charged for the maximum available bandwidth that is specified by InternetMaxBandwidthOut.
        # *   PayByTraffic: You are charged based on the amount of transferred data. InternetMaxBandwidthOut specifies only the maximum available bandwidth.
        # 
        # For the classic network, the default value is PayByBandwidth. For VPCs, the default value is PayByTraffic.
        self.internet_charge_type = internet_charge_type  # type: str
        # The maximum inbound public bandwidth. Unit: Mbit/s. Valid values: 1 to 200.
        # 
        # Default value: 200 This parameter is not used for billing because inbound traffic to instances is free of charge.
        self.internet_max_bandwidth_in = internet_max_bandwidth_in  # type: int
        # The maximum outbound public bandwidth. Unit: Mbit/s. Valid values:
        # 
        # *   Valid values if you set InternetChargeType to PayByBandwidth: 0 to 100. If you leave this parameter empty, this parameter is automatically set to 0.
        # *   Valid values if you set InternetChargeType to PayByTraffic: 0 to 100. If you leave this parameter empty, an error is returned.
        self.internet_max_bandwidth_out = internet_max_bandwidth_out  # type: int
        # Specifies whether to create an I/O optimized instance. Valid values:
        # 
        # none: does not create an I/O optimized instance. optimized: creates an I/O optimized instance.
        # 
        # For instances of retired instance types, the default value is none. For instances of other instance types, the default value is optimized.
        self.io_optimized = io_optimized  # type: str
        # The number of randomly generated IPv6 addresses that you want to allocate to the elastic network interface (ENI).
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The name of the key pair that you want to use to log on to an ECS instance.
        # 
        # *   Windows instances do not support this parameter.
        # *   By default, the username and password authentication method is disabled for Linux instances.
        self.key_pair_name = key_pair_name  # type: str
        # The weight of an ECS instance as a backend server. Valid values: 1 to 100.
        # 
        # Default value: 50
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size. Unit: GiB.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set Cpu to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify Cpu and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify instance types in the scaling configuration.
        self.memory = memory  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The password that you want to use to log on to an ECS instance. The password must be 8 to 30 characters in length and must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters. The following special characters are supported:
        # 
        # `` `() ~!@#$%^&*-_+=\|{}[]:;\"<>,.?/ ``
        # 
        # The password of a Windows instance cannot start with a forward slash (/).
        # 
        # > For security reasons, we recommend that you use HTTPS to send requests if you specify Password.
        self.password = password  # type: str
        # Specifies whether to use the password that is preconfigured in the image. Before you use this parameter, make sure that a password is configured in the image. Valid values:
        # 
        # *   true
        # *   false
        self.password_inherit = password_inherit  # type: bool
        # The name of the RAM role that you attach to the ECS instance. The name is provided and maintained by Resource Access Management (RAM). You can call the ListRoles operation to query the available RAM roles.
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group to which the ECS instances that are created by using the scaling configuration belong.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The name of the scaling configuration. The name must be 2 to 64 characters in length and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # The name of the scaling configuration must be unique in a region. If you do not specify this parameter, the scaling configuration ID is used.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The ID of the scaling group in which you want to create a scaling configuration.
        self.scaling_group_id = scaling_group_id  # type: str
        # The scheduler options.
        self.scheduler_options = scheduler_options  # type: dict[str, any]
        # Specifies whether to enable security hardening. Valid values:
        # 
        # *   Active: enables security hardening. This value is applicable only to public images.
        # *   Deactive: disables security hardening. This value is applicable to all image types.
        self.security_enhancement_strategy = security_enhancement_strategy  # type: str
        # The ID of the security group with which ECS instances are associated. ECS instances that are associated with the same security group can access each other.
        self.security_group_id = security_group_id  # type: str
        # The IDs of the security groups with which you want to associate the ECS instances that are created by using the scaling configuration. For more information, see the "Security group limits" section of the "[Limits](~~25412~~)" topic.
        # 
        # > If you specify SecurityGroupId, you cannot specify SecurityGroupIds.
        self.security_group_ids = security_group_ids  # type: list[str]
        # The retention period of the preemptible instance. Unit: hours. Valid values: 0, 1, 2, 3, 4, 5, and 6.
        # 
        # *   The following retention periods are available in invitational preview: 2, 3, 4, 5, and 6 hours. If you want to set this parameter to one of these values, submit a ticket.
        # *   If you set this parameter to 0, no protection period is specified for the preemptible instance.
        # 
        # Default value: 1
        self.spot_duration = spot_duration  # type: int
        # The interruption mode of the preemptible instance. Set the value to Terminate. The value specifies that the preemptible instance is to be released.
        self.spot_interruption_behavior = spot_interruption_behavior  # type: str
        # The billing information of the preemptible instances.
        self.spot_price_limits = spot_price_limits  # type: list[CreateScalingConfigurationRequestSpotPriceLimits]
        # The preemption policy that you want to apply to pay-as-you-go and preemptible instances. Valid values:
        # 
        # *   NoSpot: The instance is created as a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance that has a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is created as a preemptible instance for which the market price at the time of purchase is automatically used as the bid price.
        # 
        # Default value: NoSpot
        self.spot_strategy = spot_strategy  # type: str
        self.storage_set_id = storage_set_id  # type: str
        self.storage_set_partition_number = storage_set_partition_number  # type: int
        # The categories of the system disks. If Auto Scaling cannot create instances by using the disk category that has the highest priority, Auto Scaling creates instances by using the disk category that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        # 
        # > If you specify SystemDiskCategories, you cannot specify `SystemDisk.Category`.
        self.system_disk_categories = system_disk_categories  # type: list[str]
        # The tags of the ECS instance. Tags must be specified as key-value pairs. You can specify up to 20 tags. When you specify tag keys and tag values, take note of the following items:
        # 
        # *   A tag key can be up to 64 characters in length. The key cannot start with acs: or aliyun and cannot contain `http://` or `https://`. You cannot specify an empty string as a tag key.
        # *   A tag value can be up to 128 characters in length. The value cannot start with acs: or aliyun and cannot contain `http://` or `https://`. You can specify an empty string as a tag value.
        self.tags = tags  # type: str
        # Specifies whether to create an ECS instance on a dedicated host. Valid values:
        # 
        # *   default: does not create an ECS instance on a dedicated host.
        # *   host: creates an ECS instance on a dedicated host. If you do not specify DedicatedHostId, Alibaba Cloud selects a dedicated host for the ECS instance.
        # 
        # Default value: default
        self.tenancy = tenancy  # type: str
        # The user data of the ECS instance. The data must be encoded in Base64. The maximum size of the data before encoding is 16 KB.
        self.user_data = user_data  # type: str
        # The zone ID of the ECS instance.
        self.zone_id = zone_id  # type: str

    def validate(self):
        if self.image_options:
            self.image_options.validate()
        if self.private_pool_options:
            self.private_pool_options.validate()
        if self.system_disk:
            self.system_disk.validate()
        if self.custom_priorities:
            for k in self.custom_priorities:
                if k:
                    k.validate()
        if self.data_disks:
            for k in self.data_disks:
                if k:
                    k.validate()
        if self.instance_pattern_infos:
            for k in self.instance_pattern_infos:
                if k:
                    k.validate()
        if self.instance_type_overrides:
            for k in self.instance_type_overrides:
                if k:
                    k.validate()
        if self.spot_price_limits:
            for k in self.spot_price_limits:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.image_options is not None:
            result['ImageOptions'] = self.image_options.to_map()
        if self.private_pool_options is not None:
            result['PrivatePoolOptions'] = self.private_pool_options.to_map()
        if self.system_disk is not None:
            result['SystemDisk'] = self.system_disk.to_map()
        if self.affinity is not None:
            result['Affinity'] = self.affinity
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.credit_specification is not None:
            result['CreditSpecification'] = self.credit_specification
        result['CustomPriorities'] = []
        if self.custom_priorities is not None:
            for k in self.custom_priorities:
                result['CustomPriorities'].append(k.to_map() if k else None)
        result['DataDisks'] = []
        if self.data_disks is not None:
            for k in self.data_disks:
                result['DataDisks'].append(k.to_map() if k else None)
        if self.dedicated_host_id is not None:
            result['DedicatedHostId'] = self.dedicated_host_id
        if self.deletion_protection is not None:
            result['DeletionProtection'] = self.deletion_protection
        if self.deployment_set_id is not None:
            result['DeploymentSetId'] = self.deployment_set_id
        if self.host_name is not None:
            result['HostName'] = self.host_name
        if self.hpc_cluster_id is not None:
            result['HpcClusterId'] = self.hpc_cluster_id
        if self.image_family is not None:
            result['ImageFamily'] = self.image_family
        if self.image_id is not None:
            result['ImageId'] = self.image_id
        if self.image_name is not None:
            result['ImageName'] = self.image_name
        if self.instance_description is not None:
            result['InstanceDescription'] = self.instance_description
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        result['InstancePatternInfos'] = []
        if self.instance_pattern_infos is not None:
            for k in self.instance_pattern_infos:
                result['InstancePatternInfos'].append(k.to_map() if k else None)
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        result['InstanceTypeOverrides'] = []
        if self.instance_type_overrides is not None:
            for k in self.instance_type_overrides:
                result['InstanceTypeOverrides'].append(k.to_map() if k else None)
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.internet_charge_type is not None:
            result['InternetChargeType'] = self.internet_charge_type
        if self.internet_max_bandwidth_in is not None:
            result['InternetMaxBandwidthIn'] = self.internet_max_bandwidth_in
        if self.internet_max_bandwidth_out is not None:
            result['InternetMaxBandwidthOut'] = self.internet_max_bandwidth_out
        if self.io_optimized is not None:
            result['IoOptimized'] = self.io_optimized
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.key_pair_name is not None:
            result['KeyPairName'] = self.key_pair_name
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.password is not None:
            result['Password'] = self.password
        if self.password_inherit is not None:
            result['PasswordInherit'] = self.password_inherit
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduler_options is not None:
            result['SchedulerOptions'] = self.scheduler_options
        if self.security_enhancement_strategy is not None:
            result['SecurityEnhancementStrategy'] = self.security_enhancement_strategy
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.security_group_ids is not None:
            result['SecurityGroupIds'] = self.security_group_ids
        if self.spot_duration is not None:
            result['SpotDuration'] = self.spot_duration
        if self.spot_interruption_behavior is not None:
            result['SpotInterruptionBehavior'] = self.spot_interruption_behavior
        result['SpotPriceLimits'] = []
        if self.spot_price_limits is not None:
            for k in self.spot_price_limits:
                result['SpotPriceLimits'].append(k.to_map() if k else None)
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        if self.storage_set_id is not None:
            result['StorageSetId'] = self.storage_set_id
        if self.storage_set_partition_number is not None:
            result['StorageSetPartitionNumber'] = self.storage_set_partition_number
        if self.system_disk_categories is not None:
            result['SystemDiskCategories'] = self.system_disk_categories
        if self.tags is not None:
            result['Tags'] = self.tags
        if self.tenancy is not None:
            result['Tenancy'] = self.tenancy
        if self.user_data is not None:
            result['UserData'] = self.user_data
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ImageOptions') is not None:
            temp_model = CreateScalingConfigurationRequestImageOptions()
            self.image_options = temp_model.from_map(m['ImageOptions'])
        if m.get('PrivatePoolOptions') is not None:
            temp_model = CreateScalingConfigurationRequestPrivatePoolOptions()
            self.private_pool_options = temp_model.from_map(m['PrivatePoolOptions'])
        if m.get('SystemDisk') is not None:
            temp_model = CreateScalingConfigurationRequestSystemDisk()
            self.system_disk = temp_model.from_map(m['SystemDisk'])
        if m.get('Affinity') is not None:
            self.affinity = m.get('Affinity')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CreditSpecification') is not None:
            self.credit_specification = m.get('CreditSpecification')
        self.custom_priorities = []
        if m.get('CustomPriorities') is not None:
            for k in m.get('CustomPriorities'):
                temp_model = CreateScalingConfigurationRequestCustomPriorities()
                self.custom_priorities.append(temp_model.from_map(k))
        self.data_disks = []
        if m.get('DataDisks') is not None:
            for k in m.get('DataDisks'):
                temp_model = CreateScalingConfigurationRequestDataDisks()
                self.data_disks.append(temp_model.from_map(k))
        if m.get('DedicatedHostId') is not None:
            self.dedicated_host_id = m.get('DedicatedHostId')
        if m.get('DeletionProtection') is not None:
            self.deletion_protection = m.get('DeletionProtection')
        if m.get('DeploymentSetId') is not None:
            self.deployment_set_id = m.get('DeploymentSetId')
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        if m.get('HpcClusterId') is not None:
            self.hpc_cluster_id = m.get('HpcClusterId')
        if m.get('ImageFamily') is not None:
            self.image_family = m.get('ImageFamily')
        if m.get('ImageId') is not None:
            self.image_id = m.get('ImageId')
        if m.get('ImageName') is not None:
            self.image_name = m.get('ImageName')
        if m.get('InstanceDescription') is not None:
            self.instance_description = m.get('InstanceDescription')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        self.instance_pattern_infos = []
        if m.get('InstancePatternInfos') is not None:
            for k in m.get('InstancePatternInfos'):
                temp_model = CreateScalingConfigurationRequestInstancePatternInfos()
                self.instance_pattern_infos.append(temp_model.from_map(k))
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        self.instance_type_overrides = []
        if m.get('InstanceTypeOverrides') is not None:
            for k in m.get('InstanceTypeOverrides'):
                temp_model = CreateScalingConfigurationRequestInstanceTypeOverrides()
                self.instance_type_overrides.append(temp_model.from_map(k))
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('InternetChargeType') is not None:
            self.internet_charge_type = m.get('InternetChargeType')
        if m.get('InternetMaxBandwidthIn') is not None:
            self.internet_max_bandwidth_in = m.get('InternetMaxBandwidthIn')
        if m.get('InternetMaxBandwidthOut') is not None:
            self.internet_max_bandwidth_out = m.get('InternetMaxBandwidthOut')
        if m.get('IoOptimized') is not None:
            self.io_optimized = m.get('IoOptimized')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('KeyPairName') is not None:
            self.key_pair_name = m.get('KeyPairName')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('PasswordInherit') is not None:
            self.password_inherit = m.get('PasswordInherit')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('SchedulerOptions') is not None:
            self.scheduler_options = m.get('SchedulerOptions')
        if m.get('SecurityEnhancementStrategy') is not None:
            self.security_enhancement_strategy = m.get('SecurityEnhancementStrategy')
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SecurityGroupIds') is not None:
            self.security_group_ids = m.get('SecurityGroupIds')
        if m.get('SpotDuration') is not None:
            self.spot_duration = m.get('SpotDuration')
        if m.get('SpotInterruptionBehavior') is not None:
            self.spot_interruption_behavior = m.get('SpotInterruptionBehavior')
        self.spot_price_limits = []
        if m.get('SpotPriceLimits') is not None:
            for k in m.get('SpotPriceLimits'):
                temp_model = CreateScalingConfigurationRequestSpotPriceLimits()
                self.spot_price_limits.append(temp_model.from_map(k))
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        if m.get('StorageSetId') is not None:
            self.storage_set_id = m.get('StorageSetId')
        if m.get('StorageSetPartitionNumber') is not None:
            self.storage_set_partition_number = m.get('StorageSetPartitionNumber')
        if m.get('SystemDiskCategories') is not None:
            self.system_disk_categories = m.get('SystemDiskCategories')
        if m.get('Tags') is not None:
            self.tags = m.get('Tags')
        if m.get('Tenancy') is not None:
            self.tenancy = m.get('Tenancy')
        if m.get('UserData') is not None:
            self.user_data = m.get('UserData')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class CreateScalingConfigurationShrinkRequestImageOptions(TeaModel):
    def __init__(self, login_as_non_root=None):
        self.login_as_non_root = login_as_non_root  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestImageOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.login_as_non_root is not None:
            result['LoginAsNonRoot'] = self.login_as_non_root
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoginAsNonRoot') is not None:
            self.login_as_non_root = m.get('LoginAsNonRoot')
        return self


class CreateScalingConfigurationShrinkRequestPrivatePoolOptions(TeaModel):
    def __init__(self, id=None, match_criteria=None):
        # The ID of the private pool. The ID of a private pool is the same as the ID of the elasticity assurance or capacity reservation for which the private pool is generated.
        self.id = id  # type: str
        # The type of the private pool that you want to use to start ECS instances. A private pool is generated when an elasticity assurance or a capacity reservation takes effect. You can select a private pool to create ECS instances. Valid values:
        # 
        # *   Open: open private pool. Auto Scaling selects a matching open private pool to start instances. If no matching open private pools are found, Auto Scaling uses the resources in the public pool to start instances. In this case, you do not need to specify PrivatePoolOptions.Id.
        # *   Target: specified private pool. Auto Scaling uses the resources in the specified private pool to start ECS instances. If the specified private pool is unavailable, Auto Scaling cannot start ECS instances. If you set this parameter to Target, you must specify PrivatePoolOptions.Id.
        # *   None: no private pool. Auto Scaling does not use the resources in private pools to start ECS instances.
        self.match_criteria = match_criteria  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestPrivatePoolOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.id is not None:
            result['Id'] = self.id
        if self.match_criteria is not None:
            result['MatchCriteria'] = self.match_criteria
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('MatchCriteria') is not None:
            self.match_criteria = m.get('MatchCriteria')
        return self


class CreateScalingConfigurationShrinkRequestSystemDisk(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, category=None, description=None,
                 disk_name=None, encrypt_algorithm=None, encrypted=None, kmskey_id=None, performance_level=None,
                 provisioned_iops=None, size=None):
        # The ID of the automatic snapshot policy that you want to apply to the system disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The category of the system disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   ephemeral_ssd: local SSD
        # *   cloud_essd: enhanced SSD (ESSD)
        # *   cloud_auto: ESSD AutoPL disk
        # 
        # If you specify SystemDisk.Category, you cannot specify `SystemDiskCategories`. If you do not specify SystemDisk.Category or `SystemDiskCategories`, the default value of SystemDisk.Category is used.
        # 
        # *   For I/O optimized instances, the default value is cloud_efficiency.
        # *   For non-I/O optimized instances, the default value is cloud.
        self.category = category  # type: str
        # The description of the system disk. The description must be 2 to 256 characters in length. The description can contain letters and cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length. The name can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with `http://` or `https://`.
        self.disk_name = disk_name  # type: str
        # The encryption algorithm that you want to use to encrypt the system disk. Valid values:
        # 
        # *   AES-256
        # *   SM4-128
        # 
        # Default value: AES-256
        self.encrypt_algorithm = encrypt_algorithm  # type: str
        # Specifies whether to encrypt the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false
        self.encrypted = encrypted  # type: bool
        # The ID of the KMS key that you want to use to encrypt the system disk.
        self.kmskey_id = kmskey_id  # type: str
        # The performance level (PL) of the system disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # Default value: PL0
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the system disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the system disk. Unit: GiB.
        # 
        # *   If you set SystemDisk.Category cloud: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_efficiency: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_ssd: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_essd: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_essd: 20 to 500.
        # 
        # The value of SystemDisk.Size must be greater than or equal to the value of max{20, ImageSize}.
        # 
        # Default value: 40 or the size of the image, whichever is greater.
        self.size = size  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestSystemDisk, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.category is not None:
            result['Category'] = self.category
        if self.description is not None:
            result['Description'] = self.description
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypt_algorithm is not None:
            result['EncryptAlgorithm'] = self.encrypt_algorithm
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('EncryptAlgorithm') is not None:
            self.encrypt_algorithm = m.get('EncryptAlgorithm')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        return self


class CreateScalingConfigurationShrinkRequestCustomPriorities(TeaModel):
    def __init__(self, instance_type=None, vswitch_id=None):
        self.instance_type = instance_type  # type: str
        self.vswitch_id = vswitch_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestCustomPriorities, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.vswitch_id is not None:
            result['VswitchId'] = self.vswitch_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('VswitchId') is not None:
            self.vswitch_id = m.get('VswitchId')
        return self


class CreateScalingConfigurationShrinkRequestDataDisks(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, categories=None, category=None,
                 delete_with_instance=None, description=None, device=None, disk_name=None, encrypted=None, kmskey_id=None,
                 performance_level=None, provisioned_iops=None, size=None, snapshot_id=None):
        # The ID of the automatic snapshot policy that you want to apply to the data disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The categories of the data disks. If Auto Scaling cannot create instances by using the disk category that has the highest priority, Auto Scaling creates instances by using the disk category that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk. For a basic disk that is created together with the instance, DeleteWithInstance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   cloud_essd: ESSD.
        # 
        # > If you specify Categories, you cannot specify `DataDisks.Category`.
        self.categories = categories  # type: list[str]
        # The category of the data disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        # *   ephemeral_ssd: local SSD
        # *   cloud_auto: ESSD AutoPL disk
        # 
        # If you specify this parameter, you cannot specify Categories. If you do not specify Category or Categories, the default value of Category is used.
        # 
        # *   For I/O optimized instances, the default value is cloud_efficiency.
        # *   For non-I/O optimized instances, the default value is cloud.
        self.category = category  # type: str
        # Specifies whether to release the data disk when the instance to which the data disk is attached is released. Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is available only for independent disks whose value of Category is set to cloud, cloud_efficiency, cloud_ssd, or cloud_essd. If you specify this parameter for other disks, an error is reported.
        # 
        # Default value: true
        self.delete_with_instance = delete_with_instance  # type: bool
        # The description of the data disk. The description must be 2 to 256 characters in length. The description can contain letters and cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The mount target of the data disk. If you do not specify Device, a mount target is automatically assigned when Auto Scaling creates ECS instances. The names of mount targets range from /dev/xvdb to /dev/xvdz.
        self.device = device  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length and can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with `http://` or `https://`.
        self.disk_name = disk_name  # type: str
        # Specifies whether to encrypt the data disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false
        self.encrypted = encrypted  # type: str
        # The ID of the KMS key that you want to use to encrypt the data disk.
        self.kmskey_id = kmskey_id  # type: str
        # The PL of the data disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # > For more information about how to select ESSD PLs, see [ESSD](~~122389~~).
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the data disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the data disk. Unit: GiB. Valid values:
        # 
        # *   If you set Categories to cloud: 5 to 2000.
        # *   If you set Categories to cloud_efficiency: 20 to 32768.
        # *   If you set Categories to cloud_essd: 20 to 32768.
        # *   If you set Categories to ephemeral_ssd: 5 to 800.
        # 
        # The size of the data disk must be greater than or equal to the size of the snapshot that is specified by SnapshotId.
        self.size = size  # type: int
        # The ID of the snapshot that you want to use to create data disks. If you specify this parameter, DataDisks.Size is ignored. The size of the data disk is the same as the size of the specified snapshot.
        # 
        # If you specify a snapshot that is created on or before July 15, 2013, the operation fails and the system returns InvalidSnapshot.TooOld.
        self.snapshot_id = snapshot_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestDataDisks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.categories is not None:
            result['Categories'] = self.categories
        if self.category is not None:
            result['Category'] = self.category
        if self.delete_with_instance is not None:
            result['DeleteWithInstance'] = self.delete_with_instance
        if self.description is not None:
            result['Description'] = self.description
        if self.device is not None:
            result['Device'] = self.device
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        if self.snapshot_id is not None:
            result['SnapshotId'] = self.snapshot_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Categories') is not None:
            self.categories = m.get('Categories')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('DeleteWithInstance') is not None:
            self.delete_with_instance = m.get('DeleteWithInstance')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Device') is not None:
            self.device = m.get('Device')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        if m.get('SnapshotId') is not None:
            self.snapshot_id = m.get('SnapshotId')
        return self


class CreateScalingConfigurationShrinkRequestInstancePatternInfos(TeaModel):
    def __init__(self, architectures=None, burstable_performance=None, cores=None, excluded_instance_types=None,
                 instance_family_level=None, max_price=None, memory=None):
        # The architectures of the instance types. Valid values:
        # 
        # *   X86: x86 architecture.
        # *   Heterogeneous: heterogeneous architecture, such as GPUs and FPGAs.
        # *   BareMetal: ECS Bare Metal Instance architecture.
        # *   Arm: ARM architecture.
        # *   SuperComputeCluster: Super Computing Cluster architecture.
        # 
        # By default, all values are included.
        self.architectures = architectures  # type: list[str]
        # Specifies whether to include burstable instance types. Valid values:
        # 
        # *   Exclude: does not include burstable instance types.
        # *   Include: includes burstable instance types.
        # *   Required: includes only burstable instance types.
        # 
        # Default value: Include
        self.burstable_performance = burstable_performance  # type: str
        # The number of vCPUs that you want to allocate to an instance type in intelligent configuration mode. This parameter is used to filter the available instance types that meet the specified criteria. For more information, see the "[Instance families](~~25378~~)" topic.
        # 
        # Take note of the following items when you specify Cores:
        # 
        # *   InstancePatternInfos is available only for scaling groups that reside in VPCs.
        # *   If you specify InstancePatternInfos, you must specify Cores and Memory.
        # *   If you specify an instance type by using InstanceType or InstanceTypes, Auto Scaling preferentially uses the instance type that is specified by InstanceType or InstanceTypes for scale-outs. If the specified instance type does not have sufficient inventory, Auto Scaling creates instances by using the lowest-priced instance type that is specified by InstancePatternInfos.
        self.cores = cores  # type: int
        # The instance types that you want to exclude. You can use wildcard characters, such as asterisks (\*), to exclude an instance type or an instance family. Examples:
        # 
        # *   ecs.c6.large: excludes the ecs.c6.large instance type.
        # *   ecs.c6.\*: excludes the c6 instance family.
        self.excluded_instance_types = excluded_instance_types  # type: list[str]
        # The level of the instance type, which is used to filter instance types that meet the specified criteria. This parameter takes effect only if you set `CostOptimization` to true. Valid values:
        # 
        # *   EntryLevel: entry level (shared instance type). Instance types of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instance types of this level are suitable for business scenarios in which the CPU utilization is low. For more information, see the "[Shared instance families](~~108489~~)" topic.
        # *   EnterpriseLevel: enterprise level. Instance types of this level provide stable performance and dedicated resources and are suitable for business scenarios that require high stability. For more information, see the "[Instance families](~~25378~~)" topic.
        # *   CreditEntryLevel: credit entry level. This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instance types of this level are suitable for business scenarios in which the CPU utilization is low but may fluctuate in specific cases. For more information, see the "[Overview](~~59977~~)" topic of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        # The maximum hourly price of a pay-as-you-go or preemptible instance in intelligent configuration mode. This parameter is used to filter the available instance types that meet the specified criteria.
        # 
        # > If you set SpotStrategy to SpotWithPriceLimit, you must specify MaxPrice. In other cases, MaxPrice is optional.
        self.max_price = max_price  # type: float
        # The memory size that you want to allocate to an instance type in intelligent configuration mode. Unit: GiB. This parameter is used to filter the available instance types that meet the specified criteria.
        self.memory = memory  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestInstancePatternInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.architectures is not None:
            result['Architectures'] = self.architectures
        if self.burstable_performance is not None:
            result['BurstablePerformance'] = self.burstable_performance
        if self.cores is not None:
            result['Cores'] = self.cores
        if self.excluded_instance_types is not None:
            result['ExcludedInstanceTypes'] = self.excluded_instance_types
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.max_price is not None:
            result['MaxPrice'] = self.max_price
        if self.memory is not None:
            result['Memory'] = self.memory
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Architectures') is not None:
            self.architectures = m.get('Architectures')
        if m.get('BurstablePerformance') is not None:
            self.burstable_performance = m.get('BurstablePerformance')
        if m.get('Cores') is not None:
            self.cores = m.get('Cores')
        if m.get('ExcludedInstanceTypes') is not None:
            self.excluded_instance_types = m.get('ExcludedInstanceTypes')
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('MaxPrice') is not None:
            self.max_price = m.get('MaxPrice')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        return self


class CreateScalingConfigurationShrinkRequestInstanceTypeOverrides(TeaModel):
    def __init__(self, instance_type=None, weighted_capacity=None):
        # Instance type N that you want to use to override the instance type that is specified in the launch template.
        # 
        # If you want to trigger scale-outs based on the weighted capacities of instances, specify InstanceType and WeightedCapacity at the same time. You can specify N instance types by using the Extended Configurations feature. Valid values of N: 1 to 10.
        # 
        # > This parameter takes effect only if you specify LaunchTemplateId.
        # 
        # You can specify an instance type that is available for purchase as the value of InstanceType.
        self.instance_type = instance_type  # type: str
        # The weight of instance type N. If you want to trigger scale-outs based on the weighted capacities of instances, you must specify WeightedCapacity after you specify InstanceType.
        # 
        # The weight of an instance type specifies the capacity of an instance of the instance type in the scaling group. A higher weight specifies that a smaller number of instances of the specified instance type is required to meet the expected capacity requirement.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by MaxSize and the maximum weight of the instance types.
        # 
        # Valid values of WeightedCapacity: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestInstanceTypeOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class CreateScalingConfigurationShrinkRequestSpotPriceLimits(TeaModel):
    def __init__(self, instance_type=None, price_limit=None):
        # The instance type of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.instance_type = instance_type  # type: str
        # The price limit of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.price_limit = price_limit  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequestSpotPriceLimits, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.price_limit is not None:
            result['PriceLimit'] = self.price_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('PriceLimit') is not None:
            self.price_limit = m.get('PriceLimit')
        return self


class CreateScalingConfigurationShrinkRequest(TeaModel):
    def __init__(self, image_options=None, private_pool_options=None, system_disk=None, affinity=None,
                 client_token=None, cpu=None, credit_specification=None, custom_priorities=None, data_disks=None,
                 dedicated_host_id=None, deletion_protection=None, deployment_set_id=None, host_name=None, hpc_cluster_id=None,
                 image_family=None, image_id=None, image_name=None, instance_description=None, instance_name=None,
                 instance_pattern_infos=None, instance_type=None, instance_type_overrides=None, instance_types=None,
                 internet_charge_type=None, internet_max_bandwidth_in=None, internet_max_bandwidth_out=None, io_optimized=None,
                 ipv_6address_count=None, key_pair_name=None, load_balancer_weight=None, memory=None, owner_account=None,
                 owner_id=None, password=None, password_inherit=None, ram_role_name=None, resource_group_id=None,
                 resource_owner_account=None, scaling_configuration_name=None, scaling_group_id=None, scheduler_options_shrink=None,
                 security_enhancement_strategy=None, security_group_id=None, security_group_ids=None, spot_duration=None,
                 spot_interruption_behavior=None, spot_price_limits=None, spot_strategy=None, storage_set_id=None,
                 storage_set_partition_number=None, system_disk_categories=None, tags=None, tenancy=None, user_data=None, zone_id=None):
        self.image_options = image_options  # type: CreateScalingConfigurationShrinkRequestImageOptions
        self.private_pool_options = private_pool_options  # type: CreateScalingConfigurationShrinkRequestPrivatePoolOptions
        self.system_disk = system_disk  # type: CreateScalingConfigurationShrinkRequestSystemDisk
        # Specifies whether to associate an ECS instance on a dedicated host with the dedicated host. Valid values:
        # 
        # *   default: does not associate the ECS instance with the dedicated host. If you start an ECS instance that was stopped in economical mode and the original dedicated host has insufficient resources, the ECS instance is automatically deployed to another dedicated host in the automatic deployment resource pool.
        # *   host: associates the ECS instance with the dedicated host. If you start an ECS instance that was stopped in economical mode, the instance remains on the original dedicated host. If the original dedicated host has insufficient resources, the ECS instance fails to start.
        # 
        # Default value: default
        self.affinity = affinity  # type: str
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the token, but you must make sure that the token is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see the "[How to ensure the idempotence of a request](~~25693~~)" topic.
        self.client_token = client_token  # type: str
        # The number of vCPUs.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set CPU to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify Cpu and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify instance types in the scaling configuration.
        self.cpu = cpu  # type: int
        # The performance mode of the burstable instance. Valid values:
        # 
        # *   Standard: standard mode
        # *   Unlimited: unlimited mode
        # 
        # For more information, see the "Performance modes" section in the "[Overview](~~59977~~)" topic.
        self.credit_specification = credit_specification  # type: str
        self.custom_priorities = custom_priorities  # type: list[CreateScalingConfigurationShrinkRequestCustomPriorities]
        # The data disks.
        self.data_disks = data_disks  # type: list[CreateScalingConfigurationShrinkRequestDataDisks]
        # The ID of the dedicated host on which you want to create an ECS instance. You cannot create preemptible instances on dedicated hosts. If you specify DedicatedHostId, SpotStrategy and SpotPriceLimit are ignored.
        # 
        # You can call the DescribeDedicatedHosts operation to query dedicated host IDs.
        self.dedicated_host_id = dedicated_host_id  # type: str
        self.deletion_protection = deletion_protection  # type: bool
        # The ID of the deployment set of the ECS instances that are created by using the scaling configuration.
        self.deployment_set_id = deployment_set_id  # type: str
        # The hostname of the ECS instance. The hostname cannot start or end with a period (.) or a hyphen (-). The hostname cannot contain consecutive periods (.) or hyphens (-). Naming conventions for different types of instances:
        # 
        # *   Windows instances: The hostname must be 2 to 15 characters in length and can contain letters, digits, and hyphens (-). The hostname cannot contain periods (.) or contain only digits.
        # *   Other instances, such as Linux instances: The hostname must be 2 to 64 characters in length. You can use periods (.) to separate a hostname into multiple segments. Each segment can contain letters, digits, and hyphens (-).
        self.host_name = host_name  # type: str
        # The ID of the Elastic High Performance Computing (E-HPC) cluster to which the ECS instances that are created by using the scaling configuration belong.
        self.hpc_cluster_id = hpc_cluster_id  # type: str
        # The name of the image family. If you specify this parameter, the most recent custom images that are available in the specified image family are returned. You can use the images to create instances. If you specify ImageId, you cannot specify ImageFamily.
        self.image_family = image_family  # type: str
        # The ID of the image that Auto Scaling uses to automatically create ECS instances.
        self.image_id = image_id  # type: str
        # The name of the image. Each image name must be unique in a region. If you specify ImageId, ImageName is ignored.
        # 
        # You cannot use ImageName to specify images that are purchased from Alibaba Cloud Marketplace.
        self.image_name = image_name  # type: str
        # The description of the ECS instance. The description must be 2 to 256 characters in length. The description can contain letters and cannot start with `http://` or `https://`.
        self.instance_description = instance_description  # type: str
        # The name of the ECS instance that Auto Scaling creates based on the scaling configuration.
        self.instance_name = instance_name  # type: str
        # Details of the intelligent configuration settings that determine the range of instance types that meet the specified criteria.
        self.instance_pattern_infos = instance_pattern_infos  # type: list[CreateScalingConfigurationShrinkRequestInstancePatternInfos]
        # The instance type of the ECS instance. For more information, see the "Instance families" topic.
        self.instance_type = instance_type  # type: str
        # The instance types.
        self.instance_type_overrides = instance_type_overrides  # type: list[CreateScalingConfigurationShrinkRequestInstanceTypeOverrides]
        # The instance types. If you specify InstanceTypes, InstanceType is ignored.
        # 
        # Auto Scaling creates instances based on the priorities of the instance types. If Auto Scaling cannot create instances by using the instance type that has the highest priority, Auto Scaling creates instances by using the instance type that has the next highest priority.
        self.instance_types = instance_types  # type: list[str]
        # The metering method for network usage. Valid values:
        # 
        # *   PayByBandwidth: You are charged for the maximum available bandwidth that is specified by InternetMaxBandwidthOut.
        # *   PayByTraffic: You are charged based on the amount of transferred data. InternetMaxBandwidthOut specifies only the maximum available bandwidth.
        # 
        # For the classic network, the default value is PayByBandwidth. For VPCs, the default value is PayByTraffic.
        self.internet_charge_type = internet_charge_type  # type: str
        # The maximum inbound public bandwidth. Unit: Mbit/s. Valid values: 1 to 200.
        # 
        # Default value: 200 This parameter is not used for billing because inbound traffic to instances is free of charge.
        self.internet_max_bandwidth_in = internet_max_bandwidth_in  # type: int
        # The maximum outbound public bandwidth. Unit: Mbit/s. Valid values:
        # 
        # *   Valid values if you set InternetChargeType to PayByBandwidth: 0 to 100. If you leave this parameter empty, this parameter is automatically set to 0.
        # *   Valid values if you set InternetChargeType to PayByTraffic: 0 to 100. If you leave this parameter empty, an error is returned.
        self.internet_max_bandwidth_out = internet_max_bandwidth_out  # type: int
        # Specifies whether to create an I/O optimized instance. Valid values:
        # 
        # none: does not create an I/O optimized instance. optimized: creates an I/O optimized instance.
        # 
        # For instances of retired instance types, the default value is none. For instances of other instance types, the default value is optimized.
        self.io_optimized = io_optimized  # type: str
        # The number of randomly generated IPv6 addresses that you want to allocate to the elastic network interface (ENI).
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The name of the key pair that you want to use to log on to an ECS instance.
        # 
        # *   Windows instances do not support this parameter.
        # *   By default, the username and password authentication method is disabled for Linux instances.
        self.key_pair_name = key_pair_name  # type: str
        # The weight of an ECS instance as a backend server. Valid values: 1 to 100.
        # 
        # Default value: 50
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size. Unit: GiB.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set Cpu to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify Cpu and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify instance types in the scaling configuration.
        self.memory = memory  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The password that you want to use to log on to an ECS instance. The password must be 8 to 30 characters in length and must contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters. The following special characters are supported:
        # 
        # `` `() ~!@#$%^&*-_+=\|{}[]:;\"<>,.?/ ``
        # 
        # The password of a Windows instance cannot start with a forward slash (/).
        # 
        # > For security reasons, we recommend that you use HTTPS to send requests if you specify Password.
        self.password = password  # type: str
        # Specifies whether to use the password that is preconfigured in the image. Before you use this parameter, make sure that a password is configured in the image. Valid values:
        # 
        # *   true
        # *   false
        self.password_inherit = password_inherit  # type: bool
        # The name of the RAM role that you attach to the ECS instance. The name is provided and maintained by Resource Access Management (RAM). You can call the ListRoles operation to query the available RAM roles.
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group to which the ECS instances that are created by using the scaling configuration belong.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The name of the scaling configuration. The name must be 2 to 64 characters in length and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # The name of the scaling configuration must be unique in a region. If you do not specify this parameter, the scaling configuration ID is used.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The ID of the scaling group in which you want to create a scaling configuration.
        self.scaling_group_id = scaling_group_id  # type: str
        # The scheduler options.
        self.scheduler_options_shrink = scheduler_options_shrink  # type: str
        # Specifies whether to enable security hardening. Valid values:
        # 
        # *   Active: enables security hardening. This value is applicable only to public images.
        # *   Deactive: disables security hardening. This value is applicable to all image types.
        self.security_enhancement_strategy = security_enhancement_strategy  # type: str
        # The ID of the security group with which ECS instances are associated. ECS instances that are associated with the same security group can access each other.
        self.security_group_id = security_group_id  # type: str
        # The IDs of the security groups with which you want to associate the ECS instances that are created by using the scaling configuration. For more information, see the "Security group limits" section of the "[Limits](~~25412~~)" topic.
        # 
        # > If you specify SecurityGroupId, you cannot specify SecurityGroupIds.
        self.security_group_ids = security_group_ids  # type: list[str]
        # The retention period of the preemptible instance. Unit: hours. Valid values: 0, 1, 2, 3, 4, 5, and 6.
        # 
        # *   The following retention periods are available in invitational preview: 2, 3, 4, 5, and 6 hours. If you want to set this parameter to one of these values, submit a ticket.
        # *   If you set this parameter to 0, no protection period is specified for the preemptible instance.
        # 
        # Default value: 1
        self.spot_duration = spot_duration  # type: int
        # The interruption mode of the preemptible instance. Set the value to Terminate. The value specifies that the preemptible instance is to be released.
        self.spot_interruption_behavior = spot_interruption_behavior  # type: str
        # The billing information of the preemptible instances.
        self.spot_price_limits = spot_price_limits  # type: list[CreateScalingConfigurationShrinkRequestSpotPriceLimits]
        # The preemption policy that you want to apply to pay-as-you-go and preemptible instances. Valid values:
        # 
        # *   NoSpot: The instance is created as a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance that has a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is created as a preemptible instance for which the market price at the time of purchase is automatically used as the bid price.
        # 
        # Default value: NoSpot
        self.spot_strategy = spot_strategy  # type: str
        self.storage_set_id = storage_set_id  # type: str
        self.storage_set_partition_number = storage_set_partition_number  # type: int
        # The categories of the system disks. If Auto Scaling cannot create instances by using the disk category that has the highest priority, Auto Scaling creates instances by using the disk category that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        # 
        # > If you specify SystemDiskCategories, you cannot specify `SystemDisk.Category`.
        self.system_disk_categories = system_disk_categories  # type: list[str]
        # The tags of the ECS instance. Tags must be specified as key-value pairs. You can specify up to 20 tags. When you specify tag keys and tag values, take note of the following items:
        # 
        # *   A tag key can be up to 64 characters in length. The key cannot start with acs: or aliyun and cannot contain `http://` or `https://`. You cannot specify an empty string as a tag key.
        # *   A tag value can be up to 128 characters in length. The value cannot start with acs: or aliyun and cannot contain `http://` or `https://`. You can specify an empty string as a tag value.
        self.tags = tags  # type: str
        # Specifies whether to create an ECS instance on a dedicated host. Valid values:
        # 
        # *   default: does not create an ECS instance on a dedicated host.
        # *   host: creates an ECS instance on a dedicated host. If you do not specify DedicatedHostId, Alibaba Cloud selects a dedicated host for the ECS instance.
        # 
        # Default value: default
        self.tenancy = tenancy  # type: str
        # The user data of the ECS instance. The data must be encoded in Base64. The maximum size of the data before encoding is 16 KB.
        self.user_data = user_data  # type: str
        # The zone ID of the ECS instance.
        self.zone_id = zone_id  # type: str

    def validate(self):
        if self.image_options:
            self.image_options.validate()
        if self.private_pool_options:
            self.private_pool_options.validate()
        if self.system_disk:
            self.system_disk.validate()
        if self.custom_priorities:
            for k in self.custom_priorities:
                if k:
                    k.validate()
        if self.data_disks:
            for k in self.data_disks:
                if k:
                    k.validate()
        if self.instance_pattern_infos:
            for k in self.instance_pattern_infos:
                if k:
                    k.validate()
        if self.instance_type_overrides:
            for k in self.instance_type_overrides:
                if k:
                    k.validate()
        if self.spot_price_limits:
            for k in self.spot_price_limits:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateScalingConfigurationShrinkRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.image_options is not None:
            result['ImageOptions'] = self.image_options.to_map()
        if self.private_pool_options is not None:
            result['PrivatePoolOptions'] = self.private_pool_options.to_map()
        if self.system_disk is not None:
            result['SystemDisk'] = self.system_disk.to_map()
        if self.affinity is not None:
            result['Affinity'] = self.affinity
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.credit_specification is not None:
            result['CreditSpecification'] = self.credit_specification
        result['CustomPriorities'] = []
        if self.custom_priorities is not None:
            for k in self.custom_priorities:
                result['CustomPriorities'].append(k.to_map() if k else None)
        result['DataDisks'] = []
        if self.data_disks is not None:
            for k in self.data_disks:
                result['DataDisks'].append(k.to_map() if k else None)
        if self.dedicated_host_id is not None:
            result['DedicatedHostId'] = self.dedicated_host_id
        if self.deletion_protection is not None:
            result['DeletionProtection'] = self.deletion_protection
        if self.deployment_set_id is not None:
            result['DeploymentSetId'] = self.deployment_set_id
        if self.host_name is not None:
            result['HostName'] = self.host_name
        if self.hpc_cluster_id is not None:
            result['HpcClusterId'] = self.hpc_cluster_id
        if self.image_family is not None:
            result['ImageFamily'] = self.image_family
        if self.image_id is not None:
            result['ImageId'] = self.image_id
        if self.image_name is not None:
            result['ImageName'] = self.image_name
        if self.instance_description is not None:
            result['InstanceDescription'] = self.instance_description
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        result['InstancePatternInfos'] = []
        if self.instance_pattern_infos is not None:
            for k in self.instance_pattern_infos:
                result['InstancePatternInfos'].append(k.to_map() if k else None)
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        result['InstanceTypeOverrides'] = []
        if self.instance_type_overrides is not None:
            for k in self.instance_type_overrides:
                result['InstanceTypeOverrides'].append(k.to_map() if k else None)
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.internet_charge_type is not None:
            result['InternetChargeType'] = self.internet_charge_type
        if self.internet_max_bandwidth_in is not None:
            result['InternetMaxBandwidthIn'] = self.internet_max_bandwidth_in
        if self.internet_max_bandwidth_out is not None:
            result['InternetMaxBandwidthOut'] = self.internet_max_bandwidth_out
        if self.io_optimized is not None:
            result['IoOptimized'] = self.io_optimized
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.key_pair_name is not None:
            result['KeyPairName'] = self.key_pair_name
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.password is not None:
            result['Password'] = self.password
        if self.password_inherit is not None:
            result['PasswordInherit'] = self.password_inherit
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduler_options_shrink is not None:
            result['SchedulerOptions'] = self.scheduler_options_shrink
        if self.security_enhancement_strategy is not None:
            result['SecurityEnhancementStrategy'] = self.security_enhancement_strategy
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.security_group_ids is not None:
            result['SecurityGroupIds'] = self.security_group_ids
        if self.spot_duration is not None:
            result['SpotDuration'] = self.spot_duration
        if self.spot_interruption_behavior is not None:
            result['SpotInterruptionBehavior'] = self.spot_interruption_behavior
        result['SpotPriceLimits'] = []
        if self.spot_price_limits is not None:
            for k in self.spot_price_limits:
                result['SpotPriceLimits'].append(k.to_map() if k else None)
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        if self.storage_set_id is not None:
            result['StorageSetId'] = self.storage_set_id
        if self.storage_set_partition_number is not None:
            result['StorageSetPartitionNumber'] = self.storage_set_partition_number
        if self.system_disk_categories is not None:
            result['SystemDiskCategories'] = self.system_disk_categories
        if self.tags is not None:
            result['Tags'] = self.tags
        if self.tenancy is not None:
            result['Tenancy'] = self.tenancy
        if self.user_data is not None:
            result['UserData'] = self.user_data
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ImageOptions') is not None:
            temp_model = CreateScalingConfigurationShrinkRequestImageOptions()
            self.image_options = temp_model.from_map(m['ImageOptions'])
        if m.get('PrivatePoolOptions') is not None:
            temp_model = CreateScalingConfigurationShrinkRequestPrivatePoolOptions()
            self.private_pool_options = temp_model.from_map(m['PrivatePoolOptions'])
        if m.get('SystemDisk') is not None:
            temp_model = CreateScalingConfigurationShrinkRequestSystemDisk()
            self.system_disk = temp_model.from_map(m['SystemDisk'])
        if m.get('Affinity') is not None:
            self.affinity = m.get('Affinity')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CreditSpecification') is not None:
            self.credit_specification = m.get('CreditSpecification')
        self.custom_priorities = []
        if m.get('CustomPriorities') is not None:
            for k in m.get('CustomPriorities'):
                temp_model = CreateScalingConfigurationShrinkRequestCustomPriorities()
                self.custom_priorities.append(temp_model.from_map(k))
        self.data_disks = []
        if m.get('DataDisks') is not None:
            for k in m.get('DataDisks'):
                temp_model = CreateScalingConfigurationShrinkRequestDataDisks()
                self.data_disks.append(temp_model.from_map(k))
        if m.get('DedicatedHostId') is not None:
            self.dedicated_host_id = m.get('DedicatedHostId')
        if m.get('DeletionProtection') is not None:
            self.deletion_protection = m.get('DeletionProtection')
        if m.get('DeploymentSetId') is not None:
            self.deployment_set_id = m.get('DeploymentSetId')
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        if m.get('HpcClusterId') is not None:
            self.hpc_cluster_id = m.get('HpcClusterId')
        if m.get('ImageFamily') is not None:
            self.image_family = m.get('ImageFamily')
        if m.get('ImageId') is not None:
            self.image_id = m.get('ImageId')
        if m.get('ImageName') is not None:
            self.image_name = m.get('ImageName')
        if m.get('InstanceDescription') is not None:
            self.instance_description = m.get('InstanceDescription')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        self.instance_pattern_infos = []
        if m.get('InstancePatternInfos') is not None:
            for k in m.get('InstancePatternInfos'):
                temp_model = CreateScalingConfigurationShrinkRequestInstancePatternInfos()
                self.instance_pattern_infos.append(temp_model.from_map(k))
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        self.instance_type_overrides = []
        if m.get('InstanceTypeOverrides') is not None:
            for k in m.get('InstanceTypeOverrides'):
                temp_model = CreateScalingConfigurationShrinkRequestInstanceTypeOverrides()
                self.instance_type_overrides.append(temp_model.from_map(k))
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('InternetChargeType') is not None:
            self.internet_charge_type = m.get('InternetChargeType')
        if m.get('InternetMaxBandwidthIn') is not None:
            self.internet_max_bandwidth_in = m.get('InternetMaxBandwidthIn')
        if m.get('InternetMaxBandwidthOut') is not None:
            self.internet_max_bandwidth_out = m.get('InternetMaxBandwidthOut')
        if m.get('IoOptimized') is not None:
            self.io_optimized = m.get('IoOptimized')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('KeyPairName') is not None:
            self.key_pair_name = m.get('KeyPairName')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('PasswordInherit') is not None:
            self.password_inherit = m.get('PasswordInherit')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('SchedulerOptions') is not None:
            self.scheduler_options_shrink = m.get('SchedulerOptions')
        if m.get('SecurityEnhancementStrategy') is not None:
            self.security_enhancement_strategy = m.get('SecurityEnhancementStrategy')
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SecurityGroupIds') is not None:
            self.security_group_ids = m.get('SecurityGroupIds')
        if m.get('SpotDuration') is not None:
            self.spot_duration = m.get('SpotDuration')
        if m.get('SpotInterruptionBehavior') is not None:
            self.spot_interruption_behavior = m.get('SpotInterruptionBehavior')
        self.spot_price_limits = []
        if m.get('SpotPriceLimits') is not None:
            for k in m.get('SpotPriceLimits'):
                temp_model = CreateScalingConfigurationShrinkRequestSpotPriceLimits()
                self.spot_price_limits.append(temp_model.from_map(k))
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        if m.get('StorageSetId') is not None:
            self.storage_set_id = m.get('StorageSetId')
        if m.get('StorageSetPartitionNumber') is not None:
            self.storage_set_partition_number = m.get('StorageSetPartitionNumber')
        if m.get('SystemDiskCategories') is not None:
            self.system_disk_categories = m.get('SystemDiskCategories')
        if m.get('Tags') is not None:
            self.tags = m.get('Tags')
        if m.get('Tenancy') is not None:
            self.tenancy = m.get('Tenancy')
        if m.get('UserData') is not None:
            self.user_data = m.get('UserData')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class CreateScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_configuration_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling configuration.
        self.scaling_configuration_id = scaling_configuration_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        return self


class CreateScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateScalingGroupRequestAlbServerGroups(TeaModel):
    def __init__(self, alb_server_group_id=None, port=None, weight=None):
        # The ID of the ALB server group that you want to associate with the scaling group.
        # 
        # You can associate only a limited number of ALB server groups with a scaling group. Go to [Quota Center](https://quotas.console.aliyun.com/products/ess/quotas) to check the maximum number of ALB server groups that you can associate with a scaling group.
        self.alb_server_group_id = alb_server_group_id  # type: str
        # The port number that is used by an ECS instance after Auto Scaling adds the ECS instance to the ALB server group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The weight of an ECS instance after Auto Scaling adds the ECS instance to the ALB server group as a backend server. If you increase the weight of an ECS instance in the ALB server group, the number of access requests that are forwarded to the ECS instance increases. If you set the Weight parameter for an ECS instance in the ALB server group to 0, no access requests are forwarded to the ECS instance. Valid values: 0 to 100.
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestAlbServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alb_server_group_id is not None:
            result['AlbServerGroupId'] = self.alb_server_group_id
        if self.port is not None:
            result['Port'] = self.port
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlbServerGroupId') is not None:
            self.alb_server_group_id = m.get('AlbServerGroupId')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class CreateScalingGroupRequestLaunchTemplateOverrides(TeaModel):
    def __init__(self, instance_type=None, spot_price_limit=None, weighted_capacity=None):
        # The instance type that you want to use to override the instance type that is specified in the launch template.
        # 
        # If you want to scale instances based on the weighted capacities of the instances, you must specify both the InstanceType and WeightedCapacity parameters.
        # 
        # > This parameter is available only if you specify the LaunchTemplateId parameter.
        # 
        # You can use the InstanceType parameter to specify only instance types that are available for purchase.
        self.instance_type = instance_type  # type: str
        # The maximum bid price of the instance type that is specified by the `InstanceType` parameter. You can specify 1 to 10 instance types by using the Extended Configurations feature of the launch template.
        # 
        # > This parameter is available only if you specify the `LaunchTemplateId` parameter.
        self.spot_price_limit = spot_price_limit  # type: float
        # The weight of the instance type. The weight specifies the capacity of an instance of the specified instance type in the scaling group. If you want to scale instances based on the weighted capacities of the instances, you must specify the WeightedCapacity parameter after you specify the InstanceType parameter.
        # 
        # A higher weight specifies that a smaller number of instances of the specified instance type are required to meet the expected capacity requirement.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by the MaxSize parameter and the maximum weight of the instance types.
        # 
        # Valid values of the WeightedCapacity parameter: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestLaunchTemplateOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class CreateScalingGroupRequestLifecycleHooks(TeaModel):
    def __init__(self, default_result=None, heartbeat_timeout=None, lifecycle_hook_name=None,
                 lifecycle_transition=None, notification_arn=None, notification_metadata=None):
        # The action that Auto Scaling performs after the lifecycle hook of the scaling group times out. Valid values:
        # 
        # *   CONTINUE: continues to respond to scaling requests.
        # *   ABANDON: releases ECS instances that are created during scale-out activities, or removes ECS instances from the scaling group during scale-in activities.
        # 
        # If multiple lifecycle hooks in the scaling group are triggered during scale-in activities and you set the LifecycleHook.N.DefaultResult parameter to ABANDON for one of the lifecycle hooks, Auto Scaling immediately performs the action after the lifecycle hook whose DefaultResult parameter is set to ABANDON times out. In this case, other lifecycle hooks time out ahead of schedule. In other cases, Auto Scaling performs the action only after all lifecycle hooks time out. The action that Auto Scaling performs is determined by the value of the DefaultResult parameter that you set for the lifecycle hook that last times out.
        # 
        # Default value: CONTINUE.
        self.default_result = default_result  # type: str
        # The period of time before the lifecycle hook times out. When the lifecycle hook times out, Auto Scaling performs the action specified by the DefaultResult parameter. Valid values: 30 to 21600. Unit: seconds.
        # 
        # After you create a lifecycle hook, you can call the RecordLifecycleActionHeartbeat operation to extend the timeout period of the lifecycle hook. You can also call the CompleteLifecycleAction operation to end the timeout period ahead of schedule.
        # 
        # Default value: 600.
        self.heartbeat_timeout = heartbeat_timeout  # type: int
        # The name of the lifecycle hook. After you specify this parameter, you cannot change the value of this parameter. If you do not specify this parameter, the ID of the lifecycle hook is used.
        self.lifecycle_hook_name = lifecycle_hook_name  # type: str
        # The type of the scaling activity for which you create the lifecycle hook. Valid values:
        # 
        # *   SCALE_OUT: scale-out activity
        # *   SCALE_IN: scale-in activity
        # 
        # > If you create lifecycle hooks for your scaling group, you must specify the LifecycleTransition parameter.
        self.lifecycle_transition = lifecycle_transition  # type: str
        # The Alibaba Cloud Resource Name (ARN) of the notification method that Auto Scaling uses to send a notification when a lifecycle hook takes effect. This notification method can be a Message Service (MNS) queue or an MNS topic. Specify the value of this parameter in the following format: acs:ess:{region}:{account-id}:{resource-relative-id}.
        # 
        # *   region: the region where the scaling group resides
        # *   account-id: the ID of the Alibaba Cloud account
        # 
        # Examples:
        # 
        # *   MNS queue: acs:ess:{region}:{account-id}:queue/{queuename}
        # *   MNS topic: acs:ess:{region}:{account-id}:topic/{topicname}
        self.notification_arn = notification_arn  # type: str
        # The fixed string that is included in a notification. Auto Scaling sends the notification when the lifecycle hook takes effect. The value of this parameter cannot exceed 4,096 characters in length. Auto Scaling sends the value of the notificationmetadata parameter together with the notification. This way, you can categorize and manage your notifications in an efficient manner. If you specify the notificationmetadata parameter, you must also specify the notificationarn parameter.
        self.notification_metadata = notification_metadata  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestLifecycleHooks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.default_result is not None:
            result['DefaultResult'] = self.default_result
        if self.heartbeat_timeout is not None:
            result['HeartbeatTimeout'] = self.heartbeat_timeout
        if self.lifecycle_hook_name is not None:
            result['LifecycleHookName'] = self.lifecycle_hook_name
        if self.lifecycle_transition is not None:
            result['LifecycleTransition'] = self.lifecycle_transition
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_metadata is not None:
            result['NotificationMetadata'] = self.notification_metadata
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DefaultResult') is not None:
            self.default_result = m.get('DefaultResult')
        if m.get('HeartbeatTimeout') is not None:
            self.heartbeat_timeout = m.get('HeartbeatTimeout')
        if m.get('LifecycleHookName') is not None:
            self.lifecycle_hook_name = m.get('LifecycleHookName')
        if m.get('LifecycleTransition') is not None:
            self.lifecycle_transition = m.get('LifecycleTransition')
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationMetadata') is not None:
            self.notification_metadata = m.get('NotificationMetadata')
        return self


class CreateScalingGroupRequestLoadBalancerConfigs(TeaModel):
    def __init__(self, load_balancer_id=None, weight=None):
        self.load_balancer_id = load_balancer_id  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestLoadBalancerConfigs, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class CreateScalingGroupRequestServerGroups(TeaModel):
    def __init__(self, port=None, server_group_id=None, type=None, weight=None):
        # The port number that is used by an ECS instance after Auto Scaling adds the ECS instance to the server group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The ID of the server group.
        self.server_group_id = server_group_id  # type: str
        # The type of the server group. Valid values:
        # 
        # *   ALB: Application Load Balancer (ALB) server group
        # *   NLB: Network Load Balancer (NLB) server group
        self.type = type  # type: str
        # The weight of an Elastic Compute Service (ECS) instance in the scaling group as a backend server after Auto Scaling adds the ECS instance to the server group. Valid values: 0 to 100.
        # 
        # If you increase the weight of an ECS instance in the server group, the number of access requests that are forwarded to the ECS instance also increases. If you set the Weight parameter of an ECS instance in the server group to 0, no access requests are forwarded to the ECS instance.
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.server_group_id is not None:
            result['ServerGroupId'] = self.server_group_id
        if self.type is not None:
            result['Type'] = self.type
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ServerGroupId') is not None:
            self.server_group_id = m.get('ServerGroupId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class CreateScalingGroupRequestTags(TeaModel):
    def __init__(self, key=None, propagate=None, value=None):
        # The tag key that you want to add to the scaling group.
        self.key = key  # type: str
        self.propagate = propagate  # type: bool
        # The tag value that you want to add to the scaling group.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.propagate is not None:
            result['Propagate'] = self.propagate
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Propagate') is not None:
            self.propagate = m.get('Propagate')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class CreateScalingGroupRequestVServerGroupsVServerGroupAttributes(TeaModel):
    def __init__(self, port=None, vserver_group_id=None, weight=None):
        # The port number that is used by an ECS instance after Auto Scaling adds the ECS instance to the backend vServer group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The ID of the backend vServer group.
        self.vserver_group_id = vserver_group_id  # type: str
        # The weight of an ECS instance after Auto Scaling adds the ECS instance to the backend vServer group as a backend server. If you increase the weight of an ECS instance in the backend vServer group, the number of access requests that are forwarded to the ECS instance also increases. If you set the Weight parameter of an ECS instance in the backend vServer group to 0, no access requests are forwarded to the ECS instance. Valid values: 0 to 100. Default value: 50.
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupRequestVServerGroupsVServerGroupAttributes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.vserver_group_id is not None:
            result['VServerGroupId'] = self.vserver_group_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('VServerGroupId') is not None:
            self.vserver_group_id = m.get('VServerGroupId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class CreateScalingGroupRequestVServerGroups(TeaModel):
    def __init__(self, load_balancer_id=None, vserver_group_attributes=None):
        # The ID of the CLB instance to which the backend vServer group belongs.
        self.load_balancer_id = load_balancer_id  # type: str
        # The attributes of the backend vServer groups.
        self.vserver_group_attributes = vserver_group_attributes  # type: list[CreateScalingGroupRequestVServerGroupsVServerGroupAttributes]

    def validate(self):
        if self.vserver_group_attributes:
            for k in self.vserver_group_attributes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateScalingGroupRequestVServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        result['VServerGroupAttributes'] = []
        if self.vserver_group_attributes is not None:
            for k in self.vserver_group_attributes:
                result['VServerGroupAttributes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        self.vserver_group_attributes = []
        if m.get('VServerGroupAttributes') is not None:
            for k in m.get('VServerGroupAttributes'):
                temp_model = CreateScalingGroupRequestVServerGroupsVServerGroupAttributes()
                self.vserver_group_attributes.append(temp_model.from_map(k))
        return self


class CreateScalingGroupRequest(TeaModel):
    def __init__(self, alb_server_groups=None, allocation_strategy=None, az_balance=None, client_token=None,
                 compensate_with_on_demand=None, container_group_id=None, custom_policy_arn=None, dbinstance_ids=None, default_cooldown=None,
                 desired_capacity=None, group_deletion_protection=None, group_type=None, health_check_type=None,
                 health_check_types=None, instance_id=None, launch_template_id=None, launch_template_overrides=None,
                 launch_template_version=None, lifecycle_hooks=None, load_balancer_configs=None, load_balancer_ids=None,
                 max_instance_lifetime=None, max_size=None, min_size=None, multi_azpolicy=None, on_demand_base_capacity=None,
                 on_demand_percentage_above_base_capacity=None, owner_account=None, owner_id=None, region_id=None, removal_policies=None,
                 resource_group_id=None, resource_owner_account=None, scaling_group_name=None, scaling_policy=None,
                 server_groups=None, spot_allocation_strategy=None, spot_instance_pools=None, spot_instance_remedy=None,
                 sync_alarm_rule_to_cms=None, tags=None, vserver_groups=None, v_switch_id=None, v_switch_ids=None):
        # Details of the Application Load Balancer (ALB) server groups that you want to associate with the scaling group.
        self.alb_server_groups = alb_server_groups  # type: list[CreateScalingGroupRequestAlbServerGroups]
        # The allocation policy of instances. Auto Scaling selects instance types based on the allocation policy to create the required number of instances. The policy can be applied to pay-as-you-go instances and preemptible instances. This parameter takes effect only when you set the `MultiAZPolicy` parameter to `COMPOSABLE`. Valid values:
        # 
        # *   priority: Auto Scaling selects instance types based on the specified order of the instance types to create the required number of instances.
        # *   lowestPrice: Auto Scaling selects instance types that have the lowest unit price of vCPUs to create the required number of instances.
        # 
        # Default value: priority.
        self.allocation_strategy = allocation_strategy  # type: str
        # Specifies whether to evenly distribute instances in the scaling group across zones. This parameter is available only if you set the `MultiAZPolicy` parameter to `COMPOSABLE`. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.az_balance = az_balance  # type: bool
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the token, but you must make sure that the token is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [Ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to automatically create pay-as-you-go instances to meet the requirement on the number of ECS instances when the expected capacity of preemptible instances cannot be provided due to reasons such as cost-related issues and insufficient resources. This parameter is available only if you set the MultiAZPolicy parameter to COST_OPTIMIZED. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: true.
        self.compensate_with_on_demand = compensate_with_on_demand  # type: bool
        # The ID of the elastic container instance.
        self.container_group_id = container_group_id  # type: str
        # The Alibaba Cloud Resource Name (ARN) of the custom scale-in policy (Function). This parameter is available only if you specify CustomPolicy as the first step to remove instances.
        self.custom_policy_arn = custom_policy_arn  # type: str
        # The IDs of the ApsaraDB RDS instances that you want to associate with the scaling group. The value can be a JSON array that contains multiple ApsaraDB RDS instance IDs. Separate multiple IDs with commas (,).
        # 
        # You can associate only a limited number of ApsaraDB RDS instances with a scaling group. Go to [Quota Center](https://quotas.console.aliyun.com/products/ess/quotas) to check the maximum number of ApsaraDB RDS instances that you can associate with a scaling group.
        self.dbinstance_ids = dbinstance_ids  # type: str
        # The cooldown period of the scaling group after a scaling activity is complete. Valid values: 0 to 86400. Unit: seconds.
        # 
        # During the cooldown period, Auto Scaling executes only scaling activities that are triggered by CloudMonitor event-triggered tasks.
        # 
        # Default value: 300.
        self.default_cooldown = default_cooldown  # type: int
        # The expected number of ECS instances in the scaling group. Auto Scaling automatically maintains the expected number of ECS instances. The value of the DesiredCapacity parameter cannot be greater than the value of the MaxSize parameter and less than the value of the MinSize parameter.
        self.desired_capacity = desired_capacity  # type: int
        # Specifies whether to enable deletion protection for the scaling group. Valid values:
        # 
        # *   true: enables deletion protection for the scaling group. This way, the scaling group cannot be deleted.
        # *   false: disables deletion protection for the scaling group.
        # 
        # Default value: false.
        self.group_deletion_protection = group_deletion_protection  # type: bool
        # The type of the instances that are managed by the scaling group. Valid values:
        # 
        # *   ECS: ECS instances.
        # *   ECI: elastic container instances.
        # 
        # Default value: ECS.
        self.group_type = group_type  # type: str
        # The health check mode of the scaling group. Valid values:
        # 
        # *   NONE: Auto Scaling does not perform health checks on instances in the scaling group.
        # *   ECS: Auto Scaling performs health checks on ECS instances in the scaling group.
        # 
        # Default value: ECS.
        self.health_check_type = health_check_type  # type: str
        self.health_check_types = health_check_types  # type: list[str]
        # The ID of the existing ECS instance that provides instance configurations for Auto Scaling to create a scaling configuration.
        self.instance_id = instance_id  # type: str
        # The ID of the launch template that provides instance configurations for Auto Scaling to create instances.
        self.launch_template_id = launch_template_id  # type: str
        # Details of the instance types that you specify by using the Extended Configurations feature of the launch template.
        self.launch_template_overrides = launch_template_overrides  # type: list[CreateScalingGroupRequestLaunchTemplateOverrides]
        # The version number of the launch template. Valid values:
        # 
        # *   A fixed template version number.
        # *   Default: the default template version.
        # *   Latest: the latest template version.
        self.launch_template_version = launch_template_version  # type: str
        # The lifecycle hooks.
        self.lifecycle_hooks = lifecycle_hooks  # type: list[CreateScalingGroupRequestLifecycleHooks]
        self.load_balancer_configs = load_balancer_configs  # type: list[CreateScalingGroupRequestLoadBalancerConfigs]
        # The IDs of the CLB instances that you want to associate with the scaling group. The value can be a JSON array that contains multiple CLB instance IDs. Separate multiple IDs with commas (,).
        # 
        # You can associate only a limited number of CLB instances with a scaling group. Go to [Quota Center](https://quotas.console.aliyun.com/products/ess/quotas) to check the maximum number of CLB instances that you can associate with a scaling group.
        self.load_balancer_ids = load_balancer_ids  # type: str
        # The maximum life span of an instance in the scaling group. Unit: seconds.
        # 
        # Valid values: 86400 to the value of the Integer.maxValue parameter.
        # 
        # Default value: null.
        self.max_instance_lifetime = max_instance_lifetime  # type: int
        # The maximum number of ECS instances that can be contained in the scaling group. If the number of ECS instances in the scaling group is greater than the value of the MaxSize parameter, Auto Scaling removes ECS instances from the scaling group to ensure that the number of ECS instances is equal to the value of the MaxSize parameter.
        # 
        # The value range of the MaxSize parameter varies based on the instance quota. You can go to [Quota Center](https://quotas.console.aliyun.com/products/ess/quotas) to check the maximum number of instances that a scaling group can contain.****\
        # 
        # For example, if the instance quota is 2,000, the value range of the **MaxSize** parameter is 0 to 2000.
        self.max_size = max_size  # type: int
        # The minimum number of ECS instances that must be contained in the scaling group. If the number of ECS instances in the scaling group is less than the value of the MinSize parameter, Auto Scaling adds ECS instances to the scaling group to ensure that the number of ECS instances in the scaling group is equal to the value of the MinSize parameter.
        # 
        # > The value of the MinSize parameter must be less than or equal to the value of the MaxSize parameter.
        self.min_size = min_size  # type: int
        # The scaling policy for the multi-zone scaling group that contains ECS instances. Valid values:
        # 
        # *   PRIORITY: scales ECS instances based on the priority of the vSwitch that is specified by the VSwitchIds parameter. Auto Scaling preferentially scales instances in the zone where the vSwitch that has the highest priority resides. If the scaling fails, Auto Scaling scales instances in the zone where the vSwitch that has the next highest priority resides.
        # 
        # *   COST_OPTIMIZED: scales ECS instances based on the unit price of vCPUs. Auto Scaling preferentially scales out ECS instances whose vCPUs are provided at the lowest price and scales in ECS instances whose vCPUs are provided at the highest price. If preemptible instance types are specified in the scaling configuration, Auto Scaling preferentially scales out preemptible instances. You can use the CompensateWithOnDemand parameter to specify whether to automatically create pay-as-you-go instances when preemptible instances cannot be created due to insufficient resources.
        # 
        #     **\
        # 
        #     **Note**The COST_OPTIMIZED setting takes effect only when multiple instance types are specified or at least one preemptible instance type is specified.
        # 
        # *   BALANCE: evenly distributes ECS instances across zones that are specified for the scaling group. If ECS instances are unevenly distributed across zones due to insufficient resources, you can call the [RebalanceInstance](~~71516~~) operation to evenly redistribute the instances across the zones.
        # 
        # Default value: PRIORITY.
        self.multi_azpolicy = multi_azpolicy  # type: str
        # The minimum number of pay-as-you-go instances that must be contained in the scaling group. Valid values: 0 to 1000. If the number of pay-as-you-go instances is less than the value of this parameter, Auto Scaling preferentially creates pay-as-you-go instances.
        self.on_demand_base_capacity = on_demand_base_capacity  # type: int
        # The percentage of pay-as-you-go instances in the excess instances when the minimum number of pay-as-you-go instances reaches the requirement. Valid values: 0 to 100.
        self.on_demand_percentage_above_base_capacity = on_demand_percentage_above_base_capacity  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        # The instance removal policies. Valid values:
        # 
        # *   OldestInstance: removes ECS instances that are added at the earliest point in time to the scaling group.
        # *   NewestInstance: removes ECS instances that are most recently added to the scaling group.
        # *   OldestScalingConfiguration: removes ECS instances that are created based on the earliest scaling configuration.
        # *   CustomPolicy: removes ECS instances based on the custom scale-in policy (Function).
        # 
        # The scaling configuration source specified by the OldestScalingConfiguration setting can be a scaling configuration or a launch template. The CustomPolicy setting takes effect only if you specify it as the first step to remove instances. If you specify CustomPolicy, you must also specify the CustomPolicyARN parameter.
        # 
        # > The removal of ECS instances from a scaling group is also affected by the value of the MultiAZPolicy parameter. For more information, see the [Configure a combination policy for removing instances](~~254822~~) topic.
        self.removal_policies = removal_policies  # type: list[str]
        # The ID of the resource group to which you want to add the scaling group.
        # 
        # > If you specify this parameter, new scaling groups are added to the specified resource group. If you do not specify this parameter, new scaling groups are added to the default resource group.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The name of the scaling group. The name of each scaling group must be unique in a region.
        # 
        # The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # If you do not specify this parameter, the value of the ScalingGroupId parameter is used.
        self.scaling_group_name = scaling_group_name  # type: str
        # The reclaim mode of the scaling group. Valid values:
        # 
        # *   recycle: economical mode.
        # *   release: release mode.
        # 
        # The ScalingPolicy parameter specifies the reclaim mode of the scaling group. The RemovePolicy parameter of the RemoveInstances operation specifies how to remove instances in a specific manner.
        self.scaling_policy = scaling_policy  # type: str
        # Details of the server groups.
        # 
        # >  You cannot use the AlbServerGroups parameter and the ServerGroups parameter to specify the same server group.
        self.server_groups = server_groups  # type: list[CreateScalingGroupRequestServerGroups]
        # The allocation policy of preemptible instances. You can use this parameter to individually specify the allocation policy of preemptible instances. This parameter takes effect only if you set the `MultiAZPolicy` parameter to `COMPOSABLE`. Valid values:
        # 
        # *   priority: Auto Scaling selects instance types based on the specified order of the instance types to create the required number of preemptible instances.
        # *   lowestPrice: Auto Scaling selects instance types that have the lowest unit price of vCPUs to create the required number of preemptible instances.
        # 
        # Default value: priority.
        self.spot_allocation_strategy = spot_allocation_strategy  # type: str
        # The number of available instance types. Auto Scaling evenly creates preemptible instances of multiple instance types that are provided at the lowest cost in the scaling group. Valid values: 1 to 10.
        self.spot_instance_pools = spot_instance_pools  # type: int
        # Specifies whether to supplement preemptible instances. If you set this parameter to true, Auto Scaling creates an instance to replace a preemptible instance when Auto Scaling receives a system message which indicates that the preemptible instance is to be reclaimed.
        self.spot_instance_remedy = spot_instance_remedy  # type: bool
        # > This parameter is unavailable.
        self.sync_alarm_rule_to_cms = sync_alarm_rule_to_cms  # type: bool
        # Details of the tags that you want to add to the scaling group.
        self.tags = tags  # type: list[CreateScalingGroupRequestTags]
        # Details of the backend vServer groups that you want to associate with the scaling group.
        self.vserver_groups = vserver_groups  # type: list[CreateScalingGroupRequestVServerGroups]
        # The ID of the vSwitch. If you specify the VSwitchId parameter, the network type of the scaling group is VPC.
        # 
        # > If you do not specify the VSwitchId or VSwitchIds parameter, the network type of the scaling group is classic network.
        self.v_switch_id = v_switch_id  # type: str
        # The IDs of vSwitches. If you specify the VSwitchIds parameter, the VSwitchId parameter is ignored. If you specify the VSwitchIds parameter, the network type of the scaling group is VPC.
        # 
        # If you specify multiple vSwitches, take note of the following items:
        # 
        # *   The vSwitches must belong to the same VPC.
        # *   The vSwitches can belong to different zones.
        # *   The vSwitches are sorted in ascending order of priority. The first vSwitch that is specified by the VSwitchIds parameter has the highest priority. If Auto Scaling fails to create ECS instances in the zone where the vSwitch that has the highest priority resides, Auto Scaling creates ECS instances in the zone where the vSwitch that has the next highest priority resides.
        # 
        # > If you do not specify the VSwitchId or VSwitchIds parameter, the network type of the scaling group is classic network.
        self.v_switch_ids = v_switch_ids  # type: list[str]

    def validate(self):
        if self.alb_server_groups:
            for k in self.alb_server_groups:
                if k:
                    k.validate()
        if self.launch_template_overrides:
            for k in self.launch_template_overrides:
                if k:
                    k.validate()
        if self.lifecycle_hooks:
            for k in self.lifecycle_hooks:
                if k:
                    k.validate()
        if self.load_balancer_configs:
            for k in self.load_balancer_configs:
                if k:
                    k.validate()
        if self.server_groups:
            for k in self.server_groups:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.vserver_groups:
            for k in self.vserver_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateScalingGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AlbServerGroups'] = []
        if self.alb_server_groups is not None:
            for k in self.alb_server_groups:
                result['AlbServerGroups'].append(k.to_map() if k else None)
        if self.allocation_strategy is not None:
            result['AllocationStrategy'] = self.allocation_strategy
        if self.az_balance is not None:
            result['AzBalance'] = self.az_balance
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.compensate_with_on_demand is not None:
            result['CompensateWithOnDemand'] = self.compensate_with_on_demand
        if self.container_group_id is not None:
            result['ContainerGroupId'] = self.container_group_id
        if self.custom_policy_arn is not None:
            result['CustomPolicyARN'] = self.custom_policy_arn
        if self.dbinstance_ids is not None:
            result['DBInstanceIds'] = self.dbinstance_ids
        if self.default_cooldown is not None:
            result['DefaultCooldown'] = self.default_cooldown
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.group_deletion_protection is not None:
            result['GroupDeletionProtection'] = self.group_deletion_protection
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.health_check_type is not None:
            result['HealthCheckType'] = self.health_check_type
        if self.health_check_types is not None:
            result['HealthCheckTypes'] = self.health_check_types
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.launch_template_id is not None:
            result['LaunchTemplateId'] = self.launch_template_id
        result['LaunchTemplateOverrides'] = []
        if self.launch_template_overrides is not None:
            for k in self.launch_template_overrides:
                result['LaunchTemplateOverrides'].append(k.to_map() if k else None)
        if self.launch_template_version is not None:
            result['LaunchTemplateVersion'] = self.launch_template_version
        result['LifecycleHooks'] = []
        if self.lifecycle_hooks is not None:
            for k in self.lifecycle_hooks:
                result['LifecycleHooks'].append(k.to_map() if k else None)
        result['LoadBalancerConfigs'] = []
        if self.load_balancer_configs is not None:
            for k in self.load_balancer_configs:
                result['LoadBalancerConfigs'].append(k.to_map() if k else None)
        if self.load_balancer_ids is not None:
            result['LoadBalancerIds'] = self.load_balancer_ids
        if self.max_instance_lifetime is not None:
            result['MaxInstanceLifetime'] = self.max_instance_lifetime
        if self.max_size is not None:
            result['MaxSize'] = self.max_size
        if self.min_size is not None:
            result['MinSize'] = self.min_size
        if self.multi_azpolicy is not None:
            result['MultiAZPolicy'] = self.multi_azpolicy
        if self.on_demand_base_capacity is not None:
            result['OnDemandBaseCapacity'] = self.on_demand_base_capacity
        if self.on_demand_percentage_above_base_capacity is not None:
            result['OnDemandPercentageAboveBaseCapacity'] = self.on_demand_percentage_above_base_capacity
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.removal_policies is not None:
            result['RemovalPolicies'] = self.removal_policies
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_name is not None:
            result['ScalingGroupName'] = self.scaling_group_name
        if self.scaling_policy is not None:
            result['ScalingPolicy'] = self.scaling_policy
        result['ServerGroups'] = []
        if self.server_groups is not None:
            for k in self.server_groups:
                result['ServerGroups'].append(k.to_map() if k else None)
        if self.spot_allocation_strategy is not None:
            result['SpotAllocationStrategy'] = self.spot_allocation_strategy
        if self.spot_instance_pools is not None:
            result['SpotInstancePools'] = self.spot_instance_pools
        if self.spot_instance_remedy is not None:
            result['SpotInstanceRemedy'] = self.spot_instance_remedy
        if self.sync_alarm_rule_to_cms is not None:
            result['SyncAlarmRuleToCms'] = self.sync_alarm_rule_to_cms
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        result['VServerGroups'] = []
        if self.vserver_groups is not None:
            for k in self.vserver_groups:
                result['VServerGroups'].append(k.to_map() if k else None)
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        if self.v_switch_ids is not None:
            result['VSwitchIds'] = self.v_switch_ids
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.alb_server_groups = []
        if m.get('AlbServerGroups') is not None:
            for k in m.get('AlbServerGroups'):
                temp_model = CreateScalingGroupRequestAlbServerGroups()
                self.alb_server_groups.append(temp_model.from_map(k))
        if m.get('AllocationStrategy') is not None:
            self.allocation_strategy = m.get('AllocationStrategy')
        if m.get('AzBalance') is not None:
            self.az_balance = m.get('AzBalance')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('CompensateWithOnDemand') is not None:
            self.compensate_with_on_demand = m.get('CompensateWithOnDemand')
        if m.get('ContainerGroupId') is not None:
            self.container_group_id = m.get('ContainerGroupId')
        if m.get('CustomPolicyARN') is not None:
            self.custom_policy_arn = m.get('CustomPolicyARN')
        if m.get('DBInstanceIds') is not None:
            self.dbinstance_ids = m.get('DBInstanceIds')
        if m.get('DefaultCooldown') is not None:
            self.default_cooldown = m.get('DefaultCooldown')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('GroupDeletionProtection') is not None:
            self.group_deletion_protection = m.get('GroupDeletionProtection')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('HealthCheckType') is not None:
            self.health_check_type = m.get('HealthCheckType')
        if m.get('HealthCheckTypes') is not None:
            self.health_check_types = m.get('HealthCheckTypes')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('LaunchTemplateId') is not None:
            self.launch_template_id = m.get('LaunchTemplateId')
        self.launch_template_overrides = []
        if m.get('LaunchTemplateOverrides') is not None:
            for k in m.get('LaunchTemplateOverrides'):
                temp_model = CreateScalingGroupRequestLaunchTemplateOverrides()
                self.launch_template_overrides.append(temp_model.from_map(k))
        if m.get('LaunchTemplateVersion') is not None:
            self.launch_template_version = m.get('LaunchTemplateVersion')
        self.lifecycle_hooks = []
        if m.get('LifecycleHooks') is not None:
            for k in m.get('LifecycleHooks'):
                temp_model = CreateScalingGroupRequestLifecycleHooks()
                self.lifecycle_hooks.append(temp_model.from_map(k))
        self.load_balancer_configs = []
        if m.get('LoadBalancerConfigs') is not None:
            for k in m.get('LoadBalancerConfigs'):
                temp_model = CreateScalingGroupRequestLoadBalancerConfigs()
                self.load_balancer_configs.append(temp_model.from_map(k))
        if m.get('LoadBalancerIds') is not None:
            self.load_balancer_ids = m.get('LoadBalancerIds')
        if m.get('MaxInstanceLifetime') is not None:
            self.max_instance_lifetime = m.get('MaxInstanceLifetime')
        if m.get('MaxSize') is not None:
            self.max_size = m.get('MaxSize')
        if m.get('MinSize') is not None:
            self.min_size = m.get('MinSize')
        if m.get('MultiAZPolicy') is not None:
            self.multi_azpolicy = m.get('MultiAZPolicy')
        if m.get('OnDemandBaseCapacity') is not None:
            self.on_demand_base_capacity = m.get('OnDemandBaseCapacity')
        if m.get('OnDemandPercentageAboveBaseCapacity') is not None:
            self.on_demand_percentage_above_base_capacity = m.get('OnDemandPercentageAboveBaseCapacity')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('RemovalPolicies') is not None:
            self.removal_policies = m.get('RemovalPolicies')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupName') is not None:
            self.scaling_group_name = m.get('ScalingGroupName')
        if m.get('ScalingPolicy') is not None:
            self.scaling_policy = m.get('ScalingPolicy')
        self.server_groups = []
        if m.get('ServerGroups') is not None:
            for k in m.get('ServerGroups'):
                temp_model = CreateScalingGroupRequestServerGroups()
                self.server_groups.append(temp_model.from_map(k))
        if m.get('SpotAllocationStrategy') is not None:
            self.spot_allocation_strategy = m.get('SpotAllocationStrategy')
        if m.get('SpotInstancePools') is not None:
            self.spot_instance_pools = m.get('SpotInstancePools')
        if m.get('SpotInstanceRemedy') is not None:
            self.spot_instance_remedy = m.get('SpotInstanceRemedy')
        if m.get('SyncAlarmRuleToCms') is not None:
            self.sync_alarm_rule_to_cms = m.get('SyncAlarmRuleToCms')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = CreateScalingGroupRequestTags()
                self.tags.append(temp_model.from_map(k))
        self.vserver_groups = []
        if m.get('VServerGroups') is not None:
            for k in m.get('VServerGroups'):
                temp_model = CreateScalingGroupRequestVServerGroups()
                self.vserver_groups.append(temp_model.from_map(k))
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        if m.get('VSwitchIds') is not None:
            self.v_switch_ids = m.get('VSwitchIds')
        return self


class CreateScalingGroupResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_group_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class CreateScalingGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateScalingGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateScalingGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateScalingGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateScalingRuleRequestAlarmDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        # 监控项关联的维度信息键。
        self.dimension_key = dimension_key  # type: str
        # 监控项关联的维度信息值。
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingRuleRequestAlarmDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class CreateScalingRuleRequestStepAdjustments(TeaModel):
    def __init__(self, metric_interval_lower_bound=None, metric_interval_upper_bound=None,
                 scaling_adjustment=None):
        # The lower limit specified in a step adjustment. This parameter is available only if you set the ScalingRuleType parameter to StepScalingRule. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_interval_lower_bound = metric_interval_lower_bound  # type: float
        # The upper limit that is specified in a step adjustment. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_interval_upper_bound = metric_interval_upper_bound  # type: float
        # The number of ECS instances that you want to scale in a step adjustment. This parameter is available only if you set the ScalingRuleType parameter to StepScalingRule.
        self.scaling_adjustment = scaling_adjustment  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingRuleRequestStepAdjustments, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_interval_lower_bound is not None:
            result['MetricIntervalLowerBound'] = self.metric_interval_lower_bound
        if self.metric_interval_upper_bound is not None:
            result['MetricIntervalUpperBound'] = self.metric_interval_upper_bound
        if self.scaling_adjustment is not None:
            result['ScalingAdjustment'] = self.scaling_adjustment
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MetricIntervalLowerBound') is not None:
            self.metric_interval_lower_bound = m.get('MetricIntervalLowerBound')
        if m.get('MetricIntervalUpperBound') is not None:
            self.metric_interval_upper_bound = m.get('MetricIntervalUpperBound')
        if m.get('ScalingAdjustment') is not None:
            self.scaling_adjustment = m.get('ScalingAdjustment')
        return self


class CreateScalingRuleRequest(TeaModel):
    def __init__(self, adjustment_type=None, adjustment_value=None, alarm_dimensions=None, cooldown=None,
                 disable_scale_in=None, estimated_instance_warmup=None, initial_max_size=None, metric_name=None,
                 min_adjustment_magnitude=None, owner_account=None, owner_id=None, predictive_scaling_mode=None,
                 predictive_task_buffer_time=None, predictive_value_behavior=None, predictive_value_buffer=None, region_id=None,
                 resource_owner_account=None, scale_in_evaluation_count=None, scale_out_evaluation_count=None, scaling_group_id=None,
                 scaling_rule_name=None, scaling_rule_type=None, step_adjustments=None, target_value=None):
        # The scaling method of the scaling rule. This parameter is required only if you set the ScalingRuleType parameter to SimpleScalingRule or StepScalingRule. Valid values:
        # 
        # *   QuantityChangeInCapacity: adds the specified number of ECS instances to or removes the specified number of ECS instances from the scaling group.
        # *   PercentChangeInCapacity: adds the specified percentage of ECS instances to or removes the specified percentage of ECS instances from the scaling group.
        # *   TotalCapacity: adjusts the number of ECS instances in the scaling group to a specified number.
        self.adjustment_type = adjustment_type  # type: str
        # The number of instances that must be scaled based on the scaling rule. This parameter is required only if you set the ScalingRuleType parameter to SimpleScalingRule or StepScalingRule. The number of ECS instances that are scaled in a single scaling activity cannot exceed 1,000.
        # 
        # *   Valid values if you set the AdjustmentType parameter to QuantityChangeInCapacity: -1000 to 1000.
        # *   Valid values if you set the AdjustmentType parameter to PercentChangeInCapacity: -100 to 10000.
        # *   Valid values if you set the AdjustmentType parameter to TotalCapacity: 0 to 2000.
        self.adjustment_value = adjustment_value  # type: int
        # 监控项维度信息值，适用于目标追踪规则，当监控项需额外维度信息时设置，例如LoadBalancerRealServerAverageQps监控项需指定rulePool维度键值信息。
        self.alarm_dimensions = alarm_dimensions  # type: list[CreateScalingRuleRequestAlarmDimensions]
        # The cooldown time of the scaling rule. This parameter is available only if you set the ScalingRuleType parameter to SimpleScalingRule. Valid values: 0 to 86400. Unit: seconds.
        # 
        # By default, this parameter is left empty.
        self.cooldown = cooldown  # type: int
        # Specifies whether to disable scale-in. This parameter is available only if you set the ScalingRuleType parameter to TargetTrackingScalingRule.
        # 
        # Default value: false.
        self.disable_scale_in = disable_scale_in  # type: bool
        # The warmup period of an instance. This parameter is available only if you set the ScalingRuleType parameter to TargetTrackingScalingRule or PredictiveScalingRule. Auto Scaling adds ECS instances that are in the warmup state to a scaling group but does not report monitoring data to CloudMonitor during the warmup period.
        # 
        # > Auto Scaling calculates the number of ECS instances that must be scaled. ECS instances in the warmup state are not counted towards the current capacity of the scaling group.
        # 
        # Valid values: 0 to 86400. Unit: seconds.
        # 
        # Default value: 300.
        self.estimated_instance_warmup = estimated_instance_warmup  # type: int
        # The maximum number of ECS instances in the scaling group. If you specify this parameter, you must also specify the PredictiveValueBehavior parameter.
        # 
        # The default value of this parameter is the value of the MaxSize parameter.
        self.initial_max_size = initial_max_size  # type: int
        # The predefined metric that you want to monitor. This parameter is required only if you set the ScalingRuleType parameter to TargetTrackingScalingRule or PredictiveScalingRule.
        # 
        # Valid values if you set the ScalingRuleType parameter to TargetTrackingScalingRule:
        # 
        # *   CpuUtilization: the average CPU utilization
        # *   ClassicInternetRx: the average inbound Internet traffic over the classic network
        # *   ClassicInternetTx: the average outbound Internet traffic over the classic network
        # *   VpcInternetRx: the average inbound Internet traffic over the virtual private cloud (VPC)
        # *   VpcInternetTx: the average outbound Internet traffic over the VPC
        # *   IntranetRx: the average inbound traffic over the internal network
        # *   IntranetTx: the average outbound traffic over the internal network
        # 
        # Valid values if you set the ScalingRuleType parameter to PredictiveScalingRule:
        # 
        # *   CpuUtilization: the average CPU utilization
        # *   IntranetRx: the average inbound traffic over the internal network
        # *   IntranetTx: the average outbound traffic over the internal network
        self.metric_name = metric_name  # type: str
        # The minimum number of instances that must be scaled when the AdjustmentType parameter is set to PercentChangeInCapacity. This parameter takes effect only if you set the ScalingRuleType parameter to SimpleScalingRule or StepScalingRule.
        self.min_adjustment_magnitude = min_adjustment_magnitude  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The mode of the predictive scaling rule. Valid values:
        # 
        # *   PredictAndScale: produces predictions and creates prediction tasks.
        # *   PredictOnly: produces predictions but does not create prediction tasks.
        # 
        # Default value: PredictAndScale.
        self.predictive_scaling_mode = predictive_scaling_mode  # type: str
        # The amount of buffer time before the prediction task is executed. By default, all prediction tasks that are automatically created for a predictive scaling rule are executed on the hour. You can specify an amount of buffer time for resource preparation before the prediction tasks are executed. Valid values: 0 to 60. Unit: minutes.
        # 
        # Default value: 0.
        self.predictive_task_buffer_time = predictive_task_buffer_time  # type: int
        # The maximum value for predication tasks. Valid values:
        # 
        # *   MaxOverridePredictiveValue: uses the initial maximum capacity as the maximum value for prediction tasks if the predicted value is greater than the initial maximum capacity.
        # *   PredictiveValueOverrideMax: uses the predicted value as the maximum value for prediction tasks if the predicted value is greater than the initial maximum capacity.
        # *   PredictiveValueOverrideMaxWithBuffer: increases the predicted value by a percentage that is specified by the PredictiveValueBuffer parameter. If the predicted value that is increased by the percentage is greater than the initial maximum capacity, the increased value is used as the maximum value for prediction tasks.
        # 
        # Default value: MaxOverridePredictiveValue.
        self.predictive_value_behavior = predictive_value_behavior  # type: str
        # The percentage of the increment to the predicted value when the PredictiveValueBehavior parameter is set to PredictiveValueOverrideMaxWithBuffer. If the predicted value increased by this percentage is greater than the initial maximum capacity, the increased value is used as the maximum value for prediction tasks. Valid values: 0 to 100.
        # 
        # Default value: 0.
        self.predictive_value_buffer = predictive_value_buffer  # type: int
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The number of consecutive times that the event-triggered task created for scale-in activities must meet the threshold conditions before an alert is triggered. After a target tracking scaling rule is created, an event-triggered task is automatically created and then associated with the target tracking scaling rule.
        # 
        # Default value: 15.
        self.scale_in_evaluation_count = scale_in_evaluation_count  # type: int
        # The number of consecutive times that the event-triggered task created for scale-out activities must meet the threshold conditions before an alert is triggered. After a target tracking scaling rule is created, an event-triggered task is automatically created and then associated with the target tracking scaling rule.
        # 
        # Default value: 3.
        self.scale_out_evaluation_count = scale_out_evaluation_count  # type: int
        # The ID of the scaling group to which the scaling rule belongs.
        self.scaling_group_id = scaling_group_id  # type: str
        # The name of the scaling rule. It must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). It must start with a letter or a digit. The name of a scaling rule must be unique in the scaling group to which the scaling rule belongs and within an Alibaba Cloud account.
        # 
        # If you do not specify this parameter, the value of the ScalingRuleId parameter is used.
        self.scaling_rule_name = scaling_rule_name  # type: str
        # The type of the scaling rule. Valid values:
        # 
        # *   SimpleScalingRule: scales the number of ECS instances based on the values that are specified for the AdjustmentType and AdjustmentValue parameters.
        # *   TargetTrackingScalingRule: calculates the number of ECS instances that must be scaled and maintains the value of a predefined metric close to the value that is specified for the TargetValue parameter.
        # *   StepScalingRule: scales ECS instances in steps based on the specified thresholds and metric values.
        # *   PredictiveScalingRule: uses machine learning to analyze historical monitoring data of the scaling group and predicts the future values of metrics. In addition, Auto Scaling automatically creates scheduled tasks to specify the boundary values for the scaling group.
        # 
        # Default value: SimpleScalingRule.
        self.scaling_rule_type = scaling_rule_type  # type: str
        # Details of the step adjustments.
        self.step_adjustments = step_adjustments  # type: list[CreateScalingRuleRequestStepAdjustments]
        # The target value. This parameter is required only if you set the ScalingRuleType parameter to TargetTrackingScalingRule or PredictiveScalingRule. The value must be greater than 0 and can have up to three decimal places.
        self.target_value = target_value  # type: float

    def validate(self):
        if self.alarm_dimensions:
            for k in self.alarm_dimensions:
                if k:
                    k.validate()
        if self.step_adjustments:
            for k in self.step_adjustments:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(CreateScalingRuleRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.adjustment_type is not None:
            result['AdjustmentType'] = self.adjustment_type
        if self.adjustment_value is not None:
            result['AdjustmentValue'] = self.adjustment_value
        result['AlarmDimensions'] = []
        if self.alarm_dimensions is not None:
            for k in self.alarm_dimensions:
                result['AlarmDimensions'].append(k.to_map() if k else None)
        if self.cooldown is not None:
            result['Cooldown'] = self.cooldown
        if self.disable_scale_in is not None:
            result['DisableScaleIn'] = self.disable_scale_in
        if self.estimated_instance_warmup is not None:
            result['EstimatedInstanceWarmup'] = self.estimated_instance_warmup
        if self.initial_max_size is not None:
            result['InitialMaxSize'] = self.initial_max_size
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.min_adjustment_magnitude is not None:
            result['MinAdjustmentMagnitude'] = self.min_adjustment_magnitude
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.predictive_scaling_mode is not None:
            result['PredictiveScalingMode'] = self.predictive_scaling_mode
        if self.predictive_task_buffer_time is not None:
            result['PredictiveTaskBufferTime'] = self.predictive_task_buffer_time
        if self.predictive_value_behavior is not None:
            result['PredictiveValueBehavior'] = self.predictive_value_behavior
        if self.predictive_value_buffer is not None:
            result['PredictiveValueBuffer'] = self.predictive_value_buffer
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scale_in_evaluation_count is not None:
            result['ScaleInEvaluationCount'] = self.scale_in_evaluation_count
        if self.scale_out_evaluation_count is not None:
            result['ScaleOutEvaluationCount'] = self.scale_out_evaluation_count
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_rule_name is not None:
            result['ScalingRuleName'] = self.scaling_rule_name
        if self.scaling_rule_type is not None:
            result['ScalingRuleType'] = self.scaling_rule_type
        result['StepAdjustments'] = []
        if self.step_adjustments is not None:
            for k in self.step_adjustments:
                result['StepAdjustments'].append(k.to_map() if k else None)
        if self.target_value is not None:
            result['TargetValue'] = self.target_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AdjustmentType') is not None:
            self.adjustment_type = m.get('AdjustmentType')
        if m.get('AdjustmentValue') is not None:
            self.adjustment_value = m.get('AdjustmentValue')
        self.alarm_dimensions = []
        if m.get('AlarmDimensions') is not None:
            for k in m.get('AlarmDimensions'):
                temp_model = CreateScalingRuleRequestAlarmDimensions()
                self.alarm_dimensions.append(temp_model.from_map(k))
        if m.get('Cooldown') is not None:
            self.cooldown = m.get('Cooldown')
        if m.get('DisableScaleIn') is not None:
            self.disable_scale_in = m.get('DisableScaleIn')
        if m.get('EstimatedInstanceWarmup') is not None:
            self.estimated_instance_warmup = m.get('EstimatedInstanceWarmup')
        if m.get('InitialMaxSize') is not None:
            self.initial_max_size = m.get('InitialMaxSize')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MinAdjustmentMagnitude') is not None:
            self.min_adjustment_magnitude = m.get('MinAdjustmentMagnitude')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PredictiveScalingMode') is not None:
            self.predictive_scaling_mode = m.get('PredictiveScalingMode')
        if m.get('PredictiveTaskBufferTime') is not None:
            self.predictive_task_buffer_time = m.get('PredictiveTaskBufferTime')
        if m.get('PredictiveValueBehavior') is not None:
            self.predictive_value_behavior = m.get('PredictiveValueBehavior')
        if m.get('PredictiveValueBuffer') is not None:
            self.predictive_value_buffer = m.get('PredictiveValueBuffer')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScaleInEvaluationCount') is not None:
            self.scale_in_evaluation_count = m.get('ScaleInEvaluationCount')
        if m.get('ScaleOutEvaluationCount') is not None:
            self.scale_out_evaluation_count = m.get('ScaleOutEvaluationCount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingRuleName') is not None:
            self.scaling_rule_name = m.get('ScalingRuleName')
        if m.get('ScalingRuleType') is not None:
            self.scaling_rule_type = m.get('ScalingRuleType')
        self.step_adjustments = []
        if m.get('StepAdjustments') is not None:
            for k in m.get('StepAdjustments'):
                temp_model = CreateScalingRuleRequestStepAdjustments()
                self.step_adjustments.append(temp_model.from_map(k))
        if m.get('TargetValue') is not None:
            self.target_value = m.get('TargetValue')
        return self


class CreateScalingRuleResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_rule_ari=None, scaling_rule_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The unique identifier of the scaling rule.
        self.scaling_rule_ari = scaling_rule_ari  # type: str
        # The ID of the scaling rule, which is generated by the system and is globally unique.
        self.scaling_rule_id = scaling_rule_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScalingRuleResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_rule_ari is not None:
            result['ScalingRuleAri'] = self.scaling_rule_ari
        if self.scaling_rule_id is not None:
            result['ScalingRuleId'] = self.scaling_rule_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingRuleAri') is not None:
            self.scaling_rule_ari = m.get('ScalingRuleAri')
        if m.get('ScalingRuleId') is not None:
            self.scaling_rule_id = m.get('ScalingRuleId')
        return self


class CreateScalingRuleResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateScalingRuleResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateScalingRuleResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateScalingRuleResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class CreateScheduledTaskRequest(TeaModel):
    def __init__(self, description=None, desired_capacity=None, launch_expiration_time=None, launch_time=None,
                 max_value=None, min_value=None, owner_account=None, owner_id=None, recurrence_end_time=None,
                 recurrence_type=None, recurrence_value=None, region_id=None, resource_owner_account=None, scaling_group_id=None,
                 scheduled_action=None, scheduled_task_name=None, task_enabled=None):
        # The description of the scheduled task. The description must be 2 to 200 characters in length.
        self.description = description  # type: str
        # The expected number of instances in the scaling group if you specify the ScalingGroupId parameter.
        # 
        # > You must specify the `DesiredCapacity` parameter when you create a scaling group.
        self.desired_capacity = desired_capacity  # type: int
        # The time period during which the failed scheduled task can be retried. Unit: seconds. Valid values: 0 to 1800.
        # 
        # Default value: 600.
        self.launch_expiration_time = launch_expiration_time  # type: int
        # The point in time at which the scheduled task is triggered. The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mmZ format. The time must be in UTC. You cannot enter a point in time that is later than 90 days from the point in time at which the scheduled task is created.
        # 
        # *   If you specify the `RecurrenceType` parameter, the scheduled task is repeatedly executed at the point in time that is specified by the LaunchTime parameter.
        # *   If you do not specify the `RecurrenceType` parameter, the task is executed only once at the point in time that is specified by the LaunchTime parameter.
        self.launch_time = launch_time  # type: str
        # The maximum number of instances in the scaling group if you specify the ScalingGroupId parameter.
        self.max_value = max_value  # type: int
        # The minimum number of instances in the scaling group if you specify the ScalingGroupId parameter.
        self.min_value = min_value  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The end time of the scheduled task. Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mmZ format.
        # 
        # The time must be in UTC. You cannot enter a point in time that is later than 365 days from the point in time at which the scheduled task is created.
        self.recurrence_end_time = recurrence_end_time  # type: str
        # The interval at which the scheduled task is repeated. Valid values:
        # 
        # *   Daily: The scheduled task is executed once every specified number of days.
        # *   Weekly: The scheduled task is executed on each specified day of the week.
        # *   Monthly: The scheduled task is executed on each specified day of the month.
        # *   Cron: The scheduled task is executed based on the specified cron expression.
        # 
        # You must specify the `RecurrenceType` and `RecurrenceValue` parameters at the same time.
        self.recurrence_type = recurrence_type  # type: str
        # The number of recurrences of the scheduled task.
        # 
        # *   If you set the `RecurrenceType` parameter to `Daily`, you can specify only one value for this parameter. Valid values: 1 to 31.
        # *   If you set the `RecurrenceType` parameter to `Weekly`, you can specify multiple values for this parameter. Separate the values with commas (,). The values that correspond to Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, and Saturday are 0, 1, 2, 3, 4, 5, and 6.``
        # *   If you set the `RecurrenceType` parameter to `Monthly`, you can specify two values in the `A-B` format for this parameter. Valid values of A and B: 1 to 31. B must be greater than or equal to A.
        # *   If you set the `RecurrenceType` parameter to `Cron`, you can specify a cron expression. A cron expression is written in UTC time and consists of the following fields: minute, hour, day, month, and week. The expression can contain the letters L and W and the following wildcard characters: commas (,), question marks (?), hyphens (-), asterisks (\*), number signs (#), and forward slashes (/).
        # 
        # You must specify both the `RecurrenceType` parameter and the `RecurrenceValue` parameter.
        self.recurrence_value = recurrence_value  # type: str
        # The region ID of the scheduled task.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group whose number of instances must be modified when the scheduled task is triggered. If you specify the `ScalingGroupId` parameter for a scheduled task, you must specify the minimum, maximum, or expected numbers of instances for a scaling group in the scheduled task. That is, you must specify at least one of the `MinValue`, `MaxValue`, and `DesiredCapacity` parameters.
        # 
        # > You cannot specify the `ScheduledAction` and `ScalingGroupId` parameters at the same time.
        self.scaling_group_id = scaling_group_id  # type: str
        # The scaling rule that you want to execute when the scheduled task is triggered. Specify the unique identifier of the scaling rule. If you specify the `ScheduledAction` parameter, you must select an existing scaling rule for the scheduled task.
        # 
        # > You cannot specify the `ScheduledAction` and `ScalingGroupId` parameters at the same time.
        self.scheduled_action = scheduled_action  # type: str
        # The name of the scheduled task. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit. The name of the scheduled task must be unique in the region and within the Alibaba Cloud account.
        # 
        # If you do not specify this parameter, the value of the `ScheduledTaskId` parameter is used.
        self.scheduled_task_name = scheduled_task_name  # type: str
        # Specifies whether to enable the scheduled task.
        # 
        # *   true
        # *   false
        # 
        # Default value: true.
        self.task_enabled = task_enabled  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScheduledTaskRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.description is not None:
            result['Description'] = self.description
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.launch_expiration_time is not None:
            result['LaunchExpirationTime'] = self.launch_expiration_time
        if self.launch_time is not None:
            result['LaunchTime'] = self.launch_time
        if self.max_value is not None:
            result['MaxValue'] = self.max_value
        if self.min_value is not None:
            result['MinValue'] = self.min_value
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.recurrence_end_time is not None:
            result['RecurrenceEndTime'] = self.recurrence_end_time
        if self.recurrence_type is not None:
            result['RecurrenceType'] = self.recurrence_type
        if self.recurrence_value is not None:
            result['RecurrenceValue'] = self.recurrence_value
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduled_action is not None:
            result['ScheduledAction'] = self.scheduled_action
        if self.scheduled_task_name is not None:
            result['ScheduledTaskName'] = self.scheduled_task_name
        if self.task_enabled is not None:
            result['TaskEnabled'] = self.task_enabled
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('LaunchExpirationTime') is not None:
            self.launch_expiration_time = m.get('LaunchExpirationTime')
        if m.get('LaunchTime') is not None:
            self.launch_time = m.get('LaunchTime')
        if m.get('MaxValue') is not None:
            self.max_value = m.get('MaxValue')
        if m.get('MinValue') is not None:
            self.min_value = m.get('MinValue')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RecurrenceEndTime') is not None:
            self.recurrence_end_time = m.get('RecurrenceEndTime')
        if m.get('RecurrenceType') is not None:
            self.recurrence_type = m.get('RecurrenceType')
        if m.get('RecurrenceValue') is not None:
            self.recurrence_value = m.get('RecurrenceValue')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScheduledAction') is not None:
            self.scheduled_action = m.get('ScheduledAction')
        if m.get('ScheduledTaskName') is not None:
            self.scheduled_task_name = m.get('ScheduledTaskName')
        if m.get('TaskEnabled') is not None:
            self.task_enabled = m.get('TaskEnabled')
        return self


class CreateScheduledTaskResponseBody(TeaModel):
    def __init__(self, request_id=None, scheduled_task_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The globally unique ID of the scheduled task. The globally unique ID is generated by the system.
        self.scheduled_task_id = scheduled_task_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(CreateScheduledTaskResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scheduled_task_id is not None:
            result['ScheduledTaskId'] = self.scheduled_task_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScheduledTaskId') is not None:
            self.scheduled_task_id = m.get('ScheduledTaskId')
        return self


class CreateScheduledTaskResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: CreateScheduledTaskResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(CreateScheduledTaskResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = CreateScheduledTaskResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeactivateScalingConfigurationRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, resource_owner_account=None,
                 scaling_configuration_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeactivateScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        return self


class DeactivateScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeactivateScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeactivateScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeactivateScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeactivateScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeactivateScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteAlarmRequest(TeaModel):
    def __init__(self, alarm_task_id=None, owner_id=None, region_id=None, resource_owner_account=None):
        # The ID of the event-triggered task.
        self.alarm_task_id = alarm_task_id  # type: str
        self.owner_id = owner_id  # type: long
        # The ID of the region.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteAlarmRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class DeleteAlarmResponseBody(TeaModel):
    def __init__(self, alarm_task_id=None, request_id=None):
        # The ID of the event-triggered task.
        self.alarm_task_id = alarm_task_id  # type: str
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteAlarmResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteAlarmResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteAlarmResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteAlarmResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteAlarmResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteEciScalingConfigurationRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scaling_configuration_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling configuration that you want to delete.
        self.scaling_configuration_id = scaling_configuration_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteEciScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        return self


class DeleteEciScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request. This request ID is returned regardless of whether the request is successful.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteEciScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteEciScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteEciScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteEciScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteEciScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteLifecycleHookRequest(TeaModel):
    def __init__(self, lifecycle_hook_id=None, lifecycle_hook_name=None, owner_account=None, owner_id=None,
                 region_id=None, resource_owner_account=None, scaling_group_id=None):
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str
        self.lifecycle_hook_name = lifecycle_hook_name  # type: str
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteLifecycleHookRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.lifecycle_hook_id is not None:
            result['LifecycleHookId'] = self.lifecycle_hook_id
        if self.lifecycle_hook_name is not None:
            result['LifecycleHookName'] = self.lifecycle_hook_name
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('LifecycleHookId')
        if m.get('LifecycleHookName') is not None:
            self.lifecycle_hook_name = m.get('LifecycleHookName')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DeleteLifecycleHookResponseBody(TeaModel):
    def __init__(self, request_id=None):
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteLifecycleHookResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteLifecycleHookResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteLifecycleHookResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteLifecycleHookResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteLifecycleHookResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteNotificationConfigurationRequest(TeaModel):
    def __init__(self, notification_arn=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scaling_group_id=None):
        # The Alibaba Cloud Resource Name (ARN) of the notification method. The following list describes the value formats of this parameter:
        # 
        # *   If you use CloudMonitor as the notification party, the value format of this parameter is acs:ess:{region-id}:{account-id}:cloudmonitor.
        # *   If you use an MNS queue as the notification party, the value format of this parameter is acs:mns:{region-id}:{account-id}:queue/{queuename}.
        # *   If you use an MNS topic as the notification party, the value format of this parameter is acs:mns:{region-id}:{account-id}:topic/{topicname}.
        # 
        # The variables in the preceding formats have the following meanings:
        # 
        # *   region-id: the region ID of the scaling group.
        # *   account-id: the ID of the Alibaba Cloud account.
        # *   queuename: the name of the MNS queue.
        # *   topicname: the name of the MNS topic.
        self.notification_arn = notification_arn  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteNotificationConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DeleteNotificationConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteNotificationConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteNotificationConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteNotificationConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteNotificationConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteNotificationConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteScalingConfigurationRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, resource_owner_account=None,
                 scaling_configuration_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling configuration that you want to delete.
        self.scaling_configuration_id = scaling_configuration_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        return self


class DeleteScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request. The request ID is returned regardless of whether the call is successful.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteScalingGroupRequest(TeaModel):
    def __init__(self, force_delete=None, owner_account=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # Specifies whether to forcefully delete the VPC. Valid values:
        # 
        # - **true**: yes
        # - **false** (default): no
        # 
        # You can forcefully delete a VPC in the following scenarios:
        # 
        # - Only an IPv4 gateway and routes that point to the IPv4 gateway exist in the VPC.
        # - Only an IPv6 gateway and routes that point to the IPv6 gateway exist in the VPC.
        self.force_delete = force_delete  # type: bool
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScalingGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.force_delete is not None:
            result['ForceDelete'] = self.force_delete
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ForceDelete') is not None:
            self.force_delete = m.get('ForceDelete')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DeleteScalingGroupResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScalingGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteScalingGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteScalingGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteScalingGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteScalingGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteScalingRuleRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scaling_rule_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling rule that you want to delete.
        self.scaling_rule_id = scaling_rule_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScalingRuleRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_rule_id is not None:
            result['ScalingRuleId'] = self.scaling_rule_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingRuleId') is not None:
            self.scaling_rule_id = m.get('ScalingRuleId')
        return self


class DeleteScalingRuleResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScalingRuleResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteScalingRuleResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteScalingRuleResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteScalingRuleResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteScalingRuleResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DeleteScheduledTaskRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scheduled_task_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scheduled task.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scheduled task. An ID is a globally unique identifier (GUID) that is generated by the system for a scheduled task.
        self.scheduled_task_id = scheduled_task_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScheduledTaskRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scheduled_task_id is not None:
            result['ScheduledTaskId'] = self.scheduled_task_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScheduledTaskId') is not None:
            self.scheduled_task_id = m.get('ScheduledTaskId')
        return self


class DeleteScheduledTaskResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DeleteScheduledTaskResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DeleteScheduledTaskResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DeleteScheduledTaskResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DeleteScheduledTaskResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DeleteScheduledTaskResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeAlarmsRequest(TeaModel):
    def __init__(self, alarm_task_id=None, is_enable=None, metric_name=None, metric_type=None, owner_id=None,
                 page_number=None, page_size=None, region_id=None, resource_owner_account=None, scaling_group_id=None,
                 state=None):
        self.alarm_task_id = alarm_task_id  # type: str
        self.is_enable = is_enable  # type: bool
        self.metric_name = metric_name  # type: str
        self.metric_type = metric_type  # type: str
        self.owner_id = owner_id  # type: long
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.state = state  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeAlarmsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.is_enable is not None:
            result['IsEnable'] = self.is_enable
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.metric_type is not None:
            result['MetricType'] = self.metric_type
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.state is not None:
            result['State'] = self.state
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('IsEnable') is not None:
            self.is_enable = m.get('IsEnable')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MetricType') is not None:
            self.metric_type = m.get('MetricType')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('State') is not None:
            self.state = m.get('State')
        return self


class DescribeAlarmsResponseBodyAlarmListDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        self.dimension_key = dimension_key  # type: str
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeAlarmsResponseBodyAlarmListDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class DescribeAlarmsResponseBodyAlarmListExpressions(TeaModel):
    def __init__(self, comparison_operator=None, metric_name=None, period=None, statistics=None, threshold=None):
        self.comparison_operator = comparison_operator  # type: str
        self.metric_name = metric_name  # type: str
        self.period = period  # type: int
        self.statistics = statistics  # type: str
        self.threshold = threshold  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeAlarmsResponseBodyAlarmListExpressions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.period is not None:
            result['Period'] = self.period
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class DescribeAlarmsResponseBodyAlarmList(TeaModel):
    def __init__(self, alarm_actions=None, alarm_task_id=None, comparison_operator=None, description=None,
                 dimensions=None, effective=None, enable=None, evaluation_count=None, expressions=None,
                 expressions_logic_operator=None, metric_name=None, metric_type=None, name=None, period=None, scaling_group_id=None, state=None,
                 statistics=None, threshold=None):
        self.alarm_actions = alarm_actions  # type: list[str]
        self.alarm_task_id = alarm_task_id  # type: str
        self.comparison_operator = comparison_operator  # type: str
        self.description = description  # type: str
        self.dimensions = dimensions  # type: list[DescribeAlarmsResponseBodyAlarmListDimensions]
        self.effective = effective  # type: str
        self.enable = enable  # type: bool
        self.evaluation_count = evaluation_count  # type: int
        self.expressions = expressions  # type: list[DescribeAlarmsResponseBodyAlarmListExpressions]
        self.expressions_logic_operator = expressions_logic_operator  # type: str
        self.metric_name = metric_name  # type: str
        self.metric_type = metric_type  # type: str
        self.name = name  # type: str
        self.period = period  # type: int
        self.scaling_group_id = scaling_group_id  # type: str
        self.state = state  # type: str
        self.statistics = statistics  # type: str
        self.threshold = threshold  # type: float

    def validate(self):
        if self.dimensions:
            for k in self.dimensions:
                if k:
                    k.validate()
        if self.expressions:
            for k in self.expressions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeAlarmsResponseBodyAlarmList, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_actions is not None:
            result['AlarmActions'] = self.alarm_actions
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        if self.description is not None:
            result['Description'] = self.description
        result['Dimensions'] = []
        if self.dimensions is not None:
            for k in self.dimensions:
                result['Dimensions'].append(k.to_map() if k else None)
        if self.effective is not None:
            result['Effective'] = self.effective
        if self.enable is not None:
            result['Enable'] = self.enable
        if self.evaluation_count is not None:
            result['EvaluationCount'] = self.evaluation_count
        result['Expressions'] = []
        if self.expressions is not None:
            for k in self.expressions:
                result['Expressions'].append(k.to_map() if k else None)
        if self.expressions_logic_operator is not None:
            result['ExpressionsLogicOperator'] = self.expressions_logic_operator
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.metric_type is not None:
            result['MetricType'] = self.metric_type
        if self.name is not None:
            result['Name'] = self.name
        if self.period is not None:
            result['Period'] = self.period
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.state is not None:
            result['State'] = self.state
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmActions') is not None:
            self.alarm_actions = m.get('AlarmActions')
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        self.dimensions = []
        if m.get('Dimensions') is not None:
            for k in m.get('Dimensions'):
                temp_model = DescribeAlarmsResponseBodyAlarmListDimensions()
                self.dimensions.append(temp_model.from_map(k))
        if m.get('Effective') is not None:
            self.effective = m.get('Effective')
        if m.get('Enable') is not None:
            self.enable = m.get('Enable')
        if m.get('EvaluationCount') is not None:
            self.evaluation_count = m.get('EvaluationCount')
        self.expressions = []
        if m.get('Expressions') is not None:
            for k in m.get('Expressions'):
                temp_model = DescribeAlarmsResponseBodyAlarmListExpressions()
                self.expressions.append(temp_model.from_map(k))
        if m.get('ExpressionsLogicOperator') is not None:
            self.expressions_logic_operator = m.get('ExpressionsLogicOperator')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MetricType') is not None:
            self.metric_type = m.get('MetricType')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('State') is not None:
            self.state = m.get('State')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class DescribeAlarmsResponseBody(TeaModel):
    def __init__(self, alarm_list=None, page_number=None, page_size=None, request_id=None, total_count=None):
        self.alarm_list = alarm_list  # type: list[DescribeAlarmsResponseBodyAlarmList]
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.request_id = request_id  # type: str
        self.total_count = total_count  # type: int

    def validate(self):
        if self.alarm_list:
            for k in self.alarm_list:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeAlarmsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AlarmList'] = []
        if self.alarm_list is not None:
            for k in self.alarm_list:
                result['AlarmList'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.alarm_list = []
        if m.get('AlarmList') is not None:
            for k in m.get('AlarmList'):
                temp_model = DescribeAlarmsResponseBodyAlarmList()
                self.alarm_list.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeAlarmsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeAlarmsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeAlarmsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeAlarmsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeEciScalingConfigurationDetailRequest(TeaModel):
    def __init__(self, output_format=None, region_id=None, scaling_configuration_id=None, scaling_group_id=None):
        self.output_format = output_format  # type: str
        self.region_id = region_id  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.output_format is not None:
            result['OutputFormat'] = self.output_format
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OutputFormat') is not None:
            self.output_format = m.get('OutputFormat')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationAcrRegistryInfos(TeaModel):
    def __init__(self, domains=None, instance_id=None, instance_name=None, region_id=None):
        self.domains = domains  # type: list[str]
        self.instance_id = instance_id  # type: str
        self.instance_name = instance_name  # type: str
        self.region_id = region_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationAcrRegistryInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.domains is not None:
            result['Domains'] = self.domains
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Domains') is not None:
            self.domains = m.get('Domains')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersEnvironmentVars(TeaModel):
    def __init__(self, field_ref_field_path=None, key=None, value=None):
        self.field_ref_field_path = field_ref_field_path  # type: str
        self.key = key  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref_field_path is not None:
            result['FieldRefFieldPath'] = self.field_ref_field_path
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRefFieldPath') is not None:
            self.field_ref_field_path = m.get('FieldRefFieldPath')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        self.port = port  # type: int
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        self.mount_path = mount_path  # type: str
        self.mount_propagation = mount_propagation  # type: str
        self.name = name  # type: str
        self.read_only = read_only  # type: bool
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainers(TeaModel):
    def __init__(self, args=None, commands=None, cpu=None, environment_vars=None, gpu=None, image=None,
                 image_pull_policy=None, lifecycle_post_start_handler_execs=None, lifecycle_post_start_handler_http_get_host=None,
                 lifecycle_post_start_handler_http_get_path=None, lifecycle_post_start_handler_http_get_port=None,
                 lifecycle_post_start_handler_http_get_scheme=None, lifecycle_post_start_handler_tcp_socket_host=None,
                 lifecycle_post_start_handler_tcp_socket_port=None, lifecycle_pre_stop_handler_execs=None, lifecycle_pre_stop_handler_http_get_host=None,
                 lifecycle_pre_stop_handler_http_get_path=None, lifecycle_pre_stop_handler_http_get_port=None,
                 lifecycle_pre_stop_handler_http_get_scheme=None, lifecycle_pre_stop_handler_tcp_socket_host=None,
                 lifecycle_pre_stop_handler_tcp_socket_port=None, liveness_probe_exec_commands=None, liveness_probe_failure_threshold=None,
                 liveness_probe_http_get_path=None, liveness_probe_http_get_port=None, liveness_probe_http_get_scheme=None,
                 liveness_probe_initial_delay_seconds=None, liveness_probe_period_seconds=None, liveness_probe_success_threshold=None,
                 liveness_probe_tcp_socket_port=None, liveness_probe_timeout_seconds=None, memory=None, name=None, ports=None,
                 readiness_probe_exec_commands=None, readiness_probe_failure_threshold=None, readiness_probe_http_get_path=None,
                 readiness_probe_http_get_port=None, readiness_probe_http_get_scheme=None, readiness_probe_initial_delay_seconds=None,
                 readiness_probe_period_seconds=None, readiness_probe_success_threshold=None, readiness_probe_tcp_socket_port=None,
                 readiness_probe_timeout_seconds=None, security_context_capability_adds=None, security_context_read_only_root_filesystem=None,
                 security_context_run_as_user=None, stdin=None, stdin_once=None, tty=None, volume_mounts=None, working_dir=None):
        self.args = args  # type: list[str]
        self.commands = commands  # type: list[str]
        self.cpu = cpu  # type: float
        self.environment_vars = environment_vars  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersEnvironmentVars]
        self.gpu = gpu  # type: int
        self.image = image  # type: str
        self.image_pull_policy = image_pull_policy  # type: str
        self.lifecycle_post_start_handler_execs = lifecycle_post_start_handler_execs  # type: list[str]
        self.lifecycle_post_start_handler_http_get_host = lifecycle_post_start_handler_http_get_host  # type: str
        self.lifecycle_post_start_handler_http_get_path = lifecycle_post_start_handler_http_get_path  # type: str
        self.lifecycle_post_start_handler_http_get_port = lifecycle_post_start_handler_http_get_port  # type: int
        self.lifecycle_post_start_handler_http_get_scheme = lifecycle_post_start_handler_http_get_scheme  # type: str
        self.lifecycle_post_start_handler_tcp_socket_host = lifecycle_post_start_handler_tcp_socket_host  # type: str
        self.lifecycle_post_start_handler_tcp_socket_port = lifecycle_post_start_handler_tcp_socket_port  # type: int
        self.lifecycle_pre_stop_handler_execs = lifecycle_pre_stop_handler_execs  # type: list[str]
        self.lifecycle_pre_stop_handler_http_get_host = lifecycle_pre_stop_handler_http_get_host  # type: str
        self.lifecycle_pre_stop_handler_http_get_path = lifecycle_pre_stop_handler_http_get_path  # type: str
        self.lifecycle_pre_stop_handler_http_get_port = lifecycle_pre_stop_handler_http_get_port  # type: int
        self.lifecycle_pre_stop_handler_http_get_scheme = lifecycle_pre_stop_handler_http_get_scheme  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_host = lifecycle_pre_stop_handler_tcp_socket_host  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_port = lifecycle_pre_stop_handler_tcp_socket_port  # type: int
        self.liveness_probe_exec_commands = liveness_probe_exec_commands  # type: list[str]
        self.liveness_probe_failure_threshold = liveness_probe_failure_threshold  # type: int
        self.liveness_probe_http_get_path = liveness_probe_http_get_path  # type: str
        self.liveness_probe_http_get_port = liveness_probe_http_get_port  # type: int
        self.liveness_probe_http_get_scheme = liveness_probe_http_get_scheme  # type: str
        self.liveness_probe_initial_delay_seconds = liveness_probe_initial_delay_seconds  # type: int
        self.liveness_probe_period_seconds = liveness_probe_period_seconds  # type: int
        self.liveness_probe_success_threshold = liveness_probe_success_threshold  # type: int
        self.liveness_probe_tcp_socket_port = liveness_probe_tcp_socket_port  # type: int
        self.liveness_probe_timeout_seconds = liveness_probe_timeout_seconds  # type: int
        self.memory = memory  # type: float
        self.name = name  # type: str
        self.ports = ports  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersPorts]
        self.readiness_probe_exec_commands = readiness_probe_exec_commands  # type: list[str]
        self.readiness_probe_failure_threshold = readiness_probe_failure_threshold  # type: int
        self.readiness_probe_http_get_path = readiness_probe_http_get_path  # type: str
        self.readiness_probe_http_get_port = readiness_probe_http_get_port  # type: int
        self.readiness_probe_http_get_scheme = readiness_probe_http_get_scheme  # type: str
        self.readiness_probe_initial_delay_seconds = readiness_probe_initial_delay_seconds  # type: int
        self.readiness_probe_period_seconds = readiness_probe_period_seconds  # type: int
        self.readiness_probe_success_threshold = readiness_probe_success_threshold  # type: int
        self.readiness_probe_tcp_socket_port = readiness_probe_tcp_socket_port  # type: int
        self.readiness_probe_timeout_seconds = readiness_probe_timeout_seconds  # type: int
        self.security_context_capability_adds = security_context_capability_adds  # type: list[str]
        self.security_context_read_only_root_filesystem = security_context_read_only_root_filesystem  # type: bool
        self.security_context_run_as_user = security_context_run_as_user  # type: long
        self.stdin = stdin  # type: bool
        self.stdin_once = stdin_once  # type: bool
        self.tty = tty  # type: bool
        self.volume_mounts = volume_mounts  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersVolumeMounts]
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.environment_vars:
            for k in self.environment_vars:
                if k:
                    k.validate()
        if self.ports:
            for k in self.ports:
                if k:
                    k.validate()
        if self.volume_mounts:
            for k in self.volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        result['EnvironmentVars'] = []
        if self.environment_vars is not None:
            for k in self.environment_vars:
                result['EnvironmentVars'].append(k.to_map() if k else None)
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        if self.lifecycle_post_start_handler_execs is not None:
            result['LifecyclePostStartHandlerExecs'] = self.lifecycle_post_start_handler_execs
        if self.lifecycle_post_start_handler_http_get_host is not None:
            result['LifecyclePostStartHandlerHttpGetHost'] = self.lifecycle_post_start_handler_http_get_host
        if self.lifecycle_post_start_handler_http_get_path is not None:
            result['LifecyclePostStartHandlerHttpGetPath'] = self.lifecycle_post_start_handler_http_get_path
        if self.lifecycle_post_start_handler_http_get_port is not None:
            result['LifecyclePostStartHandlerHttpGetPort'] = self.lifecycle_post_start_handler_http_get_port
        if self.lifecycle_post_start_handler_http_get_scheme is not None:
            result['LifecyclePostStartHandlerHttpGetScheme'] = self.lifecycle_post_start_handler_http_get_scheme
        if self.lifecycle_post_start_handler_tcp_socket_host is not None:
            result['LifecyclePostStartHandlerTcpSocketHost'] = self.lifecycle_post_start_handler_tcp_socket_host
        if self.lifecycle_post_start_handler_tcp_socket_port is not None:
            result['LifecyclePostStartHandlerTcpSocketPort'] = self.lifecycle_post_start_handler_tcp_socket_port
        if self.lifecycle_pre_stop_handler_execs is not None:
            result['LifecyclePreStopHandlerExecs'] = self.lifecycle_pre_stop_handler_execs
        if self.lifecycle_pre_stop_handler_http_get_host is not None:
            result['LifecyclePreStopHandlerHttpGetHost'] = self.lifecycle_pre_stop_handler_http_get_host
        if self.lifecycle_pre_stop_handler_http_get_path is not None:
            result['LifecyclePreStopHandlerHttpGetPath'] = self.lifecycle_pre_stop_handler_http_get_path
        if self.lifecycle_pre_stop_handler_http_get_port is not None:
            result['LifecyclePreStopHandlerHttpGetPort'] = self.lifecycle_pre_stop_handler_http_get_port
        if self.lifecycle_pre_stop_handler_http_get_scheme is not None:
            result['LifecyclePreStopHandlerHttpGetScheme'] = self.lifecycle_pre_stop_handler_http_get_scheme
        if self.lifecycle_pre_stop_handler_tcp_socket_host is not None:
            result['LifecyclePreStopHandlerTcpSocketHost'] = self.lifecycle_pre_stop_handler_tcp_socket_host
        if self.lifecycle_pre_stop_handler_tcp_socket_port is not None:
            result['LifecyclePreStopHandlerTcpSocketPort'] = self.lifecycle_pre_stop_handler_tcp_socket_port
        if self.liveness_probe_exec_commands is not None:
            result['LivenessProbeExecCommands'] = self.liveness_probe_exec_commands
        if self.liveness_probe_failure_threshold is not None:
            result['LivenessProbeFailureThreshold'] = self.liveness_probe_failure_threshold
        if self.liveness_probe_http_get_path is not None:
            result['LivenessProbeHttpGetPath'] = self.liveness_probe_http_get_path
        if self.liveness_probe_http_get_port is not None:
            result['LivenessProbeHttpGetPort'] = self.liveness_probe_http_get_port
        if self.liveness_probe_http_get_scheme is not None:
            result['LivenessProbeHttpGetScheme'] = self.liveness_probe_http_get_scheme
        if self.liveness_probe_initial_delay_seconds is not None:
            result['LivenessProbeInitialDelaySeconds'] = self.liveness_probe_initial_delay_seconds
        if self.liveness_probe_period_seconds is not None:
            result['LivenessProbePeriodSeconds'] = self.liveness_probe_period_seconds
        if self.liveness_probe_success_threshold is not None:
            result['LivenessProbeSuccessThreshold'] = self.liveness_probe_success_threshold
        if self.liveness_probe_tcp_socket_port is not None:
            result['LivenessProbeTcpSocketPort'] = self.liveness_probe_tcp_socket_port
        if self.liveness_probe_timeout_seconds is not None:
            result['LivenessProbeTimeoutSeconds'] = self.liveness_probe_timeout_seconds
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        result['Ports'] = []
        if self.ports is not None:
            for k in self.ports:
                result['Ports'].append(k.to_map() if k else None)
        if self.readiness_probe_exec_commands is not None:
            result['ReadinessProbeExecCommands'] = self.readiness_probe_exec_commands
        if self.readiness_probe_failure_threshold is not None:
            result['ReadinessProbeFailureThreshold'] = self.readiness_probe_failure_threshold
        if self.readiness_probe_http_get_path is not None:
            result['ReadinessProbeHttpGetPath'] = self.readiness_probe_http_get_path
        if self.readiness_probe_http_get_port is not None:
            result['ReadinessProbeHttpGetPort'] = self.readiness_probe_http_get_port
        if self.readiness_probe_http_get_scheme is not None:
            result['ReadinessProbeHttpGetScheme'] = self.readiness_probe_http_get_scheme
        if self.readiness_probe_initial_delay_seconds is not None:
            result['ReadinessProbeInitialDelaySeconds'] = self.readiness_probe_initial_delay_seconds
        if self.readiness_probe_period_seconds is not None:
            result['ReadinessProbePeriodSeconds'] = self.readiness_probe_period_seconds
        if self.readiness_probe_success_threshold is not None:
            result['ReadinessProbeSuccessThreshold'] = self.readiness_probe_success_threshold
        if self.readiness_probe_tcp_socket_port is not None:
            result['ReadinessProbeTcpSocketPort'] = self.readiness_probe_tcp_socket_port
        if self.readiness_probe_timeout_seconds is not None:
            result['ReadinessProbeTimeoutSeconds'] = self.readiness_probe_timeout_seconds
        if self.security_context_capability_adds is not None:
            result['SecurityContextCapabilityAdds'] = self.security_context_capability_adds
        if self.security_context_read_only_root_filesystem is not None:
            result['SecurityContextReadOnlyRootFilesystem'] = self.security_context_read_only_root_filesystem
        if self.security_context_run_as_user is not None:
            result['SecurityContextRunAsUser'] = self.security_context_run_as_user
        if self.stdin is not None:
            result['Stdin'] = self.stdin
        if self.stdin_once is not None:
            result['StdinOnce'] = self.stdin_once
        if self.tty is not None:
            result['Tty'] = self.tty
        result['VolumeMounts'] = []
        if self.volume_mounts is not None:
            for k in self.volume_mounts:
                result['VolumeMounts'].append(k.to_map() if k else None)
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        self.environment_vars = []
        if m.get('EnvironmentVars') is not None:
            for k in m.get('EnvironmentVars'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersEnvironmentVars()
                self.environment_vars.append(temp_model.from_map(k))
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        if m.get('LifecyclePostStartHandlerExecs') is not None:
            self.lifecycle_post_start_handler_execs = m.get('LifecyclePostStartHandlerExecs')
        if m.get('LifecyclePostStartHandlerHttpGetHost') is not None:
            self.lifecycle_post_start_handler_http_get_host = m.get('LifecyclePostStartHandlerHttpGetHost')
        if m.get('LifecyclePostStartHandlerHttpGetPath') is not None:
            self.lifecycle_post_start_handler_http_get_path = m.get('LifecyclePostStartHandlerHttpGetPath')
        if m.get('LifecyclePostStartHandlerHttpGetPort') is not None:
            self.lifecycle_post_start_handler_http_get_port = m.get('LifecyclePostStartHandlerHttpGetPort')
        if m.get('LifecyclePostStartHandlerHttpGetScheme') is not None:
            self.lifecycle_post_start_handler_http_get_scheme = m.get('LifecyclePostStartHandlerHttpGetScheme')
        if m.get('LifecyclePostStartHandlerTcpSocketHost') is not None:
            self.lifecycle_post_start_handler_tcp_socket_host = m.get('LifecyclePostStartHandlerTcpSocketHost')
        if m.get('LifecyclePostStartHandlerTcpSocketPort') is not None:
            self.lifecycle_post_start_handler_tcp_socket_port = m.get('LifecyclePostStartHandlerTcpSocketPort')
        if m.get('LifecyclePreStopHandlerExecs') is not None:
            self.lifecycle_pre_stop_handler_execs = m.get('LifecyclePreStopHandlerExecs')
        if m.get('LifecyclePreStopHandlerHttpGetHost') is not None:
            self.lifecycle_pre_stop_handler_http_get_host = m.get('LifecyclePreStopHandlerHttpGetHost')
        if m.get('LifecyclePreStopHandlerHttpGetPath') is not None:
            self.lifecycle_pre_stop_handler_http_get_path = m.get('LifecyclePreStopHandlerHttpGetPath')
        if m.get('LifecyclePreStopHandlerHttpGetPort') is not None:
            self.lifecycle_pre_stop_handler_http_get_port = m.get('LifecyclePreStopHandlerHttpGetPort')
        if m.get('LifecyclePreStopHandlerHttpGetScheme') is not None:
            self.lifecycle_pre_stop_handler_http_get_scheme = m.get('LifecyclePreStopHandlerHttpGetScheme')
        if m.get('LifecyclePreStopHandlerTcpSocketHost') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_host = m.get('LifecyclePreStopHandlerTcpSocketHost')
        if m.get('LifecyclePreStopHandlerTcpSocketPort') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_port = m.get('LifecyclePreStopHandlerTcpSocketPort')
        if m.get('LivenessProbeExecCommands') is not None:
            self.liveness_probe_exec_commands = m.get('LivenessProbeExecCommands')
        if m.get('LivenessProbeFailureThreshold') is not None:
            self.liveness_probe_failure_threshold = m.get('LivenessProbeFailureThreshold')
        if m.get('LivenessProbeHttpGetPath') is not None:
            self.liveness_probe_http_get_path = m.get('LivenessProbeHttpGetPath')
        if m.get('LivenessProbeHttpGetPort') is not None:
            self.liveness_probe_http_get_port = m.get('LivenessProbeHttpGetPort')
        if m.get('LivenessProbeHttpGetScheme') is not None:
            self.liveness_probe_http_get_scheme = m.get('LivenessProbeHttpGetScheme')
        if m.get('LivenessProbeInitialDelaySeconds') is not None:
            self.liveness_probe_initial_delay_seconds = m.get('LivenessProbeInitialDelaySeconds')
        if m.get('LivenessProbePeriodSeconds') is not None:
            self.liveness_probe_period_seconds = m.get('LivenessProbePeriodSeconds')
        if m.get('LivenessProbeSuccessThreshold') is not None:
            self.liveness_probe_success_threshold = m.get('LivenessProbeSuccessThreshold')
        if m.get('LivenessProbeTcpSocketPort') is not None:
            self.liveness_probe_tcp_socket_port = m.get('LivenessProbeTcpSocketPort')
        if m.get('LivenessProbeTimeoutSeconds') is not None:
            self.liveness_probe_timeout_seconds = m.get('LivenessProbeTimeoutSeconds')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        self.ports = []
        if m.get('Ports') is not None:
            for k in m.get('Ports'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersPorts()
                self.ports.append(temp_model.from_map(k))
        if m.get('ReadinessProbeExecCommands') is not None:
            self.readiness_probe_exec_commands = m.get('ReadinessProbeExecCommands')
        if m.get('ReadinessProbeFailureThreshold') is not None:
            self.readiness_probe_failure_threshold = m.get('ReadinessProbeFailureThreshold')
        if m.get('ReadinessProbeHttpGetPath') is not None:
            self.readiness_probe_http_get_path = m.get('ReadinessProbeHttpGetPath')
        if m.get('ReadinessProbeHttpGetPort') is not None:
            self.readiness_probe_http_get_port = m.get('ReadinessProbeHttpGetPort')
        if m.get('ReadinessProbeHttpGetScheme') is not None:
            self.readiness_probe_http_get_scheme = m.get('ReadinessProbeHttpGetScheme')
        if m.get('ReadinessProbeInitialDelaySeconds') is not None:
            self.readiness_probe_initial_delay_seconds = m.get('ReadinessProbeInitialDelaySeconds')
        if m.get('ReadinessProbePeriodSeconds') is not None:
            self.readiness_probe_period_seconds = m.get('ReadinessProbePeriodSeconds')
        if m.get('ReadinessProbeSuccessThreshold') is not None:
            self.readiness_probe_success_threshold = m.get('ReadinessProbeSuccessThreshold')
        if m.get('ReadinessProbeTcpSocketPort') is not None:
            self.readiness_probe_tcp_socket_port = m.get('ReadinessProbeTcpSocketPort')
        if m.get('ReadinessProbeTimeoutSeconds') is not None:
            self.readiness_probe_timeout_seconds = m.get('ReadinessProbeTimeoutSeconds')
        if m.get('SecurityContextCapabilityAdds') is not None:
            self.security_context_capability_adds = m.get('SecurityContextCapabilityAdds')
        if m.get('SecurityContextReadOnlyRootFilesystem') is not None:
            self.security_context_read_only_root_filesystem = m.get('SecurityContextReadOnlyRootFilesystem')
        if m.get('SecurityContextRunAsUser') is not None:
            self.security_context_run_as_user = m.get('SecurityContextRunAsUser')
        if m.get('Stdin') is not None:
            self.stdin = m.get('Stdin')
        if m.get('StdinOnce') is not None:
            self.stdin_once = m.get('StdinOnce')
        if m.get('Tty') is not None:
            self.tty = m.get('Tty')
        self.volume_mounts = []
        if m.get('VolumeMounts') is not None:
            for k in m.get('VolumeMounts'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainersVolumeMounts()
                self.volume_mounts.append(temp_model.from_map(k))
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationDnsConfigOptions(TeaModel):
    def __init__(self, name=None, value=None):
        self.name = name  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationDnsConfigOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationHostAliases(TeaModel):
    def __init__(self, hostnames=None, ip=None):
        self.hostnames = hostnames  # type: list[str]
        self.ip = ip  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationHostAliases, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.hostnames is not None:
            result['Hostnames'] = self.hostnames
        if self.ip is not None:
            result['Ip'] = self.ip
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Hostnames') is not None:
            self.hostnames = m.get('Hostnames')
        if m.get('Ip') is not None:
            self.ip = m.get('Ip')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationImageRegistryCredentials(TeaModel):
    def __init__(self, password=None, server=None, user_name=None):
        self.password = password  # type: str
        self.server = server  # type: str
        self.user_name = user_name  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationImageRegistryCredentials, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.password is not None:
            result['Password'] = self.password
        if self.server is not None:
            result['Server'] = self.server
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('Server') is not None:
            self.server = m.get('Server')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerEnvironmentVars(TeaModel):
    def __init__(self, field_ref_field_path=None, key=None, value=None):
        self.field_ref_field_path = field_ref_field_path  # type: str
        self.key = key  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref_field_path is not None:
            result['FieldRefFieldPath'] = self.field_ref_field_path
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRefFieldPath') is not None:
            self.field_ref_field_path = m.get('FieldRefFieldPath')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        self.port = port  # type: int
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        self.mount_path = mount_path  # type: str
        self.mount_propagation = mount_propagation  # type: str
        self.name = name  # type: str
        self.read_only = read_only  # type: bool
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainers(TeaModel):
    def __init__(self, cpu=None, gpu=None, image=None, image_pull_policy=None, init_container_args=None,
                 init_container_commands=None, init_container_environment_vars=None, init_container_ports=None,
                 init_container_volume_mounts=None, memory=None, name=None, security_context_capability_adds=None,
                 security_context_read_only_root_filesystem=None, security_context_run_as_user=None, working_dir=None):
        self.cpu = cpu  # type: float
        self.gpu = gpu  # type: int
        self.image = image  # type: str
        self.image_pull_policy = image_pull_policy  # type: str
        self.init_container_args = init_container_args  # type: list[str]
        self.init_container_commands = init_container_commands  # type: list[str]
        self.init_container_environment_vars = init_container_environment_vars  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerEnvironmentVars]
        self.init_container_ports = init_container_ports  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerPorts]
        self.init_container_volume_mounts = init_container_volume_mounts  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerVolumeMounts]
        self.memory = memory  # type: float
        self.name = name  # type: str
        self.security_context_capability_adds = security_context_capability_adds  # type: list[str]
        self.security_context_read_only_root_filesystem = security_context_read_only_root_filesystem  # type: bool
        self.security_context_run_as_user = security_context_run_as_user  # type: str
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.init_container_environment_vars:
            for k in self.init_container_environment_vars:
                if k:
                    k.validate()
        if self.init_container_ports:
            for k in self.init_container_ports:
                if k:
                    k.validate()
        if self.init_container_volume_mounts:
            for k in self.init_container_volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        if self.init_container_args is not None:
            result['InitContainerArgs'] = self.init_container_args
        if self.init_container_commands is not None:
            result['InitContainerCommands'] = self.init_container_commands
        result['InitContainerEnvironmentVars'] = []
        if self.init_container_environment_vars is not None:
            for k in self.init_container_environment_vars:
                result['InitContainerEnvironmentVars'].append(k.to_map() if k else None)
        result['InitContainerPorts'] = []
        if self.init_container_ports is not None:
            for k in self.init_container_ports:
                result['InitContainerPorts'].append(k.to_map() if k else None)
        result['InitContainerVolumeMounts'] = []
        if self.init_container_volume_mounts is not None:
            for k in self.init_container_volume_mounts:
                result['InitContainerVolumeMounts'].append(k.to_map() if k else None)
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        if self.security_context_capability_adds is not None:
            result['SecurityContextCapabilityAdds'] = self.security_context_capability_adds
        if self.security_context_read_only_root_filesystem is not None:
            result['SecurityContextReadOnlyRootFilesystem'] = self.security_context_read_only_root_filesystem
        if self.security_context_run_as_user is not None:
            result['SecurityContextRunAsUser'] = self.security_context_run_as_user
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        if m.get('InitContainerArgs') is not None:
            self.init_container_args = m.get('InitContainerArgs')
        if m.get('InitContainerCommands') is not None:
            self.init_container_commands = m.get('InitContainerCommands')
        self.init_container_environment_vars = []
        if m.get('InitContainerEnvironmentVars') is not None:
            for k in m.get('InitContainerEnvironmentVars'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerEnvironmentVars()
                self.init_container_environment_vars.append(temp_model.from_map(k))
        self.init_container_ports = []
        if m.get('InitContainerPorts') is not None:
            for k in m.get('InitContainerPorts'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerPorts()
                self.init_container_ports.append(temp_model.from_map(k))
        self.init_container_volume_mounts = []
        if m.get('InitContainerVolumeMounts') is not None:
            for k in m.get('InitContainerVolumeMounts'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainersInitContainerVolumeMounts()
                self.init_container_volume_mounts.append(temp_model.from_map(k))
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('SecurityContextCapabilityAdds') is not None:
            self.security_context_capability_adds = m.get('SecurityContextCapabilityAdds')
        if m.get('SecurityContextReadOnlyRootFilesystem') is not None:
            self.security_context_read_only_root_filesystem = m.get('SecurityContextReadOnlyRootFilesystem')
        if m.get('SecurityContextRunAsUser') is not None:
            self.security_context_run_as_user = m.get('SecurityContextRunAsUser')
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationSecurityContextSysCtls(TeaModel):
    def __init__(self, name=None, value=None):
        self.name = name  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationSecurityContextSysCtls, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationTags(TeaModel):
    def __init__(self, key=None, value=None):
        self.key = key  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumesConfigFileVolumeConfigFileToPaths(TeaModel):
    def __init__(self, content=None, mode=None, path=None):
        self.content = content  # type: str
        self.mode = mode  # type: int
        self.path = path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumesConfigFileVolumeConfigFileToPaths, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.path is not None:
            result['Path'] = self.path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('Path') is not None:
            self.path = m.get('Path')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumes(TeaModel):
    def __init__(self, config_file_volume_config_file_to_paths=None, config_file_volume_default_mode=None,
                 disk_volume_disk_id=None, disk_volume_disk_size=None, disk_volume_fs_type=None, empty_dir_volume_medium=None,
                 empty_dir_volume_size_limit=None, flex_volume_driver=None, flex_volume_fs_type=None, flex_volume_options=None,
                 host_path_volume_path=None, host_path_volume_type=None, nfsvolume_path=None, nfsvolume_read_only=None,
                 nfsvolume_server=None, name=None, type=None):
        self.config_file_volume_config_file_to_paths = config_file_volume_config_file_to_paths  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumesConfigFileVolumeConfigFileToPaths]
        self.config_file_volume_default_mode = config_file_volume_default_mode  # type: int
        self.disk_volume_disk_id = disk_volume_disk_id  # type: str
        self.disk_volume_disk_size = disk_volume_disk_size  # type: int
        self.disk_volume_fs_type = disk_volume_fs_type  # type: str
        self.empty_dir_volume_medium = empty_dir_volume_medium  # type: str
        self.empty_dir_volume_size_limit = empty_dir_volume_size_limit  # type: str
        self.flex_volume_driver = flex_volume_driver  # type: str
        self.flex_volume_fs_type = flex_volume_fs_type  # type: str
        self.flex_volume_options = flex_volume_options  # type: str
        self.host_path_volume_path = host_path_volume_path  # type: str
        self.host_path_volume_type = host_path_volume_type  # type: str
        self.nfsvolume_path = nfsvolume_path  # type: str
        self.nfsvolume_read_only = nfsvolume_read_only  # type: bool
        self.nfsvolume_server = nfsvolume_server  # type: str
        self.name = name  # type: str
        self.type = type  # type: str

    def validate(self):
        if self.config_file_volume_config_file_to_paths:
            for k in self.config_file_volume_config_file_to_paths:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ConfigFileVolumeConfigFileToPaths'] = []
        if self.config_file_volume_config_file_to_paths is not None:
            for k in self.config_file_volume_config_file_to_paths:
                result['ConfigFileVolumeConfigFileToPaths'].append(k.to_map() if k else None)
        if self.config_file_volume_default_mode is not None:
            result['ConfigFileVolumeDefaultMode'] = self.config_file_volume_default_mode
        if self.disk_volume_disk_id is not None:
            result['DiskVolumeDiskId'] = self.disk_volume_disk_id
        if self.disk_volume_disk_size is not None:
            result['DiskVolumeDiskSize'] = self.disk_volume_disk_size
        if self.disk_volume_fs_type is not None:
            result['DiskVolumeFsType'] = self.disk_volume_fs_type
        if self.empty_dir_volume_medium is not None:
            result['EmptyDirVolumeMedium'] = self.empty_dir_volume_medium
        if self.empty_dir_volume_size_limit is not None:
            result['EmptyDirVolumeSizeLimit'] = self.empty_dir_volume_size_limit
        if self.flex_volume_driver is not None:
            result['FlexVolumeDriver'] = self.flex_volume_driver
        if self.flex_volume_fs_type is not None:
            result['FlexVolumeFsType'] = self.flex_volume_fs_type
        if self.flex_volume_options is not None:
            result['FlexVolumeOptions'] = self.flex_volume_options
        if self.host_path_volume_path is not None:
            result['HostPathVolumePath'] = self.host_path_volume_path
        if self.host_path_volume_type is not None:
            result['HostPathVolumeType'] = self.host_path_volume_type
        if self.nfsvolume_path is not None:
            result['NFSVolumePath'] = self.nfsvolume_path
        if self.nfsvolume_read_only is not None:
            result['NFSVolumeReadOnly'] = self.nfsvolume_read_only
        if self.nfsvolume_server is not None:
            result['NFSVolumeServer'] = self.nfsvolume_server
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.config_file_volume_config_file_to_paths = []
        if m.get('ConfigFileVolumeConfigFileToPaths') is not None:
            for k in m.get('ConfigFileVolumeConfigFileToPaths'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumesConfigFileVolumeConfigFileToPaths()
                self.config_file_volume_config_file_to_paths.append(temp_model.from_map(k))
        if m.get('ConfigFileVolumeDefaultMode') is not None:
            self.config_file_volume_default_mode = m.get('ConfigFileVolumeDefaultMode')
        if m.get('DiskVolumeDiskId') is not None:
            self.disk_volume_disk_id = m.get('DiskVolumeDiskId')
        if m.get('DiskVolumeDiskSize') is not None:
            self.disk_volume_disk_size = m.get('DiskVolumeDiskSize')
        if m.get('DiskVolumeFsType') is not None:
            self.disk_volume_fs_type = m.get('DiskVolumeFsType')
        if m.get('EmptyDirVolumeMedium') is not None:
            self.empty_dir_volume_medium = m.get('EmptyDirVolumeMedium')
        if m.get('EmptyDirVolumeSizeLimit') is not None:
            self.empty_dir_volume_size_limit = m.get('EmptyDirVolumeSizeLimit')
        if m.get('FlexVolumeDriver') is not None:
            self.flex_volume_driver = m.get('FlexVolumeDriver')
        if m.get('FlexVolumeFsType') is not None:
            self.flex_volume_fs_type = m.get('FlexVolumeFsType')
        if m.get('FlexVolumeOptions') is not None:
            self.flex_volume_options = m.get('FlexVolumeOptions')
        if m.get('HostPathVolumePath') is not None:
            self.host_path_volume_path = m.get('HostPathVolumePath')
        if m.get('HostPathVolumeType') is not None:
            self.host_path_volume_type = m.get('HostPathVolumeType')
        if m.get('NFSVolumePath') is not None:
            self.nfsvolume_path = m.get('NFSVolumePath')
        if m.get('NFSVolumeReadOnly') is not None:
            self.nfsvolume_read_only = m.get('NFSVolumeReadOnly')
        if m.get('NFSVolumeServer') is not None:
            self.nfsvolume_server = m.get('NFSVolumeServer')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeEciScalingConfigurationDetailResponseBodyScalingConfiguration(TeaModel):
    def __init__(self, acr_registry_infos=None, active_deadline_seconds=None, auto_create_eip=None,
                 auto_match_image_cache=None, compute_category=None, container_group_name=None, containers=None, cost_optimization=None,
                 cpu=None, cpu_options_core=None, cpu_options_threads_per_core=None, creation_time=None,
                 data_cache_bucket=None, data_cache_bursting_enabled=None, data_cache_pl=None, data_cache_provisioned_iops=None,
                 description=None, dns_config_name_servers=None, dns_config_options=None, dns_config_searches=None,
                 dns_policy=None, egress_bandwidth=None, eip_bandwidth=None, eip_common_bandwidth_package=None, eip_isp=None,
                 eip_public_ip_address_pool_id=None, ephemeral_storage=None, host_aliases=None, host_name=None, image_registry_credentials=None,
                 image_snapshot_id=None, ingress_bandwidth=None, init_containers=None, instance_family_level=None,
                 instance_types=None, ipv_6address_count=None, lifecycle_state=None, load_balancer_weight=None, memory=None,
                 ntp_servers=None, ram_role_name=None, region_id=None, resource_group_id=None, restart_policy=None,
                 scaling_configuration_id=None, scaling_configuration_name=None, scaling_group_id=None, security_context_sys_ctls=None,
                 security_group_id=None, sls_enable=None, spot_price_limit=None, spot_strategy=None, tags=None,
                 termination_grace_period_seconds=None, volumes=None):
        self.acr_registry_infos = acr_registry_infos  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationAcrRegistryInfos]
        self.active_deadline_seconds = active_deadline_seconds  # type: int
        self.auto_create_eip = auto_create_eip  # type: bool
        self.auto_match_image_cache = auto_match_image_cache  # type: bool
        self.compute_category = compute_category  # type: list[str]
        self.container_group_name = container_group_name  # type: str
        self.containers = containers  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainers]
        self.cost_optimization = cost_optimization  # type: bool
        self.cpu = cpu  # type: float
        self.cpu_options_core = cpu_options_core  # type: int
        self.cpu_options_threads_per_core = cpu_options_threads_per_core  # type: int
        self.creation_time = creation_time  # type: str
        self.data_cache_bucket = data_cache_bucket  # type: str
        self.data_cache_bursting_enabled = data_cache_bursting_enabled  # type: bool
        self.data_cache_pl = data_cache_pl  # type: str
        self.data_cache_provisioned_iops = data_cache_provisioned_iops  # type: int
        self.description = description  # type: str
        self.dns_config_name_servers = dns_config_name_servers  # type: list[str]
        self.dns_config_options = dns_config_options  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationDnsConfigOptions]
        self.dns_config_searches = dns_config_searches  # type: list[str]
        self.dns_policy = dns_policy  # type: str
        self.egress_bandwidth = egress_bandwidth  # type: long
        self.eip_bandwidth = eip_bandwidth  # type: int
        self.eip_common_bandwidth_package = eip_common_bandwidth_package  # type: str
        self.eip_isp = eip_isp  # type: str
        self.eip_public_ip_address_pool_id = eip_public_ip_address_pool_id  # type: str
        self.ephemeral_storage = ephemeral_storage  # type: int
        self.host_aliases = host_aliases  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationHostAliases]
        self.host_name = host_name  # type: str
        self.image_registry_credentials = image_registry_credentials  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationImageRegistryCredentials]
        self.image_snapshot_id = image_snapshot_id  # type: str
        self.ingress_bandwidth = ingress_bandwidth  # type: long
        self.init_containers = init_containers  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainers]
        self.instance_family_level = instance_family_level  # type: str
        self.instance_types = instance_types  # type: list[str]
        self.ipv_6address_count = ipv_6address_count  # type: int
        self.lifecycle_state = lifecycle_state  # type: str
        self.load_balancer_weight = load_balancer_weight  # type: int
        self.memory = memory  # type: float
        self.ntp_servers = ntp_servers  # type: list[str]
        self.ram_role_name = ram_role_name  # type: str
        self.region_id = region_id  # type: str
        self.resource_group_id = resource_group_id  # type: str
        self.restart_policy = restart_policy  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.security_context_sys_ctls = security_context_sys_ctls  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationSecurityContextSysCtls]
        self.security_group_id = security_group_id  # type: str
        self.sls_enable = sls_enable  # type: bool
        self.spot_price_limit = spot_price_limit  # type: float
        self.spot_strategy = spot_strategy  # type: str
        self.tags = tags  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationTags]
        self.termination_grace_period_seconds = termination_grace_period_seconds  # type: int
        self.volumes = volumes  # type: list[DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumes]

    def validate(self):
        if self.acr_registry_infos:
            for k in self.acr_registry_infos:
                if k:
                    k.validate()
        if self.containers:
            for k in self.containers:
                if k:
                    k.validate()
        if self.dns_config_options:
            for k in self.dns_config_options:
                if k:
                    k.validate()
        if self.host_aliases:
            for k in self.host_aliases:
                if k:
                    k.validate()
        if self.image_registry_credentials:
            for k in self.image_registry_credentials:
                if k:
                    k.validate()
        if self.init_containers:
            for k in self.init_containers:
                if k:
                    k.validate()
        if self.security_context_sys_ctls:
            for k in self.security_context_sys_ctls:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.volumes:
            for k in self.volumes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBodyScalingConfiguration, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcrRegistryInfos'] = []
        if self.acr_registry_infos is not None:
            for k in self.acr_registry_infos:
                result['AcrRegistryInfos'].append(k.to_map() if k else None)
        if self.active_deadline_seconds is not None:
            result['ActiveDeadlineSeconds'] = self.active_deadline_seconds
        if self.auto_create_eip is not None:
            result['AutoCreateEip'] = self.auto_create_eip
        if self.auto_match_image_cache is not None:
            result['AutoMatchImageCache'] = self.auto_match_image_cache
        if self.compute_category is not None:
            result['ComputeCategory'] = self.compute_category
        if self.container_group_name is not None:
            result['ContainerGroupName'] = self.container_group_name
        result['Containers'] = []
        if self.containers is not None:
            for k in self.containers:
                result['Containers'].append(k.to_map() if k else None)
        if self.cost_optimization is not None:
            result['CostOptimization'] = self.cost_optimization
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.cpu_options_core is not None:
            result['CpuOptionsCore'] = self.cpu_options_core
        if self.cpu_options_threads_per_core is not None:
            result['CpuOptionsThreadsPerCore'] = self.cpu_options_threads_per_core
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.data_cache_bucket is not None:
            result['DataCacheBucket'] = self.data_cache_bucket
        if self.data_cache_bursting_enabled is not None:
            result['DataCacheBurstingEnabled'] = self.data_cache_bursting_enabled
        if self.data_cache_pl is not None:
            result['DataCachePL'] = self.data_cache_pl
        if self.data_cache_provisioned_iops is not None:
            result['DataCacheProvisionedIops'] = self.data_cache_provisioned_iops
        if self.description is not None:
            result['Description'] = self.description
        if self.dns_config_name_servers is not None:
            result['DnsConfigNameServers'] = self.dns_config_name_servers
        result['DnsConfigOptions'] = []
        if self.dns_config_options is not None:
            for k in self.dns_config_options:
                result['DnsConfigOptions'].append(k.to_map() if k else None)
        if self.dns_config_searches is not None:
            result['DnsConfigSearches'] = self.dns_config_searches
        if self.dns_policy is not None:
            result['DnsPolicy'] = self.dns_policy
        if self.egress_bandwidth is not None:
            result['EgressBandwidth'] = self.egress_bandwidth
        if self.eip_bandwidth is not None:
            result['EipBandwidth'] = self.eip_bandwidth
        if self.eip_common_bandwidth_package is not None:
            result['EipCommonBandwidthPackage'] = self.eip_common_bandwidth_package
        if self.eip_isp is not None:
            result['EipISP'] = self.eip_isp
        if self.eip_public_ip_address_pool_id is not None:
            result['EipPublicIpAddressPoolId'] = self.eip_public_ip_address_pool_id
        if self.ephemeral_storage is not None:
            result['EphemeralStorage'] = self.ephemeral_storage
        result['HostAliases'] = []
        if self.host_aliases is not None:
            for k in self.host_aliases:
                result['HostAliases'].append(k.to_map() if k else None)
        if self.host_name is not None:
            result['HostName'] = self.host_name
        result['ImageRegistryCredentials'] = []
        if self.image_registry_credentials is not None:
            for k in self.image_registry_credentials:
                result['ImageRegistryCredentials'].append(k.to_map() if k else None)
        if self.image_snapshot_id is not None:
            result['ImageSnapshotId'] = self.image_snapshot_id
        if self.ingress_bandwidth is not None:
            result['IngressBandwidth'] = self.ingress_bandwidth
        result['InitContainers'] = []
        if self.init_containers is not None:
            for k in self.init_containers:
                result['InitContainers'].append(k.to_map() if k else None)
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.ntp_servers is not None:
            result['NtpServers'] = self.ntp_servers
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.restart_policy is not None:
            result['RestartPolicy'] = self.restart_policy
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['SecurityContextSysCtls'] = []
        if self.security_context_sys_ctls is not None:
            for k in self.security_context_sys_ctls:
                result['SecurityContextSysCtls'].append(k.to_map() if k else None)
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.sls_enable is not None:
            result['SlsEnable'] = self.sls_enable
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.termination_grace_period_seconds is not None:
            result['TerminationGracePeriodSeconds'] = self.termination_grace_period_seconds
        result['Volumes'] = []
        if self.volumes is not None:
            for k in self.volumes:
                result['Volumes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.acr_registry_infos = []
        if m.get('AcrRegistryInfos') is not None:
            for k in m.get('AcrRegistryInfos'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationAcrRegistryInfos()
                self.acr_registry_infos.append(temp_model.from_map(k))
        if m.get('ActiveDeadlineSeconds') is not None:
            self.active_deadline_seconds = m.get('ActiveDeadlineSeconds')
        if m.get('AutoCreateEip') is not None:
            self.auto_create_eip = m.get('AutoCreateEip')
        if m.get('AutoMatchImageCache') is not None:
            self.auto_match_image_cache = m.get('AutoMatchImageCache')
        if m.get('ComputeCategory') is not None:
            self.compute_category = m.get('ComputeCategory')
        if m.get('ContainerGroupName') is not None:
            self.container_group_name = m.get('ContainerGroupName')
        self.containers = []
        if m.get('Containers') is not None:
            for k in m.get('Containers'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationContainers()
                self.containers.append(temp_model.from_map(k))
        if m.get('CostOptimization') is not None:
            self.cost_optimization = m.get('CostOptimization')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CpuOptionsCore') is not None:
            self.cpu_options_core = m.get('CpuOptionsCore')
        if m.get('CpuOptionsThreadsPerCore') is not None:
            self.cpu_options_threads_per_core = m.get('CpuOptionsThreadsPerCore')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('DataCacheBucket') is not None:
            self.data_cache_bucket = m.get('DataCacheBucket')
        if m.get('DataCacheBurstingEnabled') is not None:
            self.data_cache_bursting_enabled = m.get('DataCacheBurstingEnabled')
        if m.get('DataCachePL') is not None:
            self.data_cache_pl = m.get('DataCachePL')
        if m.get('DataCacheProvisionedIops') is not None:
            self.data_cache_provisioned_iops = m.get('DataCacheProvisionedIops')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DnsConfigNameServers') is not None:
            self.dns_config_name_servers = m.get('DnsConfigNameServers')
        self.dns_config_options = []
        if m.get('DnsConfigOptions') is not None:
            for k in m.get('DnsConfigOptions'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationDnsConfigOptions()
                self.dns_config_options.append(temp_model.from_map(k))
        if m.get('DnsConfigSearches') is not None:
            self.dns_config_searches = m.get('DnsConfigSearches')
        if m.get('DnsPolicy') is not None:
            self.dns_policy = m.get('DnsPolicy')
        if m.get('EgressBandwidth') is not None:
            self.egress_bandwidth = m.get('EgressBandwidth')
        if m.get('EipBandwidth') is not None:
            self.eip_bandwidth = m.get('EipBandwidth')
        if m.get('EipCommonBandwidthPackage') is not None:
            self.eip_common_bandwidth_package = m.get('EipCommonBandwidthPackage')
        if m.get('EipISP') is not None:
            self.eip_isp = m.get('EipISP')
        if m.get('EipPublicIpAddressPoolId') is not None:
            self.eip_public_ip_address_pool_id = m.get('EipPublicIpAddressPoolId')
        if m.get('EphemeralStorage') is not None:
            self.ephemeral_storage = m.get('EphemeralStorage')
        self.host_aliases = []
        if m.get('HostAliases') is not None:
            for k in m.get('HostAliases'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationHostAliases()
                self.host_aliases.append(temp_model.from_map(k))
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        self.image_registry_credentials = []
        if m.get('ImageRegistryCredentials') is not None:
            for k in m.get('ImageRegistryCredentials'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationImageRegistryCredentials()
                self.image_registry_credentials.append(temp_model.from_map(k))
        if m.get('ImageSnapshotId') is not None:
            self.image_snapshot_id = m.get('ImageSnapshotId')
        if m.get('IngressBandwidth') is not None:
            self.ingress_bandwidth = m.get('IngressBandwidth')
        self.init_containers = []
        if m.get('InitContainers') is not None:
            for k in m.get('InitContainers'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationInitContainers()
                self.init_containers.append(temp_model.from_map(k))
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('NtpServers') is not None:
            self.ntp_servers = m.get('NtpServers')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('RestartPolicy') is not None:
            self.restart_policy = m.get('RestartPolicy')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.security_context_sys_ctls = []
        if m.get('SecurityContextSysCtls') is not None:
            for k in m.get('SecurityContextSysCtls'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationSecurityContextSysCtls()
                self.security_context_sys_ctls.append(temp_model.from_map(k))
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SlsEnable') is not None:
            self.sls_enable = m.get('SlsEnable')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('TerminationGracePeriodSeconds') is not None:
            self.termination_grace_period_seconds = m.get('TerminationGracePeriodSeconds')
        self.volumes = []
        if m.get('Volumes') is not None:
            for k in m.get('Volumes'):
                temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfigurationVolumes()
                self.volumes.append(temp_model.from_map(k))
        return self


class DescribeEciScalingConfigurationDetailResponseBody(TeaModel):
    def __init__(self, output=None, request_id=None, scaling_configuration=None):
        self.output = output  # type: str
        self.request_id = request_id  # type: str
        self.scaling_configuration = scaling_configuration  # type: DescribeEciScalingConfigurationDetailResponseBodyScalingConfiguration

    def validate(self):
        if self.scaling_configuration:
            self.scaling_configuration.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.output is not None:
            result['Output'] = self.output
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_configuration is not None:
            result['ScalingConfiguration'] = self.scaling_configuration.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingConfiguration') is not None:
            temp_model = DescribeEciScalingConfigurationDetailResponseBodyScalingConfiguration()
            self.scaling_configuration = temp_model.from_map(m['ScalingConfiguration'])
        return self


class DescribeEciScalingConfigurationDetailResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeEciScalingConfigurationDetailResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationDetailResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeEciScalingConfigurationDetailResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeEciScalingConfigurationsRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, page_number=None, page_size=None, region_id=None,
                 resource_owner_account=None, resource_owner_id=None, scaling_configuration_ids=None, scaling_configuration_names=None,
                 scaling_group_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The number of the page to return. Pages start from page 1.
        # 
        # Default value: 1.
        self.page_number = page_number  # type: int
        # The number of entries to return on each page. Maximum value: 50.
        # 
        # Default value: 10.
        self.page_size = page_size  # type: int
        # The region ID of the scaling group to which the scaling configuration belongs.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The IDs of the scaling configurations that you want to query.
        # 
        # The IDs of active and inactive scaling configurations are displayed in the query results. You can differentiate between active and inactive scaling configurations based on the value of the `LifecycleState` parameter.
        self.scaling_configuration_ids = scaling_configuration_ids  # type: list[str]
        # The names of the scaling configurations that you want to query.
        # 
        # The names of inactive scaling configurations are not displayed in the query results, and no error is reported.
        self.scaling_configuration_names = scaling_configuration_names  # type: list[str]
        # The ID of the scaling group. You can use the ID to query all scaling configurations in the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_configuration_ids is not None:
            result['ScalingConfigurationIds'] = self.scaling_configuration_ids
        if self.scaling_configuration_names is not None:
            result['ScalingConfigurationNames'] = self.scaling_configuration_names
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingConfigurationIds') is not None:
            self.scaling_configuration_ids = m.get('ScalingConfigurationIds')
        if m.get('ScalingConfigurationNames') is not None:
            self.scaling_configuration_names = m.get('ScalingConfigurationNames')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsAcrRegistryInfos(TeaModel):
    def __init__(self, domains=None, instance_id=None, instance_name=None, region_id=None):
        # The domain name of the Container Registry Enterprise Edition instance. By default, all domain names of the Container Registry Enterprise Edition instance are displayed. You can specify one or more domain names. Separate multiple domain names with commas (,).
        self.domains = domains  # type: list[str]
        # The ID of the Container Registry Enterprise Edition instance.
        self.instance_id = instance_id  # type: str
        # The name of the Container Registry Enterprise Edition instance.
        self.instance_name = instance_name  # type: str
        # The region ID of the Container Registry Enterprise Edition instance.
        self.region_id = region_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsAcrRegistryInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.domains is not None:
            result['Domains'] = self.domains
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Domains') is not None:
            self.domains = m.get('Domains')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersEnvironmentVars(TeaModel):
    def __init__(self, field_ref_field_path=None, key=None, value=None):
        # > This parameter is unavailable.
        self.field_ref_field_path = field_ref_field_path  # type: str
        # The name of the environment variable.
        self.key = key  # type: str
        # The value of the environment variable.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref_field_path is not None:
            result['FieldRefFieldPath'] = self.field_ref_field_path
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRefFieldPath') is not None:
            self.field_ref_field_path = m.get('FieldRefFieldPath')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        # The port number. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The protocol. Valid values:
        # 
        # *   TCP
        # *   UDP
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        # The directory in which the container mounts the volume.
        # 
        # > Data in this directory is overwritten by the data on the volume.
        self.mount_path = mount_path  # type: str
        # The mount propagation setting of the volume. Mount propagation allows the sharing of volumes that are mounted on one container with other containers in the same pod, or even with other pods on the same node. Valid values:
        # 
        # *   None: The volume mount does not receive subsequent mounts that are mounted to this volume or its subdirectories.
        # *   HostToCotainer: The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories.
        # *   Bidirectional: This value is similar to HostToCotainer. The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories. In addition, all volume mounts that are created by the container are propagated back to the instance and to all containers of all pods that use the same volume.
        # 
        # Default value: None.
        self.mount_propagation = mount_propagation  # type: str
        # The name of the volume. The value of this parameter is the same as the value of the Volumes.Name parameter.
        self.name = name  # type: str
        # Indicates whether the volume is read-only.
        # 
        # Default value: false.
        self.read_only = read_only  # type: bool
        # The subdirectory of the volume.
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainers(TeaModel):
    def __init__(self, args=None, commands=None, cpu=None, environment_vars=None, gpu=None, image=None,
                 image_pull_policy=None, lifecycle_post_start_handler_execs=None, lifecycle_post_start_handler_http_get_host=None,
                 lifecycle_post_start_handler_http_get_path=None, lifecycle_post_start_handler_http_get_port=None,
                 lifecycle_post_start_handler_http_get_scheme=None, lifecycle_post_start_handler_tcp_socket_host=None,
                 lifecycle_post_start_handler_tcp_socket_port=None, lifecycle_pre_stop_handler_execs=None, lifecycle_pre_stop_handler_http_get_host=None,
                 lifecycle_pre_stop_handler_http_get_path=None, lifecycle_pre_stop_handler_http_get_port=None,
                 lifecycle_pre_stop_handler_http_get_scheme=None, lifecycle_pre_stop_handler_tcp_socket_host=None,
                 lifecycle_pre_stop_handler_tcp_socket_port=None, liveness_probe_exec_commands=None, liveness_probe_failure_threshold=None,
                 liveness_probe_http_get_path=None, liveness_probe_http_get_port=None, liveness_probe_http_get_scheme=None,
                 liveness_probe_initial_delay_seconds=None, liveness_probe_period_seconds=None, liveness_probe_success_threshold=None,
                 liveness_probe_tcp_socket_port=None, liveness_probe_timeout_seconds=None, memory=None, name=None, ports=None,
                 readiness_probe_exec_commands=None, readiness_probe_failure_threshold=None, readiness_probe_http_get_path=None,
                 readiness_probe_http_get_port=None, readiness_probe_http_get_scheme=None, readiness_probe_initial_delay_seconds=None,
                 readiness_probe_period_seconds=None, readiness_probe_success_threshold=None, readiness_probe_tcp_socket_port=None,
                 readiness_probe_timeout_seconds=None, security_context_capability_adds=None, security_context_read_only_root_filesystem=None,
                 security_context_run_as_user=None, stdin=None, stdin_once=None, tty=None, volume_mounts=None, working_dir=None):
        # The arguments that are passed to the container startup commands. You can specify up to 10 arguments.
        self.args = args  # type: list[str]
        # The container startup commands. You can specify up to 20 commands. Each command can contain up to 256 characters.
        self.commands = commands  # type: list[str]
        # The number of vCPUs that are allocated to the container.
        self.cpu = cpu  # type: float
        # Details of the environment variables.
        self.environment_vars = environment_vars  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersEnvironmentVars]
        # The number of GPUs.
        self.gpu = gpu  # type: int
        # The image of the container.
        self.image = image  # type: str
        # The image pulling policy. Valid values:
        # 
        # *   Always: Image pulling is performed each time.
        # *   IfNotPresent: Image pulling is performed only if on-premises images are unavailable. On-premises images are preferentially used. If no on-premises images are available, image pulling is performed.
        # *   Never: On-premises images are always used. Image pulling is not performed.
        self.image_pull_policy = image_pull_policy  # type: str
        self.lifecycle_post_start_handler_execs = lifecycle_post_start_handler_execs  # type: list[str]
        self.lifecycle_post_start_handler_http_get_host = lifecycle_post_start_handler_http_get_host  # type: str
        self.lifecycle_post_start_handler_http_get_path = lifecycle_post_start_handler_http_get_path  # type: str
        self.lifecycle_post_start_handler_http_get_port = lifecycle_post_start_handler_http_get_port  # type: int
        self.lifecycle_post_start_handler_http_get_scheme = lifecycle_post_start_handler_http_get_scheme  # type: str
        self.lifecycle_post_start_handler_tcp_socket_host = lifecycle_post_start_handler_tcp_socket_host  # type: str
        self.lifecycle_post_start_handler_tcp_socket_port = lifecycle_post_start_handler_tcp_socket_port  # type: int
        self.lifecycle_pre_stop_handler_execs = lifecycle_pre_stop_handler_execs  # type: list[str]
        self.lifecycle_pre_stop_handler_http_get_host = lifecycle_pre_stop_handler_http_get_host  # type: str
        self.lifecycle_pre_stop_handler_http_get_path = lifecycle_pre_stop_handler_http_get_path  # type: str
        self.lifecycle_pre_stop_handler_http_get_port = lifecycle_pre_stop_handler_http_get_port  # type: int
        self.lifecycle_pre_stop_handler_http_get_scheme = lifecycle_pre_stop_handler_http_get_scheme  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_host = lifecycle_pre_stop_handler_tcp_socket_host  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_port = lifecycle_pre_stop_handler_tcp_socket_port  # type: int
        # The commands that are run in the container when you use the CLI to perform probes.
        self.liveness_probe_exec_commands = liveness_probe_exec_commands  # type: list[str]
        # The minimum number of consecutive failures for a probe to be considered failed after having been successful.
        # 
        # Default value: 3.
        self.liveness_probe_failure_threshold = liveness_probe_failure_threshold  # type: int
        # The path to which the system sends an HTTP GET request for a probe.
        self.liveness_probe_http_get_path = liveness_probe_http_get_path  # type: str
        # The port to which HTTP GET requests were sent.
        self.liveness_probe_http_get_port = liveness_probe_http_get_port  # type: int
        # The protocol type of HTTP GET requests when you use HTTP requests to perform probes. Valid values:
        # 
        # *   HTTP
        # *   HTTPS
        self.liveness_probe_http_get_scheme = liveness_probe_http_get_scheme  # type: str
        # The number of seconds between the time when the startup of the container ends and the time when the probe starts.
        self.liveness_probe_initial_delay_seconds = liveness_probe_initial_delay_seconds  # type: int
        # The interval at which probes are performed. Default value: 10. Minimum value: 1. Unit: seconds.
        self.liveness_probe_period_seconds = liveness_probe_period_seconds  # type: int
        # The minimum number of consecutive successes for a probe to be considered successful after having failed. Default value: 1. Valid value: 1.
        self.liveness_probe_success_threshold = liveness_probe_success_threshold  # type: int
        # The port number of TcpSocket.
        self.liveness_probe_tcp_socket_port = liveness_probe_tcp_socket_port  # type: int
        # The timeout period of a probe. Default value: 1. Minimum value: 1. Unit: seconds.
        self.liveness_probe_timeout_seconds = liveness_probe_timeout_seconds  # type: int
        # The memory size of the container.
        self.memory = memory  # type: float
        # The name of the container.
        self.name = name  # type: str
        # The exposed ports and protocols of the container.
        self.ports = ports  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersPorts]
        # The commands that are run in the container when you use the CLI to perform probes.
        self.readiness_probe_exec_commands = readiness_probe_exec_commands  # type: list[str]
        # The minimum number of consecutive failures for a probe to be considered failed after having been successful.
        # 
        # Default value: 3.
        self.readiness_probe_failure_threshold = readiness_probe_failure_threshold  # type: int
        # The path to which the system sends an HTTP GET request for a probe.
        self.readiness_probe_http_get_path = readiness_probe_http_get_path  # type: str
        # The path to which the system sends an HTTP GET request for a probe.
        self.readiness_probe_http_get_port = readiness_probe_http_get_port  # type: int
        # The protocol type of HTTP GET requests when you use HTTP requests to perform probes. Valid values:
        # 
        # *   HTTP
        # *   HTTPS
        self.readiness_probe_http_get_scheme = readiness_probe_http_get_scheme  # type: str
        # The number of seconds between the time when the startup of the container ends and the time when the probe starts.
        self.readiness_probe_initial_delay_seconds = readiness_probe_initial_delay_seconds  # type: int
        # The interval at which probes are performed. Default value: 10. Minimum value: 1. Unit: seconds.
        self.readiness_probe_period_seconds = readiness_probe_period_seconds  # type: int
        # The minimum number of consecutive successes for a probe to be considered successful after having failed. Default value: 1. Valid value: 1.
        self.readiness_probe_success_threshold = readiness_probe_success_threshold  # type: int
        # The port number of TcpSocket.
        self.readiness_probe_tcp_socket_port = readiness_probe_tcp_socket_port  # type: int
        # The timeout period of a probe. Default value: 1. Minimum value: 1. Unit: seconds.
        self.readiness_probe_timeout_seconds = readiness_probe_timeout_seconds  # type: int
        # The permissions granted to processes in the container. Valid values: NET_ADMIN and NET_RAW.
        # 
        # > To use NET_RAW, you need to submit a ticket.
        self.security_context_capability_adds = security_context_capability_adds  # type: list[str]
        # Indicates whether the root file system is set to the read-only mode. The only valid value is true.
        self.security_context_read_only_root_filesystem = security_context_read_only_root_filesystem  # type: bool
        # The user ID (UID) that is used to run the entry point of the container process.
        self.security_context_run_as_user = security_context_run_as_user  # type: long
        # Indicates whether the container allocates buffer resources to standard input streams when the container runs. If you do not specify this parameter, an end-of-file (EOF) error may occur. Default value: false.
        self.stdin = stdin  # type: bool
        # Indicates whether standard input streams are disconnected after a client is disconnected. If Stdin is set to true, standard input streams remain connected during multiple sessions.
        # 
        # If StdinOnce is set to true, standard input streams are connected after the container is started and remain idle until a client is connected to receive data. After the client is disconnected, streams are also disconnected and remain in the disconnected state until the container is started again.
        self.stdin_once = stdin_once  # type: bool
        # Indicates whether interaction is enabled. Valid values:
        # 
        # *   true
        # *   false
        # 
        # If the value of the Command parameter is /bin/bash, the value of this parameter is true.
        # 
        # Default value: false.
        self.tty = tty  # type: bool
        # The volumes that are mounted on the container.
        self.volume_mounts = volume_mounts  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersVolumeMounts]
        # The working directory of the container.
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.environment_vars:
            for k in self.environment_vars:
                if k:
                    k.validate()
        if self.ports:
            for k in self.ports:
                if k:
                    k.validate()
        if self.volume_mounts:
            for k in self.volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        result['EnvironmentVars'] = []
        if self.environment_vars is not None:
            for k in self.environment_vars:
                result['EnvironmentVars'].append(k.to_map() if k else None)
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        if self.lifecycle_post_start_handler_execs is not None:
            result['LifecyclePostStartHandlerExecs'] = self.lifecycle_post_start_handler_execs
        if self.lifecycle_post_start_handler_http_get_host is not None:
            result['LifecyclePostStartHandlerHttpGetHost'] = self.lifecycle_post_start_handler_http_get_host
        if self.lifecycle_post_start_handler_http_get_path is not None:
            result['LifecyclePostStartHandlerHttpGetPath'] = self.lifecycle_post_start_handler_http_get_path
        if self.lifecycle_post_start_handler_http_get_port is not None:
            result['LifecyclePostStartHandlerHttpGetPort'] = self.lifecycle_post_start_handler_http_get_port
        if self.lifecycle_post_start_handler_http_get_scheme is not None:
            result['LifecyclePostStartHandlerHttpGetScheme'] = self.lifecycle_post_start_handler_http_get_scheme
        if self.lifecycle_post_start_handler_tcp_socket_host is not None:
            result['LifecyclePostStartHandlerTcpSocketHost'] = self.lifecycle_post_start_handler_tcp_socket_host
        if self.lifecycle_post_start_handler_tcp_socket_port is not None:
            result['LifecyclePostStartHandlerTcpSocketPort'] = self.lifecycle_post_start_handler_tcp_socket_port
        if self.lifecycle_pre_stop_handler_execs is not None:
            result['LifecyclePreStopHandlerExecs'] = self.lifecycle_pre_stop_handler_execs
        if self.lifecycle_pre_stop_handler_http_get_host is not None:
            result['LifecyclePreStopHandlerHttpGetHost'] = self.lifecycle_pre_stop_handler_http_get_host
        if self.lifecycle_pre_stop_handler_http_get_path is not None:
            result['LifecyclePreStopHandlerHttpGetPath'] = self.lifecycle_pre_stop_handler_http_get_path
        if self.lifecycle_pre_stop_handler_http_get_port is not None:
            result['LifecyclePreStopHandlerHttpGetPort'] = self.lifecycle_pre_stop_handler_http_get_port
        if self.lifecycle_pre_stop_handler_http_get_scheme is not None:
            result['LifecyclePreStopHandlerHttpGetScheme'] = self.lifecycle_pre_stop_handler_http_get_scheme
        if self.lifecycle_pre_stop_handler_tcp_socket_host is not None:
            result['LifecyclePreStopHandlerTcpSocketHost'] = self.lifecycle_pre_stop_handler_tcp_socket_host
        if self.lifecycle_pre_stop_handler_tcp_socket_port is not None:
            result['LifecyclePreStopHandlerTcpSocketPort'] = self.lifecycle_pre_stop_handler_tcp_socket_port
        if self.liveness_probe_exec_commands is not None:
            result['LivenessProbeExecCommands'] = self.liveness_probe_exec_commands
        if self.liveness_probe_failure_threshold is not None:
            result['LivenessProbeFailureThreshold'] = self.liveness_probe_failure_threshold
        if self.liveness_probe_http_get_path is not None:
            result['LivenessProbeHttpGetPath'] = self.liveness_probe_http_get_path
        if self.liveness_probe_http_get_port is not None:
            result['LivenessProbeHttpGetPort'] = self.liveness_probe_http_get_port
        if self.liveness_probe_http_get_scheme is not None:
            result['LivenessProbeHttpGetScheme'] = self.liveness_probe_http_get_scheme
        if self.liveness_probe_initial_delay_seconds is not None:
            result['LivenessProbeInitialDelaySeconds'] = self.liveness_probe_initial_delay_seconds
        if self.liveness_probe_period_seconds is not None:
            result['LivenessProbePeriodSeconds'] = self.liveness_probe_period_seconds
        if self.liveness_probe_success_threshold is not None:
            result['LivenessProbeSuccessThreshold'] = self.liveness_probe_success_threshold
        if self.liveness_probe_tcp_socket_port is not None:
            result['LivenessProbeTcpSocketPort'] = self.liveness_probe_tcp_socket_port
        if self.liveness_probe_timeout_seconds is not None:
            result['LivenessProbeTimeoutSeconds'] = self.liveness_probe_timeout_seconds
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        result['Ports'] = []
        if self.ports is not None:
            for k in self.ports:
                result['Ports'].append(k.to_map() if k else None)
        if self.readiness_probe_exec_commands is not None:
            result['ReadinessProbeExecCommands'] = self.readiness_probe_exec_commands
        if self.readiness_probe_failure_threshold is not None:
            result['ReadinessProbeFailureThreshold'] = self.readiness_probe_failure_threshold
        if self.readiness_probe_http_get_path is not None:
            result['ReadinessProbeHttpGetPath'] = self.readiness_probe_http_get_path
        if self.readiness_probe_http_get_port is not None:
            result['ReadinessProbeHttpGetPort'] = self.readiness_probe_http_get_port
        if self.readiness_probe_http_get_scheme is not None:
            result['ReadinessProbeHttpGetScheme'] = self.readiness_probe_http_get_scheme
        if self.readiness_probe_initial_delay_seconds is not None:
            result['ReadinessProbeInitialDelaySeconds'] = self.readiness_probe_initial_delay_seconds
        if self.readiness_probe_period_seconds is not None:
            result['ReadinessProbePeriodSeconds'] = self.readiness_probe_period_seconds
        if self.readiness_probe_success_threshold is not None:
            result['ReadinessProbeSuccessThreshold'] = self.readiness_probe_success_threshold
        if self.readiness_probe_tcp_socket_port is not None:
            result['ReadinessProbeTcpSocketPort'] = self.readiness_probe_tcp_socket_port
        if self.readiness_probe_timeout_seconds is not None:
            result['ReadinessProbeTimeoutSeconds'] = self.readiness_probe_timeout_seconds
        if self.security_context_capability_adds is not None:
            result['SecurityContextCapabilityAdds'] = self.security_context_capability_adds
        if self.security_context_read_only_root_filesystem is not None:
            result['SecurityContextReadOnlyRootFilesystem'] = self.security_context_read_only_root_filesystem
        if self.security_context_run_as_user is not None:
            result['SecurityContextRunAsUser'] = self.security_context_run_as_user
        if self.stdin is not None:
            result['Stdin'] = self.stdin
        if self.stdin_once is not None:
            result['StdinOnce'] = self.stdin_once
        if self.tty is not None:
            result['Tty'] = self.tty
        result['VolumeMounts'] = []
        if self.volume_mounts is not None:
            for k in self.volume_mounts:
                result['VolumeMounts'].append(k.to_map() if k else None)
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        self.environment_vars = []
        if m.get('EnvironmentVars') is not None:
            for k in m.get('EnvironmentVars'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersEnvironmentVars()
                self.environment_vars.append(temp_model.from_map(k))
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        if m.get('LifecyclePostStartHandlerExecs') is not None:
            self.lifecycle_post_start_handler_execs = m.get('LifecyclePostStartHandlerExecs')
        if m.get('LifecyclePostStartHandlerHttpGetHost') is not None:
            self.lifecycle_post_start_handler_http_get_host = m.get('LifecyclePostStartHandlerHttpGetHost')
        if m.get('LifecyclePostStartHandlerHttpGetPath') is not None:
            self.lifecycle_post_start_handler_http_get_path = m.get('LifecyclePostStartHandlerHttpGetPath')
        if m.get('LifecyclePostStartHandlerHttpGetPort') is not None:
            self.lifecycle_post_start_handler_http_get_port = m.get('LifecyclePostStartHandlerHttpGetPort')
        if m.get('LifecyclePostStartHandlerHttpGetScheme') is not None:
            self.lifecycle_post_start_handler_http_get_scheme = m.get('LifecyclePostStartHandlerHttpGetScheme')
        if m.get('LifecyclePostStartHandlerTcpSocketHost') is not None:
            self.lifecycle_post_start_handler_tcp_socket_host = m.get('LifecyclePostStartHandlerTcpSocketHost')
        if m.get('LifecyclePostStartHandlerTcpSocketPort') is not None:
            self.lifecycle_post_start_handler_tcp_socket_port = m.get('LifecyclePostStartHandlerTcpSocketPort')
        if m.get('LifecyclePreStopHandlerExecs') is not None:
            self.lifecycle_pre_stop_handler_execs = m.get('LifecyclePreStopHandlerExecs')
        if m.get('LifecyclePreStopHandlerHttpGetHost') is not None:
            self.lifecycle_pre_stop_handler_http_get_host = m.get('LifecyclePreStopHandlerHttpGetHost')
        if m.get('LifecyclePreStopHandlerHttpGetPath') is not None:
            self.lifecycle_pre_stop_handler_http_get_path = m.get('LifecyclePreStopHandlerHttpGetPath')
        if m.get('LifecyclePreStopHandlerHttpGetPort') is not None:
            self.lifecycle_pre_stop_handler_http_get_port = m.get('LifecyclePreStopHandlerHttpGetPort')
        if m.get('LifecyclePreStopHandlerHttpGetScheme') is not None:
            self.lifecycle_pre_stop_handler_http_get_scheme = m.get('LifecyclePreStopHandlerHttpGetScheme')
        if m.get('LifecyclePreStopHandlerTcpSocketHost') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_host = m.get('LifecyclePreStopHandlerTcpSocketHost')
        if m.get('LifecyclePreStopHandlerTcpSocketPort') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_port = m.get('LifecyclePreStopHandlerTcpSocketPort')
        if m.get('LivenessProbeExecCommands') is not None:
            self.liveness_probe_exec_commands = m.get('LivenessProbeExecCommands')
        if m.get('LivenessProbeFailureThreshold') is not None:
            self.liveness_probe_failure_threshold = m.get('LivenessProbeFailureThreshold')
        if m.get('LivenessProbeHttpGetPath') is not None:
            self.liveness_probe_http_get_path = m.get('LivenessProbeHttpGetPath')
        if m.get('LivenessProbeHttpGetPort') is not None:
            self.liveness_probe_http_get_port = m.get('LivenessProbeHttpGetPort')
        if m.get('LivenessProbeHttpGetScheme') is not None:
            self.liveness_probe_http_get_scheme = m.get('LivenessProbeHttpGetScheme')
        if m.get('LivenessProbeInitialDelaySeconds') is not None:
            self.liveness_probe_initial_delay_seconds = m.get('LivenessProbeInitialDelaySeconds')
        if m.get('LivenessProbePeriodSeconds') is not None:
            self.liveness_probe_period_seconds = m.get('LivenessProbePeriodSeconds')
        if m.get('LivenessProbeSuccessThreshold') is not None:
            self.liveness_probe_success_threshold = m.get('LivenessProbeSuccessThreshold')
        if m.get('LivenessProbeTcpSocketPort') is not None:
            self.liveness_probe_tcp_socket_port = m.get('LivenessProbeTcpSocketPort')
        if m.get('LivenessProbeTimeoutSeconds') is not None:
            self.liveness_probe_timeout_seconds = m.get('LivenessProbeTimeoutSeconds')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        self.ports = []
        if m.get('Ports') is not None:
            for k in m.get('Ports'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersPorts()
                self.ports.append(temp_model.from_map(k))
        if m.get('ReadinessProbeExecCommands') is not None:
            self.readiness_probe_exec_commands = m.get('ReadinessProbeExecCommands')
        if m.get('ReadinessProbeFailureThreshold') is not None:
            self.readiness_probe_failure_threshold = m.get('ReadinessProbeFailureThreshold')
        if m.get('ReadinessProbeHttpGetPath') is not None:
            self.readiness_probe_http_get_path = m.get('ReadinessProbeHttpGetPath')
        if m.get('ReadinessProbeHttpGetPort') is not None:
            self.readiness_probe_http_get_port = m.get('ReadinessProbeHttpGetPort')
        if m.get('ReadinessProbeHttpGetScheme') is not None:
            self.readiness_probe_http_get_scheme = m.get('ReadinessProbeHttpGetScheme')
        if m.get('ReadinessProbeInitialDelaySeconds') is not None:
            self.readiness_probe_initial_delay_seconds = m.get('ReadinessProbeInitialDelaySeconds')
        if m.get('ReadinessProbePeriodSeconds') is not None:
            self.readiness_probe_period_seconds = m.get('ReadinessProbePeriodSeconds')
        if m.get('ReadinessProbeSuccessThreshold') is not None:
            self.readiness_probe_success_threshold = m.get('ReadinessProbeSuccessThreshold')
        if m.get('ReadinessProbeTcpSocketPort') is not None:
            self.readiness_probe_tcp_socket_port = m.get('ReadinessProbeTcpSocketPort')
        if m.get('ReadinessProbeTimeoutSeconds') is not None:
            self.readiness_probe_timeout_seconds = m.get('ReadinessProbeTimeoutSeconds')
        if m.get('SecurityContextCapabilityAdds') is not None:
            self.security_context_capability_adds = m.get('SecurityContextCapabilityAdds')
        if m.get('SecurityContextReadOnlyRootFilesystem') is not None:
            self.security_context_read_only_root_filesystem = m.get('SecurityContextReadOnlyRootFilesystem')
        if m.get('SecurityContextRunAsUser') is not None:
            self.security_context_run_as_user = m.get('SecurityContextRunAsUser')
        if m.get('Stdin') is not None:
            self.stdin = m.get('Stdin')
        if m.get('StdinOnce') is not None:
            self.stdin_once = m.get('StdinOnce')
        if m.get('Tty') is not None:
            self.tty = m.get('Tty')
        self.volume_mounts = []
        if m.get('VolumeMounts') is not None:
            for k in m.get('VolumeMounts'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainersVolumeMounts()
                self.volume_mounts.append(temp_model.from_map(k))
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsDnsConfigOptions(TeaModel):
    def __init__(self, name=None, value=None):
        # The variable name of the option.
        self.name = name  # type: str
        # The variable value of the option.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsDnsConfigOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsHostAliases(TeaModel):
    def __init__(self, hostnames=None, ip=None):
        # The hostnames that are added.
        self.hostnames = hostnames  # type: list[str]
        # The IP address that is added.
        self.ip = ip  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsHostAliases, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.hostnames is not None:
            result['Hostnames'] = self.hostnames
        if self.ip is not None:
            result['Ip'] = self.ip
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Hostnames') is not None:
            self.hostnames = m.get('Hostnames')
        if m.get('Ip') is not None:
            self.ip = m.get('Ip')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsImageRegistryCredentials(TeaModel):
    def __init__(self, password=None, server=None, user_name=None):
        # The password that is used to access the image repository.
        self.password = password  # type: str
        # The domain name of the image repository.
        self.server = server  # type: str
        # The username that is used to access the image repository.
        self.user_name = user_name  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsImageRegistryCredentials, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.password is not None:
            result['Password'] = self.password
        if self.server is not None:
            result['Server'] = self.server
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('Server') is not None:
            self.server = m.get('Server')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerEnvironmentVars(TeaModel):
    def __init__(self, field_ref_field_path=None, key=None, value=None):
        # > This parameter is unavailable.
        self.field_ref_field_path = field_ref_field_path  # type: str
        # The name of the environment variable.
        self.key = key  # type: str
        # The value of the environment variable.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref_field_path is not None:
            result['FieldRefFieldPath'] = self.field_ref_field_path
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRefFieldPath') is not None:
            self.field_ref_field_path = m.get('FieldRefFieldPath')
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        # The port number. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The protocol. Valid values:
        # 
        # *   TCP
        # *   UDP
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        # The directory to which the volume is mounted. Data under this directory is overwritten by the data on the volume.
        self.mount_path = mount_path  # type: str
        # The mount propagation setting of the volume. Mount propagation allows the sharing of volumes that are mounted on one container with other containers in the same pod, or even with other pods on the same node. Valid values:
        # 
        # *   None: The volume mount does not receive subsequent mounts that are mounted to this volume or its subdirectories.
        # *   HostToCotainer: The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories.
        # *   Bidirectional: This value is similar to HostToCotainer. The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories. In addition, all volume mounts that are created by the container are propagated back to the instance and to all containers of all pods that use the same volume.
        # 
        # Default value: None.
        self.mount_propagation = mount_propagation  # type: str
        # The name of the volume.
        self.name = name  # type: str
        # Indicates whether the mount path is read-only.
        # 
        # Default value: false.
        self.read_only = read_only  # type: bool
        # The subdirectory of the volume. The elastic container instance can mount different directories of the same volume to different subdirectories of containers.
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainers(TeaModel):
    def __init__(self, cpu=None, gpu=None, image=None, image_pull_policy=None, init_container_args=None,
                 init_container_commands=None, init_container_environment_vars=None, init_container_ports=None,
                 init_container_volume_mounts=None, memory=None, name=None, security_context_capability_adds=None,
                 security_context_read_only_root_filesystem=None, security_context_run_as_user=None, working_dir=None):
        # The number of vCPUs.
        self.cpu = cpu  # type: float
        # The number of GPUs that are allocated to the container.
        self.gpu = gpu  # type: int
        # The container image.
        self.image = image  # type: str
        # The image pulling policy.
        self.image_pull_policy = image_pull_policy  # type: str
        # The container startup arguments.
        self.init_container_args = init_container_args  # type: list[str]
        # The container startup commands.
        self.init_container_commands = init_container_commands  # type: list[str]
        # Details of the environment variables.
        self.init_container_environment_vars = init_container_environment_vars  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerEnvironmentVars]
        # Details of the init container ports.
        self.init_container_ports = init_container_ports  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerPorts]
        # The volumes that are mounted on the container.
        self.init_container_volume_mounts = init_container_volume_mounts  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerVolumeMounts]
        # The size of the memory.
        self.memory = memory  # type: float
        # The name of the container.
        self.name = name  # type: str
        # The permissions that are granted to the processes in the container. Valid values: NET_ADMIN and NET_RAW.
        # 
        # > To use NET_RAW, you need to submit a ticket.
        self.security_context_capability_adds = security_context_capability_adds  # type: list[str]
        # Indicates whether the root file system is read-only. The only valid value is true.
        self.security_context_read_only_root_filesystem = security_context_read_only_root_filesystem  # type: bool
        # The ID of the user that runs the container.
        self.security_context_run_as_user = security_context_run_as_user  # type: str
        # The working directory.
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.init_container_environment_vars:
            for k in self.init_container_environment_vars:
                if k:
                    k.validate()
        if self.init_container_ports:
            for k in self.init_container_ports:
                if k:
                    k.validate()
        if self.init_container_volume_mounts:
            for k in self.init_container_volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        if self.init_container_args is not None:
            result['InitContainerArgs'] = self.init_container_args
        if self.init_container_commands is not None:
            result['InitContainerCommands'] = self.init_container_commands
        result['InitContainerEnvironmentVars'] = []
        if self.init_container_environment_vars is not None:
            for k in self.init_container_environment_vars:
                result['InitContainerEnvironmentVars'].append(k.to_map() if k else None)
        result['InitContainerPorts'] = []
        if self.init_container_ports is not None:
            for k in self.init_container_ports:
                result['InitContainerPorts'].append(k.to_map() if k else None)
        result['InitContainerVolumeMounts'] = []
        if self.init_container_volume_mounts is not None:
            for k in self.init_container_volume_mounts:
                result['InitContainerVolumeMounts'].append(k.to_map() if k else None)
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        if self.security_context_capability_adds is not None:
            result['SecurityContextCapabilityAdds'] = self.security_context_capability_adds
        if self.security_context_read_only_root_filesystem is not None:
            result['SecurityContextReadOnlyRootFilesystem'] = self.security_context_read_only_root_filesystem
        if self.security_context_run_as_user is not None:
            result['SecurityContextRunAsUser'] = self.security_context_run_as_user
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        if m.get('InitContainerArgs') is not None:
            self.init_container_args = m.get('InitContainerArgs')
        if m.get('InitContainerCommands') is not None:
            self.init_container_commands = m.get('InitContainerCommands')
        self.init_container_environment_vars = []
        if m.get('InitContainerEnvironmentVars') is not None:
            for k in m.get('InitContainerEnvironmentVars'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerEnvironmentVars()
                self.init_container_environment_vars.append(temp_model.from_map(k))
        self.init_container_ports = []
        if m.get('InitContainerPorts') is not None:
            for k in m.get('InitContainerPorts'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerPorts()
                self.init_container_ports.append(temp_model.from_map(k))
        self.init_container_volume_mounts = []
        if m.get('InitContainerVolumeMounts') is not None:
            for k in m.get('InitContainerVolumeMounts'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainersInitContainerVolumeMounts()
                self.init_container_volume_mounts.append(temp_model.from_map(k))
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('SecurityContextCapabilityAdds') is not None:
            self.security_context_capability_adds = m.get('SecurityContextCapabilityAdds')
        if m.get('SecurityContextReadOnlyRootFilesystem') is not None:
            self.security_context_read_only_root_filesystem = m.get('SecurityContextReadOnlyRootFilesystem')
        if m.get('SecurityContextRunAsUser') is not None:
            self.security_context_run_as_user = m.get('SecurityContextRunAsUser')
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsSecurityContextSysCtls(TeaModel):
    def __init__(self, name=None, value=None):
        # The name of the security context in which the elastic container instance runs.
        self.name = name  # type: str
        # The variable value of the security context in which the elastic container instance runs.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsSecurityContextSysCtls, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsTags(TeaModel):
    def __init__(self, key=None, value=None):
        # The key of the tag.
        self.key = key  # type: str
        # The value of the tag.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumesConfigFileVolumeConfigFileToPaths(TeaModel):
    def __init__(self, content=None, mode=None, path=None):
        # The content of the configuration file (32 KB).
        self.content = content  # type: str
        # The permissions on the ConfigFile volume.
        self.mode = mode  # type: int
        # The relative path to the configuration file.
        self.path = path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumesConfigFileVolumeConfigFileToPaths, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.path is not None:
            result['Path'] = self.path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('Path') is not None:
            self.path = m.get('Path')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumes(TeaModel):
    def __init__(self, config_file_volume_config_file_to_paths=None, config_file_volume_default_mode=None,
                 disk_volume_disk_id=None, disk_volume_disk_size=None, disk_volume_fs_type=None, empty_dir_volume_medium=None,
                 empty_dir_volume_size_limit=None, flex_volume_driver=None, flex_volume_fs_type=None, flex_volume_options=None,
                 host_path_volume_path=None, host_path_volume_type=None, nfsvolume_path=None, nfsvolume_read_only=None,
                 nfsvolume_server=None, name=None, type=None):
        # The paths to configuration files.
        self.config_file_volume_config_file_to_paths = config_file_volume_config_file_to_paths  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumesConfigFileVolumeConfigFileToPaths]
        # The default permissions on the ConfigFile volume.
        self.config_file_volume_default_mode = config_file_volume_default_mode  # type: int
        # The storage size of a disk volume. Unit: GiB.
        self.disk_volume_disk_id = disk_volume_disk_id  # type: str
        # The storage size of a disk volume. Unit: GiB.
        self.disk_volume_disk_size = disk_volume_disk_size  # type: int
        # The file system type of a disk volume.
        self.disk_volume_fs_type = disk_volume_fs_type  # type: str
        # The storage medium of EmptyDirVolume. If this parameter is left empty, the file system that backs the node is used as the storage medium. If this parameter is set to memory, the memory is used as the storage medium.
        self.empty_dir_volume_medium = empty_dir_volume_medium  # type: str
        # EmptyDir数据卷的大小。
        self.empty_dir_volume_size_limit = empty_dir_volume_size_limit  # type: str
        # The FlexVolume driver name of the volume.
        self.flex_volume_driver = flex_volume_driver  # type: str
        # The file system type of the volume. The default value is determined by the script of FlexVolume.
        self.flex_volume_fs_type = flex_volume_fs_type  # type: str
        # The FlexVolume options. Each option is a key-value pair in a JSON string.
        # 
        # For example, when you use FlexVolume to mount a disk, the format of options is `{"volumeId":"d-2zehdahrwoa7srg****","performanceLevel": "PL2"}`.
        self.flex_volume_options = flex_volume_options  # type: str
        # HostPath Volume在主机上的目录路径。
        self.host_path_volume_path = host_path_volume_path  # type: str
        # HostPath Volume的类型。
        self.host_path_volume_type = host_path_volume_type  # type: str
        # The path to the Network File System (NFS) volume.
        self.nfsvolume_path = nfsvolume_path  # type: str
        # Indicates whether the NFS volume is read-only.
        # 
        # Default value: false.
        self.nfsvolume_read_only = nfsvolume_read_only  # type: bool
        # The endpoint of the NFS server.
        self.nfsvolume_server = nfsvolume_server  # type: str
        # The name of the volume.
        self.name = name  # type: str
        # The type of the volume. Valid values:
        # 
        # *   EmptyDirVolume
        # *   NFSVolume
        # *   ConfigFileVolume
        # *   FlexVolume
        self.type = type  # type: str

    def validate(self):
        if self.config_file_volume_config_file_to_paths:
            for k in self.config_file_volume_config_file_to_paths:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ConfigFileVolumeConfigFileToPaths'] = []
        if self.config_file_volume_config_file_to_paths is not None:
            for k in self.config_file_volume_config_file_to_paths:
                result['ConfigFileVolumeConfigFileToPaths'].append(k.to_map() if k else None)
        if self.config_file_volume_default_mode is not None:
            result['ConfigFileVolumeDefaultMode'] = self.config_file_volume_default_mode
        if self.disk_volume_disk_id is not None:
            result['DiskVolumeDiskId'] = self.disk_volume_disk_id
        if self.disk_volume_disk_size is not None:
            result['DiskVolumeDiskSize'] = self.disk_volume_disk_size
        if self.disk_volume_fs_type is not None:
            result['DiskVolumeFsType'] = self.disk_volume_fs_type
        if self.empty_dir_volume_medium is not None:
            result['EmptyDirVolumeMedium'] = self.empty_dir_volume_medium
        if self.empty_dir_volume_size_limit is not None:
            result['EmptyDirVolumeSizeLimit'] = self.empty_dir_volume_size_limit
        if self.flex_volume_driver is not None:
            result['FlexVolumeDriver'] = self.flex_volume_driver
        if self.flex_volume_fs_type is not None:
            result['FlexVolumeFsType'] = self.flex_volume_fs_type
        if self.flex_volume_options is not None:
            result['FlexVolumeOptions'] = self.flex_volume_options
        if self.host_path_volume_path is not None:
            result['HostPathVolumePath'] = self.host_path_volume_path
        if self.host_path_volume_type is not None:
            result['HostPathVolumeType'] = self.host_path_volume_type
        if self.nfsvolume_path is not None:
            result['NFSVolumePath'] = self.nfsvolume_path
        if self.nfsvolume_read_only is not None:
            result['NFSVolumeReadOnly'] = self.nfsvolume_read_only
        if self.nfsvolume_server is not None:
            result['NFSVolumeServer'] = self.nfsvolume_server
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.config_file_volume_config_file_to_paths = []
        if m.get('ConfigFileVolumeConfigFileToPaths') is not None:
            for k in m.get('ConfigFileVolumeConfigFileToPaths'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumesConfigFileVolumeConfigFileToPaths()
                self.config_file_volume_config_file_to_paths.append(temp_model.from_map(k))
        if m.get('ConfigFileVolumeDefaultMode') is not None:
            self.config_file_volume_default_mode = m.get('ConfigFileVolumeDefaultMode')
        if m.get('DiskVolumeDiskId') is not None:
            self.disk_volume_disk_id = m.get('DiskVolumeDiskId')
        if m.get('DiskVolumeDiskSize') is not None:
            self.disk_volume_disk_size = m.get('DiskVolumeDiskSize')
        if m.get('DiskVolumeFsType') is not None:
            self.disk_volume_fs_type = m.get('DiskVolumeFsType')
        if m.get('EmptyDirVolumeMedium') is not None:
            self.empty_dir_volume_medium = m.get('EmptyDirVolumeMedium')
        if m.get('EmptyDirVolumeSizeLimit') is not None:
            self.empty_dir_volume_size_limit = m.get('EmptyDirVolumeSizeLimit')
        if m.get('FlexVolumeDriver') is not None:
            self.flex_volume_driver = m.get('FlexVolumeDriver')
        if m.get('FlexVolumeFsType') is not None:
            self.flex_volume_fs_type = m.get('FlexVolumeFsType')
        if m.get('FlexVolumeOptions') is not None:
            self.flex_volume_options = m.get('FlexVolumeOptions')
        if m.get('HostPathVolumePath') is not None:
            self.host_path_volume_path = m.get('HostPathVolumePath')
        if m.get('HostPathVolumeType') is not None:
            self.host_path_volume_type = m.get('HostPathVolumeType')
        if m.get('NFSVolumePath') is not None:
            self.nfsvolume_path = m.get('NFSVolumePath')
        if m.get('NFSVolumeReadOnly') is not None:
            self.nfsvolume_read_only = m.get('NFSVolumeReadOnly')
        if m.get('NFSVolumeServer') is not None:
            self.nfsvolume_server = m.get('NFSVolumeServer')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DescribeEciScalingConfigurationsResponseBodyScalingConfigurations(TeaModel):
    def __init__(self, acr_registry_infos=None, active_deadline_seconds=None, auto_create_eip=None,
                 auto_match_image_cache=None, container_group_name=None, containers=None, cost_optimization=None, cpu=None,
                 cpu_options_core=None, cpu_options_threads_per_core=None, creation_time=None, data_cache_bucket=None,
                 data_cache_bursting_enabled=None, data_cache_pl=None, data_cache_provisioned_iops=None, description=None,
                 dns_config_name_servers=None, dns_config_options=None, dns_config_searches=None, dns_policy=None, egress_bandwidth=None,
                 eip_bandwidth=None, ephemeral_storage=None, host_aliases=None, host_name=None, image_registry_credentials=None,
                 image_snapshot_id=None, ingress_bandwidth=None, init_containers=None, instance_family_level=None,
                 instance_types=None, ipv_6address_count=None, lifecycle_state=None, load_balancer_weight=None, memory=None,
                 ntp_servers=None, ram_role_name=None, region_id=None, resource_group_id=None, restart_policy=None,
                 scaling_configuration_id=None, scaling_configuration_name=None, scaling_group_id=None, security_context_sys_ctls=None,
                 security_group_id=None, sls_enable=None, spot_price_limit=None, spot_strategy=None, tags=None,
                 termination_grace_period_seconds=None, volumes=None):
        # Details of the Container Registry Enterprise Edition instances.
        self.acr_registry_infos = acr_registry_infos  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsAcrRegistryInfos]
        # The validity period. Unit: seconds.
        self.active_deadline_seconds = active_deadline_seconds  # type: int
        # Indicates whether an elastic IP address (EIP) is automatically created, and then bound to the elastic container instance.
        self.auto_create_eip = auto_create_eip  # type: bool
        # Indicates whether the image cache is automatically matched. Default value: false.
        self.auto_match_image_cache = auto_match_image_cache  # type: bool
        # The name of the elastic container instance.
        self.container_group_name = container_group_name  # type: str
        # The containers in the elastic container instance.
        self.containers = containers  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainers]
        # Indicates whether the cost optimization feature is enabled. Valid values:
        # 
        # *   true
        # *   false
        self.cost_optimization = cost_optimization  # type: bool
        # The number of vCPUs of the elastic container instance.
        self.cpu = cpu  # type: float
        # The number of physical CPU cores. This parameter can be specified for only some instance types. For more information, see [Specify custom CPU options](~~197781~~).
        self.cpu_options_core = cpu_options_core  # type: int
        # The number of threads per core. This parameter can be specified for only some instance types. If you set this parameter to 1, Hyper-Threading is disabled. For more information, see [Specify custom CPU options](~~197781~~).
        self.cpu_options_threads_per_core = cpu_options_threads_per_core  # type: int
        # The time when the scaling configuration was created.
        self.creation_time = creation_time  # type: str
        # 数据缓存Bucket。
        self.data_cache_bucket = data_cache_bucket  # type: str
        # 数据缓存使用ESSD AutoPL云盘时，是否开启Burst（性能突发）。可能值：
        # 
        # - true：开启。
        # - false：未开启。
        # >关于ESSD AutoPL云盘的更多信息，请参见[ESSD AutoPL云盘](~~368372~~)。
        self.data_cache_bursting_enabled = data_cache_bursting_enabled  # type: bool
        # 数据缓存使用的云盘的性能等级。建议优先使用ESSD云盘，该云盘的性能等级的可能值：
        # 
        # - PL0：单盘最高随机读写IOPS 1万。
        # - PL1：单盘最高随机读写IOPS 5万。
        # - PL2：单盘最高随机读写IOPS 10万。
        # - PL3：单盘最高随机读写IOPS 100万。
        # 
        # >关于ESSD云盘的更多信息，请参见[ESSD云盘](~~122389~~)。
        self.data_cache_pl = data_cache_pl  # type: str
        # 数据缓存使用ESSD AutoPL云盘时，ESSD AutoPL云盘预配置的读写IOPS。可能值：0~min{50000, 1000*容量-基准性能}，其中，基准性能=min{1800+50*容量, 50000}。
        # 
        # >关于ESSD AutoPL云盘的更多信息，请参见[ESSD AutoPL云盘](~~368372~~)。
        self.data_cache_provisioned_iops = data_cache_provisioned_iops  # type: int
        # > This parameter is unavailable.
        self.description = description  # type: str
        # The IP addresses of the DNS servers.
        self.dns_config_name_servers = dns_config_name_servers  # type: list[str]
        # The options. Each option is a name-value pair. The value in the name-value pair is optional.
        self.dns_config_options = dns_config_options  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsDnsConfigOptions]
        # The DNS lookup domains.
        self.dns_config_searches = dns_config_searches  # type: list[str]
        # The Domain Name System (DNS) policy.
        self.dns_policy = dns_policy  # type: str
        # The maximum outbound bandwidth. Unit: bytes.
        self.egress_bandwidth = egress_bandwidth  # type: long
        # The bandwidth of the EIP. Default value: 5 Mbit/s.
        self.eip_bandwidth = eip_bandwidth  # type: int
        # The size of the temporary storage space. Unit: GiB.
        self.ephemeral_storage = ephemeral_storage  # type: int
        # The hostname aliases of a container.
        self.host_aliases = host_aliases  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsHostAliases]
        # The hostname.
        self.host_name = host_name  # type: str
        # The information about the image repository.
        self.image_registry_credentials = image_registry_credentials  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsImageRegistryCredentials]
        # The ID of the image cache snapshot.
        self.image_snapshot_id = image_snapshot_id  # type: str
        # The maximum inbound bandwidth. Unit: bit/s.
        self.ingress_bandwidth = ingress_bandwidth  # type: long
        # The init containers.
        self.init_containers = init_containers  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainers]
        # The instance family level, which is used to filter the range of instance types that meet the requirements. This parameter takes effect when the `CostOptimization` parameter is set to true. Valid values:
        # 
        # *   EntryLevel: shared instance type. Instances of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instances of this level are suitable for business scenarios in which the CPU utilization is low. For more information, see [Shared instance families](~~108489~~).
        # *   EnterpriseLevel: Instances of this level provide stable performance and dedicated resources, and are suitable for business scenarios that require high stability. For more information, see [Instance family](~~25378~~).
        # *   CreditEntryLevel: This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instances of this level are suitable for scenarios in which the CPU utilization is low but may fluctuate in specific cases. For more information, see [Overview](~~59977~~) of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        # 指定的ECS实例规格，支持多规格（最多支持5个）。
        self.instance_types = instance_types  # type: list[str]
        # The number of IPv6 addresses.
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The state of the scaling configuration in the scaling group. Valid values:
        # 
        # *   Active: The scaling configuration is active in the scaling group. Auto Scaling uses active scaling configurations to automatically create ECS instances.
        # *   Inactive: The scaling configuration is inactive in the scaling group. Auto Scaling does not use inactive scaling configurations to automatically create ECS instances. Inactive scaling configurations are retained in the scaling group.
        self.lifecycle_state = lifecycle_state  # type: str
        # The weight of the elastic container instance as a backend server. Valid values: 1 to 100.
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The size of the memory.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set the Cpu parameter to 2 and the Memory parameter to 16 to specify the instance types that have 2 vCPUs and 16 GiB of memory. If you specify the Cpu and Memory parameters, Auto Scaling determines available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances of the instance type that is provided at the lowest price.
        # 
        # > You can specify CPU and memory specifications to determine the range of instance types only if the Scaling Policy parameter is set to Cost Optimization Policy and no instance type is specified in the scaling configuration.
        self.memory = memory  # type: float
        # The domain names of the Network Time Protocol (NTP) servers.
        self.ntp_servers = ntp_servers  # type: list[str]
        # The name of the instance RAM role. You can use an instance RAM role to access both elastic container instances and Elastic Compute Service (ECS) instances. For more information, see [Use the instance RAM role by calling APIs](~~61178~~).
        self.ram_role_name = ram_role_name  # type: str
        # The region ID of the elastic container instance.
        self.region_id = region_id  # type: str
        # The ID of the resource group.
        self.resource_group_id = resource_group_id  # type: str
        # The restart policy of the elastic container instance. Valid values:
        # 
        # *   Never: never restarts the elastic container instance.
        # *   Always: always restarts the elastic container instance.
        # *   OnFailure: restarts the elastic container instance upon failures.
        self.restart_policy = restart_policy  # type: str
        # The ID of the scaling configuration.
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        # The name of the scaling configuration.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The scaling group ID of the scaling configuration.
        self.scaling_group_id = scaling_group_id  # type: str
        # The system information of the security context in which the elastic container instance runs.
        self.security_context_sys_ctls = security_context_sys_ctls  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsSecurityContextSysCtls]
        # The ID of the security group with which the elastic container instance is associated. Elastic container instances that are associated with the same security group can access each other.
        self.security_group_id = security_group_id  # type: str
        # > This parameter is unavailable.
        self.sls_enable = sls_enable  # type: bool
        # The maximum hourly price for the preemptible instance.
        # 
        # This parameter is returned only if you set the SpotStrategy parameter to SpotWithPriceLimit.
        self.spot_price_limit = spot_price_limit  # type: float
        # The preemption policy of the instance. Valid values:
        # 
        # *   NoSpot: The instance is created as a regular pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is created as a preemptible instance with a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is created as a preemptible instance for which the market price at the time of purchase is automatically used as the bid price.
        self.spot_strategy = spot_strategy  # type: str
        # The tags of the elastic container instance. The tags are specified in the key-value pair format.
        self.tags = tags  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsTags]
        # The buffer time in which the program handles operations before the program stops.
        self.termination_grace_period_seconds = termination_grace_period_seconds  # type: int
        # Details of the volumes.
        self.volumes = volumes  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumes]

    def validate(self):
        if self.acr_registry_infos:
            for k in self.acr_registry_infos:
                if k:
                    k.validate()
        if self.containers:
            for k in self.containers:
                if k:
                    k.validate()
        if self.dns_config_options:
            for k in self.dns_config_options:
                if k:
                    k.validate()
        if self.host_aliases:
            for k in self.host_aliases:
                if k:
                    k.validate()
        if self.image_registry_credentials:
            for k in self.image_registry_credentials:
                if k:
                    k.validate()
        if self.init_containers:
            for k in self.init_containers:
                if k:
                    k.validate()
        if self.security_context_sys_ctls:
            for k in self.security_context_sys_ctls:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.volumes:
            for k in self.volumes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBodyScalingConfigurations, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcrRegistryInfos'] = []
        if self.acr_registry_infos is not None:
            for k in self.acr_registry_infos:
                result['AcrRegistryInfos'].append(k.to_map() if k else None)
        if self.active_deadline_seconds is not None:
            result['ActiveDeadlineSeconds'] = self.active_deadline_seconds
        if self.auto_create_eip is not None:
            result['AutoCreateEip'] = self.auto_create_eip
        if self.auto_match_image_cache is not None:
            result['AutoMatchImageCache'] = self.auto_match_image_cache
        if self.container_group_name is not None:
            result['ContainerGroupName'] = self.container_group_name
        result['Containers'] = []
        if self.containers is not None:
            for k in self.containers:
                result['Containers'].append(k.to_map() if k else None)
        if self.cost_optimization is not None:
            result['CostOptimization'] = self.cost_optimization
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.cpu_options_core is not None:
            result['CpuOptionsCore'] = self.cpu_options_core
        if self.cpu_options_threads_per_core is not None:
            result['CpuOptionsThreadsPerCore'] = self.cpu_options_threads_per_core
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.data_cache_bucket is not None:
            result['DataCacheBucket'] = self.data_cache_bucket
        if self.data_cache_bursting_enabled is not None:
            result['DataCacheBurstingEnabled'] = self.data_cache_bursting_enabled
        if self.data_cache_pl is not None:
            result['DataCachePL'] = self.data_cache_pl
        if self.data_cache_provisioned_iops is not None:
            result['DataCacheProvisionedIops'] = self.data_cache_provisioned_iops
        if self.description is not None:
            result['Description'] = self.description
        if self.dns_config_name_servers is not None:
            result['DnsConfigNameServers'] = self.dns_config_name_servers
        result['DnsConfigOptions'] = []
        if self.dns_config_options is not None:
            for k in self.dns_config_options:
                result['DnsConfigOptions'].append(k.to_map() if k else None)
        if self.dns_config_searches is not None:
            result['DnsConfigSearches'] = self.dns_config_searches
        if self.dns_policy is not None:
            result['DnsPolicy'] = self.dns_policy
        if self.egress_bandwidth is not None:
            result['EgressBandwidth'] = self.egress_bandwidth
        if self.eip_bandwidth is not None:
            result['EipBandwidth'] = self.eip_bandwidth
        if self.ephemeral_storage is not None:
            result['EphemeralStorage'] = self.ephemeral_storage
        result['HostAliases'] = []
        if self.host_aliases is not None:
            for k in self.host_aliases:
                result['HostAliases'].append(k.to_map() if k else None)
        if self.host_name is not None:
            result['HostName'] = self.host_name
        result['ImageRegistryCredentials'] = []
        if self.image_registry_credentials is not None:
            for k in self.image_registry_credentials:
                result['ImageRegistryCredentials'].append(k.to_map() if k else None)
        if self.image_snapshot_id is not None:
            result['ImageSnapshotId'] = self.image_snapshot_id
        if self.ingress_bandwidth is not None:
            result['IngressBandwidth'] = self.ingress_bandwidth
        result['InitContainers'] = []
        if self.init_containers is not None:
            for k in self.init_containers:
                result['InitContainers'].append(k.to_map() if k else None)
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.ntp_servers is not None:
            result['NtpServers'] = self.ntp_servers
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.restart_policy is not None:
            result['RestartPolicy'] = self.restart_policy
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['SecurityContextSysCtls'] = []
        if self.security_context_sys_ctls is not None:
            for k in self.security_context_sys_ctls:
                result['SecurityContextSysCtls'].append(k.to_map() if k else None)
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.sls_enable is not None:
            result['SlsEnable'] = self.sls_enable
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.termination_grace_period_seconds is not None:
            result['TerminationGracePeriodSeconds'] = self.termination_grace_period_seconds
        result['Volumes'] = []
        if self.volumes is not None:
            for k in self.volumes:
                result['Volumes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.acr_registry_infos = []
        if m.get('AcrRegistryInfos') is not None:
            for k in m.get('AcrRegistryInfos'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsAcrRegistryInfos()
                self.acr_registry_infos.append(temp_model.from_map(k))
        if m.get('ActiveDeadlineSeconds') is not None:
            self.active_deadline_seconds = m.get('ActiveDeadlineSeconds')
        if m.get('AutoCreateEip') is not None:
            self.auto_create_eip = m.get('AutoCreateEip')
        if m.get('AutoMatchImageCache') is not None:
            self.auto_match_image_cache = m.get('AutoMatchImageCache')
        if m.get('ContainerGroupName') is not None:
            self.container_group_name = m.get('ContainerGroupName')
        self.containers = []
        if m.get('Containers') is not None:
            for k in m.get('Containers'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsContainers()
                self.containers.append(temp_model.from_map(k))
        if m.get('CostOptimization') is not None:
            self.cost_optimization = m.get('CostOptimization')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CpuOptionsCore') is not None:
            self.cpu_options_core = m.get('CpuOptionsCore')
        if m.get('CpuOptionsThreadsPerCore') is not None:
            self.cpu_options_threads_per_core = m.get('CpuOptionsThreadsPerCore')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('DataCacheBucket') is not None:
            self.data_cache_bucket = m.get('DataCacheBucket')
        if m.get('DataCacheBurstingEnabled') is not None:
            self.data_cache_bursting_enabled = m.get('DataCacheBurstingEnabled')
        if m.get('DataCachePL') is not None:
            self.data_cache_pl = m.get('DataCachePL')
        if m.get('DataCacheProvisionedIops') is not None:
            self.data_cache_provisioned_iops = m.get('DataCacheProvisionedIops')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DnsConfigNameServers') is not None:
            self.dns_config_name_servers = m.get('DnsConfigNameServers')
        self.dns_config_options = []
        if m.get('DnsConfigOptions') is not None:
            for k in m.get('DnsConfigOptions'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsDnsConfigOptions()
                self.dns_config_options.append(temp_model.from_map(k))
        if m.get('DnsConfigSearches') is not None:
            self.dns_config_searches = m.get('DnsConfigSearches')
        if m.get('DnsPolicy') is not None:
            self.dns_policy = m.get('DnsPolicy')
        if m.get('EgressBandwidth') is not None:
            self.egress_bandwidth = m.get('EgressBandwidth')
        if m.get('EipBandwidth') is not None:
            self.eip_bandwidth = m.get('EipBandwidth')
        if m.get('EphemeralStorage') is not None:
            self.ephemeral_storage = m.get('EphemeralStorage')
        self.host_aliases = []
        if m.get('HostAliases') is not None:
            for k in m.get('HostAliases'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsHostAliases()
                self.host_aliases.append(temp_model.from_map(k))
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        self.image_registry_credentials = []
        if m.get('ImageRegistryCredentials') is not None:
            for k in m.get('ImageRegistryCredentials'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsImageRegistryCredentials()
                self.image_registry_credentials.append(temp_model.from_map(k))
        if m.get('ImageSnapshotId') is not None:
            self.image_snapshot_id = m.get('ImageSnapshotId')
        if m.get('IngressBandwidth') is not None:
            self.ingress_bandwidth = m.get('IngressBandwidth')
        self.init_containers = []
        if m.get('InitContainers') is not None:
            for k in m.get('InitContainers'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsInitContainers()
                self.init_containers.append(temp_model.from_map(k))
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('NtpServers') is not None:
            self.ntp_servers = m.get('NtpServers')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('RestartPolicy') is not None:
            self.restart_policy = m.get('RestartPolicy')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.security_context_sys_ctls = []
        if m.get('SecurityContextSysCtls') is not None:
            for k in m.get('SecurityContextSysCtls'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsSecurityContextSysCtls()
                self.security_context_sys_ctls.append(temp_model.from_map(k))
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SlsEnable') is not None:
            self.sls_enable = m.get('SlsEnable')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('TerminationGracePeriodSeconds') is not None:
            self.termination_grace_period_seconds = m.get('TerminationGracePeriodSeconds')
        self.volumes = []
        if m.get('Volumes') is not None:
            for k in m.get('Volumes'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurationsVolumes()
                self.volumes.append(temp_model.from_map(k))
        return self


class DescribeEciScalingConfigurationsResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scaling_configurations=None,
                 total_count=None):
        # The page number of the returned page.
        self.page_number = page_number  # type: int
        # The number of entries returned per page.
        self.page_size = page_size  # type: int
        # The ID of the request.
        self.request_id = request_id  # type: str
        # Details of the scaling configurations.
        self.scaling_configurations = scaling_configurations  # type: list[DescribeEciScalingConfigurationsResponseBodyScalingConfigurations]
        # The total number of scaling configurations.
        self.total_count = total_count  # type: int

    def validate(self):
        if self.scaling_configurations:
            for k in self.scaling_configurations:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScalingConfigurations'] = []
        if self.scaling_configurations is not None:
            for k in self.scaling_configurations:
                result['ScalingConfigurations'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scaling_configurations = []
        if m.get('ScalingConfigurations') is not None:
            for k in m.get('ScalingConfigurations'):
                temp_model = DescribeEciScalingConfigurationsResponseBodyScalingConfigurations()
                self.scaling_configurations.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeEciScalingConfigurationsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeEciScalingConfigurationsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeEciScalingConfigurationsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeEciScalingConfigurationsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeLifecycleActionsRequest(TeaModel):
    def __init__(self, lifecycle_action_status=None, max_results=None, next_token=None, owner_id=None,
                 region_id=None, resource_owner_account=None, scaling_activity_id=None):
        # The status of the lifecycle action. Valid values:
        # 
        # *   If a lifecycle action is in the Pending state, Elastic Compute Service (ECS) instances are waiting to be added to a scaling group or waiting to be removed from a scaling group.
        # *   If a lifecycle action is in the Timeout state, the lifecycle hook that triggers the lifecycle action ends, and ECS instances are added to or removed from the scaling group.
        # *   If a lifecycle action is in the Completed state, you manually end the lifecycle hook that triggers the lifecycle action ahead of schedule.
        self.lifecycle_action_status = lifecycle_action_status  # type: str
        # The maximum number of entries to return on each page. Valid values: 1 to 50.
        # 
        # Default value: 10.
        self.max_results = max_results  # type: int
        # The token that is used to specify the lifecycle action from which the query starts.
        # 
        # For example, after the first 10 lifecycle actions are queried, the query starts from the 11th lifecycle action. Set this parameter to the NextToken value that is returned in the previous API call. If you do not specify this parameter, the query starts from the beginning.
        self.next_token = next_token  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeLifecycleActionsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.lifecycle_action_status is not None:
            result['LifecycleActionStatus'] = self.lifecycle_action_status
        if self.max_results is not None:
            result['MaxResults'] = self.max_results
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LifecycleActionStatus') is not None:
            self.lifecycle_action_status = m.get('LifecycleActionStatus')
        if m.get('MaxResults') is not None:
            self.max_results = m.get('MaxResults')
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DescribeLifecycleActionsResponseBodyLifecycleActions(TeaModel):
    def __init__(self, instance_ids=None, lifecycle_action_result=None, lifecycle_action_status=None,
                 lifecycle_action_token=None, lifecycle_hook_id=None):
        # The IDs of the ECS instances to which the lifecycle hook applies.
        self.instance_ids = instance_ids  # type: list[str]
        # The action that is performed after the lifecycle action triggered by the lifecycle hook is complete. Valid values:
        # 
        # *   CONTINUE: Auto Scaling continues to add ECS instances to the scaling group, or continues to remove ECS instances from the scaling group.
        # *   ABANDON: Auto Scaling stops adding ECS instances to the scaling group and releases the ECS instances, or continues to respond to scale-in requests and remove ECS instances from the scaling group.
        self.lifecycle_action_result = lifecycle_action_result  # type: str
        # The status of the lifecycle action.
        self.lifecycle_action_status = lifecycle_action_status  # type: str
        # The token of the lifecycle action.
        self.lifecycle_action_token = lifecycle_action_token  # type: str
        # The ID of the lifecycle hook.
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeLifecycleActionsResponseBodyLifecycleActions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.lifecycle_action_result is not None:
            result['LifecycleActionResult'] = self.lifecycle_action_result
        if self.lifecycle_action_status is not None:
            result['LifecycleActionStatus'] = self.lifecycle_action_status
        if self.lifecycle_action_token is not None:
            result['LifecycleActionToken'] = self.lifecycle_action_token
        if self.lifecycle_hook_id is not None:
            result['LifecycleHookId'] = self.lifecycle_hook_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('LifecycleActionResult') is not None:
            self.lifecycle_action_result = m.get('LifecycleActionResult')
        if m.get('LifecycleActionStatus') is not None:
            self.lifecycle_action_status = m.get('LifecycleActionStatus')
        if m.get('LifecycleActionToken') is not None:
            self.lifecycle_action_token = m.get('LifecycleActionToken')
        if m.get('LifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('LifecycleHookId')
        return self


class DescribeLifecycleActionsResponseBody(TeaModel):
    def __init__(self, lifecycle_actions=None, max_results=None, next_token=None, request_id=None, total_count=None):
        # The lifecycle actions.
        self.lifecycle_actions = lifecycle_actions  # type: list[DescribeLifecycleActionsResponseBodyLifecycleActions]
        # The maximum number of entries returned per page.
        self.max_results = max_results  # type: int
        # The query token returned in this call.
        self.next_token = next_token  # type: str
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The total number of the queried lifecycle actions.
        self.total_count = total_count  # type: int

    def validate(self):
        if self.lifecycle_actions:
            for k in self.lifecycle_actions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeLifecycleActionsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['LifecycleActions'] = []
        if self.lifecycle_actions is not None:
            for k in self.lifecycle_actions:
                result['LifecycleActions'].append(k.to_map() if k else None)
        if self.max_results is not None:
            result['MaxResults'] = self.max_results
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.lifecycle_actions = []
        if m.get('LifecycleActions') is not None:
            for k in m.get('LifecycleActions'):
                temp_model = DescribeLifecycleActionsResponseBodyLifecycleActions()
                self.lifecycle_actions.append(temp_model.from_map(k))
        if m.get('MaxResults') is not None:
            self.max_results = m.get('MaxResults')
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeLifecycleActionsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeLifecycleActionsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeLifecycleActionsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeLifecycleActionsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeLifecycleHooksRequest(TeaModel):
    def __init__(self, lifecycle_hook_ids=None, lifecycle_hook_name=None, owner_account=None, owner_id=None,
                 page_number=None, page_size=None, region_id=None, resource_owner_account=None, scaling_group_id=None):
        self.lifecycle_hook_ids = lifecycle_hook_ids  # type: list[str]
        self.lifecycle_hook_name = lifecycle_hook_name  # type: str
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeLifecycleHooksRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.lifecycle_hook_ids is not None:
            result['LifecycleHookIds'] = self.lifecycle_hook_ids
        if self.lifecycle_hook_name is not None:
            result['LifecycleHookName'] = self.lifecycle_hook_name
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LifecycleHookIds') is not None:
            self.lifecycle_hook_ids = m.get('LifecycleHookIds')
        if m.get('LifecycleHookName') is not None:
            self.lifecycle_hook_name = m.get('LifecycleHookName')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeLifecycleHooksResponseBodyLifecycleHooks(TeaModel):
    def __init__(self, default_result=None, heartbeat_timeout=None, lifecycle_hook_id=None,
                 lifecycle_hook_name=None, lifecycle_hook_status=None, lifecycle_transition=None, notification_arn=None,
                 notification_metadata=None, scaling_group_id=None):
        self.default_result = default_result  # type: str
        self.heartbeat_timeout = heartbeat_timeout  # type: int
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str
        self.lifecycle_hook_name = lifecycle_hook_name  # type: str
        self.lifecycle_hook_status = lifecycle_hook_status  # type: str
        self.lifecycle_transition = lifecycle_transition  # type: str
        self.notification_arn = notification_arn  # type: str
        self.notification_metadata = notification_metadata  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeLifecycleHooksResponseBodyLifecycleHooks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.default_result is not None:
            result['DefaultResult'] = self.default_result
        if self.heartbeat_timeout is not None:
            result['HeartbeatTimeout'] = self.heartbeat_timeout
        if self.lifecycle_hook_id is not None:
            result['LifecycleHookId'] = self.lifecycle_hook_id
        if self.lifecycle_hook_name is not None:
            result['LifecycleHookName'] = self.lifecycle_hook_name
        if self.lifecycle_hook_status is not None:
            result['LifecycleHookStatus'] = self.lifecycle_hook_status
        if self.lifecycle_transition is not None:
            result['LifecycleTransition'] = self.lifecycle_transition
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_metadata is not None:
            result['NotificationMetadata'] = self.notification_metadata
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DefaultResult') is not None:
            self.default_result = m.get('DefaultResult')
        if m.get('HeartbeatTimeout') is not None:
            self.heartbeat_timeout = m.get('HeartbeatTimeout')
        if m.get('LifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('LifecycleHookId')
        if m.get('LifecycleHookName') is not None:
            self.lifecycle_hook_name = m.get('LifecycleHookName')
        if m.get('LifecycleHookStatus') is not None:
            self.lifecycle_hook_status = m.get('LifecycleHookStatus')
        if m.get('LifecycleTransition') is not None:
            self.lifecycle_transition = m.get('LifecycleTransition')
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationMetadata') is not None:
            self.notification_metadata = m.get('NotificationMetadata')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeLifecycleHooksResponseBody(TeaModel):
    def __init__(self, lifecycle_hooks=None, page_number=None, page_size=None, request_id=None, total_count=None):
        self.lifecycle_hooks = lifecycle_hooks  # type: list[DescribeLifecycleHooksResponseBodyLifecycleHooks]
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.request_id = request_id  # type: str
        self.total_count = total_count  # type: int

    def validate(self):
        if self.lifecycle_hooks:
            for k in self.lifecycle_hooks:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeLifecycleHooksResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['LifecycleHooks'] = []
        if self.lifecycle_hooks is not None:
            for k in self.lifecycle_hooks:
                result['LifecycleHooks'].append(k.to_map() if k else None)
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.lifecycle_hooks = []
        if m.get('LifecycleHooks') is not None:
            for k in m.get('LifecycleHooks'):
                temp_model = DescribeLifecycleHooksResponseBodyLifecycleHooks()
                self.lifecycle_hooks.append(temp_model.from_map(k))
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeLifecycleHooksResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeLifecycleHooksResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeLifecycleHooksResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeLifecycleHooksResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeLimitationRequest(TeaModel):
    def __init__(self, owner_id=None, resource_owner_account=None):
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeLimitationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class DescribeLimitationResponseBody(TeaModel):
    def __init__(self, max_number_of_alb_server_group=None, max_number_of_dbinstances=None,
                 max_number_of_lifecycle_hooks=None, max_number_of_load_balancers=None, max_number_of_max_size=None,
                 max_number_of_min_size=None, max_number_of_nlb_server_group=None, max_number_of_notification_configurations=None,
                 max_number_of_scaling_configurations=None, max_number_of_scaling_groups=None, max_number_of_scaling_instances=None,
                 max_number_of_scaling_rules=None, max_number_of_scheduled_tasks=None, max_number_of_vserver_groups=None, request_id=None):
        self.max_number_of_alb_server_group = max_number_of_alb_server_group  # type: int
        self.max_number_of_dbinstances = max_number_of_dbinstances  # type: int
        self.max_number_of_lifecycle_hooks = max_number_of_lifecycle_hooks  # type: int
        self.max_number_of_load_balancers = max_number_of_load_balancers  # type: int
        self.max_number_of_max_size = max_number_of_max_size  # type: int
        self.max_number_of_min_size = max_number_of_min_size  # type: int
        self.max_number_of_nlb_server_group = max_number_of_nlb_server_group  # type: int
        self.max_number_of_notification_configurations = max_number_of_notification_configurations  # type: int
        self.max_number_of_scaling_configurations = max_number_of_scaling_configurations  # type: int
        self.max_number_of_scaling_groups = max_number_of_scaling_groups  # type: int
        self.max_number_of_scaling_instances = max_number_of_scaling_instances  # type: int
        self.max_number_of_scaling_rules = max_number_of_scaling_rules  # type: int
        self.max_number_of_scheduled_tasks = max_number_of_scheduled_tasks  # type: int
        self.max_number_of_vserver_groups = max_number_of_vserver_groups  # type: int
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeLimitationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.max_number_of_alb_server_group is not None:
            result['MaxNumberOfAlbServerGroup'] = self.max_number_of_alb_server_group
        if self.max_number_of_dbinstances is not None:
            result['MaxNumberOfDBInstances'] = self.max_number_of_dbinstances
        if self.max_number_of_lifecycle_hooks is not None:
            result['MaxNumberOfLifecycleHooks'] = self.max_number_of_lifecycle_hooks
        if self.max_number_of_load_balancers is not None:
            result['MaxNumberOfLoadBalancers'] = self.max_number_of_load_balancers
        if self.max_number_of_max_size is not None:
            result['MaxNumberOfMaxSize'] = self.max_number_of_max_size
        if self.max_number_of_min_size is not None:
            result['MaxNumberOfMinSize'] = self.max_number_of_min_size
        if self.max_number_of_nlb_server_group is not None:
            result['MaxNumberOfNlbServerGroup'] = self.max_number_of_nlb_server_group
        if self.max_number_of_notification_configurations is not None:
            result['MaxNumberOfNotificationConfigurations'] = self.max_number_of_notification_configurations
        if self.max_number_of_scaling_configurations is not None:
            result['MaxNumberOfScalingConfigurations'] = self.max_number_of_scaling_configurations
        if self.max_number_of_scaling_groups is not None:
            result['MaxNumberOfScalingGroups'] = self.max_number_of_scaling_groups
        if self.max_number_of_scaling_instances is not None:
            result['MaxNumberOfScalingInstances'] = self.max_number_of_scaling_instances
        if self.max_number_of_scaling_rules is not None:
            result['MaxNumberOfScalingRules'] = self.max_number_of_scaling_rules
        if self.max_number_of_scheduled_tasks is not None:
            result['MaxNumberOfScheduledTasks'] = self.max_number_of_scheduled_tasks
        if self.max_number_of_vserver_groups is not None:
            result['MaxNumberOfVServerGroups'] = self.max_number_of_vserver_groups
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MaxNumberOfAlbServerGroup') is not None:
            self.max_number_of_alb_server_group = m.get('MaxNumberOfAlbServerGroup')
        if m.get('MaxNumberOfDBInstances') is not None:
            self.max_number_of_dbinstances = m.get('MaxNumberOfDBInstances')
        if m.get('MaxNumberOfLifecycleHooks') is not None:
            self.max_number_of_lifecycle_hooks = m.get('MaxNumberOfLifecycleHooks')
        if m.get('MaxNumberOfLoadBalancers') is not None:
            self.max_number_of_load_balancers = m.get('MaxNumberOfLoadBalancers')
        if m.get('MaxNumberOfMaxSize') is not None:
            self.max_number_of_max_size = m.get('MaxNumberOfMaxSize')
        if m.get('MaxNumberOfMinSize') is not None:
            self.max_number_of_min_size = m.get('MaxNumberOfMinSize')
        if m.get('MaxNumberOfNlbServerGroup') is not None:
            self.max_number_of_nlb_server_group = m.get('MaxNumberOfNlbServerGroup')
        if m.get('MaxNumberOfNotificationConfigurations') is not None:
            self.max_number_of_notification_configurations = m.get('MaxNumberOfNotificationConfigurations')
        if m.get('MaxNumberOfScalingConfigurations') is not None:
            self.max_number_of_scaling_configurations = m.get('MaxNumberOfScalingConfigurations')
        if m.get('MaxNumberOfScalingGroups') is not None:
            self.max_number_of_scaling_groups = m.get('MaxNumberOfScalingGroups')
        if m.get('MaxNumberOfScalingInstances') is not None:
            self.max_number_of_scaling_instances = m.get('MaxNumberOfScalingInstances')
        if m.get('MaxNumberOfScalingRules') is not None:
            self.max_number_of_scaling_rules = m.get('MaxNumberOfScalingRules')
        if m.get('MaxNumberOfScheduledTasks') is not None:
            self.max_number_of_scheduled_tasks = m.get('MaxNumberOfScheduledTasks')
        if m.get('MaxNumberOfVServerGroups') is not None:
            self.max_number_of_vserver_groups = m.get('MaxNumberOfVServerGroups')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeLimitationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeLimitationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeLimitationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeLimitationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeNotificationConfigurationsRequest(TeaModel):
    def __init__(self, owner_id=None, region_id=None, resource_owner_account=None, scaling_group_id=None):
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeNotificationConfigurationsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeNotificationConfigurationsResponseBodyNotificationConfigurationModels(TeaModel):
    def __init__(self, notification_arn=None, notification_types=None, scaling_group_id=None):
        # The Alibaba Cloud Resource Name (ARN) of the notification method. The following list describes the value formats of this parameter:
        # 
        # *   If you use CloudMonitor as the notification method, the value format of this parameter is acs:ess:{region-id}:{account-id}:cloudmonitor.
        # *   If you use a Message Service (MNS) queue as the notification method, the value format of this parameter is acs:mns:{region-id}:{account-id}:queue/{queuename}.
        # *   If you use an MNS topic as the notification method, the value format of this parameter is acs:mns:{region-id}:{account-id}:topic/{topicname}.
        # 
        # The variables in the preceding formats have the following meanings:
        # 
        # *   region-id: the region ID of the scaling group.
        # *   account-id: the ID of the Alibaba Cloud account.
        # *   queuename: the name of the MNS queue.
        # *   topicname: the name of the MNS topic.
        self.notification_arn = notification_arn  # type: str
        # The types of notifications for scaling activities and resource changes.
        # 
        # *   AUTOSCALING:SCALE_OUT_SUCCESS: The scale-out event is successful.
        # *   AUTOSCALING:SCALE_IN_SUCCESS: The scale-in event is successful.
        # *   AUTOSCALING:SCALE_OUT_ERROR: The scale-out event fails.
        # *   AUTOSCALING:SCALE_IN_ERROR: The scale-in event fails.
        # *   AUTOSCALING:SCALE_REJECT: The scaling activity is rejected.
        # *   AUTOSCALING:SCALE_OUT_START: The scale-out event is started.
        # *   AUTOSCALING:SCALE_IN_START: The scale-in event is started.
        # *   AUTOSCALING:SCHEDULE_TASK_EXPIRING: Auto Scaling sends a notification when a scheduled task is about to expire.
        self.notification_types = notification_types  # type: list[str]
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeNotificationConfigurationsResponseBodyNotificationConfigurationModels, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_types is not None:
            result['NotificationTypes'] = self.notification_types
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationTypes') is not None:
            self.notification_types = m.get('NotificationTypes')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeNotificationConfigurationsResponseBody(TeaModel):
    def __init__(self, notification_configuration_models=None, request_id=None):
        # Details of the notifications.
        self.notification_configuration_models = notification_configuration_models  # type: list[DescribeNotificationConfigurationsResponseBodyNotificationConfigurationModels]
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        if self.notification_configuration_models:
            for k in self.notification_configuration_models:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeNotificationConfigurationsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['NotificationConfigurationModels'] = []
        if self.notification_configuration_models is not None:
            for k in self.notification_configuration_models:
                result['NotificationConfigurationModels'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.notification_configuration_models = []
        if m.get('NotificationConfigurationModels') is not None:
            for k in m.get('NotificationConfigurationModels'):
                temp_model = DescribeNotificationConfigurationsResponseBodyNotificationConfigurationModels()
                self.notification_configuration_models.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeNotificationConfigurationsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeNotificationConfigurationsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeNotificationConfigurationsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeNotificationConfigurationsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeNotificationTypesRequest(TeaModel):
    def __init__(self, owner_id=None, resource_owner_account=None):
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeNotificationTypesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class DescribeNotificationTypesResponseBody(TeaModel):
    def __init__(self, notification_types=None, request_id=None):
        # The types of the notifications.
        # 
        # *   AUTOSCALING:SCALE_OUT_SUCCESS: The scale-out activity succeeds.
        # *   AUTOSCALING:SCALE_IN_SUCCESS: The scale-in activity succeeds.
        # *   AUTOSCALING:SCALE_OUT_ERROR: The scale-out activity fails.
        # *   AUTOSCALING:SCALE_IN_ERROR: The scale-in activity fails.
        # *   AUTOSCALING:SCALE_REJECT: The request for scaling activities is rejected.
        # *   AUTOSCALING:SCALE_OUT_START: The scale-out activity starts.
        # *   AUTOSCALING:SCALE_IN_START: The scale-in activity starts.
        # *   AUTOSCALING:SCHEDULE_TASK_EXPIRING: Auto Scaling sends a notification when a scheduled task is about to expire.
        self.notification_types = notification_types  # type: list[str]
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeNotificationTypesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.notification_types is not None:
            result['NotificationTypes'] = self.notification_types
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NotificationTypes') is not None:
            self.notification_types = m.get('NotificationTypes')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeNotificationTypesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeNotificationTypesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeNotificationTypesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeNotificationTypesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeRegionsRequest(TeaModel):
    def __init__(self, accept_language=None, owner_id=None, resource_owner_account=None, resource_owner_id=None):
        # The language used for the returned value. Valid values:
        # 
        # *   **zh-CN**: Chinese.
        # *   **en-US**: English.
        # 
        # >  Default value: **zh-CN**.
        self.accept_language = accept_language  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeRegionsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.accept_language is not None:
            result['AcceptLanguage'] = self.accept_language
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AcceptLanguage') is not None:
            self.accept_language = m.get('AcceptLanguage')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class DescribeRegionsResponseBodyRegions(TeaModel):
    def __init__(self, classic_unavailable=None, local_name=None, region_endpoint=None, region_id=None,
                 vpc_unavailable=None):
        # Indicates whether the region supports scaling groups of the classic network type. Valid values:
        # 
        # *   true
        # *   false
        self.classic_unavailable = classic_unavailable  # type: bool
        # The name of the region.
        self.local_name = local_name  # type: str
        # The endpoint of the region.
        self.region_endpoint = region_endpoint  # type: str
        # The ID of the region.
        self.region_id = region_id  # type: str
        # Indicates whether the region supports scaling groups of the virtual private cloud (VPC) type. Valid values:
        # 
        # *   true: The region does not support scaling groups of the VPC type.
        # *   false: The region supports scaling groups of the VPC type.
        self.vpc_unavailable = vpc_unavailable  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeRegionsResponseBodyRegions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.classic_unavailable is not None:
            result['ClassicUnavailable'] = self.classic_unavailable
        if self.local_name is not None:
            result['LocalName'] = self.local_name
        if self.region_endpoint is not None:
            result['RegionEndpoint'] = self.region_endpoint
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.vpc_unavailable is not None:
            result['VpcUnavailable'] = self.vpc_unavailable
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClassicUnavailable') is not None:
            self.classic_unavailable = m.get('ClassicUnavailable')
        if m.get('LocalName') is not None:
            self.local_name = m.get('LocalName')
        if m.get('RegionEndpoint') is not None:
            self.region_endpoint = m.get('RegionEndpoint')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('VpcUnavailable') is not None:
            self.vpc_unavailable = m.get('VpcUnavailable')
        return self


class DescribeRegionsResponseBody(TeaModel):
    def __init__(self, regions=None, request_id=None):
        # Details of the regions.
        self.regions = regions  # type: list[DescribeRegionsResponseBodyRegions]
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        if self.regions:
            for k in self.regions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeRegionsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['Regions'] = []
        if self.regions is not None:
            for k in self.regions:
                result['Regions'].append(k.to_map() if k else None)
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.regions = []
        if m.get('Regions') is not None:
            for k in m.get('Regions'):
                temp_model = DescribeRegionsResponseBodyRegions()
                self.regions.append(temp_model.from_map(k))
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DescribeRegionsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeRegionsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeRegionsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeRegionsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingActivitiesRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, page_number=None, page_size=None, region_id=None,
                 resource_owner_account=None, resource_owner_id=None, scaling_activity_ids=None, scaling_group_id=None, status_code=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The number of the page to return. Pages start from page 1.
        # 
        # Default value: 1.
        self.page_number = page_number  # type: int
        # The number of entries to return on each page. Maximum value: 50.
        # 
        # Default value: 10.
        self.page_size = page_size  # type: int
        # The region ID of the scaling group to which the scaling activity that you want to query belongs.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The IDs of the scaling activities that you want to query.
        # 
        # > When you call this operation, you must specify one of the `ScalingGroupId` and `ScalingActivityId.N` parameters. Otherwise, an error is reported.
        self.scaling_activity_ids = scaling_activity_ids  # type: list[str]
        # The ID of the scaling group.
        # 
        # > When you call this operation, you must specify one of the `ScalingGroupId` and `ScalingActivityId.N` parameters. Otherwise, an error is reported.
        self.scaling_group_id = scaling_group_id  # type: str
        # The status of the scaling activity. Valid values:
        # 
        # *   Successful: The scaling activity is successful.
        # *   Warning: The scaling activity is partially successful.
        # *   Failed: The scaling activity failed.
        # *   InProgress: The scaling activity is in progress.
        # *   Rejected: The request to trigger the scaling activity is rejected.
        self.status_code = status_code  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingActivitiesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_activity_ids is not None:
            result['ScalingActivityIds'] = self.scaling_activity_ids
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.status_code is not None:
            result['StatusCode'] = self.status_code
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingActivityIds') is not None:
            self.scaling_activity_ids = m.get('ScalingActivityIds')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('StatusCode') is not None:
            self.status_code = m.get('StatusCode')
        return self


class DescribeScalingActivitiesResponseBodyScalingActivitiesLifecycleHookContext(TeaModel):
    def __init__(self, disable_lifecycle_hook=None, ignored_lifecycle_hook_ids=None):
        self.disable_lifecycle_hook = disable_lifecycle_hook  # type: bool
        self.ignored_lifecycle_hook_ids = ignored_lifecycle_hook_ids  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingActivitiesResponseBodyScalingActivitiesLifecycleHookContext, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disable_lifecycle_hook is not None:
            result['DisableLifecycleHook'] = self.disable_lifecycle_hook
        if self.ignored_lifecycle_hook_ids is not None:
            result['IgnoredLifecycleHookIds'] = self.ignored_lifecycle_hook_ids
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DisableLifecycleHook') is not None:
            self.disable_lifecycle_hook = m.get('DisableLifecycleHook')
        if m.get('IgnoredLifecycleHookIds') is not None:
            self.ignored_lifecycle_hook_ids = m.get('IgnoredLifecycleHookIds')
        return self


class DescribeScalingActivitiesResponseBodyScalingActivities(TeaModel):
    def __init__(self, activity_metadata=None, attached_capacity=None, auto_created_capacity=None, cause=None,
                 created_capacity=None, created_instances=None, description=None, destroyed_capacity=None, destroyed_instances=None,
                 detail=None, end_time=None, error_code=None, error_message=None, lifecycle_hook_context=None,
                 progress=None, scaling_activity_id=None, scaling_group_id=None, scaling_instance_number=None,
                 start_time=None, started_capacity=None, started_instances=None, status_code=None, status_message=None,
                 stopped_capacity=None, stopped_instances=None, total_capacity=None, trigger_source_id=None,
                 trigger_source_type=None):
        self.activity_metadata = activity_metadata  # type: str
        # The total number of instances that were manually added to the scaling group after the scaling activity was complete.
        self.attached_capacity = attached_capacity  # type: str
        # The total number of instances that were created by Auto Scaling after the scaling activity was complete.
        self.auto_created_capacity = auto_created_capacity  # type: str
        # The reason why the scaling activity was triggered.
        self.cause = cause  # type: str
        # The number of instances that were created during the scaling activity.
        self.created_capacity = created_capacity  # type: int
        # The instances that were created during the scaling activity.
        self.created_instances = created_instances  # type: list[str]
        # The description of the scaling activity.
        self.description = description  # type: str
        # The number of instances that were released during the scaling activity.
        self.destroyed_capacity = destroyed_capacity  # type: int
        # The instances that were released during the scaling activity.
        self.destroyed_instances = destroyed_instances  # type: list[str]
        # Details of the scaling activity.
        self.detail = detail  # type: str
        # The time when the scaling activity was complete.
        self.end_time = end_time  # type: str
        # The error code that is returned when the scaling activity failed.
        self.error_code = error_code  # type: str
        # The error message that is returned when the scaling activity failed.
        self.error_message = error_message  # type: str
        self.lifecycle_hook_context = lifecycle_hook_context  # type: DescribeScalingActivitiesResponseBodyScalingActivitiesLifecycleHookContext
        # The execution progress of the scaling activity.
        self.progress = progress  # type: int
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # If the scaling activity is a scale-out activity, the value of this parameter indicates the number of instances that were created during the scaling activity or the number of instances that were started from Economical Mode.
        # 
        # If the scaling activity is a scale-in activity, the value of this parameter indicates the number of instances that were deleted during the scaling activity or the number of instances that were stopped in Economical Mode.
        self.scaling_instance_number = scaling_instance_number  # type: int
        # The time when the scaling activity started.
        self.start_time = start_time  # type: str
        # The number of instances that were started from Economical Mode during the scaling activity.
        self.started_capacity = started_capacity  # type: int
        # The instances that were started from Economical Mode during the scaling activity.
        self.started_instances = started_instances  # type: list[str]
        # The status of the scaling activity. Valid values:
        # 
        # *   Successful: The scaling activity is successful.
        # *   Warning: The scaling activity is partially successful.
        # *   Failed: The scaling activity failed.
        # *   InProgress: The scaling activity is in progress.
        # *   Rejected: The request to trigger the scaling activity is rejected.
        self.status_code = status_code  # type: str
        # The status message of the scaling activity.
        self.status_message = status_message  # type: str
        # The number of instances that were stopped in Economical Mode during the scaling activity.
        self.stopped_capacity = stopped_capacity  # type: int
        # The instances that were stopped in Economical Mode during the scaling activity.
        self.stopped_instances = stopped_instances  # type: list[str]
        # The total number of instances in the scaling group after the scaling activity was complete.
        self.total_capacity = total_capacity  # type: str
        self.trigger_source_id = trigger_source_id  # type: str
        self.trigger_source_type = trigger_source_type  # type: str

    def validate(self):
        if self.lifecycle_hook_context:
            self.lifecycle_hook_context.validate()

    def to_map(self):
        _map = super(DescribeScalingActivitiesResponseBodyScalingActivities, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.activity_metadata is not None:
            result['ActivityMetadata'] = self.activity_metadata
        if self.attached_capacity is not None:
            result['AttachedCapacity'] = self.attached_capacity
        if self.auto_created_capacity is not None:
            result['AutoCreatedCapacity'] = self.auto_created_capacity
        if self.cause is not None:
            result['Cause'] = self.cause
        if self.created_capacity is not None:
            result['CreatedCapacity'] = self.created_capacity
        if self.created_instances is not None:
            result['CreatedInstances'] = self.created_instances
        if self.description is not None:
            result['Description'] = self.description
        if self.destroyed_capacity is not None:
            result['DestroyedCapacity'] = self.destroyed_capacity
        if self.destroyed_instances is not None:
            result['DestroyedInstances'] = self.destroyed_instances
        if self.detail is not None:
            result['Detail'] = self.detail
        if self.end_time is not None:
            result['EndTime'] = self.end_time
        if self.error_code is not None:
            result['ErrorCode'] = self.error_code
        if self.error_message is not None:
            result['ErrorMessage'] = self.error_message
        if self.lifecycle_hook_context is not None:
            result['LifecycleHookContext'] = self.lifecycle_hook_context.to_map()
        if self.progress is not None:
            result['Progress'] = self.progress
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_instance_number is not None:
            result['ScalingInstanceNumber'] = self.scaling_instance_number
        if self.start_time is not None:
            result['StartTime'] = self.start_time
        if self.started_capacity is not None:
            result['StartedCapacity'] = self.started_capacity
        if self.started_instances is not None:
            result['StartedInstances'] = self.started_instances
        if self.status_code is not None:
            result['StatusCode'] = self.status_code
        if self.status_message is not None:
            result['StatusMessage'] = self.status_message
        if self.stopped_capacity is not None:
            result['StoppedCapacity'] = self.stopped_capacity
        if self.stopped_instances is not None:
            result['StoppedInstances'] = self.stopped_instances
        if self.total_capacity is not None:
            result['TotalCapacity'] = self.total_capacity
        if self.trigger_source_id is not None:
            result['TriggerSourceId'] = self.trigger_source_id
        if self.trigger_source_type is not None:
            result['TriggerSourceType'] = self.trigger_source_type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActivityMetadata') is not None:
            self.activity_metadata = m.get('ActivityMetadata')
        if m.get('AttachedCapacity') is not None:
            self.attached_capacity = m.get('AttachedCapacity')
        if m.get('AutoCreatedCapacity') is not None:
            self.auto_created_capacity = m.get('AutoCreatedCapacity')
        if m.get('Cause') is not None:
            self.cause = m.get('Cause')
        if m.get('CreatedCapacity') is not None:
            self.created_capacity = m.get('CreatedCapacity')
        if m.get('CreatedInstances') is not None:
            self.created_instances = m.get('CreatedInstances')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DestroyedCapacity') is not None:
            self.destroyed_capacity = m.get('DestroyedCapacity')
        if m.get('DestroyedInstances') is not None:
            self.destroyed_instances = m.get('DestroyedInstances')
        if m.get('Detail') is not None:
            self.detail = m.get('Detail')
        if m.get('EndTime') is not None:
            self.end_time = m.get('EndTime')
        if m.get('ErrorCode') is not None:
            self.error_code = m.get('ErrorCode')
        if m.get('ErrorMessage') is not None:
            self.error_message = m.get('ErrorMessage')
        if m.get('LifecycleHookContext') is not None:
            temp_model = DescribeScalingActivitiesResponseBodyScalingActivitiesLifecycleHookContext()
            self.lifecycle_hook_context = temp_model.from_map(m['LifecycleHookContext'])
        if m.get('Progress') is not None:
            self.progress = m.get('Progress')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingInstanceNumber') is not None:
            self.scaling_instance_number = m.get('ScalingInstanceNumber')
        if m.get('StartTime') is not None:
            self.start_time = m.get('StartTime')
        if m.get('StartedCapacity') is not None:
            self.started_capacity = m.get('StartedCapacity')
        if m.get('StartedInstances') is not None:
            self.started_instances = m.get('StartedInstances')
        if m.get('StatusCode') is not None:
            self.status_code = m.get('StatusCode')
        if m.get('StatusMessage') is not None:
            self.status_message = m.get('StatusMessage')
        if m.get('StoppedCapacity') is not None:
            self.stopped_capacity = m.get('StoppedCapacity')
        if m.get('StoppedInstances') is not None:
            self.stopped_instances = m.get('StoppedInstances')
        if m.get('TotalCapacity') is not None:
            self.total_capacity = m.get('TotalCapacity')
        if m.get('TriggerSourceId') is not None:
            self.trigger_source_id = m.get('TriggerSourceId')
        if m.get('TriggerSourceType') is not None:
            self.trigger_source_type = m.get('TriggerSourceType')
        return self


class DescribeScalingActivitiesResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scaling_activities=None, total_count=None):
        # The page number of the returned page.
        self.page_number = page_number  # type: int
        # The number of entries returned per page.
        self.page_size = page_size  # type: int
        # The ID of the request.
        self.request_id = request_id  # type: str
        # Details of the scaling activities.
        self.scaling_activities = scaling_activities  # type: list[DescribeScalingActivitiesResponseBodyScalingActivities]
        # The total number of scaling activities.
        self.total_count = total_count  # type: int

    def validate(self):
        if self.scaling_activities:
            for k in self.scaling_activities:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingActivitiesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScalingActivities'] = []
        if self.scaling_activities is not None:
            for k in self.scaling_activities:
                result['ScalingActivities'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scaling_activities = []
        if m.get('ScalingActivities') is not None:
            for k in m.get('ScalingActivities'):
                temp_model = DescribeScalingActivitiesResponseBodyScalingActivities()
                self.scaling_activities.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeScalingActivitiesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingActivitiesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingActivitiesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingActivitiesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingActivityDetailRequest(TeaModel):
    def __init__(self, owner_id=None, resource_owner_account=None, resource_owner_id=None,
                 scaling_activity_id=None):
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingActivityDetailRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DescribeScalingActivityDetailResponseBody(TeaModel):
    def __init__(self, detail=None, request_id=None, scaling_activity_id=None):
        # The details about the event.
        self.detail = detail  # type: str
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingActivityDetailResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.detail is not None:
            result['Detail'] = self.detail
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Detail') is not None:
            self.detail = m.get('Detail')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DescribeScalingActivityDetailResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingActivityDetailResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingActivityDetailResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingActivityDetailResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingConfigurationsRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, page_number=None, page_size=None, region_id=None,
                 resource_owner_account=None, resource_owner_id=None, scaling_configuration_ids=None, scaling_configuration_names=None,
                 scaling_group_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The number of the page to return. Pages start from page 1.
        # 
        # Default value: 1
        self.page_number = page_number  # type: int
        # The number of entries to return on each page. Maximum value: 50.
        # 
        # Default value: 10
        self.page_size = page_size  # type: int
        # The region ID of the scaling group to which the scaling configuration that you want to query belongs.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The IDs of the scaling configurations that you want to query.
        # 
        # The IDs of active and inactive scaling configurations are displayed in the query results. You can differentiate between active and inactive scaling configurations based on the value of the `LifecycleState` parameter.
        self.scaling_configuration_ids = scaling_configuration_ids  # type: list[str]
        # The names of the scaling configurations that you want to query.
        # 
        # The names of inactive scaling configurations are not displayed in the query results, and no error is reported.
        self.scaling_configuration_names = scaling_configuration_names  # type: list[str]
        # The ID of the scaling group. You can use the ID to query all scaling configurations in the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_configuration_ids is not None:
            result['ScalingConfigurationIds'] = self.scaling_configuration_ids
        if self.scaling_configuration_names is not None:
            result['ScalingConfigurationNames'] = self.scaling_configuration_names
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingConfigurationIds') is not None:
            self.scaling_configuration_ids = m.get('ScalingConfigurationIds')
        if m.get('ScalingConfigurationNames') is not None:
            self.scaling_configuration_names = m.get('ScalingConfigurationNames')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurationsCustomPriorities(TeaModel):
    def __init__(self, instance_type=None, vswitch_id=None):
        self.instance_type = instance_type  # type: str
        self.vswitch_id = vswitch_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurationsCustomPriorities, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.vswitch_id is not None:
            result['VswitchId'] = self.vswitch_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('VswitchId') is not None:
            self.vswitch_id = m.get('VswitchId')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurationsDataDisks(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, categories=None, category=None,
                 delete_with_instance=None, description=None, device=None, disk_name=None, encrypted=None, kmskey_id=None,
                 performance_level=None, provisioned_iops=None, size=None, snapshot_id=None):
        # The ID of the automatic snapshot policy that is applied to the data disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Indicates whether the burst feature is enabled for the data disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set the `DataDisk.Category` parameter to `cloud_auto`.
        # 
        # For more information, see the [ESSD AutoPL disks](~~368372~~) topic.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The categories of the data disks. The values are sorted based on their priorities. The first value has the highest priority. If Auto Scaling cannot create instances by using the disk that has the highest priority, Auto Scaling creates instances by using the disk that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk. The DeleteWithInstance parameter of a basic disk that is created together with the instance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   cloud_essd: ESSD.
        self.categories = categories  # type: list[str]
        # The category of the data disk. Valid values:
        # 
        # *   cloud: basic disk. The DeleteWithInstance parameter of a basic disk that is created together with the instance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   ephemeral_ssd: local standard SSD.
        # *   cloud_essd: ESSD.
        # *   cloud_auto: ESSD AutoPL disk.
        self.category = category  # type: str
        # Indicates whether the data disk is released if the instance to which the data disk is attached is released. Valid values:
        # 
        # *   true
        # *   false
        self.delete_with_instance = delete_with_instance  # type: bool
        # The description of the data disk.
        self.description = description  # type: str
        # The mount target of the data disk.
        self.device = device  # type: str
        # The name of the data disk.
        self.disk_name = disk_name  # type: str
        # Indicates whether the data disk is encrypted. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.encrypted = encrypted  # type: str
        # The ID of the Key Management Service (KMS) key that is used to encrypt the data disk.
        self.kmskey_id = kmskey_id  # type: str
        # The PL of the data disk of the ESSD category.
        self.performance_level = performance_level  # type: str
        # The provisioned input/output operations per second (IOPS) for the data disk.
        # 
        # > IOPS measures the number of read and write operations that an Elastic Block Storage (EBS) device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the data disk. Unit: GiB.
        # 
        # *   Valid values if you set the Category parameter to cloud: 5 to 2000.
        # *   Valid values if you set the Category parameter to cloud_efficiency: 20 to 32768.
        # *   Valid values if you set the Category parameter to cloud_ssd: 20 to 32768.
        # *   Valid values if you set the Category parameter to cloud_essd: 20 to 32768.
        # *   Valid values if you set the Category parameter to ephemeral_ssd: 5 to 800.
        self.size = size  # type: int
        # The ID of the snapshot that is used to create the data disk.
        self.snapshot_id = snapshot_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurationsDataDisks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.categories is not None:
            result['Categories'] = self.categories
        if self.category is not None:
            result['Category'] = self.category
        if self.delete_with_instance is not None:
            result['DeleteWithInstance'] = self.delete_with_instance
        if self.description is not None:
            result['Description'] = self.description
        if self.device is not None:
            result['Device'] = self.device
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        if self.snapshot_id is not None:
            result['SnapshotId'] = self.snapshot_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Categories') is not None:
            self.categories = m.get('Categories')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('DeleteWithInstance') is not None:
            self.delete_with_instance = m.get('DeleteWithInstance')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Device') is not None:
            self.device = m.get('Device')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        if m.get('SnapshotId') is not None:
            self.snapshot_id = m.get('SnapshotId')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurationsInstancePatternInfos(TeaModel):
    def __init__(self, architectures=None, burstable_performance=None, cores=None, excluded_instance_types=None,
                 instance_family_level=None, max_price=None, memory=None):
        # The architectures of the instance types. Valid values:
        # 
        # *   X86: x86 architecture.
        # *   Heterogeneous: heterogeneous architecture, such as GPUs and FPGAs.
        # *   BareMetal: ECS Bare Metal Instance architecture.
        # *   Arm: ARM architecture.
        # *   SuperComputeCluster: Super Computing Cluster architecture.
        self.architectures = architectures  # type: list[str]
        # Indicates whether burstable instance types are included. Valid values:
        # 
        # *   Exclude: Burstable instance types are not included.
        # *   Include: Burstable instance types are included.
        # *   Required: Only burstable instance types are included.
        self.burstable_performance = burstable_performance  # type: str
        # The number of vCPUs of the instance type.
        self.cores = cores  # type: int
        # The instance types that are excluded. You can use wildcard characters such as an asterisk (\*) to exclude an instance type or an instance family. Examples:
        # 
        # *   ecs.c6.large: The ecs.c6.large instance type is excluded.
        # *   ecs.c6.\*: The c6 instance family is excluded.
        self.excluded_instance_types = excluded_instance_types  # type: list[str]
        # The level of the instance family.
        # 
        # *   EntryLevel: shared instance type. Instances of this level are cost-effective, but do not provide stable computing performance. Instances of this level are suitable for scenarios in which the CPU utilization is low. For more information, see [Shared instance families](~~108489~~).
        # *   EnterpriseLevel: Instances of this level provide stable performance and dedicated resources, and are suitable for scenarios in which high stability is required. For more information, see [Overview of instance families](~~25378~~).
        # *   CreditEntryLevel: This value is available only for burstable instances. CPU credits are used to ensure computing performance. Instances of this level are suitable for scenarios in which the CPU utilization is low but may fluctuate in specific cases. For more information, see [Overview](~~59977~~) of burstable instances
        self.instance_family_level = instance_family_level  # type: str
        # The maximum hourly price for pay-as-you-go instances or preemptible instances.
        self.max_price = max_price  # type: float
        # The memory size of the instance type. Unit: GiB.
        self.memory = memory  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurationsInstancePatternInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.architectures is not None:
            result['Architectures'] = self.architectures
        if self.burstable_performance is not None:
            result['BurstablePerformance'] = self.burstable_performance
        if self.cores is not None:
            result['Cores'] = self.cores
        if self.excluded_instance_types is not None:
            result['ExcludedInstanceTypes'] = self.excluded_instance_types
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.max_price is not None:
            result['MaxPrice'] = self.max_price
        if self.memory is not None:
            result['Memory'] = self.memory
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Architectures') is not None:
            self.architectures = m.get('Architectures')
        if m.get('BurstablePerformance') is not None:
            self.burstable_performance = m.get('BurstablePerformance')
        if m.get('Cores') is not None:
            self.cores = m.get('Cores')
        if m.get('ExcludedInstanceTypes') is not None:
            self.excluded_instance_types = m.get('ExcludedInstanceTypes')
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('MaxPrice') is not None:
            self.max_price = m.get('MaxPrice')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurationsSchedulerOptions(TeaModel):
    def __init__(self, managed_private_space_id=None):
        # > This parameter is in invitational preview and is unavailable.
        self.managed_private_space_id = managed_private_space_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurationsSchedulerOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.managed_private_space_id is not None:
            result['ManagedPrivateSpaceId'] = self.managed_private_space_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ManagedPrivateSpaceId') is not None:
            self.managed_private_space_id = m.get('ManagedPrivateSpaceId')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurationsSpotPriceLimits(TeaModel):
    def __init__(self, instance_type=None, price_limit=None):
        # The instance type of the preemptible instance.
        self.instance_type = instance_type  # type: str
        # The price limit of the preemptible instance.
        self.price_limit = price_limit  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurationsSpotPriceLimits, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.price_limit is not None:
            result['PriceLimit'] = self.price_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('PriceLimit') is not None:
            self.price_limit = m.get('PriceLimit')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurationsTags(TeaModel):
    def __init__(self, key=None, value=None):
        # The key of tag N. Valid values of N: 1 to 20.
        # 
        # The tag key cannot be an empty string. The tag key can be up to 128 characters in length, and cannot start with `acs:` or `aliyun`. The tag key cannot contain `http://` or `https://`.
        self.key = key  # type: str
        # The value of tag N. Valid values of N: 1 to 20.
        # 
        # The tag value can be an empty string. The tag value can be up to 128 characters in length, and cannot start with `acs:`. The tag value cannot contain `http://` or `https://`.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurationsTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeScalingConfigurationsResponseBodyScalingConfigurations(TeaModel):
    def __init__(self, affinity=None, cpu=None, creation_time=None, credit_specification=None,
                 custom_priorities=None, data_disks=None, dedicated_host_id=None, deletion_protection=None, deployment_set_id=None,
                 host_name=None, hpc_cluster_id=None, image_family=None, image_id=None, image_name=None,
                 image_options_login_as_non_root=None, image_owner_alias=None, instance_description=None, instance_generation=None,
                 instance_name=None, instance_pattern_infos=None, instance_type=None, instance_types=None,
                 internet_charge_type=None, internet_max_bandwidth_in=None, internet_max_bandwidth_out=None, io_optimized=None,
                 ipv_6address_count=None, key_pair_name=None, lifecycle_state=None, load_balancer_weight=None, memory=None,
                 password_inherit=None, private_pool_options_id=None, private_pool_options_match_criteria=None, ram_role_name=None,
                 resource_group_id=None, scaling_configuration_id=None, scaling_configuration_name=None, scaling_group_id=None,
                 scheduler_options=None, security_enhancement_strategy=None, security_group_id=None, security_group_ids=None,
                 spot_duration=None, spot_interruption_behavior=None, spot_price_limits=None, spot_strategy=None,
                 storage_set_id=None, storage_set_partition_number=None, system_disk_auto_snapshot_policy_id=None,
                 system_disk_bursting_enabled=None, system_disk_categories=None, system_disk_category=None, system_disk_description=None,
                 system_disk_encrypt_algorithm=None, system_disk_encrypted=None, system_disk_kmskey_id=None, system_disk_name=None,
                 system_disk_performance_level=None, system_disk_provisioned_iops=None, system_disk_size=None, tags=None, tenancy=None,
                 user_data=None, weighted_capacities=None, zone_id=None):
        # Indicates whether the instance on the dedicated host is associated with the dedicated host. Valid values:
        # 
        # *   default: The instance is not associated with the dedicated host. If you start an instance that was stopped in Economical Mode and the original dedicated host has insufficient resources, the instance is automatically deployed to another dedicated host in the automatic deployment resource pool.
        # *   host: The instance is associated with the dedicated host. If you start an instance that was stopped in Economical Mode, the instance remains on the original dedicated host. If the original dedicated host has insufficient resources, the instance cannot be started.
        self.affinity = affinity  # type: str
        # The number of vCPUs.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set the Cpu parameter to 2 and the Memory parameter to 16 to specify the instance types that have 2 vCPUs and 16 GiB of memory. If you specify the Cpu and Memory parameters, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances of the instance type that is provided at the lowest price.
        # 
        # > You can specify CPU and memory specifications to determine the range of instance types only if the Scaling Policy parameter is set to Cost Optimization Policy and no instance type is specified in the scaling configuration.
        self.cpu = cpu  # type: int
        # The time when the scaling configuration was created.
        self.creation_time = creation_time  # type: str
        # The performance mode of the burstable instance. Valid values:
        # 
        # *   Standard: standard mode. For more information, see the "Standard mode" section in the [Burstable instances](~~59977~~) topic.
        # *   Unlimited: unlimited mode. For more information, see the "Unlimited mode" section in the [Burstable instances](~~59977~~) topic.
        self.credit_specification = credit_specification  # type: str
        self.custom_priorities = custom_priorities  # type: list[DescribeScalingConfigurationsResponseBodyScalingConfigurationsCustomPriorities]
        # Details of the data disks.
        self.data_disks = data_disks  # type: list[DescribeScalingConfigurationsResponseBodyScalingConfigurationsDataDisks]
        # The ID of the dedicated host on which the ECS instance is created. Preemptible instances cannot be created on dedicated hosts. If you specify the DedicatedHostId parameter, the SpotStrategy and SpotPriceLimit parameters are ignored.
        # 
        # You can call the DescribeDedicatedHosts operation to query dedicated host IDs.
        self.dedicated_host_id = dedicated_host_id  # type: str
        self.deletion_protection = deletion_protection  # type: bool
        # The ID of the deployment set to which the Elastic Compute Service (ECS) instance belongs.
        self.deployment_set_id = deployment_set_id  # type: str
        # The hostname of the ECS instance.
        self.host_name = host_name  # type: str
        # The ID of the Elastic High Performance Computing (E-HPC) cluster to which the ECS instance belongs.
        self.hpc_cluster_id = hpc_cluster_id  # type: str
        # The name of the image family. If you specify this parameter, the latest custom images that are available in the specified image family are returned. You can use the images to create instances. If the ImageId parameter is specified, you cannot specify the ImageFamily parameter.
        self.image_family = image_family  # type: str
        # The ID of the image that is used by Auto Scaling to create instances.
        self.image_id = image_id  # type: str
        # The name of the image file.
        self.image_name = image_name  # type: str
        # ECS实例是否使用ecs-user用户登录。可能值：
        # 
        # - true：是。
        # - false：否。
        self.image_options_login_as_non_root = image_options_login_as_non_root  # type: bool
        # The source of the image. Valid values:
        # 
        # *   system: public images provided by Alibaba Cloud
        # *   self: custom images that you create
        # *   others: shared images from other Alibaba Cloud accounts or community images published by other Alibaba Cloud accounts
        # *   marketplace: images that are available in Alibaba Cloud Marketplace
        self.image_owner_alias = image_owner_alias  # type: str
        # The description of the ECS instance.
        self.instance_description = instance_description  # type: str
        # The generation of the ECS instance.
        self.instance_generation = instance_generation  # type: str
        # The name of the ECS instance.
        self.instance_name = instance_name  # type: str
        # Details of the intelligent configuration settings, which determines the range of instance types that meet the specified criteria.
        self.instance_pattern_infos = instance_pattern_infos  # type: list[DescribeScalingConfigurationsResponseBodyScalingConfigurationsInstancePatternInfos]
        # The instance type of the ECS instance.
        self.instance_type = instance_type  # type: str
        # Details of the ECS instance types.
        self.instance_types = instance_types  # type: list[str]
        # The billing method for network usage. Valid values:
        # 
        # *   PayByBandwidth: You are charged for the maximum available bandwidth that is specified by the InternetMaxBandwidthOut parameter.
        # *   PayByTraffic: You are charged for the actual data transfer. The InternetMaxBandwidthOut parameter specifies only the maximum available bandwidth.
        self.internet_charge_type = internet_charge_type  # type: str
        # The maximum inbound public bandwidth. Unit: Mbit/s. Valid values: 1 to 200.
        self.internet_max_bandwidth_in = internet_max_bandwidth_in  # type: int
        # The maximum outbound public bandwidth. Unit: Mbit/s. Valid values:
        # 
        # *   0 to 100 if you set the InternetChargeType parameter to PayByBandwidth. If you leave this parameter empty, this parameter is automatically set to 0.
        # *   0 to 100 if you set the InternetChargeType parameter to PayByTraffic. If you leave this parameter empty, an error is reported.
        self.internet_max_bandwidth_out = internet_max_bandwidth_out  # type: int
        # Indicates whether the instance is I/O optimized. Valid values:
        # 
        # *   none: The instance is not I/O optimized.
        # *   optimized: The instance is I/O optimized.
        self.io_optimized = io_optimized  # type: str
        # The number of randomly generated IPv6 addresses that are allocated to the elastic network interface (ENI).
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The name of the key pair that is used to log on to the ECS instance.
        self.key_pair_name = key_pair_name  # type: str
        # The status of the scaling configuration in the scaling group. Valid values:
        # 
        # *   Active: The scaling configuration is active in the scaling group. Auto Scaling uses the active scaling configuration to automatically create ECS instances.
        # *   Inactive: The scaling configuration is inactive in the scaling group. Auto Scaling does not use inactive scaling configurations to automatically create ECS instances. Inactive scaling configurations are retained in the scaling group.
        self.lifecycle_state = lifecycle_state  # type: str
        # The weight of the ECS instance as a backend server. Valid values: 1 to 100.
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size. Unit: GiB.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set the Cpu parameter to 2 and the Memory parameter to 16 to specify the instance types that have 2 vCPUs and 16 GiB of memory. If you specify the Cpu and Memory parameters, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances of the instance type that is provided at the lowest price.
        # 
        # > You can specify CPU and memory specifications to determine the range of instance types only if the Scaling Policy parameter is set to Cost Optimization Policy and no instance type is specified in the scaling configuration.
        self.memory = memory  # type: int
        # Indicates whether the password preconfigured in the image is used.
        self.password_inherit = password_inherit  # type: bool
        self.private_pool_options_id = private_pool_options_id  # type: str
        self.private_pool_options_match_criteria = private_pool_options_match_criteria  # type: str
        # The name of the RAM role that is associated with the ECS instance. The name is provided and maintained by Resource Access Management (RAM). You can call the ListRoles operation to query the available RAM roles.
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group to which the ECS instance belongs.
        self.resource_group_id = resource_group_id  # type: str
        # The ID of the scaling configuration.
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        # The name of the scaling configuration.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The ID of the scaling group to which the scaling configuration belongs.
        self.scaling_group_id = scaling_group_id  # type: str
        # > This parameter is in invitational preview and is unavailable.
        self.scheduler_options = scheduler_options  # type: DescribeScalingConfigurationsResponseBodyScalingConfigurationsSchedulerOptions
        # Indicates whether security hardening is enabled. Valid values:
        # 
        # *   Active: Security hardening is enabled. This value is available only to public images.
        # *   Deactive: Security hardening is disabled. This value is available to all types of images.
        self.security_enhancement_strategy = security_enhancement_strategy  # type: str
        # The ID of the security group with which the ECS instance is associated. ECS instances that are associated with the same security group can access each other.
        self.security_group_id = security_group_id  # type: str
        # The IDs of the security groups with which the ECS instance is associated. ECS instances that are associated with the same security group can access each other.
        self.security_group_ids = security_group_ids  # type: list[str]
        # The protection period of the preemptible instance. Unit: hours.
        self.spot_duration = spot_duration  # type: int
        # The interruption mode of the preemptible instance.
        self.spot_interruption_behavior = spot_interruption_behavior  # type: str
        # Details of the preemptible instances.
        self.spot_price_limits = spot_price_limits  # type: list[DescribeScalingConfigurationsResponseBodyScalingConfigurationsSpotPriceLimits]
        # The preemption policy that is applied to pay-as-you-go instances and preemptible instances. Valid values:
        # 
        # *   NoSpot: The instance is created as a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance that has a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is created as a preemptible instance for which the market price at the time of purchase is automatically used as the bid price.
        self.spot_strategy = spot_strategy  # type: str
        self.storage_set_id = storage_set_id  # type: str
        self.storage_set_partition_number = storage_set_partition_number  # type: int
        # The ID of the automatic snapshot policy that is applied to the system disk.
        self.system_disk_auto_snapshot_policy_id = system_disk_auto_snapshot_policy_id  # type: str
        # Indicates whether the burst feature is enabled for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set the SystemDisk.Category parameter to cloud_auto.
        self.system_disk_bursting_enabled = system_disk_bursting_enabled  # type: bool
        # The categories of the system disks. The values are sorted based on their priorities. The first value has the highest priority. If Auto Scaling cannot create instances by using the disk that has the highest priority, Auto Scaling creates instances by using the disk that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        self.system_disk_categories = system_disk_categories  # type: list[str]
        # The category of the system disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   ephemeral_ssd: local standard SSD
        # *   cloud_essd: enhanced SSD (ESSD)
        # *   cloud_auto: ESSD AutoPL disk
        self.system_disk_category = system_disk_category  # type: str
        # The description of the system disk.
        self.system_disk_description = system_disk_description  # type: str
        # The algorithm that is used to encrypt the system disk. Valid values:
        # 
        # *   AES-256
        # *   SM4-128
        self.system_disk_encrypt_algorithm = system_disk_encrypt_algorithm  # type: str
        # Indicates whether the system disk is encrypted. Valid values:
        # 
        # *   true
        # *   false
        self.system_disk_encrypted = system_disk_encrypted  # type: bool
        # The ID of the KMS key that is used to encrypt the system disk.
        self.system_disk_kmskey_id = system_disk_kmskey_id  # type: str
        # The name of the system disk.
        self.system_disk_name = system_disk_name  # type: str
        # The performance level (PL) of the system disk of the ESSD category.
        self.system_disk_performance_level = system_disk_performance_level  # type: str
        # The provisioned IOPS for the system disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.system_disk_provisioned_iops = system_disk_provisioned_iops  # type: long
        # The size of the system disk. Unit: GiB.
        self.system_disk_size = system_disk_size  # type: int
        # Details of the tags.
        self.tags = tags  # type: list[DescribeScalingConfigurationsResponseBodyScalingConfigurationsTags]
        # Indicates whether the instance is created on a dedicated host. Valid values:
        # 
        # *   default: The instance is created on a non-dedicated host.
        # *   host: The instance is created on a dedicated host. If you do not specify the DedicatedHostId parameter, Alibaba Cloud selects a dedicated host for the instance.
        # 
        # Default value: default.
        self.tenancy = tenancy  # type: str
        # The user data of the ECS instance.
        self.user_data = user_data  # type: str
        # The weight of the instance type. The weight of an instance type indicates the capacity of an instance of the specified instance type in the scaling group. A higher weight indicates that a smaller number of instances of the specified instance type are required to meet the expected capacity requirement.
        self.weighted_capacities = weighted_capacities  # type: list[int]
        # The zone ID of the ECS instance. You can call the DescribeZones operation to query the most recent zone list.
        self.zone_id = zone_id  # type: str

    def validate(self):
        if self.custom_priorities:
            for k in self.custom_priorities:
                if k:
                    k.validate()
        if self.data_disks:
            for k in self.data_disks:
                if k:
                    k.validate()
        if self.instance_pattern_infos:
            for k in self.instance_pattern_infos:
                if k:
                    k.validate()
        if self.scheduler_options:
            self.scheduler_options.validate()
        if self.spot_price_limits:
            for k in self.spot_price_limits:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBodyScalingConfigurations, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.affinity is not None:
            result['Affinity'] = self.affinity
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.credit_specification is not None:
            result['CreditSpecification'] = self.credit_specification
        result['CustomPriorities'] = []
        if self.custom_priorities is not None:
            for k in self.custom_priorities:
                result['CustomPriorities'].append(k.to_map() if k else None)
        result['DataDisks'] = []
        if self.data_disks is not None:
            for k in self.data_disks:
                result['DataDisks'].append(k.to_map() if k else None)
        if self.dedicated_host_id is not None:
            result['DedicatedHostId'] = self.dedicated_host_id
        if self.deletion_protection is not None:
            result['DeletionProtection'] = self.deletion_protection
        if self.deployment_set_id is not None:
            result['DeploymentSetId'] = self.deployment_set_id
        if self.host_name is not None:
            result['HostName'] = self.host_name
        if self.hpc_cluster_id is not None:
            result['HpcClusterId'] = self.hpc_cluster_id
        if self.image_family is not None:
            result['ImageFamily'] = self.image_family
        if self.image_id is not None:
            result['ImageId'] = self.image_id
        if self.image_name is not None:
            result['ImageName'] = self.image_name
        if self.image_options_login_as_non_root is not None:
            result['ImageOptionsLoginAsNonRoot'] = self.image_options_login_as_non_root
        if self.image_owner_alias is not None:
            result['ImageOwnerAlias'] = self.image_owner_alias
        if self.instance_description is not None:
            result['InstanceDescription'] = self.instance_description
        if self.instance_generation is not None:
            result['InstanceGeneration'] = self.instance_generation
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        result['InstancePatternInfos'] = []
        if self.instance_pattern_infos is not None:
            for k in self.instance_pattern_infos:
                result['InstancePatternInfos'].append(k.to_map() if k else None)
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.internet_charge_type is not None:
            result['InternetChargeType'] = self.internet_charge_type
        if self.internet_max_bandwidth_in is not None:
            result['InternetMaxBandwidthIn'] = self.internet_max_bandwidth_in
        if self.internet_max_bandwidth_out is not None:
            result['InternetMaxBandwidthOut'] = self.internet_max_bandwidth_out
        if self.io_optimized is not None:
            result['IoOptimized'] = self.io_optimized
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.key_pair_name is not None:
            result['KeyPairName'] = self.key_pair_name
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.password_inherit is not None:
            result['PasswordInherit'] = self.password_inherit
        if self.private_pool_options_id is not None:
            result['PrivatePoolOptions.Id'] = self.private_pool_options_id
        if self.private_pool_options_match_criteria is not None:
            result['PrivatePoolOptions.MatchCriteria'] = self.private_pool_options_match_criteria
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduler_options is not None:
            result['SchedulerOptions'] = self.scheduler_options.to_map()
        if self.security_enhancement_strategy is not None:
            result['SecurityEnhancementStrategy'] = self.security_enhancement_strategy
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.security_group_ids is not None:
            result['SecurityGroupIds'] = self.security_group_ids
        if self.spot_duration is not None:
            result['SpotDuration'] = self.spot_duration
        if self.spot_interruption_behavior is not None:
            result['SpotInterruptionBehavior'] = self.spot_interruption_behavior
        result['SpotPriceLimits'] = []
        if self.spot_price_limits is not None:
            for k in self.spot_price_limits:
                result['SpotPriceLimits'].append(k.to_map() if k else None)
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        if self.storage_set_id is not None:
            result['StorageSetId'] = self.storage_set_id
        if self.storage_set_partition_number is not None:
            result['StorageSetPartitionNumber'] = self.storage_set_partition_number
        if self.system_disk_auto_snapshot_policy_id is not None:
            result['SystemDiskAutoSnapshotPolicyId'] = self.system_disk_auto_snapshot_policy_id
        if self.system_disk_bursting_enabled is not None:
            result['SystemDiskBurstingEnabled'] = self.system_disk_bursting_enabled
        if self.system_disk_categories is not None:
            result['SystemDiskCategories'] = self.system_disk_categories
        if self.system_disk_category is not None:
            result['SystemDiskCategory'] = self.system_disk_category
        if self.system_disk_description is not None:
            result['SystemDiskDescription'] = self.system_disk_description
        if self.system_disk_encrypt_algorithm is not None:
            result['SystemDiskEncryptAlgorithm'] = self.system_disk_encrypt_algorithm
        if self.system_disk_encrypted is not None:
            result['SystemDiskEncrypted'] = self.system_disk_encrypted
        if self.system_disk_kmskey_id is not None:
            result['SystemDiskKMSKeyId'] = self.system_disk_kmskey_id
        if self.system_disk_name is not None:
            result['SystemDiskName'] = self.system_disk_name
        if self.system_disk_performance_level is not None:
            result['SystemDiskPerformanceLevel'] = self.system_disk_performance_level
        if self.system_disk_provisioned_iops is not None:
            result['SystemDiskProvisionedIops'] = self.system_disk_provisioned_iops
        if self.system_disk_size is not None:
            result['SystemDiskSize'] = self.system_disk_size
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.tenancy is not None:
            result['Tenancy'] = self.tenancy
        if self.user_data is not None:
            result['UserData'] = self.user_data
        if self.weighted_capacities is not None:
            result['WeightedCapacities'] = self.weighted_capacities
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Affinity') is not None:
            self.affinity = m.get('Affinity')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('CreditSpecification') is not None:
            self.credit_specification = m.get('CreditSpecification')
        self.custom_priorities = []
        if m.get('CustomPriorities') is not None:
            for k in m.get('CustomPriorities'):
                temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurationsCustomPriorities()
                self.custom_priorities.append(temp_model.from_map(k))
        self.data_disks = []
        if m.get('DataDisks') is not None:
            for k in m.get('DataDisks'):
                temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurationsDataDisks()
                self.data_disks.append(temp_model.from_map(k))
        if m.get('DedicatedHostId') is not None:
            self.dedicated_host_id = m.get('DedicatedHostId')
        if m.get('DeletionProtection') is not None:
            self.deletion_protection = m.get('DeletionProtection')
        if m.get('DeploymentSetId') is not None:
            self.deployment_set_id = m.get('DeploymentSetId')
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        if m.get('HpcClusterId') is not None:
            self.hpc_cluster_id = m.get('HpcClusterId')
        if m.get('ImageFamily') is not None:
            self.image_family = m.get('ImageFamily')
        if m.get('ImageId') is not None:
            self.image_id = m.get('ImageId')
        if m.get('ImageName') is not None:
            self.image_name = m.get('ImageName')
        if m.get('ImageOptionsLoginAsNonRoot') is not None:
            self.image_options_login_as_non_root = m.get('ImageOptionsLoginAsNonRoot')
        if m.get('ImageOwnerAlias') is not None:
            self.image_owner_alias = m.get('ImageOwnerAlias')
        if m.get('InstanceDescription') is not None:
            self.instance_description = m.get('InstanceDescription')
        if m.get('InstanceGeneration') is not None:
            self.instance_generation = m.get('InstanceGeneration')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        self.instance_pattern_infos = []
        if m.get('InstancePatternInfos') is not None:
            for k in m.get('InstancePatternInfos'):
                temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurationsInstancePatternInfos()
                self.instance_pattern_infos.append(temp_model.from_map(k))
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('InternetChargeType') is not None:
            self.internet_charge_type = m.get('InternetChargeType')
        if m.get('InternetMaxBandwidthIn') is not None:
            self.internet_max_bandwidth_in = m.get('InternetMaxBandwidthIn')
        if m.get('InternetMaxBandwidthOut') is not None:
            self.internet_max_bandwidth_out = m.get('InternetMaxBandwidthOut')
        if m.get('IoOptimized') is not None:
            self.io_optimized = m.get('IoOptimized')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('KeyPairName') is not None:
            self.key_pair_name = m.get('KeyPairName')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('PasswordInherit') is not None:
            self.password_inherit = m.get('PasswordInherit')
        if m.get('PrivatePoolOptions.Id') is not None:
            self.private_pool_options_id = m.get('PrivatePoolOptions.Id')
        if m.get('PrivatePoolOptions.MatchCriteria') is not None:
            self.private_pool_options_match_criteria = m.get('PrivatePoolOptions.MatchCriteria')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('SchedulerOptions') is not None:
            temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurationsSchedulerOptions()
            self.scheduler_options = temp_model.from_map(m['SchedulerOptions'])
        if m.get('SecurityEnhancementStrategy') is not None:
            self.security_enhancement_strategy = m.get('SecurityEnhancementStrategy')
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SecurityGroupIds') is not None:
            self.security_group_ids = m.get('SecurityGroupIds')
        if m.get('SpotDuration') is not None:
            self.spot_duration = m.get('SpotDuration')
        if m.get('SpotInterruptionBehavior') is not None:
            self.spot_interruption_behavior = m.get('SpotInterruptionBehavior')
        self.spot_price_limits = []
        if m.get('SpotPriceLimits') is not None:
            for k in m.get('SpotPriceLimits'):
                temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurationsSpotPriceLimits()
                self.spot_price_limits.append(temp_model.from_map(k))
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        if m.get('StorageSetId') is not None:
            self.storage_set_id = m.get('StorageSetId')
        if m.get('StorageSetPartitionNumber') is not None:
            self.storage_set_partition_number = m.get('StorageSetPartitionNumber')
        if m.get('SystemDiskAutoSnapshotPolicyId') is not None:
            self.system_disk_auto_snapshot_policy_id = m.get('SystemDiskAutoSnapshotPolicyId')
        if m.get('SystemDiskBurstingEnabled') is not None:
            self.system_disk_bursting_enabled = m.get('SystemDiskBurstingEnabled')
        if m.get('SystemDiskCategories') is not None:
            self.system_disk_categories = m.get('SystemDiskCategories')
        if m.get('SystemDiskCategory') is not None:
            self.system_disk_category = m.get('SystemDiskCategory')
        if m.get('SystemDiskDescription') is not None:
            self.system_disk_description = m.get('SystemDiskDescription')
        if m.get('SystemDiskEncryptAlgorithm') is not None:
            self.system_disk_encrypt_algorithm = m.get('SystemDiskEncryptAlgorithm')
        if m.get('SystemDiskEncrypted') is not None:
            self.system_disk_encrypted = m.get('SystemDiskEncrypted')
        if m.get('SystemDiskKMSKeyId') is not None:
            self.system_disk_kmskey_id = m.get('SystemDiskKMSKeyId')
        if m.get('SystemDiskName') is not None:
            self.system_disk_name = m.get('SystemDiskName')
        if m.get('SystemDiskPerformanceLevel') is not None:
            self.system_disk_performance_level = m.get('SystemDiskPerformanceLevel')
        if m.get('SystemDiskProvisionedIops') is not None:
            self.system_disk_provisioned_iops = m.get('SystemDiskProvisionedIops')
        if m.get('SystemDiskSize') is not None:
            self.system_disk_size = m.get('SystemDiskSize')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurationsTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('Tenancy') is not None:
            self.tenancy = m.get('Tenancy')
        if m.get('UserData') is not None:
            self.user_data = m.get('UserData')
        if m.get('WeightedCapacities') is not None:
            self.weighted_capacities = m.get('WeightedCapacities')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class DescribeScalingConfigurationsResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scaling_configurations=None,
                 total_count=None):
        # The page number of the returned page.
        self.page_number = page_number  # type: int
        # The number of entries returned per page.
        self.page_size = page_size  # type: int
        # The ID of the request.
        self.request_id = request_id  # type: str
        # Details of the scaling configurations.
        self.scaling_configurations = scaling_configurations  # type: list[DescribeScalingConfigurationsResponseBodyScalingConfigurations]
        # The total number of scaling configurations.
        self.total_count = total_count  # type: int

    def validate(self):
        if self.scaling_configurations:
            for k in self.scaling_configurations:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScalingConfigurations'] = []
        if self.scaling_configurations is not None:
            for k in self.scaling_configurations:
                result['ScalingConfigurations'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scaling_configurations = []
        if m.get('ScalingConfigurations') is not None:
            for k in m.get('ScalingConfigurations'):
                temp_model = DescribeScalingConfigurationsResponseBodyScalingConfigurations()
                self.scaling_configurations.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeScalingConfigurationsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingConfigurationsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingConfigurationsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingConfigurationsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingGroupDetailRequest(TeaModel):
    def __init__(self, output_format=None, owner_id=None, region_id=None, scaling_group_id=None):
        self.output_format = output_format  # type: str
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.output_format is not None:
            result['OutputFormat'] = self.output_format
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OutputFormat') is not None:
            self.output_format = m.get('OutputFormat')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupAlbServerGroups(TeaModel):
    def __init__(self, alb_server_group_id=None, port=None, weight=None):
        self.alb_server_group_id = alb_server_group_id  # type: str
        self.port = port  # type: int
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupAlbServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alb_server_group_id is not None:
            result['AlbServerGroupId'] = self.alb_server_group_id
        if self.port is not None:
            result['Port'] = self.port
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlbServerGroupId') is not None:
            self.alb_server_group_id = m.get('AlbServerGroupId')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupLaunchTemplateOverrides(TeaModel):
    def __init__(self, instance_type=None, spot_price_limit=None, weighted_capacity=None):
        self.instance_type = instance_type  # type: str
        self.spot_price_limit = spot_price_limit  # type: float
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupLaunchTemplateOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupLoadBalancerConfigs(TeaModel):
    def __init__(self, load_balancer_id=None, weight=None):
        self.load_balancer_id = load_balancer_id  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupLoadBalancerConfigs, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupServerGroups(TeaModel):
    def __init__(self, port=None, server_group_id=None, type=None, weight=None):
        self.port = port  # type: int
        self.server_group_id = server_group_id  # type: str
        self.type = type  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.server_group_id is not None:
            result['ServerGroupId'] = self.server_group_id
        if self.type is not None:
            result['Type'] = self.type
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ServerGroupId') is not None:
            self.server_group_id = m.get('ServerGroupId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupTags(TeaModel):
    def __init__(self, propagate=None, tag_key=None, tag_value=None):
        self.propagate = propagate  # type: bool
        self.tag_key = tag_key  # type: str
        self.tag_value = tag_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.propagate is not None:
            result['Propagate'] = self.propagate
        if self.tag_key is not None:
            result['TagKey'] = self.tag_key
        if self.tag_value is not None:
            result['TagValue'] = self.tag_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Propagate') is not None:
            self.propagate = m.get('Propagate')
        if m.get('TagKey') is not None:
            self.tag_key = m.get('TagKey')
        if m.get('TagValue') is not None:
            self.tag_value = m.get('TagValue')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroupsVServerGroupAttributes(TeaModel):
    def __init__(self, port=None, vserver_group_id=None, weight=None):
        self.port = port  # type: int
        self.vserver_group_id = vserver_group_id  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroupsVServerGroupAttributes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.vserver_group_id is not None:
            result['VServerGroupId'] = self.vserver_group_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('VServerGroupId') is not None:
            self.vserver_group_id = m.get('VServerGroupId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroups(TeaModel):
    def __init__(self, load_balancer_id=None, vserver_group_attributes=None):
        self.load_balancer_id = load_balancer_id  # type: str
        self.vserver_group_attributes = vserver_group_attributes  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroupsVServerGroupAttributes]

    def validate(self):
        if self.vserver_group_attributes:
            for k in self.vserver_group_attributes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        result['VServerGroupAttributes'] = []
        if self.vserver_group_attributes is not None:
            for k in self.vserver_group_attributes:
                result['VServerGroupAttributes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        self.vserver_group_attributes = []
        if m.get('VServerGroupAttributes') is not None:
            for k in m.get('VServerGroupAttributes'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroupsVServerGroupAttributes()
                self.vserver_group_attributes.append(temp_model.from_map(k))
        return self


class DescribeScalingGroupDetailResponseBodyScalingGroup(TeaModel):
    def __init__(self, active_capacity=None, active_scaling_configuration_id=None, alb_server_groups=None,
                 allocation_strategy=None, az_balance=None, compensate_with_on_demand=None, creation_time=None, current_host_name=None,
                 custom_policy_arn=None, dbinstance_ids=None, default_cooldown=None, desired_capacity=None,
                 enable_desired_capacity=None, group_deletion_protection=None, group_type=None, health_check_type=None,
                 health_check_types=None, init_capacity=None, is_elastic_strength_in_alarm=None, launch_template_id=None,
                 launch_template_overrides=None, launch_template_version=None, lifecycle_state=None, load_balancer_configs=None,
                 load_balancer_ids=None, max_instance_lifetime=None, max_size=None, min_size=None, modification_time=None,
                 monitor_group_id=None, multi_azpolicy=None, on_demand_base_capacity=None,
                 on_demand_percentage_above_base_capacity=None, pending_capacity=None, pending_wait_capacity=None, protected_capacity=None, region_id=None,
                 removal_policies=None, removing_capacity=None, removing_wait_capacity=None, resource_group_id=None,
                 scaling_group_id=None, scaling_group_name=None, scaling_policy=None, server_groups=None,
                 spot_allocation_strategy=None, spot_instance_pools=None, spot_instance_remedy=None, standby_capacity=None,
                 stopped_capacity=None, suspended_processes=None, system_suspended=None, tags=None, total_capacity=None,
                 total_instance_count=None, vserver_groups=None, v_switch_id=None, v_switch_ids=None, vpc_id=None):
        self.active_capacity = active_capacity  # type: int
        self.active_scaling_configuration_id = active_scaling_configuration_id  # type: str
        self.alb_server_groups = alb_server_groups  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupAlbServerGroups]
        self.allocation_strategy = allocation_strategy  # type: str
        self.az_balance = az_balance  # type: bool
        self.compensate_with_on_demand = compensate_with_on_demand  # type: bool
        self.creation_time = creation_time  # type: str
        self.current_host_name = current_host_name  # type: str
        self.custom_policy_arn = custom_policy_arn  # type: str
        self.dbinstance_ids = dbinstance_ids  # type: list[str]
        self.default_cooldown = default_cooldown  # type: int
        self.desired_capacity = desired_capacity  # type: int
        self.enable_desired_capacity = enable_desired_capacity  # type: bool
        self.group_deletion_protection = group_deletion_protection  # type: bool
        self.group_type = group_type  # type: str
        self.health_check_type = health_check_type  # type: str
        self.health_check_types = health_check_types  # type: list[str]
        self.init_capacity = init_capacity  # type: int
        self.is_elastic_strength_in_alarm = is_elastic_strength_in_alarm  # type: bool
        self.launch_template_id = launch_template_id  # type: str
        self.launch_template_overrides = launch_template_overrides  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupLaunchTemplateOverrides]
        self.launch_template_version = launch_template_version  # type: str
        self.lifecycle_state = lifecycle_state  # type: str
        self.load_balancer_configs = load_balancer_configs  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupLoadBalancerConfigs]
        self.load_balancer_ids = load_balancer_ids  # type: list[str]
        self.max_instance_lifetime = max_instance_lifetime  # type: int
        self.max_size = max_size  # type: int
        self.min_size = min_size  # type: int
        self.modification_time = modification_time  # type: str
        self.monitor_group_id = monitor_group_id  # type: str
        self.multi_azpolicy = multi_azpolicy  # type: str
        self.on_demand_base_capacity = on_demand_base_capacity  # type: int
        self.on_demand_percentage_above_base_capacity = on_demand_percentage_above_base_capacity  # type: int
        self.pending_capacity = pending_capacity  # type: int
        self.pending_wait_capacity = pending_wait_capacity  # type: int
        self.protected_capacity = protected_capacity  # type: int
        self.region_id = region_id  # type: str
        self.removal_policies = removal_policies  # type: list[str]
        self.removing_capacity = removing_capacity  # type: int
        self.removing_wait_capacity = removing_wait_capacity  # type: int
        self.resource_group_id = resource_group_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.scaling_group_name = scaling_group_name  # type: str
        self.scaling_policy = scaling_policy  # type: str
        self.server_groups = server_groups  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupServerGroups]
        self.spot_allocation_strategy = spot_allocation_strategy  # type: str
        self.spot_instance_pools = spot_instance_pools  # type: int
        self.spot_instance_remedy = spot_instance_remedy  # type: bool
        self.standby_capacity = standby_capacity  # type: int
        self.stopped_capacity = stopped_capacity  # type: int
        self.suspended_processes = suspended_processes  # type: list[str]
        self.system_suspended = system_suspended  # type: bool
        self.tags = tags  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupTags]
        self.total_capacity = total_capacity  # type: int
        self.total_instance_count = total_instance_count  # type: int
        self.vserver_groups = vserver_groups  # type: list[DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroups]
        self.v_switch_id = v_switch_id  # type: str
        self.v_switch_ids = v_switch_ids  # type: list[str]
        self.vpc_id = vpc_id  # type: str

    def validate(self):
        if self.alb_server_groups:
            for k in self.alb_server_groups:
                if k:
                    k.validate()
        if self.launch_template_overrides:
            for k in self.launch_template_overrides:
                if k:
                    k.validate()
        if self.load_balancer_configs:
            for k in self.load_balancer_configs:
                if k:
                    k.validate()
        if self.server_groups:
            for k in self.server_groups:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.vserver_groups:
            for k in self.vserver_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBodyScalingGroup, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_capacity is not None:
            result['ActiveCapacity'] = self.active_capacity
        if self.active_scaling_configuration_id is not None:
            result['ActiveScalingConfigurationId'] = self.active_scaling_configuration_id
        result['AlbServerGroups'] = []
        if self.alb_server_groups is not None:
            for k in self.alb_server_groups:
                result['AlbServerGroups'].append(k.to_map() if k else None)
        if self.allocation_strategy is not None:
            result['AllocationStrategy'] = self.allocation_strategy
        if self.az_balance is not None:
            result['AzBalance'] = self.az_balance
        if self.compensate_with_on_demand is not None:
            result['CompensateWithOnDemand'] = self.compensate_with_on_demand
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.current_host_name is not None:
            result['CurrentHostName'] = self.current_host_name
        if self.custom_policy_arn is not None:
            result['CustomPolicyARN'] = self.custom_policy_arn
        if self.dbinstance_ids is not None:
            result['DBInstanceIds'] = self.dbinstance_ids
        if self.default_cooldown is not None:
            result['DefaultCooldown'] = self.default_cooldown
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.enable_desired_capacity is not None:
            result['EnableDesiredCapacity'] = self.enable_desired_capacity
        if self.group_deletion_protection is not None:
            result['GroupDeletionProtection'] = self.group_deletion_protection
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.health_check_type is not None:
            result['HealthCheckType'] = self.health_check_type
        if self.health_check_types is not None:
            result['HealthCheckTypes'] = self.health_check_types
        if self.init_capacity is not None:
            result['InitCapacity'] = self.init_capacity
        if self.is_elastic_strength_in_alarm is not None:
            result['IsElasticStrengthInAlarm'] = self.is_elastic_strength_in_alarm
        if self.launch_template_id is not None:
            result['LaunchTemplateId'] = self.launch_template_id
        result['LaunchTemplateOverrides'] = []
        if self.launch_template_overrides is not None:
            for k in self.launch_template_overrides:
                result['LaunchTemplateOverrides'].append(k.to_map() if k else None)
        if self.launch_template_version is not None:
            result['LaunchTemplateVersion'] = self.launch_template_version
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        result['LoadBalancerConfigs'] = []
        if self.load_balancer_configs is not None:
            for k in self.load_balancer_configs:
                result['LoadBalancerConfigs'].append(k.to_map() if k else None)
        if self.load_balancer_ids is not None:
            result['LoadBalancerIds'] = self.load_balancer_ids
        if self.max_instance_lifetime is not None:
            result['MaxInstanceLifetime'] = self.max_instance_lifetime
        if self.max_size is not None:
            result['MaxSize'] = self.max_size
        if self.min_size is not None:
            result['MinSize'] = self.min_size
        if self.modification_time is not None:
            result['ModificationTime'] = self.modification_time
        if self.monitor_group_id is not None:
            result['MonitorGroupId'] = self.monitor_group_id
        if self.multi_azpolicy is not None:
            result['MultiAZPolicy'] = self.multi_azpolicy
        if self.on_demand_base_capacity is not None:
            result['OnDemandBaseCapacity'] = self.on_demand_base_capacity
        if self.on_demand_percentage_above_base_capacity is not None:
            result['OnDemandPercentageAboveBaseCapacity'] = self.on_demand_percentage_above_base_capacity
        if self.pending_capacity is not None:
            result['PendingCapacity'] = self.pending_capacity
        if self.pending_wait_capacity is not None:
            result['PendingWaitCapacity'] = self.pending_wait_capacity
        if self.protected_capacity is not None:
            result['ProtectedCapacity'] = self.protected_capacity
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.removal_policies is not None:
            result['RemovalPolicies'] = self.removal_policies
        if self.removing_capacity is not None:
            result['RemovingCapacity'] = self.removing_capacity
        if self.removing_wait_capacity is not None:
            result['RemovingWaitCapacity'] = self.removing_wait_capacity
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_group_name is not None:
            result['ScalingGroupName'] = self.scaling_group_name
        if self.scaling_policy is not None:
            result['ScalingPolicy'] = self.scaling_policy
        result['ServerGroups'] = []
        if self.server_groups is not None:
            for k in self.server_groups:
                result['ServerGroups'].append(k.to_map() if k else None)
        if self.spot_allocation_strategy is not None:
            result['SpotAllocationStrategy'] = self.spot_allocation_strategy
        if self.spot_instance_pools is not None:
            result['SpotInstancePools'] = self.spot_instance_pools
        if self.spot_instance_remedy is not None:
            result['SpotInstanceRemedy'] = self.spot_instance_remedy
        if self.standby_capacity is not None:
            result['StandbyCapacity'] = self.standby_capacity
        if self.stopped_capacity is not None:
            result['StoppedCapacity'] = self.stopped_capacity
        if self.suspended_processes is not None:
            result['SuspendedProcesses'] = self.suspended_processes
        if self.system_suspended is not None:
            result['SystemSuspended'] = self.system_suspended
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.total_capacity is not None:
            result['TotalCapacity'] = self.total_capacity
        if self.total_instance_count is not None:
            result['TotalInstanceCount'] = self.total_instance_count
        result['VServerGroups'] = []
        if self.vserver_groups is not None:
            for k in self.vserver_groups:
                result['VServerGroups'].append(k.to_map() if k else None)
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        if self.v_switch_ids is not None:
            result['VSwitchIds'] = self.v_switch_ids
        if self.vpc_id is not None:
            result['VpcId'] = self.vpc_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActiveCapacity') is not None:
            self.active_capacity = m.get('ActiveCapacity')
        if m.get('ActiveScalingConfigurationId') is not None:
            self.active_scaling_configuration_id = m.get('ActiveScalingConfigurationId')
        self.alb_server_groups = []
        if m.get('AlbServerGroups') is not None:
            for k in m.get('AlbServerGroups'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupAlbServerGroups()
                self.alb_server_groups.append(temp_model.from_map(k))
        if m.get('AllocationStrategy') is not None:
            self.allocation_strategy = m.get('AllocationStrategy')
        if m.get('AzBalance') is not None:
            self.az_balance = m.get('AzBalance')
        if m.get('CompensateWithOnDemand') is not None:
            self.compensate_with_on_demand = m.get('CompensateWithOnDemand')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('CurrentHostName') is not None:
            self.current_host_name = m.get('CurrentHostName')
        if m.get('CustomPolicyARN') is not None:
            self.custom_policy_arn = m.get('CustomPolicyARN')
        if m.get('DBInstanceIds') is not None:
            self.dbinstance_ids = m.get('DBInstanceIds')
        if m.get('DefaultCooldown') is not None:
            self.default_cooldown = m.get('DefaultCooldown')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('EnableDesiredCapacity') is not None:
            self.enable_desired_capacity = m.get('EnableDesiredCapacity')
        if m.get('GroupDeletionProtection') is not None:
            self.group_deletion_protection = m.get('GroupDeletionProtection')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('HealthCheckType') is not None:
            self.health_check_type = m.get('HealthCheckType')
        if m.get('HealthCheckTypes') is not None:
            self.health_check_types = m.get('HealthCheckTypes')
        if m.get('InitCapacity') is not None:
            self.init_capacity = m.get('InitCapacity')
        if m.get('IsElasticStrengthInAlarm') is not None:
            self.is_elastic_strength_in_alarm = m.get('IsElasticStrengthInAlarm')
        if m.get('LaunchTemplateId') is not None:
            self.launch_template_id = m.get('LaunchTemplateId')
        self.launch_template_overrides = []
        if m.get('LaunchTemplateOverrides') is not None:
            for k in m.get('LaunchTemplateOverrides'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupLaunchTemplateOverrides()
                self.launch_template_overrides.append(temp_model.from_map(k))
        if m.get('LaunchTemplateVersion') is not None:
            self.launch_template_version = m.get('LaunchTemplateVersion')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        self.load_balancer_configs = []
        if m.get('LoadBalancerConfigs') is not None:
            for k in m.get('LoadBalancerConfigs'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupLoadBalancerConfigs()
                self.load_balancer_configs.append(temp_model.from_map(k))
        if m.get('LoadBalancerIds') is not None:
            self.load_balancer_ids = m.get('LoadBalancerIds')
        if m.get('MaxInstanceLifetime') is not None:
            self.max_instance_lifetime = m.get('MaxInstanceLifetime')
        if m.get('MaxSize') is not None:
            self.max_size = m.get('MaxSize')
        if m.get('MinSize') is not None:
            self.min_size = m.get('MinSize')
        if m.get('ModificationTime') is not None:
            self.modification_time = m.get('ModificationTime')
        if m.get('MonitorGroupId') is not None:
            self.monitor_group_id = m.get('MonitorGroupId')
        if m.get('MultiAZPolicy') is not None:
            self.multi_azpolicy = m.get('MultiAZPolicy')
        if m.get('OnDemandBaseCapacity') is not None:
            self.on_demand_base_capacity = m.get('OnDemandBaseCapacity')
        if m.get('OnDemandPercentageAboveBaseCapacity') is not None:
            self.on_demand_percentage_above_base_capacity = m.get('OnDemandPercentageAboveBaseCapacity')
        if m.get('PendingCapacity') is not None:
            self.pending_capacity = m.get('PendingCapacity')
        if m.get('PendingWaitCapacity') is not None:
            self.pending_wait_capacity = m.get('PendingWaitCapacity')
        if m.get('ProtectedCapacity') is not None:
            self.protected_capacity = m.get('ProtectedCapacity')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('RemovalPolicies') is not None:
            self.removal_policies = m.get('RemovalPolicies')
        if m.get('RemovingCapacity') is not None:
            self.removing_capacity = m.get('RemovingCapacity')
        if m.get('RemovingWaitCapacity') is not None:
            self.removing_wait_capacity = m.get('RemovingWaitCapacity')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingGroupName') is not None:
            self.scaling_group_name = m.get('ScalingGroupName')
        if m.get('ScalingPolicy') is not None:
            self.scaling_policy = m.get('ScalingPolicy')
        self.server_groups = []
        if m.get('ServerGroups') is not None:
            for k in m.get('ServerGroups'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupServerGroups()
                self.server_groups.append(temp_model.from_map(k))
        if m.get('SpotAllocationStrategy') is not None:
            self.spot_allocation_strategy = m.get('SpotAllocationStrategy')
        if m.get('SpotInstancePools') is not None:
            self.spot_instance_pools = m.get('SpotInstancePools')
        if m.get('SpotInstanceRemedy') is not None:
            self.spot_instance_remedy = m.get('SpotInstanceRemedy')
        if m.get('StandbyCapacity') is not None:
            self.standby_capacity = m.get('StandbyCapacity')
        if m.get('StoppedCapacity') is not None:
            self.stopped_capacity = m.get('StoppedCapacity')
        if m.get('SuspendedProcesses') is not None:
            self.suspended_processes = m.get('SuspendedProcesses')
        if m.get('SystemSuspended') is not None:
            self.system_suspended = m.get('SystemSuspended')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('TotalCapacity') is not None:
            self.total_capacity = m.get('TotalCapacity')
        if m.get('TotalInstanceCount') is not None:
            self.total_instance_count = m.get('TotalInstanceCount')
        self.vserver_groups = []
        if m.get('VServerGroups') is not None:
            for k in m.get('VServerGroups'):
                temp_model = DescribeScalingGroupDetailResponseBodyScalingGroupVServerGroups()
                self.vserver_groups.append(temp_model.from_map(k))
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        if m.get('VSwitchIds') is not None:
            self.v_switch_ids = m.get('VSwitchIds')
        if m.get('VpcId') is not None:
            self.vpc_id = m.get('VpcId')
        return self


class DescribeScalingGroupDetailResponseBody(TeaModel):
    def __init__(self, output=None, request_id=None, scaling_group=None):
        self.output = output  # type: str
        self.request_id = request_id  # type: str
        self.scaling_group = scaling_group  # type: DescribeScalingGroupDetailResponseBodyScalingGroup

    def validate(self):
        if self.scaling_group:
            self.scaling_group.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.output is not None:
            result['Output'] = self.output
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_group is not None:
            result['ScalingGroup'] = self.scaling_group.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Output') is not None:
            self.output = m.get('Output')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingGroup') is not None:
            temp_model = DescribeScalingGroupDetailResponseBodyScalingGroup()
            self.scaling_group = temp_model.from_map(m['ScalingGroup'])
        return self


class DescribeScalingGroupDetailResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingGroupDetailResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupDetailResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingGroupDetailResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingGroupsRequestTags(TeaModel):
    def __init__(self, key=None, value=None):
        self.key = key  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsRequestTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class DescribeScalingGroupsRequest(TeaModel):
    def __init__(self, group_type=None, owner_account=None, owner_id=None, page_number=None, page_size=None,
                 region_id=None, resource_group_id=None, resource_owner_account=None, resource_owner_id=None,
                 scaling_group_ids=None, scaling_group_name=None, scaling_group_names=None, tags=None):
        self.group_type = group_type  # type: str
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.region_id = region_id  # type: str
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        self.scaling_group_ids = scaling_group_ids  # type: list[str]
        self.scaling_group_name = scaling_group_name  # type: str
        self.scaling_group_names = scaling_group_names  # type: list[str]
        self.tags = tags  # type: list[DescribeScalingGroupsRequestTags]

    def validate(self):
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_ids is not None:
            result['ScalingGroupIds'] = self.scaling_group_ids
        if self.scaling_group_name is not None:
            result['ScalingGroupName'] = self.scaling_group_name
        if self.scaling_group_names is not None:
            result['ScalingGroupNames'] = self.scaling_group_names
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupIds') is not None:
            self.scaling_group_ids = m.get('ScalingGroupIds')
        if m.get('ScalingGroupName') is not None:
            self.scaling_group_name = m.get('ScalingGroupName')
        if m.get('ScalingGroupNames') is not None:
            self.scaling_group_names = m.get('ScalingGroupNames')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = DescribeScalingGroupsRequestTags()
                self.tags.append(temp_model.from_map(k))
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsAlbServerGroups(TeaModel):
    def __init__(self, alb_server_group_id=None, port=None, weight=None):
        self.alb_server_group_id = alb_server_group_id  # type: str
        self.port = port  # type: int
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsAlbServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alb_server_group_id is not None:
            result['AlbServerGroupId'] = self.alb_server_group_id
        if self.port is not None:
            result['Port'] = self.port
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlbServerGroupId') is not None:
            self.alb_server_group_id = m.get('AlbServerGroupId')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsLaunchTemplateOverrides(TeaModel):
    def __init__(self, instance_type=None, spot_price_limit=None, weighted_capacity=None):
        self.instance_type = instance_type  # type: str
        self.spot_price_limit = spot_price_limit  # type: float
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsLaunchTemplateOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsLoadBalancerConfigs(TeaModel):
    def __init__(self, load_balancer_id=None, weight=None):
        self.load_balancer_id = load_balancer_id  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsLoadBalancerConfigs, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsServerGroups(TeaModel):
    def __init__(self, port=None, server_group_id=None, type=None, weight=None):
        self.port = port  # type: int
        self.server_group_id = server_group_id  # type: str
        self.type = type  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.server_group_id is not None:
            result['ServerGroupId'] = self.server_group_id
        if self.type is not None:
            result['Type'] = self.type
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ServerGroupId') is not None:
            self.server_group_id = m.get('ServerGroupId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsTags(TeaModel):
    def __init__(self, propagate=None, tag_key=None, tag_value=None):
        self.propagate = propagate  # type: bool
        self.tag_key = tag_key  # type: str
        self.tag_value = tag_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.propagate is not None:
            result['Propagate'] = self.propagate
        if self.tag_key is not None:
            result['TagKey'] = self.tag_key
        if self.tag_value is not None:
            result['TagValue'] = self.tag_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Propagate') is not None:
            self.propagate = m.get('Propagate')
        if m.get('TagKey') is not None:
            self.tag_key = m.get('TagKey')
        if m.get('TagValue') is not None:
            self.tag_value = m.get('TagValue')
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsVServerGroupsVServerGroupAttributes(TeaModel):
    def __init__(self, port=None, vserver_group_id=None, weight=None):
        self.port = port  # type: int
        self.vserver_group_id = vserver_group_id  # type: str
        self.weight = weight  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsVServerGroupsVServerGroupAttributes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.vserver_group_id is not None:
            result['VServerGroupId'] = self.vserver_group_id
        if self.weight is not None:
            result['Weight'] = self.weight
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('VServerGroupId') is not None:
            self.vserver_group_id = m.get('VServerGroupId')
        if m.get('Weight') is not None:
            self.weight = m.get('Weight')
        return self


class DescribeScalingGroupsResponseBodyScalingGroupsVServerGroups(TeaModel):
    def __init__(self, load_balancer_id=None, vserver_group_attributes=None):
        self.load_balancer_id = load_balancer_id  # type: str
        self.vserver_group_attributes = vserver_group_attributes  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsVServerGroupsVServerGroupAttributes]

    def validate(self):
        if self.vserver_group_attributes:
            for k in self.vserver_group_attributes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroupsVServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        result['VServerGroupAttributes'] = []
        if self.vserver_group_attributes is not None:
            for k in self.vserver_group_attributes:
                result['VServerGroupAttributes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        self.vserver_group_attributes = []
        if m.get('VServerGroupAttributes') is not None:
            for k in m.get('VServerGroupAttributes'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsVServerGroupsVServerGroupAttributes()
                self.vserver_group_attributes.append(temp_model.from_map(k))
        return self


class DescribeScalingGroupsResponseBodyScalingGroups(TeaModel):
    def __init__(self, active_capacity=None, active_scaling_configuration_id=None, alb_server_groups=None,
                 allocation_strategy=None, az_balance=None, compensate_with_on_demand=None, creation_time=None, current_host_name=None,
                 custom_policy_arn=None, dbinstance_ids=None, default_cooldown=None, desired_capacity=None,
                 enable_desired_capacity=None, group_deletion_protection=None, group_type=None, health_check_type=None,
                 health_check_types=None, init_capacity=None, is_elastic_strength_in_alarm=None, launch_template_id=None,
                 launch_template_overrides=None, launch_template_version=None, lifecycle_state=None, load_balancer_configs=None,
                 load_balancer_ids=None, max_instance_lifetime=None, max_size=None, min_size=None, modification_time=None,
                 monitor_group_id=None, multi_azpolicy=None, on_demand_base_capacity=None,
                 on_demand_percentage_above_base_capacity=None, pending_capacity=None, pending_wait_capacity=None, protected_capacity=None, region_id=None,
                 removal_policies=None, removing_capacity=None, removing_wait_capacity=None, resource_group_id=None,
                 scaling_group_id=None, scaling_group_name=None, scaling_policy=None, server_groups=None,
                 spot_allocation_strategy=None, spot_instance_pools=None, spot_instance_remedy=None, standby_capacity=None,
                 stopped_capacity=None, suspended_processes=None, system_suspended=None, tags=None, total_capacity=None,
                 total_instance_count=None, vserver_groups=None, v_switch_id=None, v_switch_ids=None, vpc_id=None):
        self.active_capacity = active_capacity  # type: int
        self.active_scaling_configuration_id = active_scaling_configuration_id  # type: str
        self.alb_server_groups = alb_server_groups  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsAlbServerGroups]
        self.allocation_strategy = allocation_strategy  # type: str
        self.az_balance = az_balance  # type: bool
        self.compensate_with_on_demand = compensate_with_on_demand  # type: bool
        self.creation_time = creation_time  # type: str
        self.current_host_name = current_host_name  # type: str
        self.custom_policy_arn = custom_policy_arn  # type: str
        self.dbinstance_ids = dbinstance_ids  # type: list[str]
        self.default_cooldown = default_cooldown  # type: int
        self.desired_capacity = desired_capacity  # type: int
        self.enable_desired_capacity = enable_desired_capacity  # type: bool
        self.group_deletion_protection = group_deletion_protection  # type: bool
        self.group_type = group_type  # type: str
        self.health_check_type = health_check_type  # type: str
        self.health_check_types = health_check_types  # type: list[str]
        self.init_capacity = init_capacity  # type: int
        self.is_elastic_strength_in_alarm = is_elastic_strength_in_alarm  # type: bool
        self.launch_template_id = launch_template_id  # type: str
        self.launch_template_overrides = launch_template_overrides  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsLaunchTemplateOverrides]
        self.launch_template_version = launch_template_version  # type: str
        self.lifecycle_state = lifecycle_state  # type: str
        self.load_balancer_configs = load_balancer_configs  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsLoadBalancerConfigs]
        self.load_balancer_ids = load_balancer_ids  # type: list[str]
        self.max_instance_lifetime = max_instance_lifetime  # type: int
        self.max_size = max_size  # type: int
        self.min_size = min_size  # type: int
        self.modification_time = modification_time  # type: str
        self.monitor_group_id = monitor_group_id  # type: str
        self.multi_azpolicy = multi_azpolicy  # type: str
        self.on_demand_base_capacity = on_demand_base_capacity  # type: int
        self.on_demand_percentage_above_base_capacity = on_demand_percentage_above_base_capacity  # type: int
        self.pending_capacity = pending_capacity  # type: int
        self.pending_wait_capacity = pending_wait_capacity  # type: int
        self.protected_capacity = protected_capacity  # type: int
        self.region_id = region_id  # type: str
        self.removal_policies = removal_policies  # type: list[str]
        self.removing_capacity = removing_capacity  # type: int
        self.removing_wait_capacity = removing_wait_capacity  # type: int
        self.resource_group_id = resource_group_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.scaling_group_name = scaling_group_name  # type: str
        self.scaling_policy = scaling_policy  # type: str
        self.server_groups = server_groups  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsServerGroups]
        self.spot_allocation_strategy = spot_allocation_strategy  # type: str
        self.spot_instance_pools = spot_instance_pools  # type: int
        self.spot_instance_remedy = spot_instance_remedy  # type: bool
        self.standby_capacity = standby_capacity  # type: int
        self.stopped_capacity = stopped_capacity  # type: int
        self.suspended_processes = suspended_processes  # type: list[str]
        self.system_suspended = system_suspended  # type: bool
        self.tags = tags  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsTags]
        self.total_capacity = total_capacity  # type: int
        self.total_instance_count = total_instance_count  # type: int
        self.vserver_groups = vserver_groups  # type: list[DescribeScalingGroupsResponseBodyScalingGroupsVServerGroups]
        self.v_switch_id = v_switch_id  # type: str
        self.v_switch_ids = v_switch_ids  # type: list[str]
        self.vpc_id = vpc_id  # type: str

    def validate(self):
        if self.alb_server_groups:
            for k in self.alb_server_groups:
                if k:
                    k.validate()
        if self.launch_template_overrides:
            for k in self.launch_template_overrides:
                if k:
                    k.validate()
        if self.load_balancer_configs:
            for k in self.load_balancer_configs:
                if k:
                    k.validate()
        if self.server_groups:
            for k in self.server_groups:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.vserver_groups:
            for k in self.vserver_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBodyScalingGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_capacity is not None:
            result['ActiveCapacity'] = self.active_capacity
        if self.active_scaling_configuration_id is not None:
            result['ActiveScalingConfigurationId'] = self.active_scaling_configuration_id
        result['AlbServerGroups'] = []
        if self.alb_server_groups is not None:
            for k in self.alb_server_groups:
                result['AlbServerGroups'].append(k.to_map() if k else None)
        if self.allocation_strategy is not None:
            result['AllocationStrategy'] = self.allocation_strategy
        if self.az_balance is not None:
            result['AzBalance'] = self.az_balance
        if self.compensate_with_on_demand is not None:
            result['CompensateWithOnDemand'] = self.compensate_with_on_demand
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.current_host_name is not None:
            result['CurrentHostName'] = self.current_host_name
        if self.custom_policy_arn is not None:
            result['CustomPolicyARN'] = self.custom_policy_arn
        if self.dbinstance_ids is not None:
            result['DBInstanceIds'] = self.dbinstance_ids
        if self.default_cooldown is not None:
            result['DefaultCooldown'] = self.default_cooldown
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.enable_desired_capacity is not None:
            result['EnableDesiredCapacity'] = self.enable_desired_capacity
        if self.group_deletion_protection is not None:
            result['GroupDeletionProtection'] = self.group_deletion_protection
        if self.group_type is not None:
            result['GroupType'] = self.group_type
        if self.health_check_type is not None:
            result['HealthCheckType'] = self.health_check_type
        if self.health_check_types is not None:
            result['HealthCheckTypes'] = self.health_check_types
        if self.init_capacity is not None:
            result['InitCapacity'] = self.init_capacity
        if self.is_elastic_strength_in_alarm is not None:
            result['IsElasticStrengthInAlarm'] = self.is_elastic_strength_in_alarm
        if self.launch_template_id is not None:
            result['LaunchTemplateId'] = self.launch_template_id
        result['LaunchTemplateOverrides'] = []
        if self.launch_template_overrides is not None:
            for k in self.launch_template_overrides:
                result['LaunchTemplateOverrides'].append(k.to_map() if k else None)
        if self.launch_template_version is not None:
            result['LaunchTemplateVersion'] = self.launch_template_version
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        result['LoadBalancerConfigs'] = []
        if self.load_balancer_configs is not None:
            for k in self.load_balancer_configs:
                result['LoadBalancerConfigs'].append(k.to_map() if k else None)
        if self.load_balancer_ids is not None:
            result['LoadBalancerIds'] = self.load_balancer_ids
        if self.max_instance_lifetime is not None:
            result['MaxInstanceLifetime'] = self.max_instance_lifetime
        if self.max_size is not None:
            result['MaxSize'] = self.max_size
        if self.min_size is not None:
            result['MinSize'] = self.min_size
        if self.modification_time is not None:
            result['ModificationTime'] = self.modification_time
        if self.monitor_group_id is not None:
            result['MonitorGroupId'] = self.monitor_group_id
        if self.multi_azpolicy is not None:
            result['MultiAZPolicy'] = self.multi_azpolicy
        if self.on_demand_base_capacity is not None:
            result['OnDemandBaseCapacity'] = self.on_demand_base_capacity
        if self.on_demand_percentage_above_base_capacity is not None:
            result['OnDemandPercentageAboveBaseCapacity'] = self.on_demand_percentage_above_base_capacity
        if self.pending_capacity is not None:
            result['PendingCapacity'] = self.pending_capacity
        if self.pending_wait_capacity is not None:
            result['PendingWaitCapacity'] = self.pending_wait_capacity
        if self.protected_capacity is not None:
            result['ProtectedCapacity'] = self.protected_capacity
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.removal_policies is not None:
            result['RemovalPolicies'] = self.removal_policies
        if self.removing_capacity is not None:
            result['RemovingCapacity'] = self.removing_capacity
        if self.removing_wait_capacity is not None:
            result['RemovingWaitCapacity'] = self.removing_wait_capacity
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_group_name is not None:
            result['ScalingGroupName'] = self.scaling_group_name
        if self.scaling_policy is not None:
            result['ScalingPolicy'] = self.scaling_policy
        result['ServerGroups'] = []
        if self.server_groups is not None:
            for k in self.server_groups:
                result['ServerGroups'].append(k.to_map() if k else None)
        if self.spot_allocation_strategy is not None:
            result['SpotAllocationStrategy'] = self.spot_allocation_strategy
        if self.spot_instance_pools is not None:
            result['SpotInstancePools'] = self.spot_instance_pools
        if self.spot_instance_remedy is not None:
            result['SpotInstanceRemedy'] = self.spot_instance_remedy
        if self.standby_capacity is not None:
            result['StandbyCapacity'] = self.standby_capacity
        if self.stopped_capacity is not None:
            result['StoppedCapacity'] = self.stopped_capacity
        if self.suspended_processes is not None:
            result['SuspendedProcesses'] = self.suspended_processes
        if self.system_suspended is not None:
            result['SystemSuspended'] = self.system_suspended
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.total_capacity is not None:
            result['TotalCapacity'] = self.total_capacity
        if self.total_instance_count is not None:
            result['TotalInstanceCount'] = self.total_instance_count
        result['VServerGroups'] = []
        if self.vserver_groups is not None:
            for k in self.vserver_groups:
                result['VServerGroups'].append(k.to_map() if k else None)
        if self.v_switch_id is not None:
            result['VSwitchId'] = self.v_switch_id
        if self.v_switch_ids is not None:
            result['VSwitchIds'] = self.v_switch_ids
        if self.vpc_id is not None:
            result['VpcId'] = self.vpc_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActiveCapacity') is not None:
            self.active_capacity = m.get('ActiveCapacity')
        if m.get('ActiveScalingConfigurationId') is not None:
            self.active_scaling_configuration_id = m.get('ActiveScalingConfigurationId')
        self.alb_server_groups = []
        if m.get('AlbServerGroups') is not None:
            for k in m.get('AlbServerGroups'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsAlbServerGroups()
                self.alb_server_groups.append(temp_model.from_map(k))
        if m.get('AllocationStrategy') is not None:
            self.allocation_strategy = m.get('AllocationStrategy')
        if m.get('AzBalance') is not None:
            self.az_balance = m.get('AzBalance')
        if m.get('CompensateWithOnDemand') is not None:
            self.compensate_with_on_demand = m.get('CompensateWithOnDemand')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('CurrentHostName') is not None:
            self.current_host_name = m.get('CurrentHostName')
        if m.get('CustomPolicyARN') is not None:
            self.custom_policy_arn = m.get('CustomPolicyARN')
        if m.get('DBInstanceIds') is not None:
            self.dbinstance_ids = m.get('DBInstanceIds')
        if m.get('DefaultCooldown') is not None:
            self.default_cooldown = m.get('DefaultCooldown')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('EnableDesiredCapacity') is not None:
            self.enable_desired_capacity = m.get('EnableDesiredCapacity')
        if m.get('GroupDeletionProtection') is not None:
            self.group_deletion_protection = m.get('GroupDeletionProtection')
        if m.get('GroupType') is not None:
            self.group_type = m.get('GroupType')
        if m.get('HealthCheckType') is not None:
            self.health_check_type = m.get('HealthCheckType')
        if m.get('HealthCheckTypes') is not None:
            self.health_check_types = m.get('HealthCheckTypes')
        if m.get('InitCapacity') is not None:
            self.init_capacity = m.get('InitCapacity')
        if m.get('IsElasticStrengthInAlarm') is not None:
            self.is_elastic_strength_in_alarm = m.get('IsElasticStrengthInAlarm')
        if m.get('LaunchTemplateId') is not None:
            self.launch_template_id = m.get('LaunchTemplateId')
        self.launch_template_overrides = []
        if m.get('LaunchTemplateOverrides') is not None:
            for k in m.get('LaunchTemplateOverrides'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsLaunchTemplateOverrides()
                self.launch_template_overrides.append(temp_model.from_map(k))
        if m.get('LaunchTemplateVersion') is not None:
            self.launch_template_version = m.get('LaunchTemplateVersion')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        self.load_balancer_configs = []
        if m.get('LoadBalancerConfigs') is not None:
            for k in m.get('LoadBalancerConfigs'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsLoadBalancerConfigs()
                self.load_balancer_configs.append(temp_model.from_map(k))
        if m.get('LoadBalancerIds') is not None:
            self.load_balancer_ids = m.get('LoadBalancerIds')
        if m.get('MaxInstanceLifetime') is not None:
            self.max_instance_lifetime = m.get('MaxInstanceLifetime')
        if m.get('MaxSize') is not None:
            self.max_size = m.get('MaxSize')
        if m.get('MinSize') is not None:
            self.min_size = m.get('MinSize')
        if m.get('ModificationTime') is not None:
            self.modification_time = m.get('ModificationTime')
        if m.get('MonitorGroupId') is not None:
            self.monitor_group_id = m.get('MonitorGroupId')
        if m.get('MultiAZPolicy') is not None:
            self.multi_azpolicy = m.get('MultiAZPolicy')
        if m.get('OnDemandBaseCapacity') is not None:
            self.on_demand_base_capacity = m.get('OnDemandBaseCapacity')
        if m.get('OnDemandPercentageAboveBaseCapacity') is not None:
            self.on_demand_percentage_above_base_capacity = m.get('OnDemandPercentageAboveBaseCapacity')
        if m.get('PendingCapacity') is not None:
            self.pending_capacity = m.get('PendingCapacity')
        if m.get('PendingWaitCapacity') is not None:
            self.pending_wait_capacity = m.get('PendingWaitCapacity')
        if m.get('ProtectedCapacity') is not None:
            self.protected_capacity = m.get('ProtectedCapacity')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('RemovalPolicies') is not None:
            self.removal_policies = m.get('RemovalPolicies')
        if m.get('RemovingCapacity') is not None:
            self.removing_capacity = m.get('RemovingCapacity')
        if m.get('RemovingWaitCapacity') is not None:
            self.removing_wait_capacity = m.get('RemovingWaitCapacity')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingGroupName') is not None:
            self.scaling_group_name = m.get('ScalingGroupName')
        if m.get('ScalingPolicy') is not None:
            self.scaling_policy = m.get('ScalingPolicy')
        self.server_groups = []
        if m.get('ServerGroups') is not None:
            for k in m.get('ServerGroups'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsServerGroups()
                self.server_groups.append(temp_model.from_map(k))
        if m.get('SpotAllocationStrategy') is not None:
            self.spot_allocation_strategy = m.get('SpotAllocationStrategy')
        if m.get('SpotInstancePools') is not None:
            self.spot_instance_pools = m.get('SpotInstancePools')
        if m.get('SpotInstanceRemedy') is not None:
            self.spot_instance_remedy = m.get('SpotInstanceRemedy')
        if m.get('StandbyCapacity') is not None:
            self.standby_capacity = m.get('StandbyCapacity')
        if m.get('StoppedCapacity') is not None:
            self.stopped_capacity = m.get('StoppedCapacity')
        if m.get('SuspendedProcesses') is not None:
            self.suspended_processes = m.get('SuspendedProcesses')
        if m.get('SystemSuspended') is not None:
            self.system_suspended = m.get('SystemSuspended')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('TotalCapacity') is not None:
            self.total_capacity = m.get('TotalCapacity')
        if m.get('TotalInstanceCount') is not None:
            self.total_instance_count = m.get('TotalInstanceCount')
        self.vserver_groups = []
        if m.get('VServerGroups') is not None:
            for k in m.get('VServerGroups'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroupsVServerGroups()
                self.vserver_groups.append(temp_model.from_map(k))
        if m.get('VSwitchId') is not None:
            self.v_switch_id = m.get('VSwitchId')
        if m.get('VSwitchIds') is not None:
            self.v_switch_ids = m.get('VSwitchIds')
        if m.get('VpcId') is not None:
            self.vpc_id = m.get('VpcId')
        return self


class DescribeScalingGroupsResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scaling_groups=None, total_count=None):
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.request_id = request_id  # type: str
        self.scaling_groups = scaling_groups  # type: list[DescribeScalingGroupsResponseBodyScalingGroups]
        self.total_count = total_count  # type: int

    def validate(self):
        if self.scaling_groups:
            for k in self.scaling_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScalingGroups'] = []
        if self.scaling_groups is not None:
            for k in self.scaling_groups:
                result['ScalingGroups'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scaling_groups = []
        if m.get('ScalingGroups') is not None:
            for k in m.get('ScalingGroups'):
                temp_model = DescribeScalingGroupsResponseBodyScalingGroups()
                self.scaling_groups.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeScalingGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingInstancesRequest(TeaModel):
    def __init__(self, creation_type=None, creation_types=None, health_status=None, instance_ids=None,
                 lifecycle_state=None, lifecycle_states=None, owner_account=None, owner_id=None, page_number=None, page_size=None,
                 region_id=None, resource_owner_account=None, resource_owner_id=None, scaling_activity_id=None,
                 scaling_configuration_id=None, scaling_group_id=None):
        self.creation_type = creation_type  # type: str
        self.creation_types = creation_types  # type: list[str]
        self.health_status = health_status  # type: str
        self.instance_ids = instance_ids  # type: list[str]
        self.lifecycle_state = lifecycle_state  # type: str
        self.lifecycle_states = lifecycle_states  # type: list[str]
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        self.scaling_activity_id = scaling_activity_id  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.creation_type is not None:
            result['CreationType'] = self.creation_type
        if self.creation_types is not None:
            result['CreationTypes'] = self.creation_types
        if self.health_status is not None:
            result['HealthStatus'] = self.health_status
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        if self.lifecycle_states is not None:
            result['LifecycleStates'] = self.lifecycle_states
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('CreationType') is not None:
            self.creation_type = m.get('CreationType')
        if m.get('CreationTypes') is not None:
            self.creation_types = m.get('CreationTypes')
        if m.get('HealthStatus') is not None:
            self.health_status = m.get('HealthStatus')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        if m.get('LifecycleStates') is not None:
            self.lifecycle_states = m.get('LifecycleStates')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DescribeScalingInstancesResponseBodyScalingInstances(TeaModel):
    def __init__(self, created_time=None, creation_time=None, creation_type=None, entrusted=None,
                 health_status=None, instance_id=None, launch_template_id=None, launch_template_version=None,
                 lifecycle_state=None, load_balancer_weight=None, private_ip_address=None, scaling_activity_id=None,
                 scaling_configuration_id=None, scaling_group_id=None, scaling_instance_id=None, spot_strategy=None, warmup_state=None,
                 weighted_capacity=None, zone_id=None):
        self.created_time = created_time  # type: str
        self.creation_time = creation_time  # type: str
        self.creation_type = creation_type  # type: str
        self.entrusted = entrusted  # type: bool
        self.health_status = health_status  # type: str
        self.instance_id = instance_id  # type: str
        self.launch_template_id = launch_template_id  # type: str
        self.launch_template_version = launch_template_version  # type: str
        self.lifecycle_state = lifecycle_state  # type: str
        self.load_balancer_weight = load_balancer_weight  # type: int
        self.private_ip_address = private_ip_address  # type: str
        self.scaling_activity_id = scaling_activity_id  # type: str
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.scaling_instance_id = scaling_instance_id  # type: str
        self.spot_strategy = spot_strategy  # type: str
        self.warmup_state = warmup_state  # type: str
        self.weighted_capacity = weighted_capacity  # type: int
        self.zone_id = zone_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingInstancesResponseBodyScalingInstances, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.created_time is not None:
            result['CreatedTime'] = self.created_time
        if self.creation_time is not None:
            result['CreationTime'] = self.creation_time
        if self.creation_type is not None:
            result['CreationType'] = self.creation_type
        if self.entrusted is not None:
            result['Entrusted'] = self.entrusted
        if self.health_status is not None:
            result['HealthStatus'] = self.health_status
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.launch_template_id is not None:
            result['LaunchTemplateId'] = self.launch_template_id
        if self.launch_template_version is not None:
            result['LaunchTemplateVersion'] = self.launch_template_version
        if self.lifecycle_state is not None:
            result['LifecycleState'] = self.lifecycle_state
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.private_ip_address is not None:
            result['PrivateIpAddress'] = self.private_ip_address
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_instance_id is not None:
            result['ScalingInstanceId'] = self.scaling_instance_id
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        if self.warmup_state is not None:
            result['WarmupState'] = self.warmup_state
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('CreatedTime') is not None:
            self.created_time = m.get('CreatedTime')
        if m.get('CreationTime') is not None:
            self.creation_time = m.get('CreationTime')
        if m.get('CreationType') is not None:
            self.creation_type = m.get('CreationType')
        if m.get('Entrusted') is not None:
            self.entrusted = m.get('Entrusted')
        if m.get('HealthStatus') is not None:
            self.health_status = m.get('HealthStatus')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('LaunchTemplateId') is not None:
            self.launch_template_id = m.get('LaunchTemplateId')
        if m.get('LaunchTemplateVersion') is not None:
            self.launch_template_version = m.get('LaunchTemplateVersion')
        if m.get('LifecycleState') is not None:
            self.lifecycle_state = m.get('LifecycleState')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('PrivateIpAddress') is not None:
            self.private_ip_address = m.get('PrivateIpAddress')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingInstanceId') is not None:
            self.scaling_instance_id = m.get('ScalingInstanceId')
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        if m.get('WarmupState') is not None:
            self.warmup_state = m.get('WarmupState')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class DescribeScalingInstancesResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scaling_instances=None, total_count=None,
                 total_spot_count=None):
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.request_id = request_id  # type: str
        self.scaling_instances = scaling_instances  # type: list[DescribeScalingInstancesResponseBodyScalingInstances]
        self.total_count = total_count  # type: int
        self.total_spot_count = total_spot_count  # type: int

    def validate(self):
        if self.scaling_instances:
            for k in self.scaling_instances:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScalingInstances'] = []
        if self.scaling_instances is not None:
            for k in self.scaling_instances:
                result['ScalingInstances'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        if self.total_spot_count is not None:
            result['TotalSpotCount'] = self.total_spot_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scaling_instances = []
        if m.get('ScalingInstances') is not None:
            for k in m.get('ScalingInstances'):
                temp_model = DescribeScalingInstancesResponseBodyScalingInstances()
                self.scaling_instances.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        if m.get('TotalSpotCount') is not None:
            self.total_spot_count = m.get('TotalSpotCount')
        return self


class DescribeScalingInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScalingRulesRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, page_number=None, page_size=None, region_id=None,
                 resource_owner_account=None, resource_owner_id=None, scaling_group_id=None, scaling_rule_aris=None,
                 scaling_rule_ids=None, scaling_rule_names=None, scaling_rule_type=None, show_alarm_rules=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The number of the page to return. Pages start from page 1.
        # 
        # Default value: 1.
        self.page_number = page_number  # type: int
        # The number of entries to return on each page. Maximum value: 50.
        # 
        # Default value: 10.
        self.page_size = page_size  # type: int
        # The region ID of the scaling group to which the scaling rules that you want to query belong.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # The unique identifiers of the scaling rules that you want to query.
        self.scaling_rule_aris = scaling_rule_aris  # type: list[str]
        # The IDs of the scaling rules that you want to query.
        self.scaling_rule_ids = scaling_rule_ids  # type: list[str]
        # The names of the scaling rules that you want to query.
        self.scaling_rule_names = scaling_rule_names  # type: list[str]
        # The type of the scaling rule. Valid values:
        # 
        # *   SimpleScalingRule: adjusts the number of ECS instances based on the values of the AdjustmentType and AdjustmentValue parameters.
        # *   TargetTrackingScalingRule: calculates the number of ECS instances that need to be scaled in a dynamic manner and maintains the value of a predefined metric close to the value of the TargetValue parameter.
        # *   StepScalingRule: scales ECS instances in steps based on the specified thresholds and metric values.
        # *   PredictiveScalingRule: uses machine learning to analyze historical monitoring data of the scaling group and predicts the future values of metrics. In addition, Auto Scaling automatically creates scheduled tasks to adjust the boundary values for the scaling group.
        self.scaling_rule_type = scaling_rule_type  # type: str
        # Specifies whether to return CloudMonitor event-triggered tasks associated with scaling rules. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.show_alarm_rules = show_alarm_rules  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingRulesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_rule_aris is not None:
            result['ScalingRuleAris'] = self.scaling_rule_aris
        if self.scaling_rule_ids is not None:
            result['ScalingRuleIds'] = self.scaling_rule_ids
        if self.scaling_rule_names is not None:
            result['ScalingRuleNames'] = self.scaling_rule_names
        if self.scaling_rule_type is not None:
            result['ScalingRuleType'] = self.scaling_rule_type
        if self.show_alarm_rules is not None:
            result['ShowAlarmRules'] = self.show_alarm_rules
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingRuleAris') is not None:
            self.scaling_rule_aris = m.get('ScalingRuleAris')
        if m.get('ScalingRuleIds') is not None:
            self.scaling_rule_ids = m.get('ScalingRuleIds')
        if m.get('ScalingRuleNames') is not None:
            self.scaling_rule_names = m.get('ScalingRuleNames')
        if m.get('ScalingRuleType') is not None:
            self.scaling_rule_type = m.get('ScalingRuleType')
        if m.get('ShowAlarmRules') is not None:
            self.show_alarm_rules = m.get('ShowAlarmRules')
        return self


class DescribeScalingRulesResponseBodyScalingRulesAlarmDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        # 监控项关联的维度信息键。
        self.dimension_key = dimension_key  # type: str
        # 监控项关联的维度信息值。
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingRulesResponseBodyScalingRulesAlarmDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class DescribeScalingRulesResponseBodyScalingRulesAlarmsDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        # The key of the dimension that is associated with the metric. Valid values:
        # 
        # *   scaling_group: the ID of the scaling group
        # *   userId: the ID of the Alibaba Cloud account
        self.dimension_key = dimension_key  # type: str
        # The value of the dimension that is associated with the metric.
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingRulesResponseBodyScalingRulesAlarmsDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class DescribeScalingRulesResponseBodyScalingRulesAlarms(TeaModel):
    def __init__(self, alarm_task_id=None, alarm_task_name=None, comparison_operator=None, dimensions=None,
                 evaluation_count=None, metric_name=None, metric_type=None, statistics=None, threshold=None):
        # The ID of the event-triggered task that is associated with the scaling rule.
        self.alarm_task_id = alarm_task_id  # type: str
        # The name of the event-triggered task that is associated with the scaling rule.
        self.alarm_task_name = alarm_task_name  # type: str
        # The comparison operator between the metric value and the threshold for the event-triggered task that is associated with the scaling rule. The comparison operator indicates the relationship between the metric value and the threshold that is required to meet the condition.
        # 
        # *   Valid value if the metric value is greater than or equal to the threshold: >=.
        # *   Valid value if the metric value is less than or equal to the threshold: <=.
        # *   Valid value if the metric value is greater than the threshold: >.
        # *   Valid value if the metric value is less than the threshold: <.
        self.comparison_operator = comparison_operator  # type: str
        # The dimensions of the event-triggered task that is associated with the scaling rule.
        self.dimensions = dimensions  # type: list[DescribeScalingRulesResponseBodyScalingRulesAlarmsDimensions]
        # The number of consecutive times for which the event-triggered task that is associated with the scaling rule meets the threshold expressions before an alert is triggered.
        self.evaluation_count = evaluation_count  # type: int
        # The name of the metric of the event-triggered task that is associated with the scaling rule.
        self.metric_name = metric_name  # type: str
        # The type of the event-triggered task that is associated with the scaling rule. Valid values:
        # 
        # *   system: system monitoring event-triggered tasks
        # *   custom: custom monitoring event-triggered tasks
        self.metric_type = metric_type  # type: str
        # The statistical method of the event-triggered task that is associated with the scaling rule. Valid values:
        # 
        # *   Average
        # *   Maximum
        # *   Minimum
        self.statistics = statistics  # type: str
        # The alert threshold of the event-triggered task that is associated with the scaling rule.
        self.threshold = threshold  # type: float

    def validate(self):
        if self.dimensions:
            for k in self.dimensions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingRulesResponseBodyScalingRulesAlarms, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.alarm_task_name is not None:
            result['AlarmTaskName'] = self.alarm_task_name
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        result['Dimensions'] = []
        if self.dimensions is not None:
            for k in self.dimensions:
                result['Dimensions'].append(k.to_map() if k else None)
        if self.evaluation_count is not None:
            result['EvaluationCount'] = self.evaluation_count
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.metric_type is not None:
            result['MetricType'] = self.metric_type
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('AlarmTaskName') is not None:
            self.alarm_task_name = m.get('AlarmTaskName')
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        self.dimensions = []
        if m.get('Dimensions') is not None:
            for k in m.get('Dimensions'):
                temp_model = DescribeScalingRulesResponseBodyScalingRulesAlarmsDimensions()
                self.dimensions.append(temp_model.from_map(k))
        if m.get('EvaluationCount') is not None:
            self.evaluation_count = m.get('EvaluationCount')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MetricType') is not None:
            self.metric_type = m.get('MetricType')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class DescribeScalingRulesResponseBodyScalingRulesStepAdjustments(TeaModel):
    def __init__(self, metric_interval_lower_bound=None, metric_interval_upper_bound=None,
                 scaling_adjustment=None):
        # The lower limit that is specified in a step adjustment. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_interval_lower_bound = metric_interval_lower_bound  # type: float
        # The upper limit that is specified in a step adjustment. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_interval_upper_bound = metric_interval_upper_bound  # type: float
        # The number of ECS instances that are scaled in a step adjustment.
        self.scaling_adjustment = scaling_adjustment  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScalingRulesResponseBodyScalingRulesStepAdjustments, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_interval_lower_bound is not None:
            result['MetricIntervalLowerBound'] = self.metric_interval_lower_bound
        if self.metric_interval_upper_bound is not None:
            result['MetricIntervalUpperBound'] = self.metric_interval_upper_bound
        if self.scaling_adjustment is not None:
            result['ScalingAdjustment'] = self.scaling_adjustment
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MetricIntervalLowerBound') is not None:
            self.metric_interval_lower_bound = m.get('MetricIntervalLowerBound')
        if m.get('MetricIntervalUpperBound') is not None:
            self.metric_interval_upper_bound = m.get('MetricIntervalUpperBound')
        if m.get('ScalingAdjustment') is not None:
            self.scaling_adjustment = m.get('ScalingAdjustment')
        return self


class DescribeScalingRulesResponseBodyScalingRules(TeaModel):
    def __init__(self, adjustment_type=None, adjustment_value=None, alarm_dimensions=None, alarms=None,
                 cooldown=None, disable_scale_in=None, estimated_instance_warmup=None, initial_max_size=None, max_size=None,
                 metric_name=None, min_adjustment_magnitude=None, min_size=None, predictive_scaling_mode=None,
                 predictive_task_buffer_time=None, predictive_value_behavior=None, predictive_value_buffer=None,
                 scale_in_evaluation_count=None, scale_out_evaluation_count=None, scaling_group_id=None, scaling_rule_ari=None,
                 scaling_rule_id=None, scaling_rule_name=None, scaling_rule_type=None, step_adjustments=None, target_value=None):
        # The scaling mode of the scaling rule. Valid values:
        # 
        # *   QuantityChangeInCapacity: adds the specified number of ECS instances to or removes the specified number of ECS instances from the scaling group.
        # *   PercentChangeInCapacity: adds the specified percentage of ECS instances to or removes the specified percentage of ECS instances from the scaling group.
        # *   TotalCapacity: adjusts the number of ECS instances in the scaling group to the specified number.
        self.adjustment_type = adjustment_type  # type: str
        # The adjustment value that is specified in the scaling rule.
        self.adjustment_value = adjustment_value  # type: int
        # 监控项维度信息值，适用于目标追踪规则，当监控项需额外维度信息时设置，例如LoadBalancerRealServerAverageQps监控项需指定rulePool维度信息。
        self.alarm_dimensions = alarm_dimensions  # type: list[DescribeScalingRulesResponseBodyScalingRulesAlarmDimensions]
        # The event-triggered tasks that are associated with the scaling rule. Event-triggered tasks that are associated with the scaling rule are returned only if you set the ShowAlarmRules parameter to true. Otherwise, an empty list is returned.
        self.alarms = alarms  # type: list[DescribeScalingRulesResponseBodyScalingRulesAlarms]
        # The cooldown time of the scaling rule. This parameter is available only if you set the ScalingRuleType parameter to SimpleScalingRule. Valid values: 0 to 86400. Unit: seconds.
        self.cooldown = cooldown  # type: int
        # Specifies whether to disable scale-in. This parameter is available only if you set the ScalingRuleType parameter to TargetTrackingScalingRule. Valid values:
        # 
        # *   true
        # *   false
        self.disable_scale_in = disable_scale_in  # type: bool
        # The warmup period of the ECS instance.
        self.estimated_instance_warmup = estimated_instance_warmup  # type: int
        # The maximum number of ECS instances in the scaling group. You must specify the InitialMaxSize and PredictiveValueBehavior parameters.
        self.initial_max_size = initial_max_size  # type: int
        # The maximum number of ECS instances in the scaling group.
        self.max_size = max_size  # type: int
        # The name of the metric of the event-triggered task that is associated with the scaling rule.
        self.metric_name = metric_name  # type: str
        # The minimum number of instances that must be scaled when the AdjustmentType parameter is set to PercentChangeInCapacity. This parameter takes effect only if you set the ScalingRuleType parameter to SimpleScalingRule or StepScalingRule.
        self.min_adjustment_magnitude = min_adjustment_magnitude  # type: int
        # The minimum number of ECS instances in the scaling group.
        self.min_size = min_size  # type: int
        # The mode of the predictive scaling rule. Valid values:
        # 
        # *   PredictAndScale: produces predictions and creates prediction tasks.
        # *   PredictOnly: produces predictions but does not create prediction tasks.
        self.predictive_scaling_mode = predictive_scaling_mode  # type: str
        # The amount of buffer time before the prediction task is executed. By default, all scheduled tasks that are automatically created for a predictive scaling rule are executed on the hour. You can specify a buffer time for resource preparation before prediction tasks are executed. Valid values: 0 to 60. Unit: minutes.
        self.predictive_task_buffer_time = predictive_task_buffer_time  # type: int
        # Specifies which one of the initial maximum capacity and the predicted value can be used as the maximum value for prediction tasks. Valid values:
        # 
        # *   MaxOverridePredictiveValue: uses the initial maximum capacity as the maximum value for prediction tasks if the predicted value is greater than the initial maximum capacity.
        # *   PredictiveValueOverrideMax: uses the predicted value as the maximum value for prediction tasks when the predicted value is greater than the initial maximum capacity.
        # *   PredictiveValueOverrideMaxWithBuffer: increases the predicted value by a percentage that is specified by the PredictiveValueBuffer parameter. If the predicted value that is increased by the percentage is greater than the initial maximum capacity, the increased value is used as the maximum value for prediction tasks.
        self.predictive_value_behavior = predictive_value_behavior  # type: str
        # The percentage of the increment to the predicted value when the PredictiveValueBehavior parameter is set to PredictiveValueOverrideMaxWithBuffer. If the predicted value increased by this percentage is greater than the initial maximum capacity, the increased value is used as the maximum value for prediction tasks. Valid values: 0 to 100.
        self.predictive_value_buffer = predictive_value_buffer  # type: int
        # The number of consecutive times that the event-triggered task created for scale-out activities must meet the threshold conditions before an alert is triggered. After a target tracking scaling rule is created, an event-triggered task is automatically created and then associated with the target tracking scaling rule.
        self.scale_in_evaluation_count = scale_in_evaluation_count  # type: int
        # The number of consecutive times that the event-triggered task created for scale-in activities must meet the threshold conditions before an alert is triggered. After a target tracking scaling rule is created, an event-triggered task is automatically created and then associated with the target tracking scaling rule.
        self.scale_out_evaluation_count = scale_out_evaluation_count  # type: int
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # The unique identifier of the scaling rule.
        self.scaling_rule_ari = scaling_rule_ari  # type: str
        # The ID of the scaling rule.
        self.scaling_rule_id = scaling_rule_id  # type: str
        # The name of the scaling rule.
        self.scaling_rule_name = scaling_rule_name  # type: str
        # The type of the scaling rule. Valid values:
        # 
        # *   SimpleScalingRule: adjusts the number of ECS instances based on the values of the AdjustmentType and AdjustmentValue parameters.
        # *   TargetTrackingScalingRule: calculates the number of ECS instances that need to be scaled in a dynamic manner and maintains the value of a predefined metric close to the value of the TargetValue parameter.
        # *   StepScalingRule: scales ECS instances in steps based on specified thresholds and metric values.
        # *   PredictiveScalingRule: uses machine learning to analyze historical monitoring data of the scaling group and predicts the future values of metrics. In addition, Auto Scaling automatically creates scheduled tasks to adjust the boundary values for the scaling group.
        self.scaling_rule_type = scaling_rule_type  # type: str
        # The step adjustments of the step scaling rule.
        self.step_adjustments = step_adjustments  # type: list[DescribeScalingRulesResponseBodyScalingRulesStepAdjustments]
        # The target value of the metric.
        self.target_value = target_value  # type: float

    def validate(self):
        if self.alarm_dimensions:
            for k in self.alarm_dimensions:
                if k:
                    k.validate()
        if self.alarms:
            for k in self.alarms:
                if k:
                    k.validate()
        if self.step_adjustments:
            for k in self.step_adjustments:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingRulesResponseBodyScalingRules, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.adjustment_type is not None:
            result['AdjustmentType'] = self.adjustment_type
        if self.adjustment_value is not None:
            result['AdjustmentValue'] = self.adjustment_value
        result['AlarmDimensions'] = []
        if self.alarm_dimensions is not None:
            for k in self.alarm_dimensions:
                result['AlarmDimensions'].append(k.to_map() if k else None)
        result['Alarms'] = []
        if self.alarms is not None:
            for k in self.alarms:
                result['Alarms'].append(k.to_map() if k else None)
        if self.cooldown is not None:
            result['Cooldown'] = self.cooldown
        if self.disable_scale_in is not None:
            result['DisableScaleIn'] = self.disable_scale_in
        if self.estimated_instance_warmup is not None:
            result['EstimatedInstanceWarmup'] = self.estimated_instance_warmup
        if self.initial_max_size is not None:
            result['InitialMaxSize'] = self.initial_max_size
        if self.max_size is not None:
            result['MaxSize'] = self.max_size
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.min_adjustment_magnitude is not None:
            result['MinAdjustmentMagnitude'] = self.min_adjustment_magnitude
        if self.min_size is not None:
            result['MinSize'] = self.min_size
        if self.predictive_scaling_mode is not None:
            result['PredictiveScalingMode'] = self.predictive_scaling_mode
        if self.predictive_task_buffer_time is not None:
            result['PredictiveTaskBufferTime'] = self.predictive_task_buffer_time
        if self.predictive_value_behavior is not None:
            result['PredictiveValueBehavior'] = self.predictive_value_behavior
        if self.predictive_value_buffer is not None:
            result['PredictiveValueBuffer'] = self.predictive_value_buffer
        if self.scale_in_evaluation_count is not None:
            result['ScaleInEvaluationCount'] = self.scale_in_evaluation_count
        if self.scale_out_evaluation_count is not None:
            result['ScaleOutEvaluationCount'] = self.scale_out_evaluation_count
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_rule_ari is not None:
            result['ScalingRuleAri'] = self.scaling_rule_ari
        if self.scaling_rule_id is not None:
            result['ScalingRuleId'] = self.scaling_rule_id
        if self.scaling_rule_name is not None:
            result['ScalingRuleName'] = self.scaling_rule_name
        if self.scaling_rule_type is not None:
            result['ScalingRuleType'] = self.scaling_rule_type
        result['StepAdjustments'] = []
        if self.step_adjustments is not None:
            for k in self.step_adjustments:
                result['StepAdjustments'].append(k.to_map() if k else None)
        if self.target_value is not None:
            result['TargetValue'] = self.target_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AdjustmentType') is not None:
            self.adjustment_type = m.get('AdjustmentType')
        if m.get('AdjustmentValue') is not None:
            self.adjustment_value = m.get('AdjustmentValue')
        self.alarm_dimensions = []
        if m.get('AlarmDimensions') is not None:
            for k in m.get('AlarmDimensions'):
                temp_model = DescribeScalingRulesResponseBodyScalingRulesAlarmDimensions()
                self.alarm_dimensions.append(temp_model.from_map(k))
        self.alarms = []
        if m.get('Alarms') is not None:
            for k in m.get('Alarms'):
                temp_model = DescribeScalingRulesResponseBodyScalingRulesAlarms()
                self.alarms.append(temp_model.from_map(k))
        if m.get('Cooldown') is not None:
            self.cooldown = m.get('Cooldown')
        if m.get('DisableScaleIn') is not None:
            self.disable_scale_in = m.get('DisableScaleIn')
        if m.get('EstimatedInstanceWarmup') is not None:
            self.estimated_instance_warmup = m.get('EstimatedInstanceWarmup')
        if m.get('InitialMaxSize') is not None:
            self.initial_max_size = m.get('InitialMaxSize')
        if m.get('MaxSize') is not None:
            self.max_size = m.get('MaxSize')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MinAdjustmentMagnitude') is not None:
            self.min_adjustment_magnitude = m.get('MinAdjustmentMagnitude')
        if m.get('MinSize') is not None:
            self.min_size = m.get('MinSize')
        if m.get('PredictiveScalingMode') is not None:
            self.predictive_scaling_mode = m.get('PredictiveScalingMode')
        if m.get('PredictiveTaskBufferTime') is not None:
            self.predictive_task_buffer_time = m.get('PredictiveTaskBufferTime')
        if m.get('PredictiveValueBehavior') is not None:
            self.predictive_value_behavior = m.get('PredictiveValueBehavior')
        if m.get('PredictiveValueBuffer') is not None:
            self.predictive_value_buffer = m.get('PredictiveValueBuffer')
        if m.get('ScaleInEvaluationCount') is not None:
            self.scale_in_evaluation_count = m.get('ScaleInEvaluationCount')
        if m.get('ScaleOutEvaluationCount') is not None:
            self.scale_out_evaluation_count = m.get('ScaleOutEvaluationCount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingRuleAri') is not None:
            self.scaling_rule_ari = m.get('ScalingRuleAri')
        if m.get('ScalingRuleId') is not None:
            self.scaling_rule_id = m.get('ScalingRuleId')
        if m.get('ScalingRuleName') is not None:
            self.scaling_rule_name = m.get('ScalingRuleName')
        if m.get('ScalingRuleType') is not None:
            self.scaling_rule_type = m.get('ScalingRuleType')
        self.step_adjustments = []
        if m.get('StepAdjustments') is not None:
            for k in m.get('StepAdjustments'):
                temp_model = DescribeScalingRulesResponseBodyScalingRulesStepAdjustments()
                self.step_adjustments.append(temp_model.from_map(k))
        if m.get('TargetValue') is not None:
            self.target_value = m.get('TargetValue')
        return self


class DescribeScalingRulesResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scaling_rules=None, total_count=None):
        # The page number of the returned page.
        self.page_number = page_number  # type: int
        # The number of entries returned per page.
        self.page_size = page_size  # type: int
        # The ID of the request.
        self.request_id = request_id  # type: str
        # Details of the scaling rules.
        self.scaling_rules = scaling_rules  # type: list[DescribeScalingRulesResponseBodyScalingRules]
        # The total number of scaling rules.
        self.total_count = total_count  # type: int

    def validate(self):
        if self.scaling_rules:
            for k in self.scaling_rules:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScalingRulesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScalingRules'] = []
        if self.scaling_rules is not None:
            for k in self.scaling_rules:
                result['ScalingRules'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scaling_rules = []
        if m.get('ScalingRules') is not None:
            for k in m.get('ScalingRules'):
                temp_model = DescribeScalingRulesResponseBodyScalingRules()
                self.scaling_rules.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeScalingRulesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScalingRulesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScalingRulesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScalingRulesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DescribeScheduledTasksRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, page_number=None, page_size=None, region_id=None,
                 resource_owner_account=None, resource_owner_id=None, scaling_group_id=None, scheduled_actions=None,
                 scheduled_task_ids=None, scheduled_task_names=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        self.scaling_group_id = scaling_group_id  # type: str
        self.scheduled_actions = scheduled_actions  # type: list[str]
        self.scheduled_task_ids = scheduled_task_ids  # type: list[str]
        self.scheduled_task_names = scheduled_task_names  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScheduledTasksRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduled_actions is not None:
            result['ScheduledActions'] = self.scheduled_actions
        if self.scheduled_task_ids is not None:
            result['ScheduledTaskIds'] = self.scheduled_task_ids
        if self.scheduled_task_names is not None:
            result['ScheduledTaskNames'] = self.scheduled_task_names
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScheduledActions') is not None:
            self.scheduled_actions = m.get('ScheduledActions')
        if m.get('ScheduledTaskIds') is not None:
            self.scheduled_task_ids = m.get('ScheduledTaskIds')
        if m.get('ScheduledTaskNames') is not None:
            self.scheduled_task_names = m.get('ScheduledTaskNames')
        return self


class DescribeScheduledTasksResponseBodyScheduledTasks(TeaModel):
    def __init__(self, description=None, desired_capacity=None, launch_expiration_time=None, launch_time=None,
                 max_value=None, min_value=None, recurrence_end_time=None, recurrence_type=None, recurrence_value=None,
                 scaling_group_id=None, scheduled_action=None, scheduled_task_id=None, scheduled_task_name=None, task_enabled=None):
        self.description = description  # type: str
        self.desired_capacity = desired_capacity  # type: int
        self.launch_expiration_time = launch_expiration_time  # type: int
        self.launch_time = launch_time  # type: str
        self.max_value = max_value  # type: int
        self.min_value = min_value  # type: int
        self.recurrence_end_time = recurrence_end_time  # type: str
        self.recurrence_type = recurrence_type  # type: str
        self.recurrence_value = recurrence_value  # type: str
        self.scaling_group_id = scaling_group_id  # type: str
        self.scheduled_action = scheduled_action  # type: str
        self.scheduled_task_id = scheduled_task_id  # type: str
        self.scheduled_task_name = scheduled_task_name  # type: str
        self.task_enabled = task_enabled  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(DescribeScheduledTasksResponseBodyScheduledTasks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.description is not None:
            result['Description'] = self.description
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.launch_expiration_time is not None:
            result['LaunchExpirationTime'] = self.launch_expiration_time
        if self.launch_time is not None:
            result['LaunchTime'] = self.launch_time
        if self.max_value is not None:
            result['MaxValue'] = self.max_value
        if self.min_value is not None:
            result['MinValue'] = self.min_value
        if self.recurrence_end_time is not None:
            result['RecurrenceEndTime'] = self.recurrence_end_time
        if self.recurrence_type is not None:
            result['RecurrenceType'] = self.recurrence_type
        if self.recurrence_value is not None:
            result['RecurrenceValue'] = self.recurrence_value
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduled_action is not None:
            result['ScheduledAction'] = self.scheduled_action
        if self.scheduled_task_id is not None:
            result['ScheduledTaskId'] = self.scheduled_task_id
        if self.scheduled_task_name is not None:
            result['ScheduledTaskName'] = self.scheduled_task_name
        if self.task_enabled is not None:
            result['TaskEnabled'] = self.task_enabled
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('LaunchExpirationTime') is not None:
            self.launch_expiration_time = m.get('LaunchExpirationTime')
        if m.get('LaunchTime') is not None:
            self.launch_time = m.get('LaunchTime')
        if m.get('MaxValue') is not None:
            self.max_value = m.get('MaxValue')
        if m.get('MinValue') is not None:
            self.min_value = m.get('MinValue')
        if m.get('RecurrenceEndTime') is not None:
            self.recurrence_end_time = m.get('RecurrenceEndTime')
        if m.get('RecurrenceType') is not None:
            self.recurrence_type = m.get('RecurrenceType')
        if m.get('RecurrenceValue') is not None:
            self.recurrence_value = m.get('RecurrenceValue')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScheduledAction') is not None:
            self.scheduled_action = m.get('ScheduledAction')
        if m.get('ScheduledTaskId') is not None:
            self.scheduled_task_id = m.get('ScheduledTaskId')
        if m.get('ScheduledTaskName') is not None:
            self.scheduled_task_name = m.get('ScheduledTaskName')
        if m.get('TaskEnabled') is not None:
            self.task_enabled = m.get('TaskEnabled')
        return self


class DescribeScheduledTasksResponseBody(TeaModel):
    def __init__(self, page_number=None, page_size=None, request_id=None, scheduled_tasks=None, total_count=None):
        self.page_number = page_number  # type: int
        self.page_size = page_size  # type: int
        self.request_id = request_id  # type: str
        self.scheduled_tasks = scheduled_tasks  # type: list[DescribeScheduledTasksResponseBodyScheduledTasks]
        self.total_count = total_count  # type: int

    def validate(self):
        if self.scheduled_tasks:
            for k in self.scheduled_tasks:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DescribeScheduledTasksResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.page_number is not None:
            result['PageNumber'] = self.page_number
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['ScheduledTasks'] = []
        if self.scheduled_tasks is not None:
            for k in self.scheduled_tasks:
                result['ScheduledTasks'].append(k.to_map() if k else None)
        if self.total_count is not None:
            result['TotalCount'] = self.total_count
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('PageNumber') is not None:
            self.page_number = m.get('PageNumber')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.scheduled_tasks = []
        if m.get('ScheduledTasks') is not None:
            for k in m.get('ScheduledTasks'):
                temp_model = DescribeScheduledTasksResponseBodyScheduledTasks()
                self.scheduled_tasks.append(temp_model.from_map(k))
        if m.get('TotalCount') is not None:
            self.total_count = m.get('TotalCount')
        return self


class DescribeScheduledTasksResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DescribeScheduledTasksResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DescribeScheduledTasksResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DescribeScheduledTasksResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachAlbServerGroupsRequestAlbServerGroups(TeaModel):
    def __init__(self, alb_server_group_id=None, port=None):
        # The ID of the ALB server group.
        self.alb_server_group_id = alb_server_group_id  # type: str
        # The port number used by the ECS instances in the ALB server group.
        self.port = port  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachAlbServerGroupsRequestAlbServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alb_server_group_id is not None:
            result['AlbServerGroupId'] = self.alb_server_group_id
        if self.port is not None:
            result['Port'] = self.port
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlbServerGroupId') is not None:
            self.alb_server_group_id = m.get('AlbServerGroupId')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        return self


class DetachAlbServerGroupsRequest(TeaModel):
    def __init__(self, alb_server_groups=None, client_token=None, force_detach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # Details of the ALB server groups.
        self.alb_server_groups = alb_server_groups  # type: list[DetachAlbServerGroupsRequestAlbServerGroups]
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure the idempotence of a request](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to remove existing Elastic Compute Service (ECS) instances from the ALB server group that you want to disassociate from the scaling group. Valid values:
        # 
        # *   true: removes existing ECS instances and returns the value of the `ScalingActivityId` parameter. You can use the scaling activity ID to check whether the ECS instances are removed.
        # *   false: does not remove existing ECS instances.
        # 
        # Default value: false.
        self.force_detach = force_detach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group. Examples: cn-hangzhou and cn-shanghai.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        if self.alb_server_groups:
            for k in self.alb_server_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DetachAlbServerGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AlbServerGroups'] = []
        if self.alb_server_groups is not None:
            for k in self.alb_server_groups:
                result['AlbServerGroups'].append(k.to_map() if k else None)
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_detach is not None:
            result['ForceDetach'] = self.force_detach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.alb_server_groups = []
        if m.get('AlbServerGroups') is not None:
            for k in m.get('AlbServerGroups'):
                temp_model = DetachAlbServerGroupsRequestAlbServerGroups()
                self.alb_server_groups.append(temp_model.from_map(k))
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceDetach') is not None:
            self.force_detach = m.get('ForceDetach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DetachAlbServerGroupsResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity in which the ALB server group is disassociated from the scaling group and the ECS instances in the ALB server group are removed from the ALB server group. This parameter is returned only after you set the `ForceDetach` parameter to `true`.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachAlbServerGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DetachAlbServerGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DetachAlbServerGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DetachAlbServerGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachAlbServerGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachDBInstancesRequest(TeaModel):
    def __init__(self, client_token=None, dbinstances=None, force_detach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # The IDs of the ApsaraDB RDS instances. You can specify up to five ApsaraDB RDS instances.
        self.dbinstances = dbinstances  # type: list[str]
        # Specifies whether to remove the private IP addresses of instances in the scaling group from the whitelist that manages access to the ApsaraDB RDS instance with which the scaling group is associated. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_detach = force_detach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachDBInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.dbinstances is not None:
            result['DBInstances'] = self.dbinstances
        if self.force_detach is not None:
            result['ForceDetach'] = self.force_detach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('DBInstances') is not None:
            self.dbinstances = m.get('DBInstances')
        if m.get('ForceDetach') is not None:
            self.force_detach = m.get('ForceDetach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DetachDBInstancesResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachDBInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DetachDBInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DetachDBInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DetachDBInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachDBInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachInstancesRequest(TeaModel):
    def __init__(self, client_token=None, decrease_desired_capacity=None, detach_option=None, instance_ids=None,
                 lifecycle_hook=None, owner_account=None, owner_id=None, resource_owner_account=None, resource_owner_id=None,
                 scaling_group_id=None):
        # 保证请求幂等性。从您的客户端生成一个参数值，确保不同请求间该参数值唯一。只支持ASCII字符，且不能超过64个字符。更多信息，请参见[如何保证幂等性](~~25965~~)。
        self.client_token = client_token  # type: str
        # Specifies whether to adjust the expected number of instances in the scaling group. Valid values:
        # 
        # *   true: After a specific number of instances are removed from the scaling group, the expected number of instances in the scaling group decreases.
        # *   false: After a specific number of instances are removed from the scaling group, the expected number of instances in the scaling group remains unchanged.
        # 
        # Default value: true.
        self.decrease_desired_capacity = decrease_desired_capacity  # type: bool
        # Specifies whether to remove the instances from the default server group and vServer groups of the Classic Load Balancer (CLB) instance that is associated with the scaling group, and whether to remove the IP addresses of the instances from the whitelist that manages access to the ApsaraDB RDS instance that is associated with the scaling group.
        # 
        # If you set this parameter to both, the instances are removed from the default sever group and vServer groups of the associated CLB instance, and the IP addresses of the instances are removed from the whitelist that manages access to the associated ApsaraDB RDS instance.
        self.detach_option = detach_option  # type: str
        # The IDs of the ECS instances or elastic container instances that you want to remove from the scaling group.
        self.instance_ids = instance_ids  # type: list[str]
        # Specifies whether to trigger a lifecycle hook for a scale-in activity. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.lifecycle_hook = lifecycle_hook  # type: bool
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.decrease_desired_capacity is not None:
            result['DecreaseDesiredCapacity'] = self.decrease_desired_capacity
        if self.detach_option is not None:
            result['DetachOption'] = self.detach_option
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.lifecycle_hook is not None:
            result['LifecycleHook'] = self.lifecycle_hook
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('DecreaseDesiredCapacity') is not None:
            self.decrease_desired_capacity = m.get('DecreaseDesiredCapacity')
        if m.get('DetachOption') is not None:
            self.detach_option = m.get('DetachOption')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('LifecycleHook') is not None:
            self.lifecycle_hook = m.get('LifecycleHook')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DetachInstancesResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DetachInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DetachInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DetachInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachLoadBalancersRequest(TeaModel):
    def __init__(self, async=None, client_token=None, force_detach=None, load_balancers=None, owner_id=None,
                 region_id=None, resource_owner_account=None, scaling_group_id=None):
        self.async = async  # type: bool
        self.client_token = client_token  # type: str
        self.force_detach = force_detach  # type: bool
        self.load_balancers = load_balancers  # type: list[str]
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachLoadBalancersRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.async is not None:
            result['Async'] = self.async
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_detach is not None:
            result['ForceDetach'] = self.force_detach
        if self.load_balancers is not None:
            result['LoadBalancers'] = self.load_balancers
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Async') is not None:
            self.async = m.get('Async')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceDetach') is not None:
            self.force_detach = m.get('ForceDetach')
        if m.get('LoadBalancers') is not None:
            self.load_balancers = m.get('LoadBalancers')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DetachLoadBalancersResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        self.request_id = request_id  # type: str
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachLoadBalancersResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DetachLoadBalancersResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DetachLoadBalancersResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DetachLoadBalancersResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachLoadBalancersResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachServerGroupsRequestServerGroups(TeaModel):
    def __init__(self, port=None, server_group_id=None, type=None):
        # The port number that is used by an ECS instance after Auto Scaling adds the ECS instance to the server group.
        self.port = port  # type: int
        # The ID of the server group.
        self.server_group_id = server_group_id  # type: str
        # The type of the server group. Valid values:
        # 
        # *   ALB
        # *   NLB
        self.type = type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachServerGroupsRequestServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.server_group_id is not None:
            result['ServerGroupId'] = self.server_group_id
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('ServerGroupId') is not None:
            self.server_group_id = m.get('ServerGroupId')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class DetachServerGroupsRequest(TeaModel):
    def __init__(self, client_token=None, force_detach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None, server_groups=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the token, but you must make sure that the token is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [Ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to remove the Elastic Compute Service (ECS) instances in the scaling group from the detached server group.
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_detach = force_detach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # Details of the server groups.
        self.server_groups = server_groups  # type: list[DetachServerGroupsRequestServerGroups]

    def validate(self):
        if self.server_groups:
            for k in self.server_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DetachServerGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_detach is not None:
            result['ForceDetach'] = self.force_detach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['ServerGroups'] = []
        if self.server_groups is not None:
            for k in self.server_groups:
                result['ServerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceDetach') is not None:
            self.force_detach = m.get('ForceDetach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.server_groups = []
        if m.get('ServerGroups') is not None:
            for k in m.get('ServerGroups'):
                temp_model = DetachServerGroupsRequestServerGroups()
                self.server_groups.append(temp_model.from_map(k))
        return self


class DetachServerGroupsResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity in which you detach the server group from the scaling group and Auto Scaling removes the ECS instances from the server group.
        # 
        # > This parameter is returned only if you set the ForceAttach parameter to true.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachServerGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class DetachServerGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DetachServerGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DetachServerGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachServerGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DetachVServerGroupsRequestVServerGroupsVServerGroupAttributes(TeaModel):
    def __init__(self, port=None, vserver_group_id=None):
        # The port number that is used when Auto Scaling adds ECS instances to the vServer group. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The ID of the vServer group.
        self.vserver_group_id = vserver_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachVServerGroupsRequestVServerGroupsVServerGroupAttributes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.vserver_group_id is not None:
            result['VServerGroupId'] = self.vserver_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('VServerGroupId') is not None:
            self.vserver_group_id = m.get('VServerGroupId')
        return self


class DetachVServerGroupsRequestVServerGroups(TeaModel):
    def __init__(self, load_balancer_id=None, vserver_group_attributes=None):
        # The ID of the Classic Load Balancer (CLB) instance to which the vServer group belongs.
        self.load_balancer_id = load_balancer_id  # type: str
        # Details of the vServer group attributes.
        self.vserver_group_attributes = vserver_group_attributes  # type: list[DetachVServerGroupsRequestVServerGroupsVServerGroupAttributes]

    def validate(self):
        if self.vserver_group_attributes:
            for k in self.vserver_group_attributes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DetachVServerGroupsRequestVServerGroups, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.load_balancer_id is not None:
            result['LoadBalancerId'] = self.load_balancer_id
        result['VServerGroupAttributes'] = []
        if self.vserver_group_attributes is not None:
            for k in self.vserver_group_attributes:
                result['VServerGroupAttributes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoadBalancerId') is not None:
            self.load_balancer_id = m.get('LoadBalancerId')
        self.vserver_group_attributes = []
        if m.get('VServerGroupAttributes') is not None:
            for k in m.get('VServerGroupAttributes'):
                temp_model = DetachVServerGroupsRequestVServerGroupsVServerGroupAttributes()
                self.vserver_group_attributes.append(temp_model.from_map(k))
        return self


class DetachVServerGroupsRequest(TeaModel):
    def __init__(self, client_token=None, force_detach=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None, vserver_groups=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # Specifies whether to remove ECS instances in your scaling group from the vServer group.
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.force_detach = force_detach  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group. Examples: cn-hangzhou and cn-shanghai.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # Details of the vServer groups.
        self.vserver_groups = vserver_groups  # type: list[DetachVServerGroupsRequestVServerGroups]

    def validate(self):
        if self.vserver_groups:
            for k in self.vserver_groups:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(DetachVServerGroupsRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.force_detach is not None:
            result['ForceDetach'] = self.force_detach
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        result['VServerGroups'] = []
        if self.vserver_groups is not None:
            for k in self.vserver_groups:
                result['VServerGroups'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('ForceDetach') is not None:
            self.force_detach = m.get('ForceDetach')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        self.vserver_groups = []
        if m.get('VServerGroups') is not None:
            for k in m.get('VServerGroups'):
                temp_model = DetachVServerGroupsRequestVServerGroups()
                self.vserver_groups.append(temp_model.from_map(k))
        return self


class DetachVServerGroupsResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DetachVServerGroupsResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DetachVServerGroupsResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DetachVServerGroupsResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DetachVServerGroupsResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DetachVServerGroupsResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DisableAlarmRequest(TeaModel):
    def __init__(self, alarm_task_id=None, owner_id=None, region_id=None, resource_owner_account=None):
        # The ID of the event-triggered task.
        self.alarm_task_id = alarm_task_id  # type: str
        self.owner_id = owner_id  # type: long
        # The ID of the region.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DisableAlarmRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class DisableAlarmResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DisableAlarmResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DisableAlarmResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DisableAlarmResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DisableAlarmResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DisableAlarmResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class DisableScalingGroupRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, resource_owner_account=None, resource_owner_id=None,
                 scaling_group_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DisableScalingGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class DisableScalingGroupResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(DisableScalingGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class DisableScalingGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: DisableScalingGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(DisableScalingGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = DisableScalingGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class EnableAlarmRequest(TeaModel):
    def __init__(self, alarm_task_id=None, owner_id=None, region_id=None, resource_owner_account=None):
        # The ID of the event-triggered task.
        self.alarm_task_id = alarm_task_id  # type: str
        self.owner_id = owner_id  # type: long
        # The ID of the region.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(EnableAlarmRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class EnableAlarmResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(EnableAlarmResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class EnableAlarmResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: EnableAlarmResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(EnableAlarmResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = EnableAlarmResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class EnableScalingGroupRequestLaunchTemplateOverrides(TeaModel):
    def __init__(self, instance_type=None, weighted_capacity=None):
        # The instance type that you want to use to override the instance type that is specified in the launch template.
        # 
        # If you want to scale instances based on the weighted capacities of the instances, you must specify both the InstanceType and WeightedCapacity parameters.
        # 
        # > This parameter is supported only if you specify the LaunchTemplateId parameter.
        # 
        # You can specify an instance type that is available for purchase as the value of the InstanceType parameter.
        self.instance_type = instance_type  # type: str
        # The weight of the instance type. The weight specifies the capacity of a single instance of the specified instance type in the scaling group. If you want to scale instances based on the weighted capacities of the instances, you must specify the WeightedCapacity parameter after you specify the InstanceType parameter.
        # 
        # A higher weight specifies that a smaller number of instances of the specified instance type are required to meet the expected capacity requirement.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by the MaxSize parameter and the maximum weight of the instance types.
        # 
        # Valid values of the WeightedCapacity parameter: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(EnableScalingGroupRequestLaunchTemplateOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class EnableScalingGroupRequest(TeaModel):
    def __init__(self, active_scaling_configuration_id=None, instance_ids=None, launch_template_id=None,
                 launch_template_overrides=None, launch_template_version=None, load_balancer_weights=None, owner_account=None, owner_id=None,
                 region_id=None, resource_owner_account=None, resource_owner_id=None, scaling_group_id=None):
        # The ID of the scaling configuration that you want to put into the Active state.
        self.active_scaling_configuration_id = active_scaling_configuration_id  # type: str
        # The IDs of ECS instances that you want to add to the scaling group after you enable the scaling group.
        # 
        # The ECS instances must meet the following requirements:
        # 
        # *   The ECS instances and the scaling group must reside in the same region.
        # *   The ECS instances must be in the Running state.
        # *   The ECS instances are not added to other scaling groups.
        # *   The billing method of the ECS instances must be subscription or pay-as-you-go, or the ECS instances must be preemptible instances.
        # *   If you specify the VswitchID parameter for the scaling group, the ECS instances must reside in the same virtual private cloud (VPC) as the specified vSwitch. You cannot add the ECS instances that reside in the classic network or other VPCs to the scaling group.
        # *   If you do not specify the VswitchID parameter for the scaling group, you cannot add ECS instances that reside in VPCs to the scaling group.
        self.instance_ids = instance_ids  # type: list[str]
        # The ID of the launch template that is used by Auto Scaling to create ECS instances.
        self.launch_template_id = launch_template_id  # type: str
        # Details of the instance types that you specify by using the Extended Configurations feature of the launch template.
        self.launch_template_overrides = launch_template_overrides  # type: list[EnableScalingGroupRequestLaunchTemplateOverrides]
        # The version number of the launch template. Valid values:
        # 
        # *   A fixed template version number.
        # *   Default: the default template version.
        # *   Latest: the latest template version.
        self.launch_template_version = launch_template_version  # type: str
        # The weight of an ECS instance as a backend server in the backend vServer group.
        # 
        # Default value: 50.
        self.load_balancer_weights = load_balancer_weights  # type: list[int]
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        if self.launch_template_overrides:
            for k in self.launch_template_overrides:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(EnableScalingGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_scaling_configuration_id is not None:
            result['ActiveScalingConfigurationId'] = self.active_scaling_configuration_id
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.launch_template_id is not None:
            result['LaunchTemplateId'] = self.launch_template_id
        result['LaunchTemplateOverrides'] = []
        if self.launch_template_overrides is not None:
            for k in self.launch_template_overrides:
                result['LaunchTemplateOverrides'].append(k.to_map() if k else None)
        if self.launch_template_version is not None:
            result['LaunchTemplateVersion'] = self.launch_template_version
        if self.load_balancer_weights is not None:
            result['LoadBalancerWeights'] = self.load_balancer_weights
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActiveScalingConfigurationId') is not None:
            self.active_scaling_configuration_id = m.get('ActiveScalingConfigurationId')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('LaunchTemplateId') is not None:
            self.launch_template_id = m.get('LaunchTemplateId')
        self.launch_template_overrides = []
        if m.get('LaunchTemplateOverrides') is not None:
            for k in m.get('LaunchTemplateOverrides'):
                temp_model = EnableScalingGroupRequestLaunchTemplateOverrides()
                self.launch_template_overrides.append(temp_model.from_map(k))
        if m.get('LaunchTemplateVersion') is not None:
            self.launch_template_version = m.get('LaunchTemplateVersion')
        if m.get('LoadBalancerWeights') is not None:
            self.load_balancer_weights = m.get('LoadBalancerWeights')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class EnableScalingGroupResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(EnableScalingGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class EnableScalingGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: EnableScalingGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(EnableScalingGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = EnableScalingGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class EnterStandbyRequest(TeaModel):
    def __init__(self, async=None, client_token=None, instance_ids=None, owner_id=None, resource_owner_account=None,
                 scaling_group_id=None):
        self.async = async  # type: bool
        self.client_token = client_token  # type: str
        self.instance_ids = instance_ids  # type: list[str]
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(EnterStandbyRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.async is not None:
            result['Async'] = self.async
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Async') is not None:
            self.async = m.get('Async')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class EnterStandbyResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        self.request_id = request_id  # type: str
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(EnterStandbyResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class EnterStandbyResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: EnterStandbyResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(EnterStandbyResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = EnterStandbyResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ExecuteScalingRuleRequest(TeaModel):
    def __init__(self, breach_threshold=None, client_token=None, metric_value=None, owner_account=None,
                 owner_id=None, region_id=None, resource_owner_account=None, resource_owner_id=None, scaling_rule_ari=None):
        # The threshold specified when the step scaling rule is executed. Valid values: -9.999999E18 to 9.999999E18.
        self.breach_threshold = breach_threshold  # type: float
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # The metric value specified when the step scaling rule is executed. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_value = metric_value  # type: float
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The unique identifier of the scaling rule.
        # 
        # > You can call the ExecuteScalingRule operation to execute only simple scaling rules and step scaling rules. To execute a step scaling rule, you must specify the BreachThreshold and MetricValue parameters.
        self.scaling_rule_ari = scaling_rule_ari  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ExecuteScalingRuleRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.breach_threshold is not None:
            result['BreachThreshold'] = self.breach_threshold
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.metric_value is not None:
            result['MetricValue'] = self.metric_value
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_rule_ari is not None:
            result['ScalingRuleAri'] = self.scaling_rule_ari
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('BreachThreshold') is not None:
            self.breach_threshold = m.get('BreachThreshold')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('MetricValue') is not None:
            self.metric_value = m.get('MetricValue')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingRuleAri') is not None:
            self.scaling_rule_ari = m.get('ScalingRuleAri')
        return self


class ExecuteScalingRuleResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ExecuteScalingRuleResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class ExecuteScalingRuleResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ExecuteScalingRuleResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ExecuteScalingRuleResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ExecuteScalingRuleResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ExitStandbyRequest(TeaModel):
    def __init__(self, async=None, client_token=None, instance_ids=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # Specifies whether to put the ECS instance into the Standby state in an asynchronous manner. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.async = async  # type: bool
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that it is unique among different requests.
        # 
        # The token can only contain ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        # The IDs of the ECS instances.
        self.instance_ids = instance_ids  # type: list[str]
        self.owner_id = owner_id  # type: long
        # The ID of the region.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ExitStandbyRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.async is not None:
            result['Async'] = self.async
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Async') is not None:
            self.async = m.get('Async')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ExitStandbyResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ExitStandbyResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class ExitStandbyResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ExitStandbyResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ExitStandbyResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ExitStandbyResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListTagKeysRequest(TeaModel):
    def __init__(self, next_token=None, owner_id=None, page_size=None, region_id=None, resource_owner_account=None,
                 resource_type=None):
        # The token that determines the start point of the next query. If this parameter is empty, all results are returned.
        self.next_token = next_token  # type: str
        self.owner_id = owner_id  # type: long
        # The number of entries to return on each page. Maximum value: 50.
        # 
        # Default value: 10.
        self.page_size = page_size  # type: int
        # The region ID of the Auto Scaling resource.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The type of the Auto Scaling resource. Set the value to scalinggroup. This indicates that the tags are added to scaling groups.
        self.resource_type = resource_type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ListTagKeysRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        return self


class ListTagKeysResponseBody(TeaModel):
    def __init__(self, keys=None, next_token=None, page_size=None, request_id=None):
        # Details of the tag keys.
        self.keys = keys  # type: list[str]
        # The token that determines the start point of the next query. If this parameter is empty, all results are returned.
        self.next_token = next_token  # type: str
        # The number of entries returned per page.
        self.page_size = page_size  # type: int
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ListTagKeysResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.keys is not None:
            result['Keys'] = self.keys
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Keys') is not None:
            self.keys = m.get('Keys')
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ListTagKeysResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ListTagKeysResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ListTagKeysResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListTagKeysResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListTagResourcesRequestTags(TeaModel):
    def __init__(self, key=None, value=None):
        self.key = key  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ListTagResourcesRequestTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ListTagResourcesRequest(TeaModel):
    def __init__(self, next_token=None, owner_id=None, region_id=None, resource_ids=None,
                 resource_owner_account=None, resource_type=None, tags=None):
        self.next_token = next_token  # type: str
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.resource_ids = resource_ids  # type: list[str]
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_type = resource_type  # type: str
        self.tags = tags  # type: list[ListTagResourcesRequestTags]

    def validate(self):
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ListTagResourcesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_ids is not None:
            result['ResourceIds'] = self.resource_ids
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceIds') is not None:
            self.resource_ids = m.get('ResourceIds')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = ListTagResourcesRequestTags()
                self.tags.append(temp_model.from_map(k))
        return self


class ListTagResourcesResponseBodyTagResources(TeaModel):
    def __init__(self, propagate=None, resource_id=None, resource_type=None, tag_key=None, tag_value=None):
        self.propagate = propagate  # type: bool
        self.resource_id = resource_id  # type: str
        self.resource_type = resource_type  # type: str
        self.tag_key = tag_key  # type: str
        self.tag_value = tag_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ListTagResourcesResponseBodyTagResources, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.propagate is not None:
            result['Propagate'] = self.propagate
        if self.resource_id is not None:
            result['ResourceId'] = self.resource_id
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        if self.tag_key is not None:
            result['TagKey'] = self.tag_key
        if self.tag_value is not None:
            result['TagValue'] = self.tag_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Propagate') is not None:
            self.propagate = m.get('Propagate')
        if m.get('ResourceId') is not None:
            self.resource_id = m.get('ResourceId')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        if m.get('TagKey') is not None:
            self.tag_key = m.get('TagKey')
        if m.get('TagValue') is not None:
            self.tag_value = m.get('TagValue')
        return self


class ListTagResourcesResponseBody(TeaModel):
    def __init__(self, next_token=None, request_id=None, tag_resources=None):
        self.next_token = next_token  # type: str
        self.request_id = request_id  # type: str
        self.tag_resources = tag_resources  # type: list[ListTagResourcesResponseBodyTagResources]

    def validate(self):
        if self.tag_resources:
            for k in self.tag_resources:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ListTagResourcesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        result['TagResources'] = []
        if self.tag_resources is not None:
            for k in self.tag_resources:
                result['TagResources'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        self.tag_resources = []
        if m.get('TagResources') is not None:
            for k in m.get('TagResources'):
                temp_model = ListTagResourcesResponseBodyTagResources()
                self.tag_resources.append(temp_model.from_map(k))
        return self


class ListTagResourcesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ListTagResourcesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ListTagResourcesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListTagResourcesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ListTagValuesRequest(TeaModel):
    def __init__(self, key=None, next_token=None, owner_id=None, page_size=None, region_id=None,
                 resource_owner_account=None, resource_type=None):
        # The key of the messages that you want to query.
        self.key = key  # type: str
        # The token that determines the start point of the query. The return value is the value of the NextToken response parameter that was returned last time the QueryInstanceByTag operation was called.
        self.next_token = next_token  # type: str
        self.owner_id = owner_id  # type: long
        # The number of entries to return on each page. Default value: 10. Maximum value: 100.
        self.page_size = page_size  # type: int
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The type of the Auto Scaling resource. Only scaling groups are supported. Set the value to scalinggroup.
        self.resource_type = resource_type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ListTagValuesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        return self


class ListTagValuesResponseBody(TeaModel):
    def __init__(self, next_token=None, page_size=None, request_id=None, values=None):
        # The token that is returned for the next query.
        self.next_token = next_token  # type: str
        # The number of entries returned per page.
        self.page_size = page_size  # type: int
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The information of the tag values.
        self.values = values  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(ListTagValuesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.next_token is not None:
            result['NextToken'] = self.next_token
        if self.page_size is not None:
            result['PageSize'] = self.page_size
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.values is not None:
            result['Values'] = self.values
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NextToken') is not None:
            self.next_token = m.get('NextToken')
        if m.get('PageSize') is not None:
            self.page_size = m.get('PageSize')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('Values') is not None:
            self.values = m.get('Values')
        return self


class ListTagValuesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ListTagValuesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ListTagValuesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ListTagValuesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyAlarmRequestDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        # The dimension key of the metric. Valid values of DimensionKey vary based on the value of MetricType.
        # 
        # *   If you set MetricType to custom, you can specify this parameter based on your business requirements.
        # 
        # *   If you set MetricType to system, DimensionKey has the following valid values:
        # 
        #     *   user_id: the ID of your Alibaba Cloud account
        #     *   scaling_group: the scaling group that is monitored by the event-triggered task.
        #     *   device: the type of the NIC.
        #     *   state: the state of the TCP connection
        self.dimension_key = dimension_key  # type: str
        # The dimension value of the metric. Valid values of DimensionValue vary based on the value of DimensionKey.
        # 
        # *   If you set MetricType to custom, you can specify this parameter based on your business requirements.
        # 
        # *   If you set MetricType to system, DimensionKey has the following valid values:
        # 
        #     *   user_id: The system specifies the value.
        # 
        #     *   scaling_group: The system specifies the value.
        # 
        #     *   If you set DimensionKey to device, you can set DimensionValue to eth0 or eth1.
        # 
        #         *   For instances that reside in the classic network, eth0 specifies the internal NIC. Only one eth0 NIC exists on each instance that resides in a VPC.
        #         *   For instances that reside in the classic network, eth1 specifies the public NIC.
        # 
        #     *   If you set DimensionKey to state, you can set DimensionValue to TCP_TOTAL or ESTABLISHED.
        # 
        #         *   TCP_TOTAL specifies the total number of TCP connections.
        #         *   ESTABLISHED specifies the number of established TCP connections.
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyAlarmRequestDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class ModifyAlarmRequestExpressions(TeaModel):
    def __init__(self, comparison_operator=None, metric_name=None, period=None, statistics=None, threshold=None):
        # The operator that is used to compare the metric value and the metric threshold. Valid values:
        # 
        # *   If the metric value is greater than or equal to the metric threshold, set the value to `>=`.
        # *   If the metric value is less than or equal to the metric threshold, set the value to `<=`.
        # *   If the metric value is greater than the metric threshold, set the value to `>`.
        # *   If the metric value is less than the metric threshold, set the value to `<`.
        # 
        # Default value: >=\
        self.comparison_operator = comparison_operator  # type: str
        # The name of the metric that is specified in the multi-metric alert rule. Valid values of MetricName vary based on the value of MetricType.
        # 
        # *   If you set MetricType to custom, the valid values of MetricName are your custom metrics.
        # 
        # *   If you set MetricType to system, MetricName has the following valid values:
        # 
        #     *   CpuUtilization: (ECS) the CPU utilization. Unit: %.
        #     *   IntranetTx: the outbound traffic over the internal network from an ECS instance. Unit: KB/min.
        #     *   IntranetRx: the inbound traffic over the internal network to an ECS instance. Unit: KB/min.
        #     *   VpcInternetTx: the outbound traffic over the Internet from an ECS instance that resides in a VPC. Unit: KB/min.
        #     *   VpcInternetRx: the inbound traffic over the Internet to an ECS instance that resides in a VPC. Unit: KB/min.
        #     *   SystemDiskReadBps: the number of bytes read from the system disk that is used by an ECS instance per second.
        #     *   SystemDiskWriteBps: the number of bytes written to the system disk that is used by an ECS instance per second.
        #     *   SystemDiskReadOps: the number of read operations on the system disk that is used by an ECS instance per second.
        #     *   SystemDiskWriteOps: the number of write operations on the system disk that is used by an ECS instance per second.
        #     *   CpuUtilizationAgent: the CPU utilization of an agent. Unit: %.
        #     *   GpuUtilizationAgent: the GPU utilization of an agent. Unit: %.
        #     *   GpuMemoryFreeUtilizationAgent: the percentage of idle GPU memory of an agent.
        #     *   GpuMemoryUtilizationAgent: the GPU memory usage of an agent. Unit: %.
        #     *   MemoryUtilization: the memory usage of an agent. Unit: %.
        #     *   LoadAverage: the average system load of an agent.
        #     *   TcpConnection: the total number of TCP connections of an agent.
        #     *   TcpConnection: the number of established TCP connections of an agent.
        #     *   PackagesNetOut: the number of packets that are sent by the internal NIC used by an agent.
        #     *   PackagesNetIn: the number of packets that are received by the internal NIC used by an agent.
        #     *   EciPodCpuUtilization: the CPU utilization of an elastic container instance. Unit: %.
        #     *   EciPodMemoryUtilization: the memory usage of an elastic container instance. Unit: %.
        # 
        # For more information, see [Event-triggered task for system monitoring](~~74854~~).
        self.metric_name = metric_name  # type: str
        # The period of time during which the statistics of a metric in the multi-metric alert rule is collected. Unit: seconds. Valid values:
        # 
        # *   15
        # *   60
        # *   120
        # *   300
        # *   900
        # 
        # > If your scaling group is of the ECS type and uses CloudMonitor metrics, you can set Period to 15. In other cases, you can set Period to 60, 120, 300, or 900. In most cases, the name of a CloudMonitor metric contains Agent.
        # 
        # Default value: 300
        self.period = period  # type: int
        # The method that is used to aggregate the statistics of a metric that is specified in the multi-metric alert rule. Valid values:
        # 
        # *   Average
        # *   Minimum
        # *   Maximum
        self.statistics = statistics  # type: str
        # The threshold of a metric in the multi-metric alert rule. If the threshold is reached the specified number of times within the specified period, a scaling rule is executed.
        self.threshold = threshold  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyAlarmRequestExpressions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.period is not None:
            result['Period'] = self.period
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class ModifyAlarmRequest(TeaModel):
    def __init__(self, alarm_actions=None, alarm_task_id=None, comparison_operator=None, description=None,
                 dimensions=None, effective=None, evaluation_count=None, expressions=None, expressions_logic_operator=None,
                 group_id=None, metric_name=None, metric_type=None, name=None, owner_id=None, period=None, region_id=None,
                 resource_owner_account=None, statistics=None, threshold=None):
        # The unique identifiers of the scaling rules that are associated with the event-triggered task.
        self.alarm_actions = alarm_actions  # type: list[str]
        # The ID of the event-triggered task.
        self.alarm_task_id = alarm_task_id  # type: str
        # The operator that is used to compare the metric value and the metric threshold. Valid values:
        # 
        # *   If the metric value is greater than or equal to the metric threshold, set the value to `>=`.
        # *   If the metric value is less than or equal to the metric threshold, set the value to `<=`.
        # *   If the metric value is greater than the metric threshold, set the value to `>`.
        # *   If the metric value is less than the metric threshold, set the value to `<`.
        self.comparison_operator = comparison_operator  # type: str
        # The description of the event-triggered task.
        self.description = description  # type: str
        # The dimensions of the metric.
        self.dimensions = dimensions  # type: list[ModifyAlarmRequestDimensions]
        # The effective period of the event-triggered task.
        # 
        # The Effective value follows the cron expression format. The default format is `X X X X X ?`. In the format:
        # 
        # *   X: a placeholder for a field, which represents seconds, minutes, hours, days, and months in sequence. X can be a definite value or a special character that has logical meaning. For information about the valid values of X, see [Cron expression](~~25907~~).
        # *   ?: No value is specified.
        # 
        # > By default, the value of this parameter is specified in **UTC+8**. You can specify the time zone in the `TZ=+yy` format before a cron expression. y indicates the time zone. For example, `TZ=+00 * * 1-2 * * ?` specifies that the event-triggered task is in effect between 01:00 and 02:59 (UTC+0) every day.
        # 
        # Examples:
        # 
        # *   ` * * * * * ?  `: The event-triggered task is in effect at all times.
        # *   ` * * 17-18 * * ?  `: The event-triggered task is in effect between 17:00:00 and 18:59:00 (UTC+8) every day.
        # *   `TZ=+00 * * 1-2 * * ?`: The event-triggered task is in effect between 01:00:00 and 02:59:00 (UTC+0) every day.
        self.effective = effective  # type: str
        # The number of times that the threshold must be reached before a scaling rule can be executed. For example, if you set this parameter to 3, the average CPU utilization must reach or exceed 80% three times in a row before a scaling rule is triggered.
        self.evaluation_count = evaluation_count  # type: int
        # The expressions that are specified in the multi-metric alert rule.
        self.expressions = expressions  # type: list[ModifyAlarmRequestExpressions]
        # The relationship between the trigger conditions in the multi-metric alert rule. Valid values:
        # 
        # *   `&&`: An alert is triggered only if all metrics in the multi-metric alert rule meet the trigger conditions. In this case, an alert is triggered only if the results of all trigger conditions that are specified in the multi-metric alert rule are `true`.
        # *   \`\`: An alert is triggered as long as one of the metrics in the multi-metric alert rule meets the trigger condition.
        # 
        # Default value: `&&`
        self.expressions_logic_operator = expressions_logic_operator  # type: str
        # The ID of the application group to which the custom metric belongs. This parameter must be specified when MetricType is set to custom.
        self.group_id = group_id  # type: int
        # The name of the metric. Valid values of MetricName vary based on the value of MetricType.
        # 
        # *   If you set MetricType to custom, the valid values of MetricName are your custom metrics.
        # 
        # *   If you set MetricType to system, MetricName has the following valid values:
        # 
        #     *   CpuUtilization: (ECS) the CPU utilization. Unit: %.
        #     *   IntranetTx: the outbound traffic over the internal network from an ECS instance. Unit: KB/min.
        #     *   IntranetRx: the inbound traffic over the internal network to an ECS instance. Unit: KB/min.
        #     *   VpcInternetTx: the outbound traffic over the Internet from an ECS instance that resides in a virtual private cloud (VPC). Unit: KB/min.
        #     *   VpcInternetRx: the inbound traffic over the Internet to an ECS instance that resides in a VPC. Unit: KB/min.
        #     *   SystemDiskReadBps: the number of bytes read from the system disk that is used by an ECS instance per second.
        #     *   SystemDiskWriteBps: the number of bytes written to the system disk that is used by an ECS instance per second.
        #     *   SystemDiskReadOps: the number of read operations on the system disk that is used by an ECS instance per second.
        #     *   SystemDiskWriteOps: the number of write operations on the system disk that is used by an ECS instance per second.
        #     *   CpuUtilizationAgent: the CPU utilization of an agent. Unit: %.
        #     *   GpuMemoryFreeUtilizationAgent: the percentage of idle GPU memory of an agent.
        #     *   GpuMemoryUtilizationAgent: the GPU memory usage of an agent. Unit: %.
        #     *   MemoryUtilization: the memory usage of an agent. Unit: %.
        #     *   LoadAverage: the average system load of an agent.
        #     *   TcpConnection: the total number of TCP connections of an agent.
        #     *   TcpConnection: the number of established TCP connections of an agent.
        #     *   PackagesNetOut: the number of packets that are sent by the internal network interface controller (NIC) used by an agent.
        #     *   PackagesNetIn: the number of packets that are received by the internal NIC used by an agent.
        #     *   EciPodCpuUtilization: the CPU utilization of an elastic container instance. Unit: %.
        #     *   EciPodMemoryUtilization: the memory usage of an elastic container instance. Unit: %.
        # 
        # For more information, see [Event-triggered task for system monitoring](~~74854~~).
        self.metric_name = metric_name  # type: str
        # The type of the metric. Valid values:
        # 
        # *   system: system metrics of CloudMonitor
        # *   custom: custom metrics that are reported to CloudMonitor
        self.metric_type = metric_type  # type: str
        # The name of the event-triggered task.
        self.name = name  # type: str
        self.owner_id = owner_id  # type: long
        # The period of time during which statistics about the metric is collected. Unit: seconds. Valid values:
        # 
        # *   15
        # *   60
        # *   120
        # *   300
        # *   900
        # 
        # > If your scaling group is of the ECS type and uses CloudMonitor metrics, you can set Period to 15. In other cases, you can set Period to 60, 120, 300, or 900. In most cases, the name of a CloudMonitor metric contains Agent.
        self.period = period  # type: int
        # The region ID of the event-triggered task.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The method that is used to aggregate statistics for the metric. Valid values:
        # 
        # *   Average
        # *   Minimum
        # *   Maximum
        self.statistics = statistics  # type: str
        # The threshold of a metric in the multi-metric alert rule. If the threshold is reached the specified number of times within the specified period, a scaling rule is executed.
        self.threshold = threshold  # type: float

    def validate(self):
        if self.dimensions:
            for k in self.dimensions:
                if k:
                    k.validate()
        if self.expressions:
            for k in self.expressions:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyAlarmRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_actions is not None:
            result['AlarmActions'] = self.alarm_actions
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.comparison_operator is not None:
            result['ComparisonOperator'] = self.comparison_operator
        if self.description is not None:
            result['Description'] = self.description
        result['Dimensions'] = []
        if self.dimensions is not None:
            for k in self.dimensions:
                result['Dimensions'].append(k.to_map() if k else None)
        if self.effective is not None:
            result['Effective'] = self.effective
        if self.evaluation_count is not None:
            result['EvaluationCount'] = self.evaluation_count
        result['Expressions'] = []
        if self.expressions is not None:
            for k in self.expressions:
                result['Expressions'].append(k.to_map() if k else None)
        if self.expressions_logic_operator is not None:
            result['ExpressionsLogicOperator'] = self.expressions_logic_operator
        if self.group_id is not None:
            result['GroupId'] = self.group_id
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.metric_type is not None:
            result['MetricType'] = self.metric_type
        if self.name is not None:
            result['Name'] = self.name
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.period is not None:
            result['Period'] = self.period
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.statistics is not None:
            result['Statistics'] = self.statistics
        if self.threshold is not None:
            result['Threshold'] = self.threshold
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmActions') is not None:
            self.alarm_actions = m.get('AlarmActions')
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('ComparisonOperator') is not None:
            self.comparison_operator = m.get('ComparisonOperator')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        self.dimensions = []
        if m.get('Dimensions') is not None:
            for k in m.get('Dimensions'):
                temp_model = ModifyAlarmRequestDimensions()
                self.dimensions.append(temp_model.from_map(k))
        if m.get('Effective') is not None:
            self.effective = m.get('Effective')
        if m.get('EvaluationCount') is not None:
            self.evaluation_count = m.get('EvaluationCount')
        self.expressions = []
        if m.get('Expressions') is not None:
            for k in m.get('Expressions'):
                temp_model = ModifyAlarmRequestExpressions()
                self.expressions.append(temp_model.from_map(k))
        if m.get('ExpressionsLogicOperator') is not None:
            self.expressions_logic_operator = m.get('ExpressionsLogicOperator')
        if m.get('GroupId') is not None:
            self.group_id = m.get('GroupId')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MetricType') is not None:
            self.metric_type = m.get('MetricType')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Period') is not None:
            self.period = m.get('Period')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('Statistics') is not None:
            self.statistics = m.get('Statistics')
        if m.get('Threshold') is not None:
            self.threshold = m.get('Threshold')
        return self


class ModifyAlarmResponseBody(TeaModel):
    def __init__(self, alarm_task_id=None, request_id=None):
        # The ID of the event-triggered task.
        self.alarm_task_id = alarm_task_id  # type: str
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyAlarmResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.alarm_task_id is not None:
            result['AlarmTaskId'] = self.alarm_task_id
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AlarmTaskId') is not None:
            self.alarm_task_id = m.get('AlarmTaskId')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyAlarmResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyAlarmResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyAlarmResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyAlarmResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyEciScalingConfigurationRequestAcrRegistryInfos(TeaModel):
    def __init__(self, domains=None, instance_id=None, instance_name=None, region_id=None):
        # The domain names of the Container Registry Enterprise Edition instances. By default, all domain names of the Container Registry Enterprise Edition instances are displayed. You can specify one or more domain names. Separate multiple domain names with commas (,).
        self.domains = domains  # type: list[str]
        # The ID of the Container Registry Enterprise Edition instance.
        self.instance_id = instance_id  # type: str
        # The name of the Container Registry Enterprise Edition instance.
        self.instance_name = instance_name  # type: str
        # The region ID of the Container Registry Enterprise Edition instance.
        self.region_id = region_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestAcrRegistryInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.domains is not None:
            result['Domains'] = self.domains
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Domains') is not None:
            self.domains = m.get('Domains')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        return self


class ModifyEciScalingConfigurationRequestContainersLivenessProbeExec(TeaModel):
    def __init__(self, commands=None):
        self.commands = commands  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersLivenessProbeExec, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.commands is not None:
            result['Commands'] = self.commands
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        return self


class ModifyEciScalingConfigurationRequestContainersLivenessProbeHttpGet(TeaModel):
    def __init__(self, path=None, port=None, scheme=None):
        self.path = path  # type: str
        self.port = port  # type: int
        self.scheme = scheme  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersLivenessProbeHttpGet, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.port is not None:
            result['Port'] = self.port
        if self.scheme is not None:
            result['Scheme'] = self.scheme
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Scheme') is not None:
            self.scheme = m.get('Scheme')
        return self


class ModifyEciScalingConfigurationRequestContainersLivenessProbeTcpSocket(TeaModel):
    def __init__(self, port=None):
        self.port = port  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersLivenessProbeTcpSocket, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        return self


class ModifyEciScalingConfigurationRequestContainersLivenessProbe(TeaModel):
    def __init__(self, exec_=None, failure_threshold=None, http_get=None, initial_delay_seconds=None,
                 period_seconds=None, success_threshold=None, tcp_socket=None, timeout_seconds=None):
        self.exec_ = exec_  # type: ModifyEciScalingConfigurationRequestContainersLivenessProbeExec
        self.failure_threshold = failure_threshold  # type: int
        self.http_get = http_get  # type: ModifyEciScalingConfigurationRequestContainersLivenessProbeHttpGet
        self.initial_delay_seconds = initial_delay_seconds  # type: int
        self.period_seconds = period_seconds  # type: int
        self.success_threshold = success_threshold  # type: int
        self.tcp_socket = tcp_socket  # type: ModifyEciScalingConfigurationRequestContainersLivenessProbeTcpSocket
        self.timeout_seconds = timeout_seconds  # type: int

    def validate(self):
        if self.exec_:
            self.exec_.validate()
        if self.http_get:
            self.http_get.validate()
        if self.tcp_socket:
            self.tcp_socket.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersLivenessProbe, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.exec_ is not None:
            result['Exec'] = self.exec_.to_map()
        if self.failure_threshold is not None:
            result['FailureThreshold'] = self.failure_threshold
        if self.http_get is not None:
            result['HttpGet'] = self.http_get.to_map()
        if self.initial_delay_seconds is not None:
            result['InitialDelaySeconds'] = self.initial_delay_seconds
        if self.period_seconds is not None:
            result['PeriodSeconds'] = self.period_seconds
        if self.success_threshold is not None:
            result['SuccessThreshold'] = self.success_threshold
        if self.tcp_socket is not None:
            result['TcpSocket'] = self.tcp_socket.to_map()
        if self.timeout_seconds is not None:
            result['TimeoutSeconds'] = self.timeout_seconds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Exec') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersLivenessProbeExec()
            self.exec_ = temp_model.from_map(m['Exec'])
        if m.get('FailureThreshold') is not None:
            self.failure_threshold = m.get('FailureThreshold')
        if m.get('HttpGet') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersLivenessProbeHttpGet()
            self.http_get = temp_model.from_map(m['HttpGet'])
        if m.get('InitialDelaySeconds') is not None:
            self.initial_delay_seconds = m.get('InitialDelaySeconds')
        if m.get('PeriodSeconds') is not None:
            self.period_seconds = m.get('PeriodSeconds')
        if m.get('SuccessThreshold') is not None:
            self.success_threshold = m.get('SuccessThreshold')
        if m.get('TcpSocket') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersLivenessProbeTcpSocket()
            self.tcp_socket = temp_model.from_map(m['TcpSocket'])
        if m.get('TimeoutSeconds') is not None:
            self.timeout_seconds = m.get('TimeoutSeconds')
        return self


class ModifyEciScalingConfigurationRequestContainersReadinessProbeExec(TeaModel):
    def __init__(self, commands=None):
        self.commands = commands  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersReadinessProbeExec, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.commands is not None:
            result['Commands'] = self.commands
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        return self


class ModifyEciScalingConfigurationRequestContainersReadinessProbeHttpGet(TeaModel):
    def __init__(self, path=None, port=None, scheme=None):
        self.path = path  # type: str
        self.port = port  # type: int
        self.scheme = scheme  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersReadinessProbeHttpGet, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.port is not None:
            result['Port'] = self.port
        if self.scheme is not None:
            result['Scheme'] = self.scheme
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Scheme') is not None:
            self.scheme = m.get('Scheme')
        return self


class ModifyEciScalingConfigurationRequestContainersReadinessProbeTcpSocket(TeaModel):
    def __init__(self, port=None):
        self.port = port  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersReadinessProbeTcpSocket, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        return self


class ModifyEciScalingConfigurationRequestContainersReadinessProbe(TeaModel):
    def __init__(self, exec_=None, failure_threshold=None, http_get=None, initial_delay_seconds=None,
                 period_seconds=None, success_threshold=None, tcp_socket=None, timeout_seconds=None):
        self.exec_ = exec_  # type: ModifyEciScalingConfigurationRequestContainersReadinessProbeExec
        self.failure_threshold = failure_threshold  # type: int
        self.http_get = http_get  # type: ModifyEciScalingConfigurationRequestContainersReadinessProbeHttpGet
        self.initial_delay_seconds = initial_delay_seconds  # type: int
        self.period_seconds = period_seconds  # type: int
        self.success_threshold = success_threshold  # type: int
        self.tcp_socket = tcp_socket  # type: ModifyEciScalingConfigurationRequestContainersReadinessProbeTcpSocket
        self.timeout_seconds = timeout_seconds  # type: int

    def validate(self):
        if self.exec_:
            self.exec_.validate()
        if self.http_get:
            self.http_get.validate()
        if self.tcp_socket:
            self.tcp_socket.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersReadinessProbe, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.exec_ is not None:
            result['Exec'] = self.exec_.to_map()
        if self.failure_threshold is not None:
            result['FailureThreshold'] = self.failure_threshold
        if self.http_get is not None:
            result['HttpGet'] = self.http_get.to_map()
        if self.initial_delay_seconds is not None:
            result['InitialDelaySeconds'] = self.initial_delay_seconds
        if self.period_seconds is not None:
            result['PeriodSeconds'] = self.period_seconds
        if self.success_threshold is not None:
            result['SuccessThreshold'] = self.success_threshold
        if self.tcp_socket is not None:
            result['TcpSocket'] = self.tcp_socket.to_map()
        if self.timeout_seconds is not None:
            result['TimeoutSeconds'] = self.timeout_seconds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Exec') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersReadinessProbeExec()
            self.exec_ = temp_model.from_map(m['Exec'])
        if m.get('FailureThreshold') is not None:
            self.failure_threshold = m.get('FailureThreshold')
        if m.get('HttpGet') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersReadinessProbeHttpGet()
            self.http_get = temp_model.from_map(m['HttpGet'])
        if m.get('InitialDelaySeconds') is not None:
            self.initial_delay_seconds = m.get('InitialDelaySeconds')
        if m.get('PeriodSeconds') is not None:
            self.period_seconds = m.get('PeriodSeconds')
        if m.get('SuccessThreshold') is not None:
            self.success_threshold = m.get('SuccessThreshold')
        if m.get('TcpSocket') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersReadinessProbeTcpSocket()
            self.tcp_socket = temp_model.from_map(m['TcpSocket'])
        if m.get('TimeoutSeconds') is not None:
            self.timeout_seconds = m.get('TimeoutSeconds')
        return self


class ModifyEciScalingConfigurationRequestContainersSecurityContextCapability(TeaModel):
    def __init__(self, adds=None):
        self.adds = adds  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersSecurityContextCapability, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.adds is not None:
            result['Adds'] = self.adds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Adds') is not None:
            self.adds = m.get('Adds')
        return self


class ModifyEciScalingConfigurationRequestContainersSecurityContext(TeaModel):
    def __init__(self, capability=None, read_only_root_filesystem=None, run_as_user=None):
        self.capability = capability  # type: ModifyEciScalingConfigurationRequestContainersSecurityContextCapability
        self.read_only_root_filesystem = read_only_root_filesystem  # type: bool
        self.run_as_user = run_as_user  # type: long

    def validate(self):
        if self.capability:
            self.capability.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersSecurityContext, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capability is not None:
            result['Capability'] = self.capability.to_map()
        if self.read_only_root_filesystem is not None:
            result['ReadOnlyRootFilesystem'] = self.read_only_root_filesystem
        if self.run_as_user is not None:
            result['RunAsUser'] = self.run_as_user
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Capability') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersSecurityContextCapability()
            self.capability = temp_model.from_map(m['Capability'])
        if m.get('ReadOnlyRootFilesystem') is not None:
            self.read_only_root_filesystem = m.get('ReadOnlyRootFilesystem')
        if m.get('RunAsUser') is not None:
            self.run_as_user = m.get('RunAsUser')
        return self


class ModifyEciScalingConfigurationRequestContainersEnvironmentVarsFieldRef(TeaModel):
    def __init__(self, field_path=None):
        self.field_path = field_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersEnvironmentVarsFieldRef, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_path is not None:
            result['FieldPath'] = self.field_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldPath') is not None:
            self.field_path = m.get('FieldPath')
        return self


class ModifyEciScalingConfigurationRequestContainersEnvironmentVars(TeaModel):
    def __init__(self, field_ref=None, key=None, value=None):
        self.field_ref = field_ref  # type: ModifyEciScalingConfigurationRequestContainersEnvironmentVarsFieldRef
        # The key of the environment variable. Specify the name in the `[0-9a-zA-Z]` format. The name must be 1 to 128 characters in length, and can contain underscores (\_). It cannot start with a digit.
        self.key = key  # type: str
        # The value of the environment variable. The value must be 0 to 256 characters in length.
        self.value = value  # type: str

    def validate(self):
        if self.field_ref:
            self.field_ref.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref is not None:
            result['FieldRef'] = self.field_ref.to_map()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRef') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersEnvironmentVarsFieldRef()
            self.field_ref = temp_model.from_map(m['FieldRef'])
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ModifyEciScalingConfigurationRequestContainersPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        # The port number. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The type of the protocol. Valid values:
        # 
        # *   TCP
        # *   UDP
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class ModifyEciScalingConfigurationRequestContainersVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        # The path where the container mounts the volume.
        # 
        # >  Data stored in the path of the container is directly overwritten by the content of the volume.
        self.mount_path = mount_path  # type: str
        # The mount propagation setting of the volume. Mount propagation allows the sharing of volumes that are mounted on one container with other containers in the same pod, or even with other pods on the same node. Valid values:
        # 
        # *   None: The volume mount does not receive subsequent mounts that are mounted to this volume or its subdirectories.
        # *   HostToCotainer: The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories.
        # *   Bidirectional: This value is similar to HostToCotainer. The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories. In addition, all volume mounts that are created by the container are propagated back to the instance and to all containers of all pods that use the same volume.
        self.mount_propagation = mount_propagation  # type: str
        # The name of the volume. The value of this parameter is the same as the value of the Volumes.Name parameter.
        self.name = name  # type: str
        # Specifies whether the volume is read-only.
        # 
        # Default value: false.
        self.read_only = read_only  # type: bool
        # The subdirectory of the volume.
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainersVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class ModifyEciScalingConfigurationRequestContainers(TeaModel):
    def __init__(self, liveness_probe=None, readiness_probe=None, security_context=None, args=None, commands=None,
                 cpu=None, environment_vars=None, gpu=None, image=None, image_pull_policy=None,
                 lifecycle_post_start_handler_execs=None, lifecycle_post_start_handler_http_get_host=None,
                 lifecycle_post_start_handler_http_get_path=None, lifecycle_post_start_handler_http_get_port=None,
                 lifecycle_post_start_handler_http_get_scheme=None, lifecycle_post_start_handler_tcp_socket_host=None,
                 lifecycle_post_start_handler_tcp_socket_port=None, lifecycle_pre_stop_handler_execs=None, lifecycle_pre_stop_handler_http_get_host=None,
                 lifecycle_pre_stop_handler_http_get_path=None, lifecycle_pre_stop_handler_http_get_port=None,
                 lifecycle_pre_stop_handler_http_get_scheme=None, lifecycle_pre_stop_handler_tcp_socket_host=None,
                 lifecycle_pre_stop_handler_tcp_socket_port=None, memory=None, name=None, ports=None, stdin=None, stdin_once=None, tty=None, volume_mounts=None,
                 working_dir=None):
        self.liveness_probe = liveness_probe  # type: ModifyEciScalingConfigurationRequestContainersLivenessProbe
        self.readiness_probe = readiness_probe  # type: ModifyEciScalingConfigurationRequestContainersReadinessProbe
        self.security_context = security_context  # type: ModifyEciScalingConfigurationRequestContainersSecurityContext
        # The arguments that correspond to the startup commands of the container. You can specify up to 10 arguments.
        self.args = args  # type: list[str]
        # The commands that you want to execute in the container when you use the command line interface (CLI) to perform probes.
        self.commands = commands  # type: list[str]
        # The number of vCPUs that you want to allocate to the container.
        self.cpu = cpu  # type: float
        # Information about the environment variables.
        self.environment_vars = environment_vars  # type: list[ModifyEciScalingConfigurationRequestContainersEnvironmentVars]
        # The number of GPUs that you want to allocate to the container.
        self.gpu = gpu  # type: int
        # The image of the container.
        self.image = image  # type: str
        # The image pulling policy. Valid values:
        # 
        # *   Always: pulls images each time.
        # *   IfNotPresent: pulls images only if no on-premises images are available. On-premises images are preferentially used. If no on-premises images are available, image pulling is performed.
        # *   Never: never pulls images. On-premises images are always used.
        self.image_pull_policy = image_pull_policy  # type: str
        self.lifecycle_post_start_handler_execs = lifecycle_post_start_handler_execs  # type: list[str]
        self.lifecycle_post_start_handler_http_get_host = lifecycle_post_start_handler_http_get_host  # type: str
        self.lifecycle_post_start_handler_http_get_path = lifecycle_post_start_handler_http_get_path  # type: str
        self.lifecycle_post_start_handler_http_get_port = lifecycle_post_start_handler_http_get_port  # type: int
        self.lifecycle_post_start_handler_http_get_scheme = lifecycle_post_start_handler_http_get_scheme  # type: str
        self.lifecycle_post_start_handler_tcp_socket_host = lifecycle_post_start_handler_tcp_socket_host  # type: str
        self.lifecycle_post_start_handler_tcp_socket_port = lifecycle_post_start_handler_tcp_socket_port  # type: int
        self.lifecycle_pre_stop_handler_execs = lifecycle_pre_stop_handler_execs  # type: list[str]
        self.lifecycle_pre_stop_handler_http_get_host = lifecycle_pre_stop_handler_http_get_host  # type: str
        self.lifecycle_pre_stop_handler_http_get_path = lifecycle_pre_stop_handler_http_get_path  # type: str
        self.lifecycle_pre_stop_handler_http_get_port = lifecycle_pre_stop_handler_http_get_port  # type: int
        self.lifecycle_pre_stop_handler_http_get_scheme = lifecycle_pre_stop_handler_http_get_scheme  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_host = lifecycle_pre_stop_handler_tcp_socket_host  # type: str
        self.lifecycle_pre_stop_handler_tcp_socket_port = lifecycle_pre_stop_handler_tcp_socket_port  # type: int
        # The memory size of the container. Unit: GiB.
        self.memory = memory  # type: float
        # The name of the container image.
        self.name = name  # type: str
        # Information about the ports.
        self.ports = ports  # type: list[ModifyEciScalingConfigurationRequestContainersPorts]
        # Specifies whether the container allocates buffer resources to standard input streams when the container is running. If you do not specify this parameter, an end-of-file (EOF) error may occur.
        # 
        # Default value: false.
        self.stdin = stdin  # type: bool
        # Specifies whether standard input streams are disconnected after a client is disconnected.
        # 
        # If you set the StdinOnce parameter to true, standard input streams are connected after the container is started, and remain idle until a client is connected to receive data. After the client is disconnected, streams are also disconnected, and remain disconnected until the container is started again.
        self.stdin_once = stdin_once  # type: bool
        # Specifies whether to enable interaction. Default value: false.
        # 
        # If the command is a /bin/bash command, set the value to true.
        self.tty = tty  # type: bool
        # Information about the volume mount of the container.
        self.volume_mounts = volume_mounts  # type: list[ModifyEciScalingConfigurationRequestContainersVolumeMounts]
        # The working directory of the container.
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.liveness_probe:
            self.liveness_probe.validate()
        if self.readiness_probe:
            self.readiness_probe.validate()
        if self.security_context:
            self.security_context.validate()
        if self.environment_vars:
            for k in self.environment_vars:
                if k:
                    k.validate()
        if self.ports:
            for k in self.ports:
                if k:
                    k.validate()
        if self.volume_mounts:
            for k in self.volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.liveness_probe is not None:
            result['LivenessProbe'] = self.liveness_probe.to_map()
        if self.readiness_probe is not None:
            result['ReadinessProbe'] = self.readiness_probe.to_map()
        if self.security_context is not None:
            result['SecurityContext'] = self.security_context.to_map()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        result['EnvironmentVars'] = []
        if self.environment_vars is not None:
            for k in self.environment_vars:
                result['EnvironmentVars'].append(k.to_map() if k else None)
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        if self.lifecycle_post_start_handler_execs is not None:
            result['LifecyclePostStartHandlerExecs'] = self.lifecycle_post_start_handler_execs
        if self.lifecycle_post_start_handler_http_get_host is not None:
            result['LifecyclePostStartHandlerHttpGetHost'] = self.lifecycle_post_start_handler_http_get_host
        if self.lifecycle_post_start_handler_http_get_path is not None:
            result['LifecyclePostStartHandlerHttpGetPath'] = self.lifecycle_post_start_handler_http_get_path
        if self.lifecycle_post_start_handler_http_get_port is not None:
            result['LifecyclePostStartHandlerHttpGetPort'] = self.lifecycle_post_start_handler_http_get_port
        if self.lifecycle_post_start_handler_http_get_scheme is not None:
            result['LifecyclePostStartHandlerHttpGetScheme'] = self.lifecycle_post_start_handler_http_get_scheme
        if self.lifecycle_post_start_handler_tcp_socket_host is not None:
            result['LifecyclePostStartHandlerTcpSocketHost'] = self.lifecycle_post_start_handler_tcp_socket_host
        if self.lifecycle_post_start_handler_tcp_socket_port is not None:
            result['LifecyclePostStartHandlerTcpSocketPort'] = self.lifecycle_post_start_handler_tcp_socket_port
        if self.lifecycle_pre_stop_handler_execs is not None:
            result['LifecyclePreStopHandlerExecs'] = self.lifecycle_pre_stop_handler_execs
        if self.lifecycle_pre_stop_handler_http_get_host is not None:
            result['LifecyclePreStopHandlerHttpGetHost'] = self.lifecycle_pre_stop_handler_http_get_host
        if self.lifecycle_pre_stop_handler_http_get_path is not None:
            result['LifecyclePreStopHandlerHttpGetPath'] = self.lifecycle_pre_stop_handler_http_get_path
        if self.lifecycle_pre_stop_handler_http_get_port is not None:
            result['LifecyclePreStopHandlerHttpGetPort'] = self.lifecycle_pre_stop_handler_http_get_port
        if self.lifecycle_pre_stop_handler_http_get_scheme is not None:
            result['LifecyclePreStopHandlerHttpGetScheme'] = self.lifecycle_pre_stop_handler_http_get_scheme
        if self.lifecycle_pre_stop_handler_tcp_socket_host is not None:
            result['LifecyclePreStopHandlerTcpSocketHost'] = self.lifecycle_pre_stop_handler_tcp_socket_host
        if self.lifecycle_pre_stop_handler_tcp_socket_port is not None:
            result['LifecyclePreStopHandlerTcpSocketPort'] = self.lifecycle_pre_stop_handler_tcp_socket_port
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        result['Ports'] = []
        if self.ports is not None:
            for k in self.ports:
                result['Ports'].append(k.to_map() if k else None)
        if self.stdin is not None:
            result['Stdin'] = self.stdin
        if self.stdin_once is not None:
            result['StdinOnce'] = self.stdin_once
        if self.tty is not None:
            result['Tty'] = self.tty
        result['VolumeMounts'] = []
        if self.volume_mounts is not None:
            for k in self.volume_mounts:
                result['VolumeMounts'].append(k.to_map() if k else None)
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LivenessProbe') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersLivenessProbe()
            self.liveness_probe = temp_model.from_map(m['LivenessProbe'])
        if m.get('ReadinessProbe') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersReadinessProbe()
            self.readiness_probe = temp_model.from_map(m['ReadinessProbe'])
        if m.get('SecurityContext') is not None:
            temp_model = ModifyEciScalingConfigurationRequestContainersSecurityContext()
            self.security_context = temp_model.from_map(m['SecurityContext'])
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        self.environment_vars = []
        if m.get('EnvironmentVars') is not None:
            for k in m.get('EnvironmentVars'):
                temp_model = ModifyEciScalingConfigurationRequestContainersEnvironmentVars()
                self.environment_vars.append(temp_model.from_map(k))
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        if m.get('LifecyclePostStartHandlerExecs') is not None:
            self.lifecycle_post_start_handler_execs = m.get('LifecyclePostStartHandlerExecs')
        if m.get('LifecyclePostStartHandlerHttpGetHost') is not None:
            self.lifecycle_post_start_handler_http_get_host = m.get('LifecyclePostStartHandlerHttpGetHost')
        if m.get('LifecyclePostStartHandlerHttpGetPath') is not None:
            self.lifecycle_post_start_handler_http_get_path = m.get('LifecyclePostStartHandlerHttpGetPath')
        if m.get('LifecyclePostStartHandlerHttpGetPort') is not None:
            self.lifecycle_post_start_handler_http_get_port = m.get('LifecyclePostStartHandlerHttpGetPort')
        if m.get('LifecyclePostStartHandlerHttpGetScheme') is not None:
            self.lifecycle_post_start_handler_http_get_scheme = m.get('LifecyclePostStartHandlerHttpGetScheme')
        if m.get('LifecyclePostStartHandlerTcpSocketHost') is not None:
            self.lifecycle_post_start_handler_tcp_socket_host = m.get('LifecyclePostStartHandlerTcpSocketHost')
        if m.get('LifecyclePostStartHandlerTcpSocketPort') is not None:
            self.lifecycle_post_start_handler_tcp_socket_port = m.get('LifecyclePostStartHandlerTcpSocketPort')
        if m.get('LifecyclePreStopHandlerExecs') is not None:
            self.lifecycle_pre_stop_handler_execs = m.get('LifecyclePreStopHandlerExecs')
        if m.get('LifecyclePreStopHandlerHttpGetHost') is not None:
            self.lifecycle_pre_stop_handler_http_get_host = m.get('LifecyclePreStopHandlerHttpGetHost')
        if m.get('LifecyclePreStopHandlerHttpGetPath') is not None:
            self.lifecycle_pre_stop_handler_http_get_path = m.get('LifecyclePreStopHandlerHttpGetPath')
        if m.get('LifecyclePreStopHandlerHttpGetPort') is not None:
            self.lifecycle_pre_stop_handler_http_get_port = m.get('LifecyclePreStopHandlerHttpGetPort')
        if m.get('LifecyclePreStopHandlerHttpGetScheme') is not None:
            self.lifecycle_pre_stop_handler_http_get_scheme = m.get('LifecyclePreStopHandlerHttpGetScheme')
        if m.get('LifecyclePreStopHandlerTcpSocketHost') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_host = m.get('LifecyclePreStopHandlerTcpSocketHost')
        if m.get('LifecyclePreStopHandlerTcpSocketPort') is not None:
            self.lifecycle_pre_stop_handler_tcp_socket_port = m.get('LifecyclePreStopHandlerTcpSocketPort')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        self.ports = []
        if m.get('Ports') is not None:
            for k in m.get('Ports'):
                temp_model = ModifyEciScalingConfigurationRequestContainersPorts()
                self.ports.append(temp_model.from_map(k))
        if m.get('Stdin') is not None:
            self.stdin = m.get('Stdin')
        if m.get('StdinOnce') is not None:
            self.stdin_once = m.get('StdinOnce')
        if m.get('Tty') is not None:
            self.tty = m.get('Tty')
        self.volume_mounts = []
        if m.get('VolumeMounts') is not None:
            for k in m.get('VolumeMounts'):
                temp_model = ModifyEciScalingConfigurationRequestContainersVolumeMounts()
                self.volume_mounts.append(temp_model.from_map(k))
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class ModifyEciScalingConfigurationRequestDnsConfigOptions(TeaModel):
    def __init__(self, name=None, value=None):
        # The variable name of the option.
        self.name = name  # type: str
        # The variable value of the option.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestDnsConfigOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ModifyEciScalingConfigurationRequestHostAliases(TeaModel):
    def __init__(self, hostnames=None, ip=None):
        # The hostnames that you want to add.
        self.hostnames = hostnames  # type: list[str]
        # The IP address that you want to add.
        self.ip = ip  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestHostAliases, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.hostnames is not None:
            result['Hostnames'] = self.hostnames
        if self.ip is not None:
            result['Ip'] = self.ip
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Hostnames') is not None:
            self.hostnames = m.get('Hostnames')
        if m.get('Ip') is not None:
            self.ip = m.get('Ip')
        return self


class ModifyEciScalingConfigurationRequestImageRegistryCredentials(TeaModel):
    def __init__(self, password=None, server=None, user_name=None):
        # The password that is used to access the image repository.
        self.password = password  # type: str
        # The domain name of the image repository.
        self.server = server  # type: str
        # The username that is used to access the image repository.
        self.user_name = user_name  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestImageRegistryCredentials, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.password is not None:
            result['Password'] = self.password
        if self.server is not None:
            result['Server'] = self.server
        if self.user_name is not None:
            result['UserName'] = self.user_name
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Password') is not None:
            self.password = m.get('Password')
        if m.get('Server') is not None:
            self.server = m.get('Server')
        if m.get('UserName') is not None:
            self.user_name = m.get('UserName')
        return self


class ModifyEciScalingConfigurationRequestInitContainersSecurityContextCapability(TeaModel):
    def __init__(self, adds=None):
        self.adds = adds  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainersSecurityContextCapability, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.adds is not None:
            result['Adds'] = self.adds
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Adds') is not None:
            self.adds = m.get('Adds')
        return self


class ModifyEciScalingConfigurationRequestInitContainersSecurityContext(TeaModel):
    def __init__(self, capability=None, read_only_root_filesystem=None, run_as_user=None):
        self.capability = capability  # type: ModifyEciScalingConfigurationRequestInitContainersSecurityContextCapability
        self.read_only_root_filesystem = read_only_root_filesystem  # type: bool
        self.run_as_user = run_as_user  # type: long

    def validate(self):
        if self.capability:
            self.capability.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainersSecurityContext, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.capability is not None:
            result['Capability'] = self.capability.to_map()
        if self.read_only_root_filesystem is not None:
            result['ReadOnlyRootFilesystem'] = self.read_only_root_filesystem
        if self.run_as_user is not None:
            result['RunAsUser'] = self.run_as_user
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Capability') is not None:
            temp_model = ModifyEciScalingConfigurationRequestInitContainersSecurityContextCapability()
            self.capability = temp_model.from_map(m['Capability'])
        if m.get('ReadOnlyRootFilesystem') is not None:
            self.read_only_root_filesystem = m.get('ReadOnlyRootFilesystem')
        if m.get('RunAsUser') is not None:
            self.run_as_user = m.get('RunAsUser')
        return self


class ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVarsFieldRef(TeaModel):
    def __init__(self, field_path=None):
        self.field_path = field_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVarsFieldRef, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_path is not None:
            result['FieldPath'] = self.field_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldPath') is not None:
            self.field_path = m.get('FieldPath')
        return self


class ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars(TeaModel):
    def __init__(self, field_ref=None, key=None, value=None):
        self.field_ref = field_ref  # type: ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVarsFieldRef
        # The key of the environment variable. The key must be 1 to 128 characters in length. Specify the name in the `[0-9a-zA-Z]` format. The name can contain underscores and cannot start with a digit.
        self.key = key  # type: str
        # The value of the environment variable. The value must be 0 to 256 characters in length.
        self.value = value  # type: str

    def validate(self):
        if self.field_ref:
            self.field_ref.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.field_ref is not None:
            result['FieldRef'] = self.field_ref.to_map()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('FieldRef') is not None:
            temp_model = ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVarsFieldRef()
            self.field_ref = temp_model.from_map(m['FieldRef'])
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ModifyEciScalingConfigurationRequestInitContainersInitContainerPorts(TeaModel):
    def __init__(self, port=None, protocol=None):
        # The port number. Valid values: 1 to 65535.
        self.port = port  # type: int
        # The type of the protocol. Valid values:
        # 
        # *   TCP
        # *   UDP
        self.protocol = protocol  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainersInitContainerPorts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.port is not None:
            result['Port'] = self.port
        if self.protocol is not None:
            result['Protocol'] = self.protocol
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Port') is not None:
            self.port = m.get('Port')
        if m.get('Protocol') is not None:
            self.protocol = m.get('Protocol')
        return self


class ModifyEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts(TeaModel):
    def __init__(self, mount_path=None, mount_propagation=None, name=None, read_only=None, sub_path=None):
        # The path where the container mounts the volume.
        # 
        # >  Data stored in the path of the container is overwritten by the content of the volume.
        self.mount_path = mount_path  # type: str
        # The mount propagation setting of the volume. Mount propagation allows the sharing of volumes that are mounted on one container with other containers in the same pod, or even with other pods on the same node. Valid values:
        # 
        # *   None: The volume mount does not receive subsequent mounts that are mounted to this volume or its subdirectories.
        # *   HostToCotainer: The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories.
        # *   Bidirectional: This value is similar to HostToCotainer. The volume mount receives all subsequent mounts that are mounted to this volume or its subdirectories. In addition, all volume mounts that are created by the container are propagated back to the instance and to all containers of all pods that use the same volume.
        # 
        # Default value: None.
        self.mount_propagation = mount_propagation  # type: str
        # The name of the volume.
        self.name = name  # type: str
        # Specifies whether the mount path is read-only.
        # 
        # Default value: false.
        self.read_only = read_only  # type: bool
        # The subdirectory of the volume. The elastic container instance can mount different directories of the same volume to different subdirectories of containers.
        self.sub_path = sub_path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.mount_path is not None:
            result['MountPath'] = self.mount_path
        if self.mount_propagation is not None:
            result['MountPropagation'] = self.mount_propagation
        if self.name is not None:
            result['Name'] = self.name
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.sub_path is not None:
            result['SubPath'] = self.sub_path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MountPath') is not None:
            self.mount_path = m.get('MountPath')
        if m.get('MountPropagation') is not None:
            self.mount_propagation = m.get('MountPropagation')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('SubPath') is not None:
            self.sub_path = m.get('SubPath')
        return self


class ModifyEciScalingConfigurationRequestInitContainers(TeaModel):
    def __init__(self, security_context=None, args=None, commands=None, cpu=None, gpu=None, image=None,
                 image_pull_policy=None, init_container_environment_vars=None, init_container_ports=None,
                 init_container_volume_mounts=None, memory=None, name=None, working_dir=None):
        self.security_context = security_context  # type: ModifyEciScalingConfigurationRequestInitContainersSecurityContext
        # The startup parameter of the container.
        self.args = args  # type: list[str]
        # The commands that you want to run to start the container.
        self.commands = commands  # type: list[str]
        # The number of vCPUs that you want to allocate to the container.
        self.cpu = cpu  # type: float
        # The number of GPUs that you want to allocate to the container.
        self.gpu = gpu  # type: int
        # The container image.
        self.image = image  # type: str
        # The image pulling policy. Valid values:
        # 
        # *   Always: pulls images each time.
        # *   IfNotPresent: pulls images only if no on-premises images are available. On-premises images are preferentially used. If no on-premises images are available, image pulling is performed.
        # *   Never: never pulls images. On-premises images are always used. Image pulling is not performed.
        self.image_pull_policy = image_pull_policy  # type: str
        # The environment variables of the init container.
        self.init_container_environment_vars = init_container_environment_vars  # type: list[ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars]
        # The ports of the init container.
        self.init_container_ports = init_container_ports  # type: list[ModifyEciScalingConfigurationRequestInitContainersInitContainerPorts]
        # Information about the volume mounts of the init container.
        self.init_container_volume_mounts = init_container_volume_mounts  # type: list[ModifyEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts]
        # The size of the memory. Unit: GiB.
        self.memory = memory  # type: float
        # The name of the container.
        self.name = name  # type: str
        # The working directory.
        self.working_dir = working_dir  # type: str

    def validate(self):
        if self.security_context:
            self.security_context.validate()
        if self.init_container_environment_vars:
            for k in self.init_container_environment_vars:
                if k:
                    k.validate()
        if self.init_container_ports:
            for k in self.init_container_ports:
                if k:
                    k.validate()
        if self.init_container_volume_mounts:
            for k in self.init_container_volume_mounts:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestInitContainers, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.security_context is not None:
            result['SecurityContext'] = self.security_context.to_map()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.gpu is not None:
            result['Gpu'] = self.gpu
        if self.image is not None:
            result['Image'] = self.image
        if self.image_pull_policy is not None:
            result['ImagePullPolicy'] = self.image_pull_policy
        result['InitContainerEnvironmentVars'] = []
        if self.init_container_environment_vars is not None:
            for k in self.init_container_environment_vars:
                result['InitContainerEnvironmentVars'].append(k.to_map() if k else None)
        result['InitContainerPorts'] = []
        if self.init_container_ports is not None:
            for k in self.init_container_ports:
                result['InitContainerPorts'].append(k.to_map() if k else None)
        result['InitContainerVolumeMounts'] = []
        if self.init_container_volume_mounts is not None:
            for k in self.init_container_volume_mounts:
                result['InitContainerVolumeMounts'].append(k.to_map() if k else None)
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        if self.working_dir is not None:
            result['WorkingDir'] = self.working_dir
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('SecurityContext') is not None:
            temp_model = ModifyEciScalingConfigurationRequestInitContainersSecurityContext()
            self.security_context = temp_model.from_map(m['SecurityContext'])
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('Gpu') is not None:
            self.gpu = m.get('Gpu')
        if m.get('Image') is not None:
            self.image = m.get('Image')
        if m.get('ImagePullPolicy') is not None:
            self.image_pull_policy = m.get('ImagePullPolicy')
        self.init_container_environment_vars = []
        if m.get('InitContainerEnvironmentVars') is not None:
            for k in m.get('InitContainerEnvironmentVars'):
                temp_model = ModifyEciScalingConfigurationRequestInitContainersInitContainerEnvironmentVars()
                self.init_container_environment_vars.append(temp_model.from_map(k))
        self.init_container_ports = []
        if m.get('InitContainerPorts') is not None:
            for k in m.get('InitContainerPorts'):
                temp_model = ModifyEciScalingConfigurationRequestInitContainersInitContainerPorts()
                self.init_container_ports.append(temp_model.from_map(k))
        self.init_container_volume_mounts = []
        if m.get('InitContainerVolumeMounts') is not None:
            for k in m.get('InitContainerVolumeMounts'):
                temp_model = ModifyEciScalingConfigurationRequestInitContainersInitContainerVolumeMounts()
                self.init_container_volume_mounts.append(temp_model.from_map(k))
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('WorkingDir') is not None:
            self.working_dir = m.get('WorkingDir')
        return self


class ModifyEciScalingConfigurationRequestSecurityContextSysCtls(TeaModel):
    def __init__(self, name=None, value=None):
        # The name of the security context in which the elastic container instance runs.
        self.name = name  # type: str
        # The variable value of the security context in which the elastic container instance runs.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestSecurityContextSysCtls, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.name is not None:
            result['Name'] = self.name
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ModifyEciScalingConfigurationRequestTags(TeaModel):
    def __init__(self, key=None, value=None):
        # The key of the tag.
        self.key = key  # type: str
        # The value of the tag.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ModifyEciScalingConfigurationRequestVolumesDiskVolume(TeaModel):
    def __init__(self, disk_id=None, disk_size=None, fs_type=None):
        self.disk_id = disk_id  # type: str
        self.disk_size = disk_size  # type: int
        self.fs_type = fs_type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumesDiskVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disk_id is not None:
            result['DiskId'] = self.disk_id
        if self.disk_size is not None:
            result['DiskSize'] = self.disk_size
        if self.fs_type is not None:
            result['FsType'] = self.fs_type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DiskId') is not None:
            self.disk_id = m.get('DiskId')
        if m.get('DiskSize') is not None:
            self.disk_size = m.get('DiskSize')
        if m.get('FsType') is not None:
            self.fs_type = m.get('FsType')
        return self


class ModifyEciScalingConfigurationRequestVolumesEmptyDirVolume(TeaModel):
    def __init__(self, medium=None, size_limit=None):
        self.medium = medium  # type: str
        self.size_limit = size_limit  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumesEmptyDirVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.medium is not None:
            result['Medium'] = self.medium
        if self.size_limit is not None:
            result['SizeLimit'] = self.size_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Medium') is not None:
            self.medium = m.get('Medium')
        if m.get('SizeLimit') is not None:
            self.size_limit = m.get('SizeLimit')
        return self


class ModifyEciScalingConfigurationRequestVolumesFlexVolume(TeaModel):
    def __init__(self, driver=None, fs_type=None, options=None):
        self.driver = driver  # type: str
        self.fs_type = fs_type  # type: str
        self.options = options  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumesFlexVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.driver is not None:
            result['Driver'] = self.driver
        if self.fs_type is not None:
            result['FsType'] = self.fs_type
        if self.options is not None:
            result['Options'] = self.options
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Driver') is not None:
            self.driver = m.get('Driver')
        if m.get('FsType') is not None:
            self.fs_type = m.get('FsType')
        if m.get('Options') is not None:
            self.options = m.get('Options')
        return self


class ModifyEciScalingConfigurationRequestVolumesHostPathVolume(TeaModel):
    def __init__(self, path=None, type=None):
        self.path = path  # type: str
        self.type = type  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumesHostPathVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class ModifyEciScalingConfigurationRequestVolumesNFSVolume(TeaModel):
    def __init__(self, path=None, read_only=None, server=None):
        self.path = path  # type: str
        self.read_only = read_only  # type: bool
        self.server = server  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumesNFSVolume, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.path is not None:
            result['Path'] = self.path
        if self.read_only is not None:
            result['ReadOnly'] = self.read_only
        if self.server is not None:
            result['Server'] = self.server
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Path') is not None:
            self.path = m.get('Path')
        if m.get('ReadOnly') is not None:
            self.read_only = m.get('ReadOnly')
        if m.get('Server') is not None:
            self.server = m.get('Server')
        return self


class ModifyEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPath(TeaModel):
    def __init__(self, content=None, mode=None, path=None):
        # The content of the configuration file, which can be up to 32 KB in size.
        self.content = content  # type: str
        # The permissions on ConfigFileVolume.
        self.mode = mode  # type: int
        # The relative path to the configuration file.
        self.path = path  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPath, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.content is not None:
            result['Content'] = self.content
        if self.mode is not None:
            result['Mode'] = self.mode
        if self.path is not None:
            result['Path'] = self.path
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Content') is not None:
            self.content = m.get('Content')
        if m.get('Mode') is not None:
            self.mode = m.get('Mode')
        if m.get('Path') is not None:
            self.path = m.get('Path')
        return self


class ModifyEciScalingConfigurationRequestVolumes(TeaModel):
    def __init__(self, disk_volume=None, empty_dir_volume=None, flex_volume=None, host_path_volume=None,
                 nfsvolume=None, config_file_volume_config_file_to_path=None, config_file_volume_default_mode=None,
                 name=None, type=None):
        self.disk_volume = disk_volume  # type: ModifyEciScalingConfigurationRequestVolumesDiskVolume
        self.empty_dir_volume = empty_dir_volume  # type: ModifyEciScalingConfigurationRequestVolumesEmptyDirVolume
        self.flex_volume = flex_volume  # type: ModifyEciScalingConfigurationRequestVolumesFlexVolume
        self.host_path_volume = host_path_volume  # type: ModifyEciScalingConfigurationRequestVolumesHostPathVolume
        self.nfsvolume = nfsvolume  # type: ModifyEciScalingConfigurationRequestVolumesNFSVolume
        # The paths to the configuration files.
        self.config_file_volume_config_file_to_path = config_file_volume_config_file_to_path  # type: list[ModifyEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPath]
        # The default permissions on ConfigFileVolume.
        self.config_file_volume_default_mode = config_file_volume_default_mode  # type: int
        # The name of the volume.
        self.name = name  # type: str
        # The type of HostPathVolume. Examples: File, Directory, and Socket.
        self.type = type  # type: str

    def validate(self):
        if self.disk_volume:
            self.disk_volume.validate()
        if self.empty_dir_volume:
            self.empty_dir_volume.validate()
        if self.flex_volume:
            self.flex_volume.validate()
        if self.host_path_volume:
            self.host_path_volume.validate()
        if self.nfsvolume:
            self.nfsvolume.validate()
        if self.config_file_volume_config_file_to_path:
            for k in self.config_file_volume_config_file_to_path:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequestVolumes, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disk_volume is not None:
            result['DiskVolume'] = self.disk_volume.to_map()
        if self.empty_dir_volume is not None:
            result['EmptyDirVolume'] = self.empty_dir_volume.to_map()
        if self.flex_volume is not None:
            result['FlexVolume'] = self.flex_volume.to_map()
        if self.host_path_volume is not None:
            result['HostPathVolume'] = self.host_path_volume.to_map()
        if self.nfsvolume is not None:
            result['NFSVolume'] = self.nfsvolume.to_map()
        result['ConfigFileVolumeConfigFileToPath'] = []
        if self.config_file_volume_config_file_to_path is not None:
            for k in self.config_file_volume_config_file_to_path:
                result['ConfigFileVolumeConfigFileToPath'].append(k.to_map() if k else None)
        if self.config_file_volume_default_mode is not None:
            result['ConfigFileVolumeDefaultMode'] = self.config_file_volume_default_mode
        if self.name is not None:
            result['Name'] = self.name
        if self.type is not None:
            result['Type'] = self.type
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DiskVolume') is not None:
            temp_model = ModifyEciScalingConfigurationRequestVolumesDiskVolume()
            self.disk_volume = temp_model.from_map(m['DiskVolume'])
        if m.get('EmptyDirVolume') is not None:
            temp_model = ModifyEciScalingConfigurationRequestVolumesEmptyDirVolume()
            self.empty_dir_volume = temp_model.from_map(m['EmptyDirVolume'])
        if m.get('FlexVolume') is not None:
            temp_model = ModifyEciScalingConfigurationRequestVolumesFlexVolume()
            self.flex_volume = temp_model.from_map(m['FlexVolume'])
        if m.get('HostPathVolume') is not None:
            temp_model = ModifyEciScalingConfigurationRequestVolumesHostPathVolume()
            self.host_path_volume = temp_model.from_map(m['HostPathVolume'])
        if m.get('NFSVolume') is not None:
            temp_model = ModifyEciScalingConfigurationRequestVolumesNFSVolume()
            self.nfsvolume = temp_model.from_map(m['NFSVolume'])
        self.config_file_volume_config_file_to_path = []
        if m.get('ConfigFileVolumeConfigFileToPath') is not None:
            for k in m.get('ConfigFileVolumeConfigFileToPath'):
                temp_model = ModifyEciScalingConfigurationRequestVolumesConfigFileVolumeConfigFileToPath()
                self.config_file_volume_config_file_to_path.append(temp_model.from_map(k))
        if m.get('ConfigFileVolumeDefaultMode') is not None:
            self.config_file_volume_default_mode = m.get('ConfigFileVolumeDefaultMode')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        if m.get('Type') is not None:
            self.type = m.get('Type')
        return self


class ModifyEciScalingConfigurationRequest(TeaModel):
    def __init__(self, acr_registry_infos=None, active_deadline_seconds=None, auto_create_eip=None,
                 auto_match_image_cache=None, container_group_name=None, containers=None, containers_update_type=None,
                 cost_optimization=None, cpu=None, cpu_options_core=None, cpu_options_threads_per_core=None, data_cache_bucket=None,
                 data_cache_bursting_enabled=None, data_cache_pl=None, data_cache_provisioned_iops=None, description=None,
                 dns_config_name_servers=None, dns_config_options=None, dns_config_searchs=None, dns_policy=None, egress_bandwidth=None,
                 eip_bandwidth=None, enable_sls=None, ephemeral_storage=None, host_aliases=None, host_name=None,
                 image_registry_credentials=None, image_snapshot_id=None, ingress_bandwidth=None, init_containers=None,
                 instance_family_level=None, instance_types=None, ipv_6address_count=None, load_balancer_weight=None, memory=None,
                 ntp_servers=None, owner_id=None, ram_role_name=None, resource_group_id=None, resource_owner_account=None,
                 restart_policy=None, scaling_configuration_id=None, scaling_configuration_name=None,
                 security_context_sys_ctls=None, security_group_id=None, spot_price_limit=None, spot_strategy=None, tags=None,
                 termination_grace_period_seconds=None, volumes=None):
        # Information about the Container Registry Enterprise Edition instance.
        self.acr_registry_infos = acr_registry_infos  # type: list[ModifyEciScalingConfigurationRequestAcrRegistryInfos]
        # The validity period. Unit: seconds.
        self.active_deadline_seconds = active_deadline_seconds  # type: long
        # Specifies whether to automatically create an elastic IP address (EIP) and bind the EIP to the elastic container instance.
        self.auto_create_eip = auto_create_eip  # type: bool
        # Specifies whether to automatically match the image cache.
        # 
        # Default value: false.
        self.auto_match_image_cache = auto_match_image_cache  # type: bool
        # The name of the elastic container instance. The name must meet the following requirements:
        # 
        # *   The name must be 2 to 128 characters in length
        # *   The name can contain only lowercase letters, digits, and hyphens (-). It cannot start or end with a hyphen (-).
        self.container_group_name = container_group_name  # type: str
        # The containers.
        self.containers = containers  # type: list[ModifyEciScalingConfigurationRequestContainers]
        self.containers_update_type = containers_update_type  # type: str
        # Specifies whether to enable the cost optimization feature. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.cost_optimization = cost_optimization  # type: bool
        # The number of vCPUs of the elastic container instance.
        self.cpu = cpu  # type: float
        # The number of physical CPU cores. This parameter is not available for all instance types. For more information, see [Specify custom CPU options](~~197781~~).
        self.cpu_options_core = cpu_options_core  # type: int
        # The number of threads per core. This parameter is not available for all instance types. A value of 1 indicates that Hyper-Threading is disabled. For more information, see [Specify custom CPU options](~~197781~~).
        self.cpu_options_threads_per_core = cpu_options_threads_per_core  # type: int
        self.data_cache_bucket = data_cache_bucket  # type: str
        self.data_cache_bursting_enabled = data_cache_bursting_enabled  # type: bool
        self.data_cache_pl = data_cache_pl  # type: str
        self.data_cache_provisioned_iops = data_cache_provisioned_iops  # type: int
        # > This parameter is unavailable.
        self.description = description  # type: str
        # The IP addresses of the DNS servers.
        self.dns_config_name_servers = dns_config_name_servers  # type: list[str]
        # The options. Each option is a name-value pair. The value in the name-value pair is optional.
        self.dns_config_options = dns_config_options  # type: list[ModifyEciScalingConfigurationRequestDnsConfigOptions]
        # The DNS lookup domains.
        self.dns_config_searchs = dns_config_searchs  # type: list[str]
        # The Domain Name System (DNS) policy. Valid values:
        # 
        # *   None: uses the DNS that is set for the DnsConfig field.
        # *   Default: use the DNS that is set for the runtime environment.
        self.dns_policy = dns_policy  # type: str
        # The maximum outbound bandwidth. Unit: bit/s.
        self.egress_bandwidth = egress_bandwidth  # type: long
        # The bandwidth of the EIP.
        # 
        # Default value: 5. Unit: Mbit/s.
        self.eip_bandwidth = eip_bandwidth  # type: int
        # > This parameter is unavailable.
        self.enable_sls = enable_sls  # type: bool
        # The size of the temporary storage space. By default, an enhanced SSD (ESSD) of the PL1 level is used. Unit: GiB.
        self.ephemeral_storage = ephemeral_storage  # type: int
        # Information about the hosts.
        self.host_aliases = host_aliases  # type: list[ModifyEciScalingConfigurationRequestHostAliases]
        # The name of the elastic container instance.
        self.host_name = host_name  # type: str
        # Information about the image repository.
        self.image_registry_credentials = image_registry_credentials  # type: list[ModifyEciScalingConfigurationRequestImageRegistryCredentials]
        # The ID of the image cache.
        self.image_snapshot_id = image_snapshot_id  # type: str
        # The maximum inbound bandwidth. Unit: bit/s.
        self.ingress_bandwidth = ingress_bandwidth  # type: long
        # The init containers.
        self.init_containers = init_containers  # type: list[ModifyEciScalingConfigurationRequestInitContainers]
        # The level of the instance type, which is used to filter the instance types that meet the specified criteria. This parameter takes effect only if you set the `CostOptimization` parameter to true. Valid values:
        # 
        # *   EntryLevel: shared instance type. Instances of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instances of this level are suitable for business scenarios in which the CPU utilization is low. For more information, see [Shared instance families](~~108489~~).
        # *   EnterpriseLevel: Instances of this level provide stable performance and dedicated resources, and are suitable for business scenarios that require high stability. For more information, see [Instance family](~~25378~~).
        # *   CreditEntryLevel: This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instances of this level are suitable for scenarios in which the CPU utilization is low but may fluctuate in specific cases. For more information, see the [Overview](~~59977~~) topic of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        self.instance_types = instance_types  # type: list[str]
        # The number of IPv6 addresses.
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The weight of the elastic container instance as a backend server. Valid values: 1 to 100.
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size of the elastic container instance. Unit: GiB.
        self.memory = memory  # type: float
        # The domain names of the NTP server.
        self.ntp_servers = ntp_servers  # type: list[str]
        self.owner_id = owner_id  # type: long
        # The name of the RAM role for the instance. You can use an instance RAM role to access both elastic container instances and Elastic Compute Service (ECS) instances. For more information, see [Use an instance RAM role by calling API operations](~~61178~~).
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The instance restart policy. Valid values:
        # 
        # *   Always: always restarts the elastic container instance.
        # *   Never: never restarts the elastic container instance.
        # *   OnFailure: restarts the elastic container instance upon failures.
        # 
        # Default value: Always.
        self.restart_policy = restart_policy  # type: str
        # The ID of the scaling configuration that you want to modify.
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        # The name of the scaling configuration. The name must be 2 to 64 characters in length and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # The name of the scaling configuration must be unique within a scaling group in a region. If you do not specify this parameter, the value of the ScalingConfigurationId parameter is used.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The system information of the security context in which the elastic container instance runs.
        self.security_context_sys_ctls = security_context_sys_ctls  # type: list[ModifyEciScalingConfigurationRequestSecurityContextSysCtls]
        # The ID of the security group with which you want to associate the elastic container instance. Elastic container instances that are associated with the same security group can access each other.
        # 
        # If you do not specify a security group, the system uses the default security group in the region that you selected. Make sure that the inbound rules of the security group contain the protocols and the port numbers of the containers that you want to expose. If you do not have a default security group in the region, the system creates a default security group, and then adds the declared container protocols and port numbers to the inbound rules of the security group.
        self.security_group_id = security_group_id  # type: str
        # The maximum hourly price of the preemptible elastic container instance. The value can be accurate to three decimal places.
        # 
        # If you set the SpotStrategy parameter to SpotWithPriceLimit, you must also specify the SpotPriceLimit parameter.
        self.spot_price_limit = spot_price_limit  # type: float
        # The bidding policy for the elastic container instance. Valid values:
        # 
        # *   NoSpot: The instance is a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance with a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is a preemptible instance for which the market price at the time of purchase is used as the bid price.
        # 
        # Default value: NoSpot.
        self.spot_strategy = spot_strategy  # type: str
        # Information about the tags.
        self.tags = tags  # type: list[ModifyEciScalingConfigurationRequestTags]
        # The buffer time in which the program handles operations before the program is stopped. Unit: seconds.
        self.termination_grace_period_seconds = termination_grace_period_seconds  # type: long
        # Information about the volumes.
        self.volumes = volumes  # type: list[ModifyEciScalingConfigurationRequestVolumes]

    def validate(self):
        if self.acr_registry_infos:
            for k in self.acr_registry_infos:
                if k:
                    k.validate()
        if self.containers:
            for k in self.containers:
                if k:
                    k.validate()
        if self.dns_config_options:
            for k in self.dns_config_options:
                if k:
                    k.validate()
        if self.host_aliases:
            for k in self.host_aliases:
                if k:
                    k.validate()
        if self.image_registry_credentials:
            for k in self.image_registry_credentials:
                if k:
                    k.validate()
        if self.init_containers:
            for k in self.init_containers:
                if k:
                    k.validate()
        if self.security_context_sys_ctls:
            for k in self.security_context_sys_ctls:
                if k:
                    k.validate()
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()
        if self.volumes:
            for k in self.volumes:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['AcrRegistryInfos'] = []
        if self.acr_registry_infos is not None:
            for k in self.acr_registry_infos:
                result['AcrRegistryInfos'].append(k.to_map() if k else None)
        if self.active_deadline_seconds is not None:
            result['ActiveDeadlineSeconds'] = self.active_deadline_seconds
        if self.auto_create_eip is not None:
            result['AutoCreateEip'] = self.auto_create_eip
        if self.auto_match_image_cache is not None:
            result['AutoMatchImageCache'] = self.auto_match_image_cache
        if self.container_group_name is not None:
            result['ContainerGroupName'] = self.container_group_name
        result['Containers'] = []
        if self.containers is not None:
            for k in self.containers:
                result['Containers'].append(k.to_map() if k else None)
        if self.containers_update_type is not None:
            result['ContainersUpdateType'] = self.containers_update_type
        if self.cost_optimization is not None:
            result['CostOptimization'] = self.cost_optimization
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.cpu_options_core is not None:
            result['CpuOptionsCore'] = self.cpu_options_core
        if self.cpu_options_threads_per_core is not None:
            result['CpuOptionsThreadsPerCore'] = self.cpu_options_threads_per_core
        if self.data_cache_bucket is not None:
            result['DataCacheBucket'] = self.data_cache_bucket
        if self.data_cache_bursting_enabled is not None:
            result['DataCacheBurstingEnabled'] = self.data_cache_bursting_enabled
        if self.data_cache_pl is not None:
            result['DataCachePL'] = self.data_cache_pl
        if self.data_cache_provisioned_iops is not None:
            result['DataCacheProvisionedIops'] = self.data_cache_provisioned_iops
        if self.description is not None:
            result['Description'] = self.description
        if self.dns_config_name_servers is not None:
            result['DnsConfigNameServers'] = self.dns_config_name_servers
        result['DnsConfigOptions'] = []
        if self.dns_config_options is not None:
            for k in self.dns_config_options:
                result['DnsConfigOptions'].append(k.to_map() if k else None)
        if self.dns_config_searchs is not None:
            result['DnsConfigSearchs'] = self.dns_config_searchs
        if self.dns_policy is not None:
            result['DnsPolicy'] = self.dns_policy
        if self.egress_bandwidth is not None:
            result['EgressBandwidth'] = self.egress_bandwidth
        if self.eip_bandwidth is not None:
            result['EipBandwidth'] = self.eip_bandwidth
        if self.enable_sls is not None:
            result['EnableSls'] = self.enable_sls
        if self.ephemeral_storage is not None:
            result['EphemeralStorage'] = self.ephemeral_storage
        result['HostAliases'] = []
        if self.host_aliases is not None:
            for k in self.host_aliases:
                result['HostAliases'].append(k.to_map() if k else None)
        if self.host_name is not None:
            result['HostName'] = self.host_name
        result['ImageRegistryCredentials'] = []
        if self.image_registry_credentials is not None:
            for k in self.image_registry_credentials:
                result['ImageRegistryCredentials'].append(k.to_map() if k else None)
        if self.image_snapshot_id is not None:
            result['ImageSnapshotId'] = self.image_snapshot_id
        if self.ingress_bandwidth is not None:
            result['IngressBandwidth'] = self.ingress_bandwidth
        result['InitContainers'] = []
        if self.init_containers is not None:
            for k in self.init_containers:
                result['InitContainers'].append(k.to_map() if k else None)
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.ntp_servers is not None:
            result['NtpServers'] = self.ntp_servers
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.restart_policy is not None:
            result['RestartPolicy'] = self.restart_policy
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        result['SecurityContextSysCtls'] = []
        if self.security_context_sys_ctls is not None:
            for k in self.security_context_sys_ctls:
                result['SecurityContextSysCtls'].append(k.to_map() if k else None)
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        if self.termination_grace_period_seconds is not None:
            result['TerminationGracePeriodSeconds'] = self.termination_grace_period_seconds
        result['Volumes'] = []
        if self.volumes is not None:
            for k in self.volumes:
                result['Volumes'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.acr_registry_infos = []
        if m.get('AcrRegistryInfos') is not None:
            for k in m.get('AcrRegistryInfos'):
                temp_model = ModifyEciScalingConfigurationRequestAcrRegistryInfos()
                self.acr_registry_infos.append(temp_model.from_map(k))
        if m.get('ActiveDeadlineSeconds') is not None:
            self.active_deadline_seconds = m.get('ActiveDeadlineSeconds')
        if m.get('AutoCreateEip') is not None:
            self.auto_create_eip = m.get('AutoCreateEip')
        if m.get('AutoMatchImageCache') is not None:
            self.auto_match_image_cache = m.get('AutoMatchImageCache')
        if m.get('ContainerGroupName') is not None:
            self.container_group_name = m.get('ContainerGroupName')
        self.containers = []
        if m.get('Containers') is not None:
            for k in m.get('Containers'):
                temp_model = ModifyEciScalingConfigurationRequestContainers()
                self.containers.append(temp_model.from_map(k))
        if m.get('ContainersUpdateType') is not None:
            self.containers_update_type = m.get('ContainersUpdateType')
        if m.get('CostOptimization') is not None:
            self.cost_optimization = m.get('CostOptimization')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CpuOptionsCore') is not None:
            self.cpu_options_core = m.get('CpuOptionsCore')
        if m.get('CpuOptionsThreadsPerCore') is not None:
            self.cpu_options_threads_per_core = m.get('CpuOptionsThreadsPerCore')
        if m.get('DataCacheBucket') is not None:
            self.data_cache_bucket = m.get('DataCacheBucket')
        if m.get('DataCacheBurstingEnabled') is not None:
            self.data_cache_bursting_enabled = m.get('DataCacheBurstingEnabled')
        if m.get('DataCachePL') is not None:
            self.data_cache_pl = m.get('DataCachePL')
        if m.get('DataCacheProvisionedIops') is not None:
            self.data_cache_provisioned_iops = m.get('DataCacheProvisionedIops')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DnsConfigNameServers') is not None:
            self.dns_config_name_servers = m.get('DnsConfigNameServers')
        self.dns_config_options = []
        if m.get('DnsConfigOptions') is not None:
            for k in m.get('DnsConfigOptions'):
                temp_model = ModifyEciScalingConfigurationRequestDnsConfigOptions()
                self.dns_config_options.append(temp_model.from_map(k))
        if m.get('DnsConfigSearchs') is not None:
            self.dns_config_searchs = m.get('DnsConfigSearchs')
        if m.get('DnsPolicy') is not None:
            self.dns_policy = m.get('DnsPolicy')
        if m.get('EgressBandwidth') is not None:
            self.egress_bandwidth = m.get('EgressBandwidth')
        if m.get('EipBandwidth') is not None:
            self.eip_bandwidth = m.get('EipBandwidth')
        if m.get('EnableSls') is not None:
            self.enable_sls = m.get('EnableSls')
        if m.get('EphemeralStorage') is not None:
            self.ephemeral_storage = m.get('EphemeralStorage')
        self.host_aliases = []
        if m.get('HostAliases') is not None:
            for k in m.get('HostAliases'):
                temp_model = ModifyEciScalingConfigurationRequestHostAliases()
                self.host_aliases.append(temp_model.from_map(k))
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        self.image_registry_credentials = []
        if m.get('ImageRegistryCredentials') is not None:
            for k in m.get('ImageRegistryCredentials'):
                temp_model = ModifyEciScalingConfigurationRequestImageRegistryCredentials()
                self.image_registry_credentials.append(temp_model.from_map(k))
        if m.get('ImageSnapshotId') is not None:
            self.image_snapshot_id = m.get('ImageSnapshotId')
        if m.get('IngressBandwidth') is not None:
            self.ingress_bandwidth = m.get('IngressBandwidth')
        self.init_containers = []
        if m.get('InitContainers') is not None:
            for k in m.get('InitContainers'):
                temp_model = ModifyEciScalingConfigurationRequestInitContainers()
                self.init_containers.append(temp_model.from_map(k))
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('NtpServers') is not None:
            self.ntp_servers = m.get('NtpServers')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('RestartPolicy') is not None:
            self.restart_policy = m.get('RestartPolicy')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        self.security_context_sys_ctls = []
        if m.get('SecurityContextSysCtls') is not None:
            for k in m.get('SecurityContextSysCtls'):
                temp_model = ModifyEciScalingConfigurationRequestSecurityContextSysCtls()
                self.security_context_sys_ctls.append(temp_model.from_map(k))
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = ModifyEciScalingConfigurationRequestTags()
                self.tags.append(temp_model.from_map(k))
        if m.get('TerminationGracePeriodSeconds') is not None:
            self.termination_grace_period_seconds = m.get('TerminationGracePeriodSeconds')
        self.volumes = []
        if m.get('Volumes') is not None:
            for k in m.get('Volumes'):
                temp_model = ModifyEciScalingConfigurationRequestVolumes()
                self.volumes.append(temp_model.from_map(k))
        return self


class ModifyEciScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyEciScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyEciScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyEciScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyEciScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyInstanceAttributeRequest(TeaModel):
    def __init__(self, entrusted=None, instance_id=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scaling_group_id=None):
        self.entrusted = entrusted  # type: bool
        self.instance_id = instance_id  # type: str
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyInstanceAttributeRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.entrusted is not None:
            result['Entrusted'] = self.entrusted
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Entrusted') is not None:
            self.entrusted = m.get('Entrusted')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ModifyInstanceAttributeResponseBody(TeaModel):
    def __init__(self, request_id=None):
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyInstanceAttributeResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyInstanceAttributeResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyInstanceAttributeResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyInstanceAttributeResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyInstanceAttributeResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyLifecycleHookRequest(TeaModel):
    def __init__(self, default_result=None, heartbeat_timeout=None, lifecycle_hook_id=None,
                 lifecycle_hook_name=None, lifecycle_hook_status=None, lifecycle_transition=None, notification_arn=None,
                 notification_metadata=None, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scaling_group_id=None):
        # The action that you want Auto Scaling to perform after the lifecycle hook times out. Valid values:
        # 
        # *   CONTINUE: Auto Scaling continues to respond to scale-in or scale-out requests.
        # *   ABANDON: Auto Scaling releases Elastic Compute Service (ECS) instances that are created during scale-out activities or removes ECS instances from the scaling group during scale-in activities.
        # *   ROLLBACK: For scale-in activities, Auto Scaling rejects the requests to release ECS instances but rolls back ECS instances. For scale-out activities, the ROLLBACK setting has the same effect as the ABANDON setting.
        # 
        # If a scaling group has multiple lifecycle hooks in effect and you set the DefaultResult parameter for one of the lifecycle hooks to ABANDON or ROLLBACK, the following rule applies to scale-in activities: When the lifecycle hook whose DefaultResult parameter is set to ABANDON or ROLLBACK times out, other lifecycle hooks time out ahead of schedule. In other cases, Auto Scaling performs the action only after all lifecycle hooks time out. The action that Auto Scaling performs is specified by the DefaultResult parameter of the last lifecycle hook that times out.
        self.default_result = default_result  # type: str
        # The period of time before the lifecycle hook times out. When the lifecycle hook times out, Auto Scaling performs the action specified by the DefaultResult parameter. Valid values: 30 to 21600. Unit: seconds.
        # 
        # You can call the RecordLifecycleActionHeartbeat operation to extend the period of time before a lifecycle hook times out. You can also call the CompleteLifecycleAction operation to end a lifecycle hook ahead of schedule.
        self.heartbeat_timeout = heartbeat_timeout  # type: int
        # The ID of the lifecycle hook that you want to modify.
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str
        # The name of the lifecycle hook that you want to modify.
        self.lifecycle_hook_name = lifecycle_hook_name  # type: str
        # The status that you want to specify for the lifecycle hook. Valid values:
        # 
        # *   Active
        # *   InActive
        # 
        # If you do not specify this parameter, the status of the lifecycle hook remains unchanged after you call this operation.
        # 
        # > By default, a lifecycle hook is in the Active state after you create it.
        self.lifecycle_hook_status = lifecycle_hook_status  # type: str
        # The type of the scaling activity to which the lifecycle hook applies. Valid values:
        # 
        # *   SCALE_OUT: scale-out activity
        # *   SCALE_IN: scale-in activity
        self.lifecycle_transition = lifecycle_transition  # type: str
        # The Alibaba Cloud Resource Name (ARN) of the notification method.
        # 
        # *   If the notification method is a Message Service (MNS) queue, specify the value in the acs:mns:{region-id}:{account-id}:queue/{queuename} format.
        # *   If the notification method is an MNS topic, specify the value in the acs:mns:{region-id}:{account-id}:topic/{topicname} format.
        # *   If the notification method is an Operation Orchestration Service (OOS) template, specify the value in the acs:oos:{region-id}:{account-id}:template/{templatename} format.
        # 
        # The variables in the preceding formats have the following meanings:
        # 
        # *   region-id: the region ID of the scaling group.
        # *   account-id: the ID of the Alibaba Cloud account.
        # *   queuename: the name of the MNS queue.
        # *   topicname: the name of the MNS topic.
        # *   templatename: the name of the OOS template.
        self.notification_arn = notification_arn  # type: str
        # The fixed string that is included in a notification. Auto Scaling sends the notification when the lifecycle hook takes effect. The value of this parameter cannot exceed 4,096 characters in length.
        # 
        # Auto Scaling sends the value of the NotificationMetadata parameter together with the notification. This helps you categorize your notifications. If you specify the NotificationMetadata parameter, you must also specify the NotificationArn parameter.
        self.notification_metadata = notification_metadata  # type: str
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group to which the lifecycle hook belongs.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyLifecycleHookRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.default_result is not None:
            result['DefaultResult'] = self.default_result
        if self.heartbeat_timeout is not None:
            result['HeartbeatTimeout'] = self.heartbeat_timeout
        if self.lifecycle_hook_id is not None:
            result['LifecycleHookId'] = self.lifecycle_hook_id
        if self.lifecycle_hook_name is not None:
            result['LifecycleHookName'] = self.lifecycle_hook_name
        if self.lifecycle_hook_status is not None:
            result['LifecycleHookStatus'] = self.lifecycle_hook_status
        if self.lifecycle_transition is not None:
            result['LifecycleTransition'] = self.lifecycle_transition
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_metadata is not None:
            result['NotificationMetadata'] = self.notification_metadata
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DefaultResult') is not None:
            self.default_result = m.get('DefaultResult')
        if m.get('HeartbeatTimeout') is not None:
            self.heartbeat_timeout = m.get('HeartbeatTimeout')
        if m.get('LifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('LifecycleHookId')
        if m.get('LifecycleHookName') is not None:
            self.lifecycle_hook_name = m.get('LifecycleHookName')
        if m.get('LifecycleHookStatus') is not None:
            self.lifecycle_hook_status = m.get('LifecycleHookStatus')
        if m.get('LifecycleTransition') is not None:
            self.lifecycle_transition = m.get('LifecycleTransition')
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationMetadata') is not None:
            self.notification_metadata = m.get('NotificationMetadata')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ModifyLifecycleHookResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyLifecycleHookResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyLifecycleHookResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyLifecycleHookResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyLifecycleHookResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyLifecycleHookResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyNotificationConfigurationRequest(TeaModel):
    def __init__(self, notification_arn=None, notification_types=None, owner_id=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The Alibaba Cloud Resource Name (ARN) of the notification method. The following list describes the value formats of this parameter:
        # 
        # *   If you use CloudMonitor as the notification method, the value format of this parameter is acs:ess:{region-id}:{account-id}:cloudmonitor.
        # *   If you use an MNS queue as the notification method, the value format of this parameter is acs:mns:{region-id}:{account-id}:queue/{queuename}.
        # *   If you use an MNS topic as the notification method, the value format of this parameter is acs:mns:{region-id}:{account-id}:topic/{topicname}.
        # 
        # The variables in the preceding formats have the following meanings:
        # 
        # *   region-id: the region ID of the scaling group.
        # *   account-id: the ID of the Alibaba Cloud account.
        # *   queuename: the name of the MNS queue.
        # *   topicname: the name of the MNS topic.
        self.notification_arn = notification_arn  # type: str
        # The types of the notifications that you want to modify. You can modify one to eight notifications. Specify multiple values in the repeated list form.
        # 
        # You can call the DescribeNotificationTypes operation to query the values of this parameter.
        self.notification_types = notification_types  # type: list[str]
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyNotificationConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.notification_arn is not None:
            result['NotificationArn'] = self.notification_arn
        if self.notification_types is not None:
            result['NotificationTypes'] = self.notification_types
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('NotificationArn') is not None:
            self.notification_arn = m.get('NotificationArn')
        if m.get('NotificationTypes') is not None:
            self.notification_types = m.get('NotificationTypes')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ModifyNotificationConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyNotificationConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyNotificationConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyNotificationConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyNotificationConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyNotificationConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyScalingConfigurationRequestImageOptions(TeaModel):
    def __init__(self, login_as_non_root=None):
        self.login_as_non_root = login_as_non_root  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestImageOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.login_as_non_root is not None:
            result['LoginAsNonRoot'] = self.login_as_non_root
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoginAsNonRoot') is not None:
            self.login_as_non_root = m.get('LoginAsNonRoot')
        return self


class ModifyScalingConfigurationRequestPrivatePoolOptions(TeaModel):
    def __init__(self, id=None, match_criteria=None):
        # The ID of the private pool. The ID of a private pool is the same as the ID of the elasticity assurance or capacity reservation for which the private pool is generated.
        self.id = id  # type: str
        # The type of the private pool that you want to use to start instances. A private pool is generated when an elasticity assurance or a capacity reservation takes effect. You can select a private pool for Auto Scaling to start instances. Valid values:
        # 
        # *   Open: open private pool. Auto Scaling selects a matching open private pool to start instances. If no matching open private pools exist, Auto Scaling uses the resources in the public pool to start instances. In this case, you do not need to specify PrivatePoolOptions.Id.
        # *   Target: specified private pool. Auto Scaling uses the resources in the specified private pool to start instances. If the private pool is unavailable, Auto Scaling cannot start the instances. If you set this parameter to Target, you must specify PrivatePoolOptions.Id.
        # *   None: no private pool: Auto Scaling does not use the resources in private pools to start instances.
        self.match_criteria = match_criteria  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestPrivatePoolOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.id is not None:
            result['Id'] = self.id
        if self.match_criteria is not None:
            result['MatchCriteria'] = self.match_criteria
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('MatchCriteria') is not None:
            self.match_criteria = m.get('MatchCriteria')
        return self


class ModifyScalingConfigurationRequestSystemDisk(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, category=None, description=None,
                 disk_name=None, encrypt_algorithm=None, encrypted=None, kmskey_id=None, performance_level=None,
                 provisioned_iops=None, size=None):
        # The ID of the automatic snapshot policy that you want to apply to the system disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The category of the system disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: enhanced SSD (ESSD)
        # *   ephemeral_ssd: local SSD
        # 
        # If you specify SystemDisk.Category, you cannot specify `SystemDiskCategories`. If you do not specify SystemDisk.Category or `SystemDiskCategories`, the default value of SystemDisk.Category is used. For non-I/O optimized instances of Generation I instance types, the default value is cloud. For instances of other instance types, the default value is cloud_efficiency.
        self.category = category  # type: str
        # The description of the system disk. The description must be 2 to 256 characters in length. The description can contain letters but cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length, and can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with [http:// or https://. Default value: null.](http://https://。、（:）、（\_）（-）。：)
        self.disk_name = disk_name  # type: str
        # The algorithm that you want to use to encrypt the system disk. Valid values:
        # 
        # *   AES-256
        # *   SM4-128
        # 
        # Default value: AES-256
        self.encrypt_algorithm = encrypt_algorithm  # type: str
        # Specifies whether to encrypt the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false
        self.encrypted = encrypted  # type: bool
        # The ID of the KMS key that you want to use to encrypt the system disk.
        self.kmskey_id = kmskey_id  # type: str
        # The performance level (PL) of the system disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # > For more information about how to select ESSD PLs, see [ESSD](~~122389~~).
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the system disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the system disk. Unit: GiB. Valid values:
        # 
        # *   If you set SystemDisk.Category to cloud: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_efficiency: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_ssd: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_essd: 20 to 500.
        # *   If you set SystemDisk.Category to ephemeral_ssd: 20 to 500.
        # 
        # The value of SystemDisk.Size must be greater than or equal to max{20, ImageSize}.
        self.size = size  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestSystemDisk, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.category is not None:
            result['Category'] = self.category
        if self.description is not None:
            result['Description'] = self.description
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypt_algorithm is not None:
            result['EncryptAlgorithm'] = self.encrypt_algorithm
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('EncryptAlgorithm') is not None:
            self.encrypt_algorithm = m.get('EncryptAlgorithm')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        return self


class ModifyScalingConfigurationRequestCustomPriorities(TeaModel):
    def __init__(self, instance_type=None, vswitch_id=None):
        self.instance_type = instance_type  # type: str
        self.vswitch_id = vswitch_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestCustomPriorities, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.vswitch_id is not None:
            result['VswitchId'] = self.vswitch_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('VswitchId') is not None:
            self.vswitch_id = m.get('VswitchId')
        return self


class ModifyScalingConfigurationRequestDataDisks(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, categories=None, category=None,
                 delete_with_instance=None, description=None, device=None, disk_name=None, encrypted=None, kmskey_id=None,
                 performance_level=None, provisioned_iops=None, size=None, snapshot_id=None):
        # The ID of the automatic snapshot policy that you want to apply to the data disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The categories of the data disks. Valid values:
        # 
        # *   cloud: basic disk. The DeleteWithInstance attribute of a basic disk that is created together with the instance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   cloud_essd: ESSD.
        # 
        # > If you specify Categories, you cannot specify `DataDisk.Category`.
        self.categories = categories  # type: list[str]
        # The category of the data disk. Valid values:
        # 
        # *   cloud: basic disk. The DeleteWithInstance attribute of a basic disk that is created together with the instance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   ephemeral_ssd: local SSD.
        # *   cloud_essd: ESSD.
        # 
        # If you specify Category, you cannot specify `Categories`. If you do not specify Category or `Categories`, the default value of Category is used:
        # 
        # *   For I/O optimized instances, the default value is cloud_efficiency.
        # *   For non-I/O optimized instances, the default value is cloud.
        self.category = category  # type: str
        # Specifies whether to release the data disk when the instance to which the data disk is attached is released. Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is available only for independent disks whose Category is set to cloud, cloud_efficiency, cloud_ssd, cloud_essd, or cloud_auto. If you specify this parameter for other disks, an error is reported.
        self.delete_with_instance = delete_with_instance  # type: bool
        # The description of the system disk. The description must be 2 to 256 characters in length. The description can contain letters but cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The mount target of the data disk. If you do not specify Device, a mount target is automatically assigned when Auto Scaling creates ECS instances. The name of the mount target ranges from /dev/xvdb to /dev/xvdz.
        self.device = device  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length, and can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with `http://` or `https://`.
        self.disk_name = disk_name  # type: str
        # Specifies whether to encrypt the system disk. Valid values:
        # 
        # *   true
        # *   false
        self.encrypted = encrypted  # type: str
        # The ID of the Key Management Service (KMS) key that you want to use to encrypt the data disk.
        self.kmskey_id = kmskey_id  # type: str
        # The PL of the data disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # > For more information about how to select ESSD PLs, see [ESSD](~~122389~~).
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the data disk.
        # 
        # > IOPS measures the number of read and write operations that an Elastic Block Storage (EBS) device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the data disk. Unit: GiB. Valid values:
        # 
        # *   If you set Categories cloud: 5 to 2000.
        # *   If you set Categories to cloud_efficiency: 20 to 32768.
        # *   If you set Categories to cloud_ssd: 20 to 32768.
        # *   If you set Categories to cloud_essd: 20 to 32768.
        # *   If you set Categories to ephemeral_ssd: 5 to 800.
        # 
        # The size of the data disk must be greater than or equal to the size of the snapshot that is specified by SnapshotId.
        self.size = size  # type: int
        # The ID of the snapshot that you want to use to create data disks. If you specify this parameter, DataDisk.N.Size is ignored. The size of the disk is the same as the size of the specified snapshot.
        # 
        # If you specify a snapshot that is created on or before July 15, 2013, the operation fails and the system returns InvalidSnapshot.TooOld.
        self.snapshot_id = snapshot_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestDataDisks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.categories is not None:
            result['Categories'] = self.categories
        if self.category is not None:
            result['Category'] = self.category
        if self.delete_with_instance is not None:
            result['DeleteWithInstance'] = self.delete_with_instance
        if self.description is not None:
            result['Description'] = self.description
        if self.device is not None:
            result['Device'] = self.device
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        if self.snapshot_id is not None:
            result['SnapshotId'] = self.snapshot_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Categories') is not None:
            self.categories = m.get('Categories')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('DeleteWithInstance') is not None:
            self.delete_with_instance = m.get('DeleteWithInstance')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Device') is not None:
            self.device = m.get('Device')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        if m.get('SnapshotId') is not None:
            self.snapshot_id = m.get('SnapshotId')
        return self


class ModifyScalingConfigurationRequestInstancePatternInfos(TeaModel):
    def __init__(self, architectures=None, burstable_performance=None, cores=None, excluded_instance_types=None,
                 instance_family_level=None, max_price=None, memory=None):
        # The architectures of the instance types.
        # 
        # *   X86: x86 architecture.
        # *   Heterogeneous: heterogeneous architecture, such as GPUs and FPGAs.
        # *   BareMetal: ECS Bare Metal Instance architecture.
        # *   Arm: ARM architecture.
        # *   SuperComputeCluster: Super Computing Cluster architecture.
        # 
        # By default, all values are included.
        self.architectures = architectures  # type: list[str]
        # Specifies whether to include burstable instance types. Valid values:
        # 
        # *   Exclude: does not include burstable instance types.
        # *   Include: includes burstable instance types.
        # *   Required: includes only burstable instance types.
        # 
        # Default value: Include
        self.burstable_performance = burstable_performance  # type: str
        # The number of vCPUs that you want to allocate to an instance type in intelligent configuration mode. You can use this parameter to filter the available instance types that meet the specified criteria. For more information, see [Overview of instance families](~~25378~~).
        # 
        # When you specify this parameter, take note of the following items:
        # 
        # *   InstancePatternInfo is available only for scaling groups that reside in VPCs.
        # *   If you specify InstancePatternInfo, you must also specify Cores and Memory.
        # *   If you specify an instance type by using InstanceType or InstanceTypes, Auto Scaling preferentially creates instances by using the instance type that is specified by InstanceType or InstanceTypes for scale-outs. If the specified instance type does not have sufficient inventory, Auto Scaling creates instances by using the lowest-priced instance type that is specified by InstancePatternInfo.
        self.cores = cores  # type: int
        # The instance types that you want to exclude. You can use wildcard characters such as an asterisk (\*) to exclude an instance type or an instance family. Examples:
        # 
        # *   ecs.c6.large: excludes the ecs.c6.large instance type.
        # *   ecs.c6.\*: excludes the c6 instance family.
        self.excluded_instance_types = excluded_instance_types  # type: list[str]
        # The level of the instance family. You can use this parameter to filter instance types that meet the specified criteria. This parameter takes effect only if you set `CostOptimization` to true. Valid values:
        # 
        # *   EntryLevel: entry level (shared instance type). Instance types of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instance types of this level are suitable for business scenarios in which CPU utilization is low. For more information, see [Shared instance families](~~108489~~).
        # *   EnterpriseLevel: enterprise level. Instance types of this level provide stable performance and dedicated resources and are suitable for business scenarios that require high stability. For more information, see the [Overview of instance families](~~25378~~) topic.
        # *   CreditEntryLevel: credit entry level. This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instance types of this level are suitable for business scenarios in which CPU utilization is low but may fluctuate in specific scenarios. For more information, see [Overview](~~59977~~) of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        # The maximum hourly price for a pay-as-you-go instance or a preemptible instance in intelligent configuration mode. You can use this parameter to filter the available instance types that meet the specified criteria.
        # 
        # > If you set SpotStrategy to SpotWithPriceLimit, specify MaxPrice. In other scenarios, MaxPrice is optional.
        self.max_price = max_price  # type: float
        # The memory size that you want to allocate to an instance type in intelligent configuration mode. Unit: GiB. You can use this parameter to filter the available instance types that meet the specified criteria.
        self.memory = memory  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestInstancePatternInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.architectures is not None:
            result['Architectures'] = self.architectures
        if self.burstable_performance is not None:
            result['BurstablePerformance'] = self.burstable_performance
        if self.cores is not None:
            result['Cores'] = self.cores
        if self.excluded_instance_types is not None:
            result['ExcludedInstanceTypes'] = self.excluded_instance_types
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.max_price is not None:
            result['MaxPrice'] = self.max_price
        if self.memory is not None:
            result['Memory'] = self.memory
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Architectures') is not None:
            self.architectures = m.get('Architectures')
        if m.get('BurstablePerformance') is not None:
            self.burstable_performance = m.get('BurstablePerformance')
        if m.get('Cores') is not None:
            self.cores = m.get('Cores')
        if m.get('ExcludedInstanceTypes') is not None:
            self.excluded_instance_types = m.get('ExcludedInstanceTypes')
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('MaxPrice') is not None:
            self.max_price = m.get('MaxPrice')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        return self


class ModifyScalingConfigurationRequestInstanceTypeOverrides(TeaModel):
    def __init__(self, instance_type=None, weighted_capacity=None):
        # The instance type. If you want to specify the capacity of instance types in the scaling configuration, specify InstanceType and WeightedCapacity at the same time.
        # 
        # You can use InstanceType to specify multiple instance types and WeightedCapacity to specify the weights of the instance types.
        # 
        # > If you specify InstanceType, you cannot specify InstanceTypes.
        # 
        # You can use InstanceType to specify only instance types that are available for purchase.
        self.instance_type = instance_type  # type: str
        # The weight of the instance type. The weight specifies the capacity of an instance of the specified instance type in the scaling group. If you want Auto Scaling to scale instances in the scaling group based on the weighted capacity of the instances, specify WeightedCapacity after you specify InstanceType.
        # 
        # A higher weight specifies that a smaller number of instances of the specified instance type are required to meet the expected capacity requirement.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by MaxSize and the maximum weight of the instance types.
        # 
        # Valid values of WeightedCapacity: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestInstanceTypeOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class ModifyScalingConfigurationRequestSpotPriceLimits(TeaModel):
    def __init__(self, instance_type=None, price_limit=None):
        # The instance type of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.instance_type = instance_type  # type: str
        # The price limit of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.price_limit = price_limit  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequestSpotPriceLimits, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.price_limit is not None:
            result['PriceLimit'] = self.price_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('PriceLimit') is not None:
            self.price_limit = m.get('PriceLimit')
        return self


class ModifyScalingConfigurationRequest(TeaModel):
    def __init__(self, image_options=None, private_pool_options=None, system_disk=None, affinity=None, cpu=None,
                 credit_specification=None, custom_priorities=None, data_disks=None, dedicated_host_id=None, deletion_protection=None,
                 deployment_set_id=None, host_name=None, hpc_cluster_id=None, image_family=None, image_id=None, image_name=None,
                 instance_description=None, instance_name=None, instance_pattern_infos=None, instance_type_overrides=None,
                 instance_types=None, internet_charge_type=None, internet_max_bandwidth_out=None, io_optimized=None,
                 ipv_6address_count=None, key_pair_name=None, load_balancer_weight=None, memory=None, override=None,
                 owner_account=None, owner_id=None, password_inherit=None, ram_role_name=None, resource_group_id=None,
                 resource_owner_account=None, scaling_configuration_id=None, scaling_configuration_name=None, scheduler_options=None,
                 security_group_id=None, security_group_ids=None, spot_duration=None, spot_interruption_behavior=None,
                 spot_price_limits=None, spot_strategy=None, storage_set_id=None, storage_set_partition_number=None,
                 system_disk_categories=None, tags=None, tenancy=None, user_data=None, zone_id=None):
        self.image_options = image_options  # type: ModifyScalingConfigurationRequestImageOptions
        self.private_pool_options = private_pool_options  # type: ModifyScalingConfigurationRequestPrivatePoolOptions
        self.system_disk = system_disk  # type: ModifyScalingConfigurationRequestSystemDisk
        # Specifies whether to associate an ECS instance on a dedicated host with the dedicated host. Valid values:
        # 
        # *   default: does not associate the ECS instance with the dedicated host. If you start an instance that is stopped in economical mode and the original dedicated host has insufficient resources, the instance is automatically deployed to another dedicated host in the automatic deployment resource pool.
        # *   host: associates the ECS instance with the dedicated host. If you start an ECS instance that is stopped in economical mode, the ECS instance remains on the original dedicated host. If the original dedicated host has insufficient resources, the ECS instance fails to start.
        self.affinity = affinity  # type: str
        # The number of vCPUs.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set Cpu to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify CPU and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify an instance type in the scaling configuration.
        self.cpu = cpu  # type: int
        # The performance mode of the burstable instance. Valid values:
        # 
        # *   Standard: standard mode. For more information, see the "Standard mode" section in the [Burstable instances](~~59977~~) topic.
        # *   Unlimited: unlimited mode. For more information, see the "Unlimited mode" section in the [Burstable instances](~~59977~~) topic.
        self.credit_specification = credit_specification  # type: str
        self.custom_priorities = custom_priorities  # type: list[ModifyScalingConfigurationRequestCustomPriorities]
        # The data disks.
        self.data_disks = data_disks  # type: list[ModifyScalingConfigurationRequestDataDisks]
        # The ID of the dedicated host on which you want to create ECS instances. You cannot create preemptible instances on dedicated hosts. If you specify DedicatedHostId, SpotStrategy and SpotPriceLimit are ignored.
        # 
        # You can call the DescribeDedicatedHosts operation to query the most recent list of dedicated host IDs.
        self.dedicated_host_id = dedicated_host_id  # type: str
        self.deletion_protection = deletion_protection  # type: bool
        # The ID of the deployment set of the ECS instances that are created by using the scaling configuration.
        self.deployment_set_id = deployment_set_id  # type: str
        # The hostname of the ECS instance. The hostname cannot start or end with a period (.) or a hyphen (-). The hostname cannot contain consecutive periods (.) or hyphens (-). Naming conventions for different types of instances:
        # 
        # *   Windows instances: The hostname must be 2 to 15 characters in length, and can contain letters, digits, and hyphens (-). The hostname cannot contain periods (.) or contain only digits.
        # *   Other instances, such as Linux instances: The hostname must be 2 to 64 characters in length. Separate a hostname into multiple segments with periods (.). Each segment can contain letters, digits, and hyphens (-).
        self.host_name = host_name  # type: str
        # The ID of the Elastic High Performance Computing (E-HPC) cluster to which the ECS instances belong.
        self.hpc_cluster_id = hpc_cluster_id  # type: str
        # The name of the image family. If you specify this parameter, the latest custom images that are available in the specified image family are returned. Then, you can use the images to create instances. If you specify ImageId, you cannot specify ImageFamily.
        self.image_family = image_family  # type: str
        # The ID of the image that is used by Auto Scaling to automatically create ECS instances.
        # 
        # > If the image that is specified in the scaling configuration contains system disks and data disks, the data that is stored in the data disks is cleared after you modify the image.
        self.image_id = image_id  # type: str
        # The name of the image. Each image name must be unique in a region. If you specify ImageId, ImageName is ignored.
        # 
        # You cannot use ImageName to specify images from Alibaba Cloud Marketplace.
        self.image_name = image_name  # type: str
        # The description of the ECS instance. The description must be 2 to 256 characters in length. The description can contain letters but cannot start with `http://` or `https://`.
        self.instance_description = instance_description  # type: str
        # The name of the Elastic Compute Service (ECS) instance that is automatically created by using the scaling configuration.
        self.instance_name = instance_name  # type: str
        # The intelligent configuration settings, which determines the range of instance types that meet the specified criteria.
        self.instance_pattern_infos = instance_pattern_infos  # type: list[ModifyScalingConfigurationRequestInstancePatternInfos]
        # The instance types.
        self.instance_type_overrides = instance_type_overrides  # type: list[ModifyScalingConfigurationRequestInstanceTypeOverrides]
        # The instance type. If you specify InstanceTypes, InstanceType is ignored.
        # 
        # Auto Scaling creates instances based on the priorities of instance types. If Auto Scaling cannot create instances by using the instance type that has the highest priority, Auto Scaling creates instances by using the instance type that has the next highest priority.
        self.instance_types = instance_types  # type: list[str]
        # The metering method for network usage. Valid values:
        # 
        # *   PayByBandwidth: You are charged for the maximum available bandwidth that is specified by InternetMaxBandwidthOut.
        # *   PayByTraffic: You are charged for the actual data transfer. InternetMaxBandwidthOut specifies only the maximum available bandwidth.
        self.internet_charge_type = internet_charge_type  # type: str
        # The maximum outbound public bandwidth. Unit: Mbit/s. Valid values:
        # 
        # *   If you set InternetChargeType to PayByBandwidth: 0 to 100. If you leave this parameter empty, this parameter is automatically set to 0.
        # *   If you set InternetChargeType to PayByTraffic: 0 to 100. If you leave this parameter empty, an error is returned.
        self.internet_max_bandwidth_out = internet_max_bandwidth_out  # type: int
        # Specifies whether to create an I/O optimized instance. Valid values:
        # 
        # *   none: does not create an I/O optimized instance.
        # *   optimized: creates an I/O optimized instance.
        self.io_optimized = io_optimized  # type: str
        # The number of randomly generated IPv6 addresses that you want to allocate to the elastic network interface (ENI).
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The name of the key pair that you can use to log on to an ECS instance.
        # 
        # *   Windows instances do not support this parameter.
        # *   By default, the username and password authentication method is disabled for Linux instances.
        self.key_pair_name = key_pair_name  # type: str
        # The weight of an ECS instance as a backend server. Valid values: 1 to 100.
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size. Unit: GiB.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set Cpu to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify CPU and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify an instance type in the scaling configuration.
        self.memory = memory  # type: int
        # Specifies whether to overwrite existing data. Valid values:
        # 
        # *   true
        # *   false
        self.override = override  # type: bool
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # Specifies whether to use the password that is preconfigured in the image. Before you use this parameter, make sure that a password is configured in the image.
        self.password_inherit = password_inherit  # type: bool
        # The name of the RAM role that you want to attach to the ECS instance. The name is provided and maintained by Resource Access Management (RAM). You can call the ListRoles operation to query the available RAM roles. You can call the CreateRole operation to create RAM roles.
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group to which the ECS instances belong.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling configuration that you want to modify.
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        # The name of the scaling configuration. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # The name of the scaling configuration must be unique in a region. If you do not specify this parameter, the scaling configuration ID is used.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The scheduler options.
        self.scheduler_options = scheduler_options  # type: dict[str, any]
        # The ID of the security group with which ECS instances are associated. The ECS instances that are associated with the same security group can access each other.
        self.security_group_id = security_group_id  # type: str
        # The IDs of the security groups.
        self.security_group_ids = security_group_ids  # type: list[str]
        # The retention period of the preemptible instance. Unit: hours. Valid values: 0, 1, 2, 3, 4, 5, and 6.
        # 
        # *   The following retention periods are available in invitational preview: 2, 3, 4, 5, and 6 hours. If you want to set this parameter to one of these values, submit a ticket.
        # *   If you set this parameter to 0, no retention period is specified for the preemptible instance.
        self.spot_duration = spot_duration  # type: int
        # The interruption mode of the preemptible instance. Default value: Terminate. Set the value to Terminate. This value specifies that the preemptible instance is to be released.
        self.spot_interruption_behavior = spot_interruption_behavior  # type: str
        # The preemptible instance types.
        self.spot_price_limits = spot_price_limits  # type: list[ModifyScalingConfigurationRequestSpotPriceLimits]
        # The preemption policy that you want to apply to pay-as-you-go instances and preemptible instances. Valid values:
        # 
        # *   NoSpot: The instance is created as a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance that has a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is created as a preemptible instance for which the market price at the time of purchase is automatically used as the bidding price.
        self.spot_strategy = spot_strategy  # type: str
        self.storage_set_id = storage_set_id  # type: str
        self.storage_set_partition_number = storage_set_partition_number  # type: int
        # The categories of the system disks. If Auto Scaling cannot create instances by using the disk category that has the highest priority, Auto Scaling creates instances by using the disk category that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        # 
        # > If you specify SystemDiskCategories, you cannot specify `SystemDisk.Category`.
        self.system_disk_categories = system_disk_categories  # type: list[str]
        # The tags of the ECS instance. Specify the tags as key-value pairs. You can specify up to 20 tags. When you specify tag keys and tag values, take note of the following items:
        # 
        # *   A tag key can be up to 64 characters in length. The key cannot start with `acs:` or `aliyun`, and cannot contain `http://` or `https://`. The tag key cannot be an empty string.
        # *   A tag value can be up to 128 characters in length. The value cannot start with `acs:` or `aliyun`, and cannot contain `http://` or `https://`. The tag value can be an empty string.
        self.tags = tags  # type: str
        # Specifies whether to create an ECS instance on a dedicated host. Valid values:
        # 
        # *   default: does not create the ECS instance on a dedicated host.
        # *   host: creates the ECS instance on a dedicated host. If you do not specify DedicatedHostId, Alibaba Cloud selects a dedicated host for the ECS instance.
        self.tenancy = tenancy  # type: str
        # The user data of the ECS instance. The data must be encoded in Base64. The maximum size of the data before encoding is 16 KB.
        self.user_data = user_data  # type: str
        # The zone ID of the ECS instances that are created by using the scaling configuration.
        self.zone_id = zone_id  # type: str

    def validate(self):
        if self.image_options:
            self.image_options.validate()
        if self.private_pool_options:
            self.private_pool_options.validate()
        if self.system_disk:
            self.system_disk.validate()
        if self.custom_priorities:
            for k in self.custom_priorities:
                if k:
                    k.validate()
        if self.data_disks:
            for k in self.data_disks:
                if k:
                    k.validate()
        if self.instance_pattern_infos:
            for k in self.instance_pattern_infos:
                if k:
                    k.validate()
        if self.instance_type_overrides:
            for k in self.instance_type_overrides:
                if k:
                    k.validate()
        if self.spot_price_limits:
            for k in self.spot_price_limits:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyScalingConfigurationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.image_options is not None:
            result['ImageOptions'] = self.image_options.to_map()
        if self.private_pool_options is not None:
            result['PrivatePoolOptions'] = self.private_pool_options.to_map()
        if self.system_disk is not None:
            result['SystemDisk'] = self.system_disk.to_map()
        if self.affinity is not None:
            result['Affinity'] = self.affinity
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.credit_specification is not None:
            result['CreditSpecification'] = self.credit_specification
        result['CustomPriorities'] = []
        if self.custom_priorities is not None:
            for k in self.custom_priorities:
                result['CustomPriorities'].append(k.to_map() if k else None)
        result['DataDisks'] = []
        if self.data_disks is not None:
            for k in self.data_disks:
                result['DataDisks'].append(k.to_map() if k else None)
        if self.dedicated_host_id is not None:
            result['DedicatedHostId'] = self.dedicated_host_id
        if self.deletion_protection is not None:
            result['DeletionProtection'] = self.deletion_protection
        if self.deployment_set_id is not None:
            result['DeploymentSetId'] = self.deployment_set_id
        if self.host_name is not None:
            result['HostName'] = self.host_name
        if self.hpc_cluster_id is not None:
            result['HpcClusterId'] = self.hpc_cluster_id
        if self.image_family is not None:
            result['ImageFamily'] = self.image_family
        if self.image_id is not None:
            result['ImageId'] = self.image_id
        if self.image_name is not None:
            result['ImageName'] = self.image_name
        if self.instance_description is not None:
            result['InstanceDescription'] = self.instance_description
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        result['InstancePatternInfos'] = []
        if self.instance_pattern_infos is not None:
            for k in self.instance_pattern_infos:
                result['InstancePatternInfos'].append(k.to_map() if k else None)
        result['InstanceTypeOverrides'] = []
        if self.instance_type_overrides is not None:
            for k in self.instance_type_overrides:
                result['InstanceTypeOverrides'].append(k.to_map() if k else None)
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.internet_charge_type is not None:
            result['InternetChargeType'] = self.internet_charge_type
        if self.internet_max_bandwidth_out is not None:
            result['InternetMaxBandwidthOut'] = self.internet_max_bandwidth_out
        if self.io_optimized is not None:
            result['IoOptimized'] = self.io_optimized
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.key_pair_name is not None:
            result['KeyPairName'] = self.key_pair_name
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.override is not None:
            result['Override'] = self.override
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.password_inherit is not None:
            result['PasswordInherit'] = self.password_inherit
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scheduler_options is not None:
            result['SchedulerOptions'] = self.scheduler_options
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.security_group_ids is not None:
            result['SecurityGroupIds'] = self.security_group_ids
        if self.spot_duration is not None:
            result['SpotDuration'] = self.spot_duration
        if self.spot_interruption_behavior is not None:
            result['SpotInterruptionBehavior'] = self.spot_interruption_behavior
        result['SpotPriceLimits'] = []
        if self.spot_price_limits is not None:
            for k in self.spot_price_limits:
                result['SpotPriceLimits'].append(k.to_map() if k else None)
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        if self.storage_set_id is not None:
            result['StorageSetId'] = self.storage_set_id
        if self.storage_set_partition_number is not None:
            result['StorageSetPartitionNumber'] = self.storage_set_partition_number
        if self.system_disk_categories is not None:
            result['SystemDiskCategories'] = self.system_disk_categories
        if self.tags is not None:
            result['Tags'] = self.tags
        if self.tenancy is not None:
            result['Tenancy'] = self.tenancy
        if self.user_data is not None:
            result['UserData'] = self.user_data
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ImageOptions') is not None:
            temp_model = ModifyScalingConfigurationRequestImageOptions()
            self.image_options = temp_model.from_map(m['ImageOptions'])
        if m.get('PrivatePoolOptions') is not None:
            temp_model = ModifyScalingConfigurationRequestPrivatePoolOptions()
            self.private_pool_options = temp_model.from_map(m['PrivatePoolOptions'])
        if m.get('SystemDisk') is not None:
            temp_model = ModifyScalingConfigurationRequestSystemDisk()
            self.system_disk = temp_model.from_map(m['SystemDisk'])
        if m.get('Affinity') is not None:
            self.affinity = m.get('Affinity')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CreditSpecification') is not None:
            self.credit_specification = m.get('CreditSpecification')
        self.custom_priorities = []
        if m.get('CustomPriorities') is not None:
            for k in m.get('CustomPriorities'):
                temp_model = ModifyScalingConfigurationRequestCustomPriorities()
                self.custom_priorities.append(temp_model.from_map(k))
        self.data_disks = []
        if m.get('DataDisks') is not None:
            for k in m.get('DataDisks'):
                temp_model = ModifyScalingConfigurationRequestDataDisks()
                self.data_disks.append(temp_model.from_map(k))
        if m.get('DedicatedHostId') is not None:
            self.dedicated_host_id = m.get('DedicatedHostId')
        if m.get('DeletionProtection') is not None:
            self.deletion_protection = m.get('DeletionProtection')
        if m.get('DeploymentSetId') is not None:
            self.deployment_set_id = m.get('DeploymentSetId')
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        if m.get('HpcClusterId') is not None:
            self.hpc_cluster_id = m.get('HpcClusterId')
        if m.get('ImageFamily') is not None:
            self.image_family = m.get('ImageFamily')
        if m.get('ImageId') is not None:
            self.image_id = m.get('ImageId')
        if m.get('ImageName') is not None:
            self.image_name = m.get('ImageName')
        if m.get('InstanceDescription') is not None:
            self.instance_description = m.get('InstanceDescription')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        self.instance_pattern_infos = []
        if m.get('InstancePatternInfos') is not None:
            for k in m.get('InstancePatternInfos'):
                temp_model = ModifyScalingConfigurationRequestInstancePatternInfos()
                self.instance_pattern_infos.append(temp_model.from_map(k))
        self.instance_type_overrides = []
        if m.get('InstanceTypeOverrides') is not None:
            for k in m.get('InstanceTypeOverrides'):
                temp_model = ModifyScalingConfigurationRequestInstanceTypeOverrides()
                self.instance_type_overrides.append(temp_model.from_map(k))
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('InternetChargeType') is not None:
            self.internet_charge_type = m.get('InternetChargeType')
        if m.get('InternetMaxBandwidthOut') is not None:
            self.internet_max_bandwidth_out = m.get('InternetMaxBandwidthOut')
        if m.get('IoOptimized') is not None:
            self.io_optimized = m.get('IoOptimized')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('KeyPairName') is not None:
            self.key_pair_name = m.get('KeyPairName')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Override') is not None:
            self.override = m.get('Override')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PasswordInherit') is not None:
            self.password_inherit = m.get('PasswordInherit')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('SchedulerOptions') is not None:
            self.scheduler_options = m.get('SchedulerOptions')
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SecurityGroupIds') is not None:
            self.security_group_ids = m.get('SecurityGroupIds')
        if m.get('SpotDuration') is not None:
            self.spot_duration = m.get('SpotDuration')
        if m.get('SpotInterruptionBehavior') is not None:
            self.spot_interruption_behavior = m.get('SpotInterruptionBehavior')
        self.spot_price_limits = []
        if m.get('SpotPriceLimits') is not None:
            for k in m.get('SpotPriceLimits'):
                temp_model = ModifyScalingConfigurationRequestSpotPriceLimits()
                self.spot_price_limits.append(temp_model.from_map(k))
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        if m.get('StorageSetId') is not None:
            self.storage_set_id = m.get('StorageSetId')
        if m.get('StorageSetPartitionNumber') is not None:
            self.storage_set_partition_number = m.get('StorageSetPartitionNumber')
        if m.get('SystemDiskCategories') is not None:
            self.system_disk_categories = m.get('SystemDiskCategories')
        if m.get('Tags') is not None:
            self.tags = m.get('Tags')
        if m.get('Tenancy') is not None:
            self.tenancy = m.get('Tenancy')
        if m.get('UserData') is not None:
            self.user_data = m.get('UserData')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class ModifyScalingConfigurationShrinkRequestImageOptions(TeaModel):
    def __init__(self, login_as_non_root=None):
        self.login_as_non_root = login_as_non_root  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestImageOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.login_as_non_root is not None:
            result['LoginAsNonRoot'] = self.login_as_non_root
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('LoginAsNonRoot') is not None:
            self.login_as_non_root = m.get('LoginAsNonRoot')
        return self


class ModifyScalingConfigurationShrinkRequestPrivatePoolOptions(TeaModel):
    def __init__(self, id=None, match_criteria=None):
        # The ID of the private pool. The ID of a private pool is the same as the ID of the elasticity assurance or capacity reservation for which the private pool is generated.
        self.id = id  # type: str
        # The type of the private pool that you want to use to start instances. A private pool is generated when an elasticity assurance or a capacity reservation takes effect. You can select a private pool for Auto Scaling to start instances. Valid values:
        # 
        # *   Open: open private pool. Auto Scaling selects a matching open private pool to start instances. If no matching open private pools exist, Auto Scaling uses the resources in the public pool to start instances. In this case, you do not need to specify PrivatePoolOptions.Id.
        # *   Target: specified private pool. Auto Scaling uses the resources in the specified private pool to start instances. If the private pool is unavailable, Auto Scaling cannot start the instances. If you set this parameter to Target, you must specify PrivatePoolOptions.Id.
        # *   None: no private pool: Auto Scaling does not use the resources in private pools to start instances.
        self.match_criteria = match_criteria  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestPrivatePoolOptions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.id is not None:
            result['Id'] = self.id
        if self.match_criteria is not None:
            result['MatchCriteria'] = self.match_criteria
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Id') is not None:
            self.id = m.get('Id')
        if m.get('MatchCriteria') is not None:
            self.match_criteria = m.get('MatchCriteria')
        return self


class ModifyScalingConfigurationShrinkRequestSystemDisk(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, category=None, description=None,
                 disk_name=None, encrypt_algorithm=None, encrypted=None, kmskey_id=None, performance_level=None,
                 provisioned_iops=None, size=None):
        # The ID of the automatic snapshot policy that you want to apply to the system disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The category of the system disk. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: enhanced SSD (ESSD)
        # *   ephemeral_ssd: local SSD
        # 
        # If you specify SystemDisk.Category, you cannot specify `SystemDiskCategories`. If you do not specify SystemDisk.Category or `SystemDiskCategories`, the default value of SystemDisk.Category is used. For non-I/O optimized instances of Generation I instance types, the default value is cloud. For instances of other instance types, the default value is cloud_efficiency.
        self.category = category  # type: str
        # The description of the system disk. The description must be 2 to 256 characters in length. The description can contain letters but cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length, and can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with [http:// or https://. Default value: null.](http://https://。、（:）、（\_）（-）。：)
        self.disk_name = disk_name  # type: str
        # The algorithm that you want to use to encrypt the system disk. Valid values:
        # 
        # *   AES-256
        # *   SM4-128
        # 
        # Default value: AES-256
        self.encrypt_algorithm = encrypt_algorithm  # type: str
        # Specifies whether to encrypt the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false
        self.encrypted = encrypted  # type: bool
        # The ID of the KMS key that you want to use to encrypt the system disk.
        self.kmskey_id = kmskey_id  # type: str
        # The performance level (PL) of the system disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # > For more information about how to select ESSD PLs, see [ESSD](~~122389~~).
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the system disk.
        # 
        # > IOPS measures the number of read and write operations that an EBS device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the system disk. Unit: GiB. Valid values:
        # 
        # *   If you set SystemDisk.Category to cloud: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_efficiency: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_ssd: 20 to 500.
        # *   If you set SystemDisk.Category to cloud_essd: 20 to 500.
        # *   If you set SystemDisk.Category to ephemeral_ssd: 20 to 500.
        # 
        # The value of SystemDisk.Size must be greater than or equal to max{20, ImageSize}.
        self.size = size  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestSystemDisk, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.category is not None:
            result['Category'] = self.category
        if self.description is not None:
            result['Description'] = self.description
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypt_algorithm is not None:
            result['EncryptAlgorithm'] = self.encrypt_algorithm
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('EncryptAlgorithm') is not None:
            self.encrypt_algorithm = m.get('EncryptAlgorithm')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        return self


class ModifyScalingConfigurationShrinkRequestCustomPriorities(TeaModel):
    def __init__(self, instance_type=None, vswitch_id=None):
        self.instance_type = instance_type  # type: str
        self.vswitch_id = vswitch_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestCustomPriorities, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.vswitch_id is not None:
            result['VswitchId'] = self.vswitch_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('VswitchId') is not None:
            self.vswitch_id = m.get('VswitchId')
        return self


class ModifyScalingConfigurationShrinkRequestDataDisks(TeaModel):
    def __init__(self, auto_snapshot_policy_id=None, bursting_enabled=None, categories=None, category=None,
                 delete_with_instance=None, description=None, device=None, disk_name=None, encrypted=None, kmskey_id=None,
                 performance_level=None, provisioned_iops=None, size=None, snapshot_id=None):
        # The ID of the automatic snapshot policy that you want to apply to the data disk.
        self.auto_snapshot_policy_id = auto_snapshot_policy_id  # type: str
        # Specifies whether to enable the burst feature for the system disk. Valid values:
        # 
        # *   true
        # *   false
        # 
        # > This parameter is available only if you set `SystemDisk.Category` to `cloud_auto`.
        self.bursting_enabled = bursting_enabled  # type: bool
        # The categories of the data disks. Valid values:
        # 
        # *   cloud: basic disk. The DeleteWithInstance attribute of a basic disk that is created together with the instance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   cloud_essd: ESSD.
        # 
        # > If you specify Categories, you cannot specify `DataDisk.Category`.
        self.categories = categories  # type: list[str]
        # The category of the data disk. Valid values:
        # 
        # *   cloud: basic disk. The DeleteWithInstance attribute of a basic disk that is created together with the instance is set to true.
        # *   cloud_efficiency: ultra disk.
        # *   cloud_ssd: standard SSD.
        # *   ephemeral_ssd: local SSD.
        # *   cloud_essd: ESSD.
        # 
        # If you specify Category, you cannot specify `Categories`. If you do not specify Category or `Categories`, the default value of Category is used:
        # 
        # *   For I/O optimized instances, the default value is cloud_efficiency.
        # *   For non-I/O optimized instances, the default value is cloud.
        self.category = category  # type: str
        # Specifies whether to release the data disk when the instance to which the data disk is attached is released. Valid values:
        # 
        # *   true
        # *   false
        # 
        # This parameter is available only for independent disks whose Category is set to cloud, cloud_efficiency, cloud_ssd, cloud_essd, or cloud_auto. If you specify this parameter for other disks, an error is reported.
        self.delete_with_instance = delete_with_instance  # type: bool
        # The description of the system disk. The description must be 2 to 256 characters in length. The description can contain letters but cannot start with `http://` or `https://`.
        self.description = description  # type: str
        # The mount target of the data disk. If you do not specify Device, a mount target is automatically assigned when Auto Scaling creates ECS instances. The name of the mount target ranges from /dev/xvdb to /dev/xvdz.
        self.device = device  # type: str
        # The name of the system disk. The name must be 2 to 128 characters in length, and can contain letters, digits, colons (:), underscores (\_), and hyphens (-). The name must start with a letter but cannot start with `http://` or `https://`.
        self.disk_name = disk_name  # type: str
        # Specifies whether to encrypt the system disk. Valid values:
        # 
        # *   true
        # *   false
        self.encrypted = encrypted  # type: str
        # The ID of the Key Management Service (KMS) key that you want to use to encrypt the data disk.
        self.kmskey_id = kmskey_id  # type: str
        # The PL of the data disk that is an ESSD. Valid values:
        # 
        # *   PL0: An ESSD can provide up to 10,000 random read/write IOPS.
        # *   PL1: An ESSD can provide up to 50,000 random read/write IOPS.
        # *   PL2: An ESSD can provide up to 100,000 random read/write IOPS.
        # *   PL3: An ESSD can provide up to 1,000,000 random read/write IOPS.
        # 
        # > For more information about how to select ESSD PLs, see [ESSD](~~122389~~).
        self.performance_level = performance_level  # type: str
        # The IOPS metric that is preconfigured for the data disk.
        # 
        # > IOPS measures the number of read and write operations that an Elastic Block Storage (EBS) device can process per second.
        self.provisioned_iops = provisioned_iops  # type: long
        # The size of the data disk. Unit: GiB. Valid values:
        # 
        # *   If you set Categories cloud: 5 to 2000.
        # *   If you set Categories to cloud_efficiency: 20 to 32768.
        # *   If you set Categories to cloud_ssd: 20 to 32768.
        # *   If you set Categories to cloud_essd: 20 to 32768.
        # *   If you set Categories to ephemeral_ssd: 5 to 800.
        # 
        # The size of the data disk must be greater than or equal to the size of the snapshot that is specified by SnapshotId.
        self.size = size  # type: int
        # The ID of the snapshot that you want to use to create data disks. If you specify this parameter, DataDisk.N.Size is ignored. The size of the disk is the same as the size of the specified snapshot.
        # 
        # If you specify a snapshot that is created on or before July 15, 2013, the operation fails and the system returns InvalidSnapshot.TooOld.
        self.snapshot_id = snapshot_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestDataDisks, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.auto_snapshot_policy_id is not None:
            result['AutoSnapshotPolicyId'] = self.auto_snapshot_policy_id
        if self.bursting_enabled is not None:
            result['BurstingEnabled'] = self.bursting_enabled
        if self.categories is not None:
            result['Categories'] = self.categories
        if self.category is not None:
            result['Category'] = self.category
        if self.delete_with_instance is not None:
            result['DeleteWithInstance'] = self.delete_with_instance
        if self.description is not None:
            result['Description'] = self.description
        if self.device is not None:
            result['Device'] = self.device
        if self.disk_name is not None:
            result['DiskName'] = self.disk_name
        if self.encrypted is not None:
            result['Encrypted'] = self.encrypted
        if self.kmskey_id is not None:
            result['KMSKeyId'] = self.kmskey_id
        if self.performance_level is not None:
            result['PerformanceLevel'] = self.performance_level
        if self.provisioned_iops is not None:
            result['ProvisionedIops'] = self.provisioned_iops
        if self.size is not None:
            result['Size'] = self.size
        if self.snapshot_id is not None:
            result['SnapshotId'] = self.snapshot_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AutoSnapshotPolicyId') is not None:
            self.auto_snapshot_policy_id = m.get('AutoSnapshotPolicyId')
        if m.get('BurstingEnabled') is not None:
            self.bursting_enabled = m.get('BurstingEnabled')
        if m.get('Categories') is not None:
            self.categories = m.get('Categories')
        if m.get('Category') is not None:
            self.category = m.get('Category')
        if m.get('DeleteWithInstance') is not None:
            self.delete_with_instance = m.get('DeleteWithInstance')
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('Device') is not None:
            self.device = m.get('Device')
        if m.get('DiskName') is not None:
            self.disk_name = m.get('DiskName')
        if m.get('Encrypted') is not None:
            self.encrypted = m.get('Encrypted')
        if m.get('KMSKeyId') is not None:
            self.kmskey_id = m.get('KMSKeyId')
        if m.get('PerformanceLevel') is not None:
            self.performance_level = m.get('PerformanceLevel')
        if m.get('ProvisionedIops') is not None:
            self.provisioned_iops = m.get('ProvisionedIops')
        if m.get('Size') is not None:
            self.size = m.get('Size')
        if m.get('SnapshotId') is not None:
            self.snapshot_id = m.get('SnapshotId')
        return self


class ModifyScalingConfigurationShrinkRequestInstancePatternInfos(TeaModel):
    def __init__(self, architectures=None, burstable_performance=None, cores=None, excluded_instance_types=None,
                 instance_family_level=None, max_price=None, memory=None):
        # The architectures of the instance types.
        # 
        # *   X86: x86 architecture.
        # *   Heterogeneous: heterogeneous architecture, such as GPUs and FPGAs.
        # *   BareMetal: ECS Bare Metal Instance architecture.
        # *   Arm: ARM architecture.
        # *   SuperComputeCluster: Super Computing Cluster architecture.
        # 
        # By default, all values are included.
        self.architectures = architectures  # type: list[str]
        # Specifies whether to include burstable instance types. Valid values:
        # 
        # *   Exclude: does not include burstable instance types.
        # *   Include: includes burstable instance types.
        # *   Required: includes only burstable instance types.
        # 
        # Default value: Include
        self.burstable_performance = burstable_performance  # type: str
        # The number of vCPUs that you want to allocate to an instance type in intelligent configuration mode. You can use this parameter to filter the available instance types that meet the specified criteria. For more information, see [Overview of instance families](~~25378~~).
        # 
        # When you specify this parameter, take note of the following items:
        # 
        # *   InstancePatternInfo is available only for scaling groups that reside in VPCs.
        # *   If you specify InstancePatternInfo, you must also specify Cores and Memory.
        # *   If you specify an instance type by using InstanceType or InstanceTypes, Auto Scaling preferentially creates instances by using the instance type that is specified by InstanceType or InstanceTypes for scale-outs. If the specified instance type does not have sufficient inventory, Auto Scaling creates instances by using the lowest-priced instance type that is specified by InstancePatternInfo.
        self.cores = cores  # type: int
        # The instance types that you want to exclude. You can use wildcard characters such as an asterisk (\*) to exclude an instance type or an instance family. Examples:
        # 
        # *   ecs.c6.large: excludes the ecs.c6.large instance type.
        # *   ecs.c6.\*: excludes the c6 instance family.
        self.excluded_instance_types = excluded_instance_types  # type: list[str]
        # The level of the instance family. You can use this parameter to filter instance types that meet the specified criteria. This parameter takes effect only if you set `CostOptimization` to true. Valid values:
        # 
        # *   EntryLevel: entry level (shared instance type). Instance types of this level are the most cost-effective but may not provide stable computing performance in a consistent manner. Instance types of this level are suitable for business scenarios in which CPU utilization is low. For more information, see [Shared instance families](~~108489~~).
        # *   EnterpriseLevel: enterprise level. Instance types of this level provide stable performance and dedicated resources and are suitable for business scenarios that require high stability. For more information, see the [Overview of instance families](~~25378~~) topic.
        # *   CreditEntryLevel: credit entry level. This value is valid only for burstable instances. CPU credits are used to ensure computing performance. Instance types of this level are suitable for business scenarios in which CPU utilization is low but may fluctuate in specific scenarios. For more information, see [Overview](~~59977~~) of burstable instances.
        self.instance_family_level = instance_family_level  # type: str
        # The maximum hourly price for a pay-as-you-go instance or a preemptible instance in intelligent configuration mode. You can use this parameter to filter the available instance types that meet the specified criteria.
        # 
        # > If you set SpotStrategy to SpotWithPriceLimit, specify MaxPrice. In other scenarios, MaxPrice is optional.
        self.max_price = max_price  # type: float
        # The memory size that you want to allocate to an instance type in intelligent configuration mode. Unit: GiB. You can use this parameter to filter the available instance types that meet the specified criteria.
        self.memory = memory  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestInstancePatternInfos, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.architectures is not None:
            result['Architectures'] = self.architectures
        if self.burstable_performance is not None:
            result['BurstablePerformance'] = self.burstable_performance
        if self.cores is not None:
            result['Cores'] = self.cores
        if self.excluded_instance_types is not None:
            result['ExcludedInstanceTypes'] = self.excluded_instance_types
        if self.instance_family_level is not None:
            result['InstanceFamilyLevel'] = self.instance_family_level
        if self.max_price is not None:
            result['MaxPrice'] = self.max_price
        if self.memory is not None:
            result['Memory'] = self.memory
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Architectures') is not None:
            self.architectures = m.get('Architectures')
        if m.get('BurstablePerformance') is not None:
            self.burstable_performance = m.get('BurstablePerformance')
        if m.get('Cores') is not None:
            self.cores = m.get('Cores')
        if m.get('ExcludedInstanceTypes') is not None:
            self.excluded_instance_types = m.get('ExcludedInstanceTypes')
        if m.get('InstanceFamilyLevel') is not None:
            self.instance_family_level = m.get('InstanceFamilyLevel')
        if m.get('MaxPrice') is not None:
            self.max_price = m.get('MaxPrice')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        return self


class ModifyScalingConfigurationShrinkRequestInstanceTypeOverrides(TeaModel):
    def __init__(self, instance_type=None, weighted_capacity=None):
        # The instance type. If you want to specify the capacity of instance types in the scaling configuration, specify InstanceType and WeightedCapacity at the same time.
        # 
        # You can use InstanceType to specify multiple instance types and WeightedCapacity to specify the weights of the instance types.
        # 
        # > If you specify InstanceType, you cannot specify InstanceTypes.
        # 
        # You can use InstanceType to specify only instance types that are available for purchase.
        self.instance_type = instance_type  # type: str
        # The weight of the instance type. The weight specifies the capacity of an instance of the specified instance type in the scaling group. If you want Auto Scaling to scale instances in the scaling group based on the weighted capacity of the instances, specify WeightedCapacity after you specify InstanceType.
        # 
        # A higher weight specifies that a smaller number of instances of the specified instance type are required to meet the expected capacity requirement.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by MaxSize and the maximum weight of the instance types.
        # 
        # Valid values of WeightedCapacity: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestInstanceTypeOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class ModifyScalingConfigurationShrinkRequestSpotPriceLimits(TeaModel):
    def __init__(self, instance_type=None, price_limit=None):
        # The instance type of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.instance_type = instance_type  # type: str
        # The price limit of the preemptible instance. This parameter takes effect only if you set SpotStrategy to SpotWithPriceLimit.
        self.price_limit = price_limit  # type: float

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequestSpotPriceLimits, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.price_limit is not None:
            result['PriceLimit'] = self.price_limit
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('PriceLimit') is not None:
            self.price_limit = m.get('PriceLimit')
        return self


class ModifyScalingConfigurationShrinkRequest(TeaModel):
    def __init__(self, image_options=None, private_pool_options=None, system_disk=None, affinity=None, cpu=None,
                 credit_specification=None, custom_priorities=None, data_disks=None, dedicated_host_id=None, deletion_protection=None,
                 deployment_set_id=None, host_name=None, hpc_cluster_id=None, image_family=None, image_id=None, image_name=None,
                 instance_description=None, instance_name=None, instance_pattern_infos=None, instance_type_overrides=None,
                 instance_types=None, internet_charge_type=None, internet_max_bandwidth_out=None, io_optimized=None,
                 ipv_6address_count=None, key_pair_name=None, load_balancer_weight=None, memory=None, override=None,
                 owner_account=None, owner_id=None, password_inherit=None, ram_role_name=None, resource_group_id=None,
                 resource_owner_account=None, scaling_configuration_id=None, scaling_configuration_name=None,
                 scheduler_options_shrink=None, security_group_id=None, security_group_ids=None, spot_duration=None,
                 spot_interruption_behavior=None, spot_price_limits=None, spot_strategy=None, storage_set_id=None,
                 storage_set_partition_number=None, system_disk_categories=None, tags=None, tenancy=None, user_data=None, zone_id=None):
        self.image_options = image_options  # type: ModifyScalingConfigurationShrinkRequestImageOptions
        self.private_pool_options = private_pool_options  # type: ModifyScalingConfigurationShrinkRequestPrivatePoolOptions
        self.system_disk = system_disk  # type: ModifyScalingConfigurationShrinkRequestSystemDisk
        # Specifies whether to associate an ECS instance on a dedicated host with the dedicated host. Valid values:
        # 
        # *   default: does not associate the ECS instance with the dedicated host. If you start an instance that is stopped in economical mode and the original dedicated host has insufficient resources, the instance is automatically deployed to another dedicated host in the automatic deployment resource pool.
        # *   host: associates the ECS instance with the dedicated host. If you start an ECS instance that is stopped in economical mode, the ECS instance remains on the original dedicated host. If the original dedicated host has insufficient resources, the ECS instance fails to start.
        self.affinity = affinity  # type: str
        # The number of vCPUs.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set Cpu to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify CPU and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify an instance type in the scaling configuration.
        self.cpu = cpu  # type: int
        # The performance mode of the burstable instance. Valid values:
        # 
        # *   Standard: standard mode. For more information, see the "Standard mode" section in the [Burstable instances](~~59977~~) topic.
        # *   Unlimited: unlimited mode. For more information, see the "Unlimited mode" section in the [Burstable instances](~~59977~~) topic.
        self.credit_specification = credit_specification  # type: str
        self.custom_priorities = custom_priorities  # type: list[ModifyScalingConfigurationShrinkRequestCustomPriorities]
        # The data disks.
        self.data_disks = data_disks  # type: list[ModifyScalingConfigurationShrinkRequestDataDisks]
        # The ID of the dedicated host on which you want to create ECS instances. You cannot create preemptible instances on dedicated hosts. If you specify DedicatedHostId, SpotStrategy and SpotPriceLimit are ignored.
        # 
        # You can call the DescribeDedicatedHosts operation to query the most recent list of dedicated host IDs.
        self.dedicated_host_id = dedicated_host_id  # type: str
        self.deletion_protection = deletion_protection  # type: bool
        # The ID of the deployment set of the ECS instances that are created by using the scaling configuration.
        self.deployment_set_id = deployment_set_id  # type: str
        # The hostname of the ECS instance. The hostname cannot start or end with a period (.) or a hyphen (-). The hostname cannot contain consecutive periods (.) or hyphens (-). Naming conventions for different types of instances:
        # 
        # *   Windows instances: The hostname must be 2 to 15 characters in length, and can contain letters, digits, and hyphens (-). The hostname cannot contain periods (.) or contain only digits.
        # *   Other instances, such as Linux instances: The hostname must be 2 to 64 characters in length. Separate a hostname into multiple segments with periods (.). Each segment can contain letters, digits, and hyphens (-).
        self.host_name = host_name  # type: str
        # The ID of the Elastic High Performance Computing (E-HPC) cluster to which the ECS instances belong.
        self.hpc_cluster_id = hpc_cluster_id  # type: str
        # The name of the image family. If you specify this parameter, the latest custom images that are available in the specified image family are returned. Then, you can use the images to create instances. If you specify ImageId, you cannot specify ImageFamily.
        self.image_family = image_family  # type: str
        # The ID of the image that is used by Auto Scaling to automatically create ECS instances.
        # 
        # > If the image that is specified in the scaling configuration contains system disks and data disks, the data that is stored in the data disks is cleared after you modify the image.
        self.image_id = image_id  # type: str
        # The name of the image. Each image name must be unique in a region. If you specify ImageId, ImageName is ignored.
        # 
        # You cannot use ImageName to specify images from Alibaba Cloud Marketplace.
        self.image_name = image_name  # type: str
        # The description of the ECS instance. The description must be 2 to 256 characters in length. The description can contain letters but cannot start with `http://` or `https://`.
        self.instance_description = instance_description  # type: str
        # The name of the Elastic Compute Service (ECS) instance that is automatically created by using the scaling configuration.
        self.instance_name = instance_name  # type: str
        # The intelligent configuration settings, which determines the range of instance types that meet the specified criteria.
        self.instance_pattern_infos = instance_pattern_infos  # type: list[ModifyScalingConfigurationShrinkRequestInstancePatternInfos]
        # The instance types.
        self.instance_type_overrides = instance_type_overrides  # type: list[ModifyScalingConfigurationShrinkRequestInstanceTypeOverrides]
        # The instance type. If you specify InstanceTypes, InstanceType is ignored.
        # 
        # Auto Scaling creates instances based on the priorities of instance types. If Auto Scaling cannot create instances by using the instance type that has the highest priority, Auto Scaling creates instances by using the instance type that has the next highest priority.
        self.instance_types = instance_types  # type: list[str]
        # The metering method for network usage. Valid values:
        # 
        # *   PayByBandwidth: You are charged for the maximum available bandwidth that is specified by InternetMaxBandwidthOut.
        # *   PayByTraffic: You are charged for the actual data transfer. InternetMaxBandwidthOut specifies only the maximum available bandwidth.
        self.internet_charge_type = internet_charge_type  # type: str
        # The maximum outbound public bandwidth. Unit: Mbit/s. Valid values:
        # 
        # *   If you set InternetChargeType to PayByBandwidth: 0 to 100. If you leave this parameter empty, this parameter is automatically set to 0.
        # *   If you set InternetChargeType to PayByTraffic: 0 to 100. If you leave this parameter empty, an error is returned.
        self.internet_max_bandwidth_out = internet_max_bandwidth_out  # type: int
        # Specifies whether to create an I/O optimized instance. Valid values:
        # 
        # *   none: does not create an I/O optimized instance.
        # *   optimized: creates an I/O optimized instance.
        self.io_optimized = io_optimized  # type: str
        # The number of randomly generated IPv6 addresses that you want to allocate to the elastic network interface (ENI).
        self.ipv_6address_count = ipv_6address_count  # type: int
        # The name of the key pair that you can use to log on to an ECS instance.
        # 
        # *   Windows instances do not support this parameter.
        # *   By default, the username and password authentication method is disabled for Linux instances.
        self.key_pair_name = key_pair_name  # type: str
        # The weight of an ECS instance as a backend server. Valid values: 1 to 100.
        self.load_balancer_weight = load_balancer_weight  # type: int
        # The memory size. Unit: GiB.
        # 
        # You can specify the number of vCPUs and the memory size to determine the range of instance types. For example, you can set Cpu to 2 and Memory to 16 to specify instance types that have 2 vCPUs and 16 GiB of memory. If you specify Cpu and Memory, Auto Scaling determines the available instance types based on factors such as I/O optimization requirements and zones. Then, Auto Scaling preferentially creates instances by using the lowest-priced instance type.
        # 
        # > You can specify CPU and Memory to determine the range of instance types only if you set Scaling Policy to Cost Optimization Policy and you do not specify an instance type in the scaling configuration.
        self.memory = memory  # type: int
        # Specifies whether to overwrite existing data. Valid values:
        # 
        # *   true
        # *   false
        self.override = override  # type: bool
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # Specifies whether to use the password that is preconfigured in the image. Before you use this parameter, make sure that a password is configured in the image.
        self.password_inherit = password_inherit  # type: bool
        # The name of the RAM role that you want to attach to the ECS instance. The name is provided and maintained by Resource Access Management (RAM). You can call the ListRoles operation to query the available RAM roles. You can call the CreateRole operation to create RAM roles.
        self.ram_role_name = ram_role_name  # type: str
        # The ID of the resource group to which the ECS instances belong.
        self.resource_group_id = resource_group_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling configuration that you want to modify.
        self.scaling_configuration_id = scaling_configuration_id  # type: str
        # The name of the scaling configuration. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        # 
        # The name of the scaling configuration must be unique in a region. If you do not specify this parameter, the scaling configuration ID is used.
        self.scaling_configuration_name = scaling_configuration_name  # type: str
        # The scheduler options.
        self.scheduler_options_shrink = scheduler_options_shrink  # type: str
        # The ID of the security group with which ECS instances are associated. The ECS instances that are associated with the same security group can access each other.
        self.security_group_id = security_group_id  # type: str
        # The IDs of the security groups.
        self.security_group_ids = security_group_ids  # type: list[str]
        # The retention period of the preemptible instance. Unit: hours. Valid values: 0, 1, 2, 3, 4, 5, and 6.
        # 
        # *   The following retention periods are available in invitational preview: 2, 3, 4, 5, and 6 hours. If you want to set this parameter to one of these values, submit a ticket.
        # *   If you set this parameter to 0, no retention period is specified for the preemptible instance.
        self.spot_duration = spot_duration  # type: int
        # The interruption mode of the preemptible instance. Default value: Terminate. Set the value to Terminate. This value specifies that the preemptible instance is to be released.
        self.spot_interruption_behavior = spot_interruption_behavior  # type: str
        # The preemptible instance types.
        self.spot_price_limits = spot_price_limits  # type: list[ModifyScalingConfigurationShrinkRequestSpotPriceLimits]
        # The preemption policy that you want to apply to pay-as-you-go instances and preemptible instances. Valid values:
        # 
        # *   NoSpot: The instance is created as a pay-as-you-go instance.
        # *   SpotWithPriceLimit: The instance is a preemptible instance that has a user-defined maximum hourly price.
        # *   SpotAsPriceGo: The instance is created as a preemptible instance for which the market price at the time of purchase is automatically used as the bidding price.
        self.spot_strategy = spot_strategy  # type: str
        self.storage_set_id = storage_set_id  # type: str
        self.storage_set_partition_number = storage_set_partition_number  # type: int
        # The categories of the system disks. If Auto Scaling cannot create instances by using the disk category that has the highest priority, Auto Scaling creates instances by using the disk category that has the next highest priority. Valid values:
        # 
        # *   cloud: basic disk
        # *   cloud_efficiency: ultra disk
        # *   cloud_ssd: standard SSD
        # *   cloud_essd: ESSD
        # 
        # > If you specify SystemDiskCategories, you cannot specify `SystemDisk.Category`.
        self.system_disk_categories = system_disk_categories  # type: list[str]
        # The tags of the ECS instance. Specify the tags as key-value pairs. You can specify up to 20 tags. When you specify tag keys and tag values, take note of the following items:
        # 
        # *   A tag key can be up to 64 characters in length. The key cannot start with `acs:` or `aliyun`, and cannot contain `http://` or `https://`. The tag key cannot be an empty string.
        # *   A tag value can be up to 128 characters in length. The value cannot start with `acs:` or `aliyun`, and cannot contain `http://` or `https://`. The tag value can be an empty string.
        self.tags = tags  # type: str
        # Specifies whether to create an ECS instance on a dedicated host. Valid values:
        # 
        # *   default: does not create the ECS instance on a dedicated host.
        # *   host: creates the ECS instance on a dedicated host. If you do not specify DedicatedHostId, Alibaba Cloud selects a dedicated host for the ECS instance.
        self.tenancy = tenancy  # type: str
        # The user data of the ECS instance. The data must be encoded in Base64. The maximum size of the data before encoding is 16 KB.
        self.user_data = user_data  # type: str
        # The zone ID of the ECS instances that are created by using the scaling configuration.
        self.zone_id = zone_id  # type: str

    def validate(self):
        if self.image_options:
            self.image_options.validate()
        if self.private_pool_options:
            self.private_pool_options.validate()
        if self.system_disk:
            self.system_disk.validate()
        if self.custom_priorities:
            for k in self.custom_priorities:
                if k:
                    k.validate()
        if self.data_disks:
            for k in self.data_disks:
                if k:
                    k.validate()
        if self.instance_pattern_infos:
            for k in self.instance_pattern_infos:
                if k:
                    k.validate()
        if self.instance_type_overrides:
            for k in self.instance_type_overrides:
                if k:
                    k.validate()
        if self.spot_price_limits:
            for k in self.spot_price_limits:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyScalingConfigurationShrinkRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.image_options is not None:
            result['ImageOptions'] = self.image_options.to_map()
        if self.private_pool_options is not None:
            result['PrivatePoolOptions'] = self.private_pool_options.to_map()
        if self.system_disk is not None:
            result['SystemDisk'] = self.system_disk.to_map()
        if self.affinity is not None:
            result['Affinity'] = self.affinity
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.credit_specification is not None:
            result['CreditSpecification'] = self.credit_specification
        result['CustomPriorities'] = []
        if self.custom_priorities is not None:
            for k in self.custom_priorities:
                result['CustomPriorities'].append(k.to_map() if k else None)
        result['DataDisks'] = []
        if self.data_disks is not None:
            for k in self.data_disks:
                result['DataDisks'].append(k.to_map() if k else None)
        if self.dedicated_host_id is not None:
            result['DedicatedHostId'] = self.dedicated_host_id
        if self.deletion_protection is not None:
            result['DeletionProtection'] = self.deletion_protection
        if self.deployment_set_id is not None:
            result['DeploymentSetId'] = self.deployment_set_id
        if self.host_name is not None:
            result['HostName'] = self.host_name
        if self.hpc_cluster_id is not None:
            result['HpcClusterId'] = self.hpc_cluster_id
        if self.image_family is not None:
            result['ImageFamily'] = self.image_family
        if self.image_id is not None:
            result['ImageId'] = self.image_id
        if self.image_name is not None:
            result['ImageName'] = self.image_name
        if self.instance_description is not None:
            result['InstanceDescription'] = self.instance_description
        if self.instance_name is not None:
            result['InstanceName'] = self.instance_name
        result['InstancePatternInfos'] = []
        if self.instance_pattern_infos is not None:
            for k in self.instance_pattern_infos:
                result['InstancePatternInfos'].append(k.to_map() if k else None)
        result['InstanceTypeOverrides'] = []
        if self.instance_type_overrides is not None:
            for k in self.instance_type_overrides:
                result['InstanceTypeOverrides'].append(k.to_map() if k else None)
        if self.instance_types is not None:
            result['InstanceTypes'] = self.instance_types
        if self.internet_charge_type is not None:
            result['InternetChargeType'] = self.internet_charge_type
        if self.internet_max_bandwidth_out is not None:
            result['InternetMaxBandwidthOut'] = self.internet_max_bandwidth_out
        if self.io_optimized is not None:
            result['IoOptimized'] = self.io_optimized
        if self.ipv_6address_count is not None:
            result['Ipv6AddressCount'] = self.ipv_6address_count
        if self.key_pair_name is not None:
            result['KeyPairName'] = self.key_pair_name
        if self.load_balancer_weight is not None:
            result['LoadBalancerWeight'] = self.load_balancer_weight
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.override is not None:
            result['Override'] = self.override
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.password_inherit is not None:
            result['PasswordInherit'] = self.password_inherit
        if self.ram_role_name is not None:
            result['RamRoleName'] = self.ram_role_name
        if self.resource_group_id is not None:
            result['ResourceGroupId'] = self.resource_group_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_configuration_id is not None:
            result['ScalingConfigurationId'] = self.scaling_configuration_id
        if self.scaling_configuration_name is not None:
            result['ScalingConfigurationName'] = self.scaling_configuration_name
        if self.scheduler_options_shrink is not None:
            result['SchedulerOptions'] = self.scheduler_options_shrink
        if self.security_group_id is not None:
            result['SecurityGroupId'] = self.security_group_id
        if self.security_group_ids is not None:
            result['SecurityGroupIds'] = self.security_group_ids
        if self.spot_duration is not None:
            result['SpotDuration'] = self.spot_duration
        if self.spot_interruption_behavior is not None:
            result['SpotInterruptionBehavior'] = self.spot_interruption_behavior
        result['SpotPriceLimits'] = []
        if self.spot_price_limits is not None:
            for k in self.spot_price_limits:
                result['SpotPriceLimits'].append(k.to_map() if k else None)
        if self.spot_strategy is not None:
            result['SpotStrategy'] = self.spot_strategy
        if self.storage_set_id is not None:
            result['StorageSetId'] = self.storage_set_id
        if self.storage_set_partition_number is not None:
            result['StorageSetPartitionNumber'] = self.storage_set_partition_number
        if self.system_disk_categories is not None:
            result['SystemDiskCategories'] = self.system_disk_categories
        if self.tags is not None:
            result['Tags'] = self.tags
        if self.tenancy is not None:
            result['Tenancy'] = self.tenancy
        if self.user_data is not None:
            result['UserData'] = self.user_data
        if self.zone_id is not None:
            result['ZoneId'] = self.zone_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ImageOptions') is not None:
            temp_model = ModifyScalingConfigurationShrinkRequestImageOptions()
            self.image_options = temp_model.from_map(m['ImageOptions'])
        if m.get('PrivatePoolOptions') is not None:
            temp_model = ModifyScalingConfigurationShrinkRequestPrivatePoolOptions()
            self.private_pool_options = temp_model.from_map(m['PrivatePoolOptions'])
        if m.get('SystemDisk') is not None:
            temp_model = ModifyScalingConfigurationShrinkRequestSystemDisk()
            self.system_disk = temp_model.from_map(m['SystemDisk'])
        if m.get('Affinity') is not None:
            self.affinity = m.get('Affinity')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('CreditSpecification') is not None:
            self.credit_specification = m.get('CreditSpecification')
        self.custom_priorities = []
        if m.get('CustomPriorities') is not None:
            for k in m.get('CustomPriorities'):
                temp_model = ModifyScalingConfigurationShrinkRequestCustomPriorities()
                self.custom_priorities.append(temp_model.from_map(k))
        self.data_disks = []
        if m.get('DataDisks') is not None:
            for k in m.get('DataDisks'):
                temp_model = ModifyScalingConfigurationShrinkRequestDataDisks()
                self.data_disks.append(temp_model.from_map(k))
        if m.get('DedicatedHostId') is not None:
            self.dedicated_host_id = m.get('DedicatedHostId')
        if m.get('DeletionProtection') is not None:
            self.deletion_protection = m.get('DeletionProtection')
        if m.get('DeploymentSetId') is not None:
            self.deployment_set_id = m.get('DeploymentSetId')
        if m.get('HostName') is not None:
            self.host_name = m.get('HostName')
        if m.get('HpcClusterId') is not None:
            self.hpc_cluster_id = m.get('HpcClusterId')
        if m.get('ImageFamily') is not None:
            self.image_family = m.get('ImageFamily')
        if m.get('ImageId') is not None:
            self.image_id = m.get('ImageId')
        if m.get('ImageName') is not None:
            self.image_name = m.get('ImageName')
        if m.get('InstanceDescription') is not None:
            self.instance_description = m.get('InstanceDescription')
        if m.get('InstanceName') is not None:
            self.instance_name = m.get('InstanceName')
        self.instance_pattern_infos = []
        if m.get('InstancePatternInfos') is not None:
            for k in m.get('InstancePatternInfos'):
                temp_model = ModifyScalingConfigurationShrinkRequestInstancePatternInfos()
                self.instance_pattern_infos.append(temp_model.from_map(k))
        self.instance_type_overrides = []
        if m.get('InstanceTypeOverrides') is not None:
            for k in m.get('InstanceTypeOverrides'):
                temp_model = ModifyScalingConfigurationShrinkRequestInstanceTypeOverrides()
                self.instance_type_overrides.append(temp_model.from_map(k))
        if m.get('InstanceTypes') is not None:
            self.instance_types = m.get('InstanceTypes')
        if m.get('InternetChargeType') is not None:
            self.internet_charge_type = m.get('InternetChargeType')
        if m.get('InternetMaxBandwidthOut') is not None:
            self.internet_max_bandwidth_out = m.get('InternetMaxBandwidthOut')
        if m.get('IoOptimized') is not None:
            self.io_optimized = m.get('IoOptimized')
        if m.get('Ipv6AddressCount') is not None:
            self.ipv_6address_count = m.get('Ipv6AddressCount')
        if m.get('KeyPairName') is not None:
            self.key_pair_name = m.get('KeyPairName')
        if m.get('LoadBalancerWeight') is not None:
            self.load_balancer_weight = m.get('LoadBalancerWeight')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Override') is not None:
            self.override = m.get('Override')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PasswordInherit') is not None:
            self.password_inherit = m.get('PasswordInherit')
        if m.get('RamRoleName') is not None:
            self.ram_role_name = m.get('RamRoleName')
        if m.get('ResourceGroupId') is not None:
            self.resource_group_id = m.get('ResourceGroupId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingConfigurationId') is not None:
            self.scaling_configuration_id = m.get('ScalingConfigurationId')
        if m.get('ScalingConfigurationName') is not None:
            self.scaling_configuration_name = m.get('ScalingConfigurationName')
        if m.get('SchedulerOptions') is not None:
            self.scheduler_options_shrink = m.get('SchedulerOptions')
        if m.get('SecurityGroupId') is not None:
            self.security_group_id = m.get('SecurityGroupId')
        if m.get('SecurityGroupIds') is not None:
            self.security_group_ids = m.get('SecurityGroupIds')
        if m.get('SpotDuration') is not None:
            self.spot_duration = m.get('SpotDuration')
        if m.get('SpotInterruptionBehavior') is not None:
            self.spot_interruption_behavior = m.get('SpotInterruptionBehavior')
        self.spot_price_limits = []
        if m.get('SpotPriceLimits') is not None:
            for k in m.get('SpotPriceLimits'):
                temp_model = ModifyScalingConfigurationShrinkRequestSpotPriceLimits()
                self.spot_price_limits.append(temp_model.from_map(k))
        if m.get('SpotStrategy') is not None:
            self.spot_strategy = m.get('SpotStrategy')
        if m.get('StorageSetId') is not None:
            self.storage_set_id = m.get('StorageSetId')
        if m.get('StorageSetPartitionNumber') is not None:
            self.storage_set_partition_number = m.get('StorageSetPartitionNumber')
        if m.get('SystemDiskCategories') is not None:
            self.system_disk_categories = m.get('SystemDiskCategories')
        if m.get('Tags') is not None:
            self.tags = m.get('Tags')
        if m.get('Tenancy') is not None:
            self.tenancy = m.get('Tenancy')
        if m.get('UserData') is not None:
            self.user_data = m.get('UserData')
        if m.get('ZoneId') is not None:
            self.zone_id = m.get('ZoneId')
        return self


class ModifyScalingConfigurationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingConfigurationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyScalingConfigurationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyScalingConfigurationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyScalingConfigurationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyScalingConfigurationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyScalingGroupRequestLaunchTemplateOverrides(TeaModel):
    def __init__(self, instance_type=None, spot_price_limit=None, weighted_capacity=None):
        # The instance type. The instance type that you specify by using the InstanceType parameter overwrites the instance type that is specified in the launch template.
        # 
        # If you want Auto Scaling to scale instances in the scaling group based on the instance type weight, you must specify both the InstanceType and WeightedCapacity parameters.
        # 
        # > This parameter takes effect only after you specify the LaunchTemplateId parameter.
        # 
        # You can use the InstanceType parameter to specify only instance types that are available for purchase.
        self.instance_type = instance_type  # type: str
        # 本参数用于指定实例启动模板覆盖规格（即`LaunchTemplateOverride.N.InstanceType`）的竞价价格上限。您可以指定N个该参数，扩展启动模板支持N个实例规格。N的取值范围：1~10。
        # >仅当`LaunchTemplateId`参数指定了启动模板时，该参数才生效。
        self.spot_price_limit = spot_price_limit  # type: float
        # The weight of the instance type. The weight specifies the capacity of a single instance of the specified instance type in the scaling group. If you want Auto Scaling to scale instances in the scaling group based on the weighted capacity of instances, you must specify the WeightedCapacity parameter after you specify the InstanceType parameter.
        # 
        # A higher weight specifies that a smaller number of instances of the specified instance type are required to meet the expected capacity.
        # 
        # Performance metrics, such as the number of vCPUs and the memory size of each instance type, may vary. You can specify different weights for different instance types based on your business requirements.
        # 
        # Example:
        # 
        # *   Current capacity: 0
        # *   Expected capacity: 6
        # *   Capacity of ecs.c5.xlarge: 4
        # 
        # To meet the expected capacity requirement, Auto Scaling must create and add two ecs.c5.xlarge instances.
        # 
        # > The capacity of the scaling group cannot exceed the sum of the maximum number of instances that is specified by the MaxSize parameter and the maximum weight of the instance type.
        # 
        # Valid values of the WeightedCapacity parameter: 1 to 500.
        self.weighted_capacity = weighted_capacity  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingGroupRequestLaunchTemplateOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_type is not None:
            result['InstanceType'] = self.instance_type
        if self.spot_price_limit is not None:
            result['SpotPriceLimit'] = self.spot_price_limit
        if self.weighted_capacity is not None:
            result['WeightedCapacity'] = self.weighted_capacity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceType') is not None:
            self.instance_type = m.get('InstanceType')
        if m.get('SpotPriceLimit') is not None:
            self.spot_price_limit = m.get('SpotPriceLimit')
        if m.get('WeightedCapacity') is not None:
            self.weighted_capacity = m.get('WeightedCapacity')
        return self


class ModifyScalingGroupRequest(TeaModel):
    def __init__(self, active_scaling_configuration_id=None, allocation_strategy=None, az_balance=None,
                 compensate_with_on_demand=None, custom_policy_arn=None, default_cooldown=None, desired_capacity=None,
                 disable_desired_capacity=None, group_deletion_protection=None, health_check_type=None, health_check_types=None,
                 launch_template_id=None, launch_template_overrides=None, launch_template_version=None, max_instance_lifetime=None,
                 max_size=None, min_size=None, multi_azpolicy=None, on_demand_base_capacity=None,
                 on_demand_percentage_above_base_capacity=None, owner_account=None, owner_id=None, removal_policies=None, resource_owner_account=None,
                 resource_owner_id=None, scaling_group_id=None, scaling_group_name=None, scaling_policy=None,
                 spot_allocation_strategy=None, spot_instance_pools=None, spot_instance_remedy=None, v_switch_ids=None):
        # The ID of the active scaling configuration in the scaling group.
        self.active_scaling_configuration_id = active_scaling_configuration_id  # type: str
        # The allocation policy. Auto Scaling selects instance types based on the allocation policy to create the required number of instances. The policy can be applied to pay-as-you-go instances and preemptible instances at the same time. This parameter takes effect only when you set the MultiAZPolicy parameter to COMPOSABLE. Valid values:
        # 
        # *   priority: Auto Scaling selects instance types based on the specified order to create the required number of instances.
        # *   lowestPrice: Auto Scaling selects instance types that have the lowest unit price of vCPUs to create the required number of instances.
        # 
        # Default value: priority.
        self.allocation_strategy = allocation_strategy  # type: str
        # Specifies whether to evenly distribute instances in the scaling group across zones. This parameter takes effect only when you set the `MultiAZPolicy` parameter to `COMPOSABLE`. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: false.
        self.az_balance = az_balance  # type: bool
        # Specifies whether to automatically create pay-as-you-go instances to meet the requirements on the number of ECS instances in the scaling group when the number of preemptible instances cannot be reached due to reasons such as costs and insufficient resources. This parameter takes effect only if you set the MultiAZPolicy parameter in the CreateScalingGroup operation to COST_OPTIMIZED. Valid values:
        # 
        # *   true
        # *   false
        self.compensate_with_on_demand = compensate_with_on_demand  # type: bool
        # The ARN of the custom scaling policy (Function). This parameter takes effect only when you specify CustomPolicy as the first step of the instance removal policy.
        self.custom_policy_arn = custom_policy_arn  # type: str
        # The default cooldown time of the scaling group. This parameter takes effect only for scaling groups that have simple scaling rules. Valid values: 0 to 86400. Unit: seconds. During the cooldown time, Auto Scaling executes only scaling activities that are triggered by event-triggered tasks associated with CloudMonitor.
        self.default_cooldown = default_cooldown  # type: int
        # The expected number of ECS instances in the scaling group. Auto Scaling automatically maintains the specified expected number of ECS instances. The expected number cannot be greater than the value of the MaxSize parameter and cannot be less than the value of the MinSize parameter.
        self.desired_capacity = desired_capacity  # type: int
        # 伸缩组是否关闭期望实例数功能。取值范围：
        # 
        # - false：启用期望实例数功能。
        # - true：关闭期望实例数功能。
        # 
        # > 只有伸缩组当前无伸缩活动时，才能将该参数设置为true（即关闭伸缩组的期望实例数功能），关闭伸缩组的期望实例数功能时伸缩组当前的DesiredCapacity属性也会被清空，但伸缩组中当前的实例数量不发生变化。
        self.disable_desired_capacity = disable_desired_capacity  # type: bool
        # Specifies whether to enable deletion protection for the scaling group. Valid values:
        # 
        # *   true: enables deletion protection for the scaling group. This way, the scaling group cannot be deleted.
        # *   false: disables deletion protection for the scaling group.
        self.group_deletion_protection = group_deletion_protection  # type: bool
        # The health check mode of the scaling group. Valid values:
        # 
        # *   NONE: Auto Scaling does not perform health checks on instances in the scaling group.
        # *   ECS: Auto Scaling performs health checks on ECS instances in the scaling group.
        self.health_check_type = health_check_type  # type: str
        self.health_check_types = health_check_types  # type: list[str]
        # The ID of the launch template that is used by Auto Scaling to create instances.
        self.launch_template_id = launch_template_id  # type: str
        # Details of the instance types that are specified in the extended configurations of the launch template.
        self.launch_template_overrides = launch_template_overrides  # type: list[ModifyScalingGroupRequestLaunchTemplateOverrides]
        # The version number of the launch template. Valid values:
        # 
        # *   A fixed template version number.
        # *   Default: The default template version is always used.
        # *   Latest: The latest template version is always used.
        self.launch_template_version = launch_template_version  # type: str
        # The maximum life span of the instance in the scaling group. Unit: seconds.
        # 
        # Valid values: 86400 to Integer.maxValue. ``You can also set this parameter to 0. A value of 0 indicates that the instance has an unlimited life span in the scaling group.
        # 
        # Default value: null.
        # 
        # > You cannot specify this parameter for scaling groups that manage elastic container instances or scaling groups whose ScalingPolicy is set to recycle.
        self.max_instance_lifetime = max_instance_lifetime  # type: int
        # The maximum number of ECS instances in the scaling group. When the number of ECS instances in the scaling group is greater than the value of the MaxSize parameter, Auto Scaling automatically removes ECS instances from the scaling group until the number of instances is equal to the value of the MaxSize parameter.
        # 
        # The value range of the MaxSize parameter varies based on the instance quota. You can go to [Quota Center](https://quotas.console.aliyun.com/products/ess/quotas) to check the quota of **instances that can be included in a scaling group**.
        # 
        # For example, if the quota of instances that can be included in a scaling group is 2000, the valid values of the MaxSize parameter range from 0 to 2000.
        self.max_size = max_size  # type: int
        # The minimum number of ECS instances in the scaling group. When the number of ECS instances in the scaling group is less than the value of the MinSize parameter, Auto Scaling automatically creates ECS instances and adds the instances to the scaling group until the number of instances is equal to the value of the MinSize parameter.
        # 
        # > The value of the MinSize parameter must be less than or equal to the value of the MaxSize parameter.
        self.min_size = min_size  # type: int
        # The scaling policy for the multi-zone scaling group that contains ECS instances. Valid values:
        # 
        # *   PRIORITY: ECS instances are scaled based on the vSwitch priority. The first vSwitch specified by using the VSwitchIds parameter has the highest priority. Auto Scaling preferentially scales instances in the zone where the vSwitch that has the highest priority resides. If the scaling fails, Auto Scaling scales instances in the zone where the vSwitch that has the next highest priority resides.
        # *   COST_OPTIMIZED: During a scale-out activity, Auto Scaling preferentially creates ECS instances of the instance type that has the lowest unit price of vCPU. During a scale-in activity, Auto Scaling preferentially removes ECS instances of the instance types that have the highest unit price of vCPU. Auto Scaling preferentially creates preemptible instances when preemptible instance types are specified in the scaling configuration. You can use the `CompensateWithOnDemand` parameter to specify whether to automatically create pay-as-you-go instances when Auto Scaling fails to create preemptible instances.
        # 
        # > The `COST_OPTIMIZED` setting takes effect only when multiple instance types are specified or at least one instance type is specified for preemptible instances.
        # 
        # *   BALANCE: ECS instances are evenly distributed across zones that are specified in the scaling group. If ECS instances are unevenly distributed among zones due to insufficient resources, you can call the RebalanceInstance operation to evenly distribute the instances among the zones.
        # *   COMPOSABLE: You can flexibly combine the preceding policies based on your business requirements.
        self.multi_azpolicy = multi_azpolicy  # type: str
        # The minimum number of pay-as-you-go instances that must be included in the scaling group. Valid values: 0 to 1000. If the number of pay-as-you-go instances is less than the value of this parameter, Auto Scaling preferentially creates pay-as-you-go instances.
        # 
        # If you set the `MultiAZPolicy` parameter to `COMPOSABLE` Policy, the default value is 0.
        self.on_demand_base_capacity = on_demand_base_capacity  # type: int
        # The expected percentage of pay-as-you-go instances in the excess instances when the minimum number of pay-as-you-go instances reaches the requirement. Valid values: 0 to 100.
        # 
        # If you set the `MultiAZPolicy` parameter to `COMPOSABLE` Policy, the default value is 100.
        self.on_demand_percentage_above_base_capacity = on_demand_percentage_above_base_capacity  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The policy that is used to remove ECS instances from the scaling group. Valid values:
        # 
        # *   OldestInstance: removes ECS instances that are added at the earliest point in time to the scaling group.
        # *   NewestInstance: removes ECS instances that are most recently added to the scaling group.
        # *   OldestScalingConfiguration: removes ECS instances that are created based on the earliest scaling configuration.
        self.removal_policies = removal_policies  # type: list[str]
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group that you want to modify.
        self.scaling_group_id = scaling_group_id  # type: str
        # The name of the scaling group. The name of each scaling group must be unique in a region. The name must be 2 to 64 characters in length and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit.
        self.scaling_group_name = scaling_group_name  # type: str
        self.scaling_policy = scaling_policy  # type: str
        # The allocation policy of preemptible instances. You can use this parameter to individually specify the allocation policy of preemptible instances. This parameter takes effect only when you set the `MultiAZPolicy` parameter to `COMPOSABLE`. Valid values:
        # 
        # *   priority: Auto Scaling selects instance types based on the specified order to create the required number of preemptible instances.
        # *   lowestPrice: Auto Scaling selects instance types that have the lowest unit price of vCPUs to create the required number of preemptible instances.
        # 
        # Default value: priority.
        self.spot_allocation_strategy = spot_allocation_strategy  # type: str
        # The number of instance types that you specify. Auto Scaling creates preemptible instances of multiple instance types that are provided at the lowest price. Valid values: 0 to 10.
        # 
        # If you set the `MultiAZPolicy` parameter to `COMPOSABLE` Policy, the default value is 2.
        self.spot_instance_pools = spot_instance_pools  # type: int
        # Specifies whether to supplement preemptible instances. If this parameter is set to true, Auto Scaling creates an instance to replace a preemptible instance when Auto Scaling receives the system message that the preemptible instance is to be reclaimed.
        self.spot_instance_remedy = spot_instance_remedy  # type: bool
        # The IDs of vSwitches.
        # 
        # This parameter takes effect only when the network type of the scaling group is virtual private cloud (VPC). The specified vSwitches and the scaling group must reside in the same VPC.
        # 
        # The vSwitches can reside in different zones. The vSwitches are sorted in ascending order. The first vSwitch specified by using the VSwitchIds parameter has the highest priority. If Auto Scaling fails to create ECS instances in the zone where the vSwitch that has the highest priority resides, Auto Scaling creates ECS instances in the zone where the vSwitch that has the next highest priority resides.
        self.v_switch_ids = v_switch_ids  # type: list[str]

    def validate(self):
        if self.launch_template_overrides:
            for k in self.launch_template_overrides:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyScalingGroupRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.active_scaling_configuration_id is not None:
            result['ActiveScalingConfigurationId'] = self.active_scaling_configuration_id
        if self.allocation_strategy is not None:
            result['AllocationStrategy'] = self.allocation_strategy
        if self.az_balance is not None:
            result['AzBalance'] = self.az_balance
        if self.compensate_with_on_demand is not None:
            result['CompensateWithOnDemand'] = self.compensate_with_on_demand
        if self.custom_policy_arn is not None:
            result['CustomPolicyARN'] = self.custom_policy_arn
        if self.default_cooldown is not None:
            result['DefaultCooldown'] = self.default_cooldown
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.disable_desired_capacity is not None:
            result['DisableDesiredCapacity'] = self.disable_desired_capacity
        if self.group_deletion_protection is not None:
            result['GroupDeletionProtection'] = self.group_deletion_protection
        if self.health_check_type is not None:
            result['HealthCheckType'] = self.health_check_type
        if self.health_check_types is not None:
            result['HealthCheckTypes'] = self.health_check_types
        if self.launch_template_id is not None:
            result['LaunchTemplateId'] = self.launch_template_id
        result['LaunchTemplateOverrides'] = []
        if self.launch_template_overrides is not None:
            for k in self.launch_template_overrides:
                result['LaunchTemplateOverrides'].append(k.to_map() if k else None)
        if self.launch_template_version is not None:
            result['LaunchTemplateVersion'] = self.launch_template_version
        if self.max_instance_lifetime is not None:
            result['MaxInstanceLifetime'] = self.max_instance_lifetime
        if self.max_size is not None:
            result['MaxSize'] = self.max_size
        if self.min_size is not None:
            result['MinSize'] = self.min_size
        if self.multi_azpolicy is not None:
            result['MultiAZPolicy'] = self.multi_azpolicy
        if self.on_demand_base_capacity is not None:
            result['OnDemandBaseCapacity'] = self.on_demand_base_capacity
        if self.on_demand_percentage_above_base_capacity is not None:
            result['OnDemandPercentageAboveBaseCapacity'] = self.on_demand_percentage_above_base_capacity
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.removal_policies is not None:
            result['RemovalPolicies'] = self.removal_policies
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scaling_group_name is not None:
            result['ScalingGroupName'] = self.scaling_group_name
        if self.scaling_policy is not None:
            result['ScalingPolicy'] = self.scaling_policy
        if self.spot_allocation_strategy is not None:
            result['SpotAllocationStrategy'] = self.spot_allocation_strategy
        if self.spot_instance_pools is not None:
            result['SpotInstancePools'] = self.spot_instance_pools
        if self.spot_instance_remedy is not None:
            result['SpotInstanceRemedy'] = self.spot_instance_remedy
        if self.v_switch_ids is not None:
            result['VSwitchIds'] = self.v_switch_ids
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActiveScalingConfigurationId') is not None:
            self.active_scaling_configuration_id = m.get('ActiveScalingConfigurationId')
        if m.get('AllocationStrategy') is not None:
            self.allocation_strategy = m.get('AllocationStrategy')
        if m.get('AzBalance') is not None:
            self.az_balance = m.get('AzBalance')
        if m.get('CompensateWithOnDemand') is not None:
            self.compensate_with_on_demand = m.get('CompensateWithOnDemand')
        if m.get('CustomPolicyARN') is not None:
            self.custom_policy_arn = m.get('CustomPolicyARN')
        if m.get('DefaultCooldown') is not None:
            self.default_cooldown = m.get('DefaultCooldown')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('DisableDesiredCapacity') is not None:
            self.disable_desired_capacity = m.get('DisableDesiredCapacity')
        if m.get('GroupDeletionProtection') is not None:
            self.group_deletion_protection = m.get('GroupDeletionProtection')
        if m.get('HealthCheckType') is not None:
            self.health_check_type = m.get('HealthCheckType')
        if m.get('HealthCheckTypes') is not None:
            self.health_check_types = m.get('HealthCheckTypes')
        if m.get('LaunchTemplateId') is not None:
            self.launch_template_id = m.get('LaunchTemplateId')
        self.launch_template_overrides = []
        if m.get('LaunchTemplateOverrides') is not None:
            for k in m.get('LaunchTemplateOverrides'):
                temp_model = ModifyScalingGroupRequestLaunchTemplateOverrides()
                self.launch_template_overrides.append(temp_model.from_map(k))
        if m.get('LaunchTemplateVersion') is not None:
            self.launch_template_version = m.get('LaunchTemplateVersion')
        if m.get('MaxInstanceLifetime') is not None:
            self.max_instance_lifetime = m.get('MaxInstanceLifetime')
        if m.get('MaxSize') is not None:
            self.max_size = m.get('MaxSize')
        if m.get('MinSize') is not None:
            self.min_size = m.get('MinSize')
        if m.get('MultiAZPolicy') is not None:
            self.multi_azpolicy = m.get('MultiAZPolicy')
        if m.get('OnDemandBaseCapacity') is not None:
            self.on_demand_base_capacity = m.get('OnDemandBaseCapacity')
        if m.get('OnDemandPercentageAboveBaseCapacity') is not None:
            self.on_demand_percentage_above_base_capacity = m.get('OnDemandPercentageAboveBaseCapacity')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RemovalPolicies') is not None:
            self.removal_policies = m.get('RemovalPolicies')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScalingGroupName') is not None:
            self.scaling_group_name = m.get('ScalingGroupName')
        if m.get('ScalingPolicy') is not None:
            self.scaling_policy = m.get('ScalingPolicy')
        if m.get('SpotAllocationStrategy') is not None:
            self.spot_allocation_strategy = m.get('SpotAllocationStrategy')
        if m.get('SpotInstancePools') is not None:
            self.spot_instance_pools = m.get('SpotInstancePools')
        if m.get('SpotInstanceRemedy') is not None:
            self.spot_instance_remedy = m.get('SpotInstanceRemedy')
        if m.get('VSwitchIds') is not None:
            self.v_switch_ids = m.get('VSwitchIds')
        return self


class ModifyScalingGroupResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingGroupResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyScalingGroupResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyScalingGroupResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyScalingGroupResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyScalingGroupResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyScalingRuleRequestAlarmDimensions(TeaModel):
    def __init__(self, dimension_key=None, dimension_value=None):
        # 监控项关联的维度信息键。
        self.dimension_key = dimension_key  # type: str
        # 监控项关联的维度信息值。
        self.dimension_value = dimension_value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingRuleRequestAlarmDimensions, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.dimension_key is not None:
            result['DimensionKey'] = self.dimension_key
        if self.dimension_value is not None:
            result['DimensionValue'] = self.dimension_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DimensionKey') is not None:
            self.dimension_key = m.get('DimensionKey')
        if m.get('DimensionValue') is not None:
            self.dimension_value = m.get('DimensionValue')
        return self


class ModifyScalingRuleRequestStepAdjustments(TeaModel):
    def __init__(self, metric_interval_lower_bound=None, metric_interval_upper_bound=None,
                 scaling_adjustment=None):
        # The lower limit that is specified in a step adjustment. This parameter is available only if you set the ScalingRuleType parameter to StepScalingRule. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_interval_lower_bound = metric_interval_lower_bound  # type: float
        # The upper limit specified in a step adjustment. This parameter is available only if you set the ScalingRuleType parameter to StepScalingRule. Valid values: -9.999999E18 to 9.999999E18.
        self.metric_interval_upper_bound = metric_interval_upper_bound  # type: float
        # The number of ECS instances that you want to scale in a step adjustment. This parameter is available only if you set the ScalingRuleType parameter to StepScalingRule.
        self.scaling_adjustment = scaling_adjustment  # type: int

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingRuleRequestStepAdjustments, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.metric_interval_lower_bound is not None:
            result['MetricIntervalLowerBound'] = self.metric_interval_lower_bound
        if self.metric_interval_upper_bound is not None:
            result['MetricIntervalUpperBound'] = self.metric_interval_upper_bound
        if self.scaling_adjustment is not None:
            result['ScalingAdjustment'] = self.scaling_adjustment
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('MetricIntervalLowerBound') is not None:
            self.metric_interval_lower_bound = m.get('MetricIntervalLowerBound')
        if m.get('MetricIntervalUpperBound') is not None:
            self.metric_interval_upper_bound = m.get('MetricIntervalUpperBound')
        if m.get('ScalingAdjustment') is not None:
            self.scaling_adjustment = m.get('ScalingAdjustment')
        return self


class ModifyScalingRuleRequest(TeaModel):
    def __init__(self, adjustment_type=None, adjustment_value=None, alarm_dimensions=None, cooldown=None,
                 disable_scale_in=None, estimated_instance_warmup=None, initial_max_size=None, metric_name=None,
                 min_adjustment_magnitude=None, owner_account=None, owner_id=None, predictive_scaling_mode=None,
                 predictive_task_buffer_time=None, predictive_value_behavior=None, predictive_value_buffer=None, resource_owner_account=None,
                 resource_owner_id=None, scale_in_evaluation_count=None, scale_out_evaluation_count=None, scaling_rule_id=None,
                 scaling_rule_name=None, step_adjustments=None, target_value=None):
        # The adjustment method of the scaling rule. This is required when the ScalingRuleType parameter is set to SimpleScalingRule or StepScalingRule. Valid values:
        # 
        # *   QuantityChangeInCapacity: adds the specified number of ECS instances to or removes the specified number of ECS instances from the scaling group.
        # *   PercentChangeInCapacity: adds the specified percentage of ECS instances to or removes the specified percentage of ECS instances from the scaling group.
        # *   TotalCapacity: adjusts the number of ECS instances in the scaling group to the specified number.
        self.adjustment_type = adjustment_type  # type: str
        # The target value specified in the scaling rule. This parameter is required when the ScalingRuleType parameter is set to SimpleScalingRule or StepScalingRule. The number of ECS instances that are scaled in a single scaling activity cannot exceed 1,000.
        # 
        # *   Valid values if you set the AdjustmentType parameter to QuantityChangeInCapacity: -1000 to 1000.
        # *   Valid values if you set the AdjustmentType parameter to PercentChangeInCapacity: -100 to 10000.
        # *   Valid values if you set the AdjustmentType parameter to TotalCapacity: 0 to 2000.
        self.adjustment_value = adjustment_value  # type: int
        # 监控项维度信息值，适用于目标追踪规则，当监控项需额外维度信息时设置，例如LoadBalancerRealServerAverageQps监控项需指定rulePool维度信息。
        self.alarm_dimensions = alarm_dimensions  # type: list[ModifyScalingRuleRequestAlarmDimensions]
        # The cooldown time of the scaling rule. This parameter is available only if you set the ScalingRuleType parameter to SimpleScalingRule.
        # 
        # Valid values: 0 to 86400. Unit: seconds.
        self.cooldown = cooldown  # type: int
        # Specifies whether to disable scale-in. This parameter is available only if you set the ScalingRuleType parameter to TargetTrackingScalingRule.
        self.disable_scale_in = disable_scale_in  # type: bool
        # The warmup period of an instance. This parameter is available only if you set the ScalingRuleType parameter to TargetTrackingScalingRule or PredictiveScalingRule. Auto Scaling adds ECS instances that are in the warmup state to a scaling group but does not report monitoring data to CloudMonitor during the warmup period.
        # 
        # > Auto Scaling calculates the number of ECS instances that need to be scaled. ECS instances in the warmup state are not counted towards the current capacity of the scaling group.
        # 
        # Valid values: 0 to 86400. Unit: seconds.
        self.estimated_instance_warmup = estimated_instance_warmup  # type: int
        # The maximum number of ECS instances in the scaling group. If you specify this parameter, you must also specify the PredictiveValueBehavior parameter.
        self.initial_max_size = initial_max_size  # type: int
        # The predefined metric that you want to monitor. This parameter is required only if you set the ScalingRuleType parameter to TargetTrackingScalingRule or PredictiveScalingRule.
        # 
        # Valid values if you set the ScalingRuleType parameter to TargetTrackingScalingRule:
        # 
        # *   CpuUtilization: the average CPU utilization
        # *   ClassicInternetRx: the average inbound Internet traffic over the classic network
        # *   ClassicInternetTx: the average outbound Internet traffic over the classic network
        # *   VpcInternetRx: the average inbound Internet traffic over the virtual private cloud (VPC)
        # *   VpcInternetTx: the average outbound Internet traffic over the VPC
        # *   IntranetRx: the average inbound traffic over the internal network
        # *   IntranetTx: the average outbound traffic over the internal network
        # 
        # Valid values if you set the ScalingRuleType parameter to PredictiveScalingRule:
        # 
        # *   CpuUtilization: the average CPU utilization
        # *   IntranetRx: the average inbound traffic over the internal network
        # *   IntranetTx: the average outbound traffic over the internal network
        self.metric_name = metric_name  # type: str
        # The minimum number of instances that must be scaled when the AdjustmentType parameter is set to PercentChangeInCapacity. This parameter takes effect only if you set the ScalingRuleType parameter to SimpleScalingRule or StepScalingRule.
        self.min_adjustment_magnitude = min_adjustment_magnitude  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The mode of the predictive scaling rule. Valid values:
        # 
        # *   PredictAndScale: produces predictions and creates prediction tasks.
        # *   PredictOnly: produces predictions but does not create prediction tasks.
        self.predictive_scaling_mode = predictive_scaling_mode  # type: str
        # The amount of buffer time before the prediction task is executed. By default, all prediction tasks that are automatically created for a predictive scaling rule are executed on the hour. You can specify an amount of buffer time for resource preparation before the prediction tasks are executed. Valid values: 0 to 60.
        self.predictive_task_buffer_time = predictive_task_buffer_time  # type: int
        # Specifies which one of the initial maximum capacity and the predicted value can be used as the maximum value for prediction tasks. Valid values:
        # 
        # *   MaxOverridePredictiveValue: uses the initial maximum capacity as the maximum value for prediction tasks if the predicted value is greater than the initial maximum capacity.
        # *   PredictiveValueOverrideMax: uses the predicted value as the maximum value for prediction tasks when the predicted value is greater than the initial maximum capacity.
        # *   PredictiveValueOverrideMaxWithBuffer: increases the predicted value by a percentage that is specified by the PredictiveValueBuffer parameter. If the predicted value that is increased by the percentage is greater than the initial maximum capacity, the increased value is used as the maximum value for prediction tasks.
        self.predictive_value_behavior = predictive_value_behavior  # type: str
        # The percentage of the increment to the predicted value when the PredictiveValueBehavior parameter is set to PredictiveValueOverrideMaxWithBuffer. If the predicted value increased by this percentage is greater than the initial maximum capacity, the increased value is used as the maximum value for prediction tasks. Valid values: 0 to 100.
        self.predictive_value_buffer = predictive_value_buffer  # type: int
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The number of consecutive times that the event-triggered task created for scale-in activities must meet the threshold conditions before an alert is triggered. After a target tracking scaling rule is created, an event-triggered task is automatically created and then associated with the target tracking scaling rule.
        self.scale_in_evaluation_count = scale_in_evaluation_count  # type: int
        # The number of consecutive times that the event-triggered task created for scale-out activities must meet the threshold conditions before an alert is triggered. After a target tracking scaling rule is created, an event-triggered task is automatically created and then associated with the target tracking scaling rule.
        self.scale_out_evaluation_count = scale_out_evaluation_count  # type: int
        # The ID of the scaling rule that you want to modify.
        self.scaling_rule_id = scaling_rule_id  # type: str
        # The name of the scaling rule. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). The name must start with a letter or a digit. The name of a scaling rule must be unique in the scaling group to which the scaling rule belongs and within an Alibaba Cloud account.
        self.scaling_rule_name = scaling_rule_name  # type: str
        # Details of the step adjustments.
        self.step_adjustments = step_adjustments  # type: list[ModifyScalingRuleRequestStepAdjustments]
        # The target value. This parameter is available only if you set the ScalingRuleType parameter to TargetTrackingScalingRule or PredictiveScalingRule. The value must be greater than 0 and can have up to three decimal places.
        self.target_value = target_value  # type: float

    def validate(self):
        if self.alarm_dimensions:
            for k in self.alarm_dimensions:
                if k:
                    k.validate()
        if self.step_adjustments:
            for k in self.step_adjustments:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ModifyScalingRuleRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.adjustment_type is not None:
            result['AdjustmentType'] = self.adjustment_type
        if self.adjustment_value is not None:
            result['AdjustmentValue'] = self.adjustment_value
        result['AlarmDimensions'] = []
        if self.alarm_dimensions is not None:
            for k in self.alarm_dimensions:
                result['AlarmDimensions'].append(k.to_map() if k else None)
        if self.cooldown is not None:
            result['Cooldown'] = self.cooldown
        if self.disable_scale_in is not None:
            result['DisableScaleIn'] = self.disable_scale_in
        if self.estimated_instance_warmup is not None:
            result['EstimatedInstanceWarmup'] = self.estimated_instance_warmup
        if self.initial_max_size is not None:
            result['InitialMaxSize'] = self.initial_max_size
        if self.metric_name is not None:
            result['MetricName'] = self.metric_name
        if self.min_adjustment_magnitude is not None:
            result['MinAdjustmentMagnitude'] = self.min_adjustment_magnitude
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.predictive_scaling_mode is not None:
            result['PredictiveScalingMode'] = self.predictive_scaling_mode
        if self.predictive_task_buffer_time is not None:
            result['PredictiveTaskBufferTime'] = self.predictive_task_buffer_time
        if self.predictive_value_behavior is not None:
            result['PredictiveValueBehavior'] = self.predictive_value_behavior
        if self.predictive_value_buffer is not None:
            result['PredictiveValueBuffer'] = self.predictive_value_buffer
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scale_in_evaluation_count is not None:
            result['ScaleInEvaluationCount'] = self.scale_in_evaluation_count
        if self.scale_out_evaluation_count is not None:
            result['ScaleOutEvaluationCount'] = self.scale_out_evaluation_count
        if self.scaling_rule_id is not None:
            result['ScalingRuleId'] = self.scaling_rule_id
        if self.scaling_rule_name is not None:
            result['ScalingRuleName'] = self.scaling_rule_name
        result['StepAdjustments'] = []
        if self.step_adjustments is not None:
            for k in self.step_adjustments:
                result['StepAdjustments'].append(k.to_map() if k else None)
        if self.target_value is not None:
            result['TargetValue'] = self.target_value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('AdjustmentType') is not None:
            self.adjustment_type = m.get('AdjustmentType')
        if m.get('AdjustmentValue') is not None:
            self.adjustment_value = m.get('AdjustmentValue')
        self.alarm_dimensions = []
        if m.get('AlarmDimensions') is not None:
            for k in m.get('AlarmDimensions'):
                temp_model = ModifyScalingRuleRequestAlarmDimensions()
                self.alarm_dimensions.append(temp_model.from_map(k))
        if m.get('Cooldown') is not None:
            self.cooldown = m.get('Cooldown')
        if m.get('DisableScaleIn') is not None:
            self.disable_scale_in = m.get('DisableScaleIn')
        if m.get('EstimatedInstanceWarmup') is not None:
            self.estimated_instance_warmup = m.get('EstimatedInstanceWarmup')
        if m.get('InitialMaxSize') is not None:
            self.initial_max_size = m.get('InitialMaxSize')
        if m.get('MetricName') is not None:
            self.metric_name = m.get('MetricName')
        if m.get('MinAdjustmentMagnitude') is not None:
            self.min_adjustment_magnitude = m.get('MinAdjustmentMagnitude')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('PredictiveScalingMode') is not None:
            self.predictive_scaling_mode = m.get('PredictiveScalingMode')
        if m.get('PredictiveTaskBufferTime') is not None:
            self.predictive_task_buffer_time = m.get('PredictiveTaskBufferTime')
        if m.get('PredictiveValueBehavior') is not None:
            self.predictive_value_behavior = m.get('PredictiveValueBehavior')
        if m.get('PredictiveValueBuffer') is not None:
            self.predictive_value_buffer = m.get('PredictiveValueBuffer')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScaleInEvaluationCount') is not None:
            self.scale_in_evaluation_count = m.get('ScaleInEvaluationCount')
        if m.get('ScaleOutEvaluationCount') is not None:
            self.scale_out_evaluation_count = m.get('ScaleOutEvaluationCount')
        if m.get('ScalingRuleId') is not None:
            self.scaling_rule_id = m.get('ScalingRuleId')
        if m.get('ScalingRuleName') is not None:
            self.scaling_rule_name = m.get('ScalingRuleName')
        self.step_adjustments = []
        if m.get('StepAdjustments') is not None:
            for k in m.get('StepAdjustments'):
                temp_model = ModifyScalingRuleRequestStepAdjustments()
                self.step_adjustments.append(temp_model.from_map(k))
        if m.get('TargetValue') is not None:
            self.target_value = m.get('TargetValue')
        return self


class ModifyScalingRuleResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScalingRuleResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyScalingRuleResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyScalingRuleResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyScalingRuleResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyScalingRuleResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ModifyScheduledTaskRequest(TeaModel):
    def __init__(self, description=None, desired_capacity=None, launch_expiration_time=None, launch_time=None,
                 max_value=None, min_value=None, owner_account=None, owner_id=None, recurrence_end_time=None,
                 recurrence_type=None, recurrence_value=None, resource_owner_account=None, resource_owner_id=None,
                 scaling_group_id=None, scheduled_action=None, scheduled_task_id=None, scheduled_task_name=None, task_enabled=None):
        # The description of the scheduled task. The description must be 2 to 200 characters in length.
        self.description = description  # type: str
        # The expected number of instances in the scaling group if you specify the ScalingGroupId parameter.
        # 
        # > You must specify the `DesiredCapacity` parameter when you create a scaling group.
        self.desired_capacity = desired_capacity  # type: int
        # The time period during which the failed scheduled task is retried. Unit: seconds. Valid values: 0 to 1800.
        # 
        # Default value: 600.
        self.launch_expiration_time = launch_expiration_time  # type: int
        # The point in time at which the scheduled task is triggered. The time follows the ISO 8601 standard in the YYYY-MM-DDThh:mmZ format. The time must be in UTC. You cannot enter a time point later than 90 days from the point in time at which the scheduled task is modified.
        # 
        # *   If you specify the `RecurrenceType` parameter, the task is repeatedly executed at the time point that is specified by the LaunchTime parameter.
        # *   If you do not specify the `RecurrenceType` parameter, the task is executed only once at the point in time that is specified by the LaunchTime parameter.
        self.launch_time = launch_time  # type: str
        # The maximum number of instances in the scaling group if you specify the ScalingGroupId parameter.
        self.max_value = max_value  # type: int
        # The minimum number of instances in the scaling group if you specify the ScalingGroupId parameter.
        self.min_value = min_value  # type: int
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The end time of the scheduled task. Specify the time in the ISO 8601 standard in the YYYY-MM-DDThh:mmZ format. The time must be in UTC. You cannot enter a point in time that is later than 365 days from the point in time at which the scheduled task is modified.
        self.recurrence_end_time = recurrence_end_time  # type: str
        # The interval at which the scheduled task is repeated. Valid values:
        # 
        # *   Daily: The scheduled task is executed once every specified number of days.
        # *   Weekly: The scheduled task is executed on each specified day of the week.
        # *   Monthly: The scheduled task is executed on each specified day of the month.
        # *   Cron: The scheduled task is executed based on the specified cron expression.
        # 
        # After you modify the scheduled task, the values that you specify for the `RecurrenceType` and `RecurrenceValue` parameters must be valid at the same time.
        self.recurrence_type = recurrence_type  # type: str
        # The number of recurrences of the scheduled task.
        # 
        # *   If you set the `RecurrenceType` parameter to `Daily`, you can specify only one value for this parameter. Valid values: 1 to 31.
        # *   If you set the `RecurrenceType` parameter to `Weekly`, you can specify multiple values for this parameter. Separate the values with commas (,). The values that correspond to Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, and Saturday are 0, 1, 2, 3, 4, 5, and 6.``
        # *   If you set the `RecurrenceType` parameter to `Monthly`, you can specify two values in the `A-B` format for this parameter. Valid values of A and B: 1 to 31. B must be greater than or equal to A.
        # *   If you set the `RecurrenceType` parameter to `Cron`, you can specify a cron expression. A cron expression is written in UTC time and consists of the following fields: minute, hour, day, month, and week. The expression can contain the letters L and W and the following wildcard characters: commas (,), question marks (?), hyphens (-), asterisks (\*), number signs (#), and forward slashes (/).
        # 
        # After you modify the scheduled task, the values that you specify for the `RecurrenceType` and `RecurrenceValue` parameters must be valid at the same time.
        self.recurrence_value = recurrence_value  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group whose number of instances must be modified when the scheduled task is triggered. If you specify the `ScalingGroupId` parameter for a scheduled task, you must specify the minimum, maximum, or expected numbers of instances for a scaling group in the scheduled task. That is, you must specify at least one of the `MinValue`, `MaxValue`, and `DesiredCapacity` parameters.
        # 
        # > You cannot specify the `ScheduledAction` and `ScalingGroupId` parameters at the same time.
        self.scaling_group_id = scaling_group_id  # type: str
        # The scaling rule that you want to execute when the scheduled task is triggered. Specify the unique identifier of the scaling rule. If you specify the `ScheduledAction` parameter, you must select an existing scaling rule for the scheduled task.
        # 
        # > You cannot specify the `ScheduledAction` and `ScalingGroupId` parameters at the same time.
        self.scheduled_action = scheduled_action  # type: str
        # The ID of the scheduled task.
        self.scheduled_task_id = scheduled_task_id  # type: str
        # The name of the scheduled task. The name must be 2 to 64 characters in length, and can contain letters, digits, underscores (\_), hyphens (-), and periods (.). It must start with a letter or a digit. The name of the scheduled task must be unique in the region and within the Alibaba Cloud account.
        self.scheduled_task_name = scheduled_task_name  # type: str
        # Specifies whether to enable the scheduled task. Valid values:
        # 
        # *   true
        # *   false
        # 
        # Default value: true.
        self.task_enabled = task_enabled  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScheduledTaskRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.description is not None:
            result['Description'] = self.description
        if self.desired_capacity is not None:
            result['DesiredCapacity'] = self.desired_capacity
        if self.launch_expiration_time is not None:
            result['LaunchExpirationTime'] = self.launch_expiration_time
        if self.launch_time is not None:
            result['LaunchTime'] = self.launch_time
        if self.max_value is not None:
            result['MaxValue'] = self.max_value
        if self.min_value is not None:
            result['MinValue'] = self.min_value
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.recurrence_end_time is not None:
            result['RecurrenceEndTime'] = self.recurrence_end_time
        if self.recurrence_type is not None:
            result['RecurrenceType'] = self.recurrence_type
        if self.recurrence_value is not None:
            result['RecurrenceValue'] = self.recurrence_value
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.scheduled_action is not None:
            result['ScheduledAction'] = self.scheduled_action
        if self.scheduled_task_id is not None:
            result['ScheduledTaskId'] = self.scheduled_task_id
        if self.scheduled_task_name is not None:
            result['ScheduledTaskName'] = self.scheduled_task_name
        if self.task_enabled is not None:
            result['TaskEnabled'] = self.task_enabled
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Description') is not None:
            self.description = m.get('Description')
        if m.get('DesiredCapacity') is not None:
            self.desired_capacity = m.get('DesiredCapacity')
        if m.get('LaunchExpirationTime') is not None:
            self.launch_expiration_time = m.get('LaunchExpirationTime')
        if m.get('LaunchTime') is not None:
            self.launch_time = m.get('LaunchTime')
        if m.get('MaxValue') is not None:
            self.max_value = m.get('MaxValue')
        if m.get('MinValue') is not None:
            self.min_value = m.get('MinValue')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RecurrenceEndTime') is not None:
            self.recurrence_end_time = m.get('RecurrenceEndTime')
        if m.get('RecurrenceType') is not None:
            self.recurrence_type = m.get('RecurrenceType')
        if m.get('RecurrenceValue') is not None:
            self.recurrence_value = m.get('RecurrenceValue')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('ScheduledAction') is not None:
            self.scheduled_action = m.get('ScheduledAction')
        if m.get('ScheduledTaskId') is not None:
            self.scheduled_task_id = m.get('ScheduledTaskId')
        if m.get('ScheduledTaskName') is not None:
            self.scheduled_task_name = m.get('ScheduledTaskName')
        if m.get('TaskEnabled') is not None:
            self.task_enabled = m.get('TaskEnabled')
        return self


class ModifyScheduledTaskResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ModifyScheduledTaskResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ModifyScheduledTaskResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ModifyScheduledTaskResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ModifyScheduledTaskResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ModifyScheduledTaskResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class RebalanceInstancesRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 resource_owner_id=None, scaling_group_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(RebalanceInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class RebalanceInstancesResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(RebalanceInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class RebalanceInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: RebalanceInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(RebalanceInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = RebalanceInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class RecordLifecycleActionHeartbeatRequest(TeaModel):
    def __init__(self, owner_account=None, owner_id=None, region_id=None, resource_owner_account=None,
                 heartbeat_timeout=None, lifecycle_action_token=None, lifecycle_hook_id=None):
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The period of time before the lifecycle hook ends. Auto Scaling performs the specified action after the lifecycle hook ends. Valid values: 30 to 21600. Unit: seconds.
        # 
        # You can call this operation to prolong the length of a lifecycle hook. You can also call the CompleteLifecycleAction operation to end a lifecycle hook ahead of schedule.
        # 
        # Default value: 600.
        self.heartbeat_timeout = heartbeat_timeout  # type: int
        # The token of the lifecycle hook. You can obtain this token by using a Message Service (MNS) queue or an MNS topic that is specified for the lifecycle hook.
        self.lifecycle_action_token = lifecycle_action_token  # type: str
        # The ID of the lifecycle hook.
        self.lifecycle_hook_id = lifecycle_hook_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(RecordLifecycleActionHeartbeatRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.heartbeat_timeout is not None:
            result['heartbeatTimeout'] = self.heartbeat_timeout
        if self.lifecycle_action_token is not None:
            result['lifecycleActionToken'] = self.lifecycle_action_token
        if self.lifecycle_hook_id is not None:
            result['lifecycleHookId'] = self.lifecycle_hook_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('heartbeatTimeout') is not None:
            self.heartbeat_timeout = m.get('heartbeatTimeout')
        if m.get('lifecycleActionToken') is not None:
            self.lifecycle_action_token = m.get('lifecycleActionToken')
        if m.get('lifecycleHookId') is not None:
            self.lifecycle_hook_id = m.get('lifecycleHookId')
        return self


class RecordLifecycleActionHeartbeatResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(RecordLifecycleActionHeartbeatResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class RecordLifecycleActionHeartbeatResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: RecordLifecycleActionHeartbeatResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(RecordLifecycleActionHeartbeatResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = RecordLifecycleActionHeartbeatResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class RemoveInstancesRequest(TeaModel):
    def __init__(self, client_token=None, decrease_desired_capacity=None, instance_ids=None, owner_account=None,
                 owner_id=None, region_id=None, remove_policy=None, resource_owner_account=None, resource_owner_id=None,
                 scaling_group_id=None):
        self.client_token = client_token  # type: str
        self.decrease_desired_capacity = decrease_desired_capacity  # type: bool
        self.instance_ids = instance_ids  # type: list[str]
        self.owner_account = owner_account  # type: str
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.remove_policy = remove_policy  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(RemoveInstancesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.decrease_desired_capacity is not None:
            result['DecreaseDesiredCapacity'] = self.decrease_desired_capacity
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.owner_account is not None:
            result['OwnerAccount'] = self.owner_account
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.remove_policy is not None:
            result['RemovePolicy'] = self.remove_policy
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('DecreaseDesiredCapacity') is not None:
            self.decrease_desired_capacity = m.get('DecreaseDesiredCapacity')
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('OwnerAccount') is not None:
            self.owner_account = m.get('OwnerAccount')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('RemovePolicy') is not None:
            self.remove_policy = m.get('RemovePolicy')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class RemoveInstancesResponseBody(TeaModel):
    def __init__(self, request_id=None, scaling_activity_id=None):
        self.request_id = request_id  # type: str
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(RemoveInstancesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class RemoveInstancesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: RemoveInstancesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(RemoveInstancesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = RemoveInstancesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ResumeProcessesRequest(TeaModel):
    def __init__(self, client_token=None, owner_id=None, processes=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can only contain ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        self.owner_id = owner_id  # type: long
        # Details of the processes that you want to resume.
        self.processes = processes  # type: list[str]
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ResumeProcessesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.processes is not None:
            result['Processes'] = self.processes
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Processes') is not None:
            self.processes = m.get('Processes')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class ResumeProcessesResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ResumeProcessesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class ResumeProcessesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ResumeProcessesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ResumeProcessesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ResumeProcessesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class ScaleWithAdjustmentRequestLifecycleHookContext(TeaModel):
    def __init__(self, disable_lifecycle_hook=None, ignored_lifecycle_hook_ids=None):
        self.disable_lifecycle_hook = disable_lifecycle_hook  # type: bool
        self.ignored_lifecycle_hook_ids = ignored_lifecycle_hook_ids  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(ScaleWithAdjustmentRequestLifecycleHookContext, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.disable_lifecycle_hook is not None:
            result['DisableLifecycleHook'] = self.disable_lifecycle_hook
        if self.ignored_lifecycle_hook_ids is not None:
            result['IgnoredLifecycleHookIds'] = self.ignored_lifecycle_hook_ids
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('DisableLifecycleHook') is not None:
            self.disable_lifecycle_hook = m.get('DisableLifecycleHook')
        if m.get('IgnoredLifecycleHookIds') is not None:
            self.ignored_lifecycle_hook_ids = m.get('IgnoredLifecycleHookIds')
        return self


class ScaleWithAdjustmentRequestOverridesContainerOverridesEnvironmentVars(TeaModel):
    def __init__(self, key=None, value=None):
        self.key = key  # type: str
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ScaleWithAdjustmentRequestOverridesContainerOverridesEnvironmentVars, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class ScaleWithAdjustmentRequestOverridesContainerOverrides(TeaModel):
    def __init__(self, args=None, commands=None, cpu=None, environment_vars=None, memory=None, name=None):
        self.args = args  # type: list[str]
        self.commands = commands  # type: list[str]
        self.cpu = cpu  # type: float
        self.environment_vars = environment_vars  # type: list[ScaleWithAdjustmentRequestOverridesContainerOverridesEnvironmentVars]
        self.memory = memory  # type: float
        self.name = name  # type: str

    def validate(self):
        if self.environment_vars:
            for k in self.environment_vars:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ScaleWithAdjustmentRequestOverridesContainerOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.args is not None:
            result['Args'] = self.args
        if self.commands is not None:
            result['Commands'] = self.commands
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        result['EnvironmentVars'] = []
        if self.environment_vars is not None:
            for k in self.environment_vars:
                result['EnvironmentVars'].append(k.to_map() if k else None)
        if self.memory is not None:
            result['Memory'] = self.memory
        if self.name is not None:
            result['Name'] = self.name
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Args') is not None:
            self.args = m.get('Args')
        if m.get('Commands') is not None:
            self.commands = m.get('Commands')
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        self.environment_vars = []
        if m.get('EnvironmentVars') is not None:
            for k in m.get('EnvironmentVars'):
                temp_model = ScaleWithAdjustmentRequestOverridesContainerOverridesEnvironmentVars()
                self.environment_vars.append(temp_model.from_map(k))
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        if m.get('Name') is not None:
            self.name = m.get('Name')
        return self


class ScaleWithAdjustmentRequestOverrides(TeaModel):
    def __init__(self, container_overrides=None, cpu=None, memory=None):
        self.container_overrides = container_overrides  # type: list[ScaleWithAdjustmentRequestOverridesContainerOverrides]
        self.cpu = cpu  # type: float
        self.memory = memory  # type: float

    def validate(self):
        if self.container_overrides:
            for k in self.container_overrides:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(ScaleWithAdjustmentRequestOverrides, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        result['ContainerOverrides'] = []
        if self.container_overrides is not None:
            for k in self.container_overrides:
                result['ContainerOverrides'].append(k.to_map() if k else None)
        if self.cpu is not None:
            result['Cpu'] = self.cpu
        if self.memory is not None:
            result['Memory'] = self.memory
        return result

    def from_map(self, m=None):
        m = m or dict()
        self.container_overrides = []
        if m.get('ContainerOverrides') is not None:
            for k in m.get('ContainerOverrides'):
                temp_model = ScaleWithAdjustmentRequestOverridesContainerOverrides()
                self.container_overrides.append(temp_model.from_map(k))
        if m.get('Cpu') is not None:
            self.cpu = m.get('Cpu')
        if m.get('Memory') is not None:
            self.memory = m.get('Memory')
        return self


class ScaleWithAdjustmentRequest(TeaModel):
    def __init__(self, activity_metadata=None, adjustment_type=None, adjustment_value=None, client_token=None,
                 lifecycle_hook_context=None, min_adjustment_magnitude=None, overrides=None, owner_id=None, resource_owner_account=None,
                 scaling_group_id=None, sync_activity=None):
        self.activity_metadata = activity_metadata  # type: str
        # The type of the scaling policy. Valid values:
        # 
        # *   QuantityChangeInCapacity: adds the specified number of ECS instances to or removes the specified number of ECS instances from the scaling group.
        # *   PercentChangeInCapacity: adds the specified percentage of ECS instances to or removes the specified percentage of ECS instances from the scaling group.
        # *   TotalCapacity: adjusts the number of ECS instances in the scaling group to a specified number.
        self.adjustment_type = adjustment_type  # type: str
        # The number of instances in each adjustment. The number of ECS instances in each adjustment cannot exceed 1,000.
        # 
        # *   Valid values if you set the AdjustmentType parameter to QuantityChangeInCapacity: -1000 to 1000.
        # *   Valid values if you set the AdjustmentType parameter to PercentChangeInCapacity: -100 to 10000.
        # *   Valid values if you set the AdjustmentType parameter to TotalCapacity: 0 to 2000.
        self.adjustment_value = adjustment_value  # type: int
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length.
        self.client_token = client_token  # type: str
        self.lifecycle_hook_context = lifecycle_hook_context  # type: ScaleWithAdjustmentRequestLifecycleHookContext
        # The minimum number of instances allowed in each adjustment. This parameter takes effect only if you set the `AdjustmentType` parameter to `PercentChangeInCapacity`.
        self.min_adjustment_magnitude = min_adjustment_magnitude  # type: int
        self.overrides = overrides  # type: ScaleWithAdjustmentRequestOverrides
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # Specifies whether to trigger the scaling activity in a synchronous manner. This parameter takes effect only on scaling groups for which you specified an expected number of instances. Valid values:
        # 
        # *   true: triggers the scaling activity in a synchronous manner. The scaling activity is triggered at the time when the scaling rule is executed.
        # *   false: does not trigger the scaling activity in a synchronous manner. After you change the expected number of instances for the scaling group, Auto Scaling checks whether the total number of instances in the scaling group matches the new expected number of instances and determines whether to trigger the scaling activity based on the check result.
        # 
        # > For more information about the Expected Number of Instances feature, see [Expected number of instances](~~146231~~).
        # 
        # Default value: false.
        self.sync_activity = sync_activity  # type: bool

    def validate(self):
        if self.lifecycle_hook_context:
            self.lifecycle_hook_context.validate()
        if self.overrides:
            self.overrides.validate()

    def to_map(self):
        _map = super(ScaleWithAdjustmentRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.activity_metadata is not None:
            result['ActivityMetadata'] = self.activity_metadata
        if self.adjustment_type is not None:
            result['AdjustmentType'] = self.adjustment_type
        if self.adjustment_value is not None:
            result['AdjustmentValue'] = self.adjustment_value
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.lifecycle_hook_context is not None:
            result['LifecycleHookContext'] = self.lifecycle_hook_context.to_map()
        if self.min_adjustment_magnitude is not None:
            result['MinAdjustmentMagnitude'] = self.min_adjustment_magnitude
        if self.overrides is not None:
            result['Overrides'] = self.overrides.to_map()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.sync_activity is not None:
            result['SyncActivity'] = self.sync_activity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActivityMetadata') is not None:
            self.activity_metadata = m.get('ActivityMetadata')
        if m.get('AdjustmentType') is not None:
            self.adjustment_type = m.get('AdjustmentType')
        if m.get('AdjustmentValue') is not None:
            self.adjustment_value = m.get('AdjustmentValue')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('LifecycleHookContext') is not None:
            temp_model = ScaleWithAdjustmentRequestLifecycleHookContext()
            self.lifecycle_hook_context = temp_model.from_map(m['LifecycleHookContext'])
        if m.get('MinAdjustmentMagnitude') is not None:
            self.min_adjustment_magnitude = m.get('MinAdjustmentMagnitude')
        if m.get('Overrides') is not None:
            temp_model = ScaleWithAdjustmentRequestOverrides()
            self.overrides = temp_model.from_map(m['Overrides'])
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('SyncActivity') is not None:
            self.sync_activity = m.get('SyncActivity')
        return self


class ScaleWithAdjustmentShrinkRequest(TeaModel):
    def __init__(self, activity_metadata=None, adjustment_type=None, adjustment_value=None, client_token=None,
                 lifecycle_hook_context_shrink=None, min_adjustment_magnitude=None, overrides_shrink=None, owner_id=None,
                 resource_owner_account=None, scaling_group_id=None, sync_activity=None):
        self.activity_metadata = activity_metadata  # type: str
        # The type of the scaling policy. Valid values:
        # 
        # *   QuantityChangeInCapacity: adds the specified number of ECS instances to or removes the specified number of ECS instances from the scaling group.
        # *   PercentChangeInCapacity: adds the specified percentage of ECS instances to or removes the specified percentage of ECS instances from the scaling group.
        # *   TotalCapacity: adjusts the number of ECS instances in the scaling group to a specified number.
        self.adjustment_type = adjustment_type  # type: str
        # The number of instances in each adjustment. The number of ECS instances in each adjustment cannot exceed 1,000.
        # 
        # *   Valid values if you set the AdjustmentType parameter to QuantityChangeInCapacity: -1000 to 1000.
        # *   Valid values if you set the AdjustmentType parameter to PercentChangeInCapacity: -100 to 10000.
        # *   Valid values if you set the AdjustmentType parameter to TotalCapacity: 0 to 2000.
        self.adjustment_value = adjustment_value  # type: int
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests. The token can contain only ASCII characters and cannot exceed 64 characters in length.
        self.client_token = client_token  # type: str
        self.lifecycle_hook_context_shrink = lifecycle_hook_context_shrink  # type: str
        # The minimum number of instances allowed in each adjustment. This parameter takes effect only if you set the `AdjustmentType` parameter to `PercentChangeInCapacity`.
        self.min_adjustment_magnitude = min_adjustment_magnitude  # type: int
        self.overrides_shrink = overrides_shrink  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str
        # Specifies whether to trigger the scaling activity in a synchronous manner. This parameter takes effect only on scaling groups for which you specified an expected number of instances. Valid values:
        # 
        # *   true: triggers the scaling activity in a synchronous manner. The scaling activity is triggered at the time when the scaling rule is executed.
        # *   false: does not trigger the scaling activity in a synchronous manner. After you change the expected number of instances for the scaling group, Auto Scaling checks whether the total number of instances in the scaling group matches the new expected number of instances and determines whether to trigger the scaling activity based on the check result.
        # 
        # > For more information about the Expected Number of Instances feature, see [Expected number of instances](~~146231~~).
        # 
        # Default value: false.
        self.sync_activity = sync_activity  # type: bool

    def validate(self):
        pass

    def to_map(self):
        _map = super(ScaleWithAdjustmentShrinkRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.activity_metadata is not None:
            result['ActivityMetadata'] = self.activity_metadata
        if self.adjustment_type is not None:
            result['AdjustmentType'] = self.adjustment_type
        if self.adjustment_value is not None:
            result['AdjustmentValue'] = self.adjustment_value
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.lifecycle_hook_context_shrink is not None:
            result['LifecycleHookContext'] = self.lifecycle_hook_context_shrink
        if self.min_adjustment_magnitude is not None:
            result['MinAdjustmentMagnitude'] = self.min_adjustment_magnitude
        if self.overrides_shrink is not None:
            result['Overrides'] = self.overrides_shrink
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        if self.sync_activity is not None:
            result['SyncActivity'] = self.sync_activity
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActivityMetadata') is not None:
            self.activity_metadata = m.get('ActivityMetadata')
        if m.get('AdjustmentType') is not None:
            self.adjustment_type = m.get('AdjustmentType')
        if m.get('AdjustmentValue') is not None:
            self.adjustment_value = m.get('AdjustmentValue')
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('LifecycleHookContext') is not None:
            self.lifecycle_hook_context_shrink = m.get('LifecycleHookContext')
        if m.get('MinAdjustmentMagnitude') is not None:
            self.min_adjustment_magnitude = m.get('MinAdjustmentMagnitude')
        if m.get('Overrides') is not None:
            self.overrides_shrink = m.get('Overrides')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        if m.get('SyncActivity') is not None:
            self.sync_activity = m.get('SyncActivity')
        return self


class ScaleWithAdjustmentResponseBody(TeaModel):
    def __init__(self, activity_type=None, request_id=None, scaling_activity_id=None):
        # 伸缩活动的类型。
        # 
        # 当ActivityType为CapacityChange时，表示返回值ScalingActivityId对应伸缩活动仅修改伸缩组期望实例数，没有立刻执行扩缩。适用范围：期望实例数类型伸缩组。
        self.activity_type = activity_type  # type: str
        # The ID of the request.
        self.request_id = request_id  # type: str
        # The ID of the scaling activity.
        self.scaling_activity_id = scaling_activity_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(ScaleWithAdjustmentResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.activity_type is not None:
            result['ActivityType'] = self.activity_type
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        if self.scaling_activity_id is not None:
            result['ScalingActivityId'] = self.scaling_activity_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ActivityType') is not None:
            self.activity_type = m.get('ActivityType')
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        if m.get('ScalingActivityId') is not None:
            self.scaling_activity_id = m.get('ScalingActivityId')
        return self


class ScaleWithAdjustmentResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: ScaleWithAdjustmentResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(ScaleWithAdjustmentResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = ScaleWithAdjustmentResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SetGroupDeletionProtectionRequest(TeaModel):
    def __init__(self, group_deletion_protection=None, owner_id=None, region_id=None, resource_owner_account=None,
                 scaling_group_id=None):
        # Specifies whether to enable deletion protection for the scaling group. Valid values:
        # 
        # *   true: enables deletion protection for the scaling group. This way, the scaling group cannot be deleted.
        # *   false: disables deletion protection for the scaling group.
        self.group_deletion_protection = group_deletion_protection  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SetGroupDeletionProtectionRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.group_deletion_protection is not None:
            result['GroupDeletionProtection'] = self.group_deletion_protection
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('GroupDeletionProtection') is not None:
            self.group_deletion_protection = m.get('GroupDeletionProtection')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class SetGroupDeletionProtectionResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SetGroupDeletionProtectionResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SetGroupDeletionProtectionResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: SetGroupDeletionProtectionResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(SetGroupDeletionProtectionResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SetGroupDeletionProtectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SetInstanceHealthRequest(TeaModel):
    def __init__(self, health_status=None, instance_id=None, owner_id=None, resource_owner_account=None):
        # The health status of the ECS instance in the scaling group. If ECS instances do not run as expected, Auto Scaling considers the ECS instances unhealthy. Valid values:
        # 
        # *   Healthy
        # *   Unhealthy
        # 
        # Auto Scaling automatically removes unhealthy ECS instances from the scaling group and then releases the automatically created instances among the unhealthy instances.
        # 
        # Unhealthy ECS instances that are manually added to the scaling group are released based on the management mode of the instance lifecycles. If the lifecycles of the ECS instances are not managed by the scaling group, Auto Scaling removes the instances from the scaling group but does not release the instances. If the lifecycles of the ECS instances are managed by the scaling group, Auto Scaling removes the instances from the scaling group and releases the instances.
        # 
        # >  Make sure that you have sufficient balance within your Alibaba Cloud account. If you have overdue payments within your Alibaba Cloud account, pay-as-you-go and preemptible instances are stopped or released. For information about how the states of ECS instances change when you have overdue payments within your Alibaba Cloud account, see [Overdue payments](~~170589~~).
        self.health_status = health_status  # type: str
        # The ID of the instance.
        self.instance_id = instance_id  # type: str
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SetInstanceHealthRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.health_status is not None:
            result['HealthStatus'] = self.health_status
        if self.instance_id is not None:
            result['InstanceId'] = self.instance_id
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('HealthStatus') is not None:
            self.health_status = m.get('HealthStatus')
        if m.get('InstanceId') is not None:
            self.instance_id = m.get('InstanceId')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        return self


class SetInstanceHealthResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SetInstanceHealthResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SetInstanceHealthResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: SetInstanceHealthResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(SetInstanceHealthResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SetInstanceHealthResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SetInstancesProtectionRequest(TeaModel):
    def __init__(self, instance_ids=None, owner_id=None, protected_from_scale_in=None, resource_owner_account=None,
                 scaling_group_id=None):
        # The IDs of the ECS instances.
        self.instance_ids = instance_ids  # type: list[str]
        self.owner_id = owner_id  # type: long
        # Specifies whether to put ECS instances into the Protected state. Auto Scaling does not remove ECS instances in the Protected state from scaling groups during scale-in activities.
        # 
        # *   true
        # *   false
        self.protected_from_scale_in = protected_from_scale_in  # type: bool
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SetInstancesProtectionRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.instance_ids is not None:
            result['InstanceIds'] = self.instance_ids
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.protected_from_scale_in is not None:
            result['ProtectedFromScaleIn'] = self.protected_from_scale_in
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('InstanceIds') is not None:
            self.instance_ids = m.get('InstanceIds')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ProtectedFromScaleIn') is not None:
            self.protected_from_scale_in = m.get('ProtectedFromScaleIn')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class SetInstancesProtectionResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SetInstancesProtectionResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SetInstancesProtectionResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: SetInstancesProtectionResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(SetInstancesProtectionResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SetInstancesProtectionResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class SuspendProcessesRequest(TeaModel):
    def __init__(self, client_token=None, owner_id=None, processes=None, region_id=None,
                 resource_owner_account=None, scaling_group_id=None):
        # The client token that is used to ensure the idempotence of the request. You can use the client to generate the value, but you must ensure that the value is unique among different requests.
        # 
        # The token can only contain ASCII characters and cannot exceed 64 characters in length. For more information, see [How to ensure idempotence](~~25965~~).
        self.client_token = client_token  # type: str
        self.owner_id = owner_id  # type: long
        # The types of the processes that you want to suspend. Valid values:
        # 
        # *   scalein
        # *   scaleout
        # *   healthcheck
        # *   alarmnotification
        # *   scheduledaction
        # 
        # You can suspend five processes of the preceding types at the same time. If you try to suspend more than five processes at the same time, Auto Scaling automatically removes duplicate processes.
        self.processes = processes  # type: list[str]
        # The region ID of the scaling group.
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        # The ID of the scaling group.
        self.scaling_group_id = scaling_group_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SuspendProcessesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.client_token is not None:
            result['ClientToken'] = self.client_token
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.processes is not None:
            result['Processes'] = self.processes
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.scaling_group_id is not None:
            result['ScalingGroupId'] = self.scaling_group_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('ClientToken') is not None:
            self.client_token = m.get('ClientToken')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('Processes') is not None:
            self.processes = m.get('Processes')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ScalingGroupId') is not None:
            self.scaling_group_id = m.get('ScalingGroupId')
        return self


class SuspendProcessesResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(SuspendProcessesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class SuspendProcessesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: SuspendProcessesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(SuspendProcessesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = SuspendProcessesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class TagResourcesRequestTags(TeaModel):
    def __init__(self, key=None, propagate=None, value=None):
        # The key of the tag that you want to add to the Auto Scaling resource.
        # 
        # You cannot specify empty strings as tag keys. The tag key must be 1 to 128 characters in length and cannot contain `http://` or `https://`. The tag key cannot start with `acs:` or `aliyun`.
        self.key = key  # type: str
        # Specifies whether to propagate the tag that you want to add. Valid values:
        # 
        # *   true: propagates the tag only to instances that are newly created and does not propagate the tag to instances that are already running in the scaling group.
        # *   false: does not propagate the tag to any instances.
        # 
        # Default value: false.
        self.propagate = propagate  # type: bool
        # The value of the tag that you want to add to the Auto Scaling resource.
        # 
        # You can specify empty strings as tag values. The tag value must be 0 to 128 characters in length and cannot contain `http://` or `https://`. The tag value cannot start with `acs:`.
        self.value = value  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(TagResourcesRequestTags, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.key is not None:
            result['Key'] = self.key
        if self.propagate is not None:
            result['Propagate'] = self.propagate
        if self.value is not None:
            result['Value'] = self.value
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('Key') is not None:
            self.key = m.get('Key')
        if m.get('Propagate') is not None:
            self.propagate = m.get('Propagate')
        if m.get('Value') is not None:
            self.value = m.get('Value')
        return self


class TagResourcesRequest(TeaModel):
    def __init__(self, owner_id=None, region_id=None, resource_ids=None, resource_owner_account=None,
                 resource_type=None, tags=None):
        self.owner_id = owner_id  # type: long
        # The region ID.
        self.region_id = region_id  # type: str
        # The IDs of the Auto Scaling resources. You can specify 1 to 50 resource IDs.
        self.resource_ids = resource_ids  # type: list[str]
        self.resource_owner_account = resource_owner_account  # type: str
        # The type of the resource. Only scaling groups are supported. Set the value to scalinggroup.
        self.resource_type = resource_type  # type: str
        # Details of the tags.
        self.tags = tags  # type: list[TagResourcesRequestTags]

    def validate(self):
        if self.tags:
            for k in self.tags:
                if k:
                    k.validate()

    def to_map(self):
        _map = super(TagResourcesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_ids is not None:
            result['ResourceIds'] = self.resource_ids
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        result['Tags'] = []
        if self.tags is not None:
            for k in self.tags:
                result['Tags'].append(k.to_map() if k else None)
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceIds') is not None:
            self.resource_ids = m.get('ResourceIds')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        self.tags = []
        if m.get('Tags') is not None:
            for k in m.get('Tags'):
                temp_model = TagResourcesRequestTags()
                self.tags.append(temp_model.from_map(k))
        return self


class TagResourcesResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(TagResourcesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class TagResourcesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: TagResourcesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(TagResourcesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = TagResourcesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class UntagResourcesRequest(TeaModel):
    def __init__(self, all=None, owner_id=None, region_id=None, resource_ids=None, resource_owner_account=None,
                 resource_type=None, tag_keys=None):
        # Specifies whether to remove all tags from the Auto Scaling resource. This parameter takes effect only if you do not specify the `TagKeys` parameter. Valid values:
        # 
        # *   true: removes all tags from the Auto Scaling resource.
        # *   false: does not remove tags from the Auto Scaling resource.
        # 
        # Default value: false.
        self.all = all  # type: bool
        self.owner_id = owner_id  # type: long
        # The region ID of the Auto Scaling resource. You can call the DescribeRegions operation to query the most recent region list.
        self.region_id = region_id  # type: str
        # The IDs of the Auto Scaling resources. You can specify 1 to 50 resource IDs.
        self.resource_ids = resource_ids  # type: list[str]
        self.resource_owner_account = resource_owner_account  # type: str
        # The type of the resource. Only scaling groups are supported. Set the value to scalinggroup.
        self.resource_type = resource_type  # type: str
        # The keys of the tags that you want to remove from the Auto Scaling resource. You can specify 1 to 20 tag keys.
        self.tag_keys = tag_keys  # type: list[str]

    def validate(self):
        pass

    def to_map(self):
        _map = super(UntagResourcesRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.all is not None:
            result['All'] = self.all
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_ids is not None:
            result['ResourceIds'] = self.resource_ids
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_type is not None:
            result['ResourceType'] = self.resource_type
        if self.tag_keys is not None:
            result['TagKeys'] = self.tag_keys
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('All') is not None:
            self.all = m.get('All')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceIds') is not None:
            self.resource_ids = m.get('ResourceIds')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceType') is not None:
            self.resource_type = m.get('ResourceType')
        if m.get('TagKeys') is not None:
            self.tag_keys = m.get('TagKeys')
        return self


class UntagResourcesResponseBody(TeaModel):
    def __init__(self, request_id=None):
        # The ID of the request.
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(UntagResourcesResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class UntagResourcesResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: UntagResourcesResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(UntagResourcesResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = UntagResourcesResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class VerifyAuthenticationRequest(TeaModel):
    def __init__(self, only_check=None, owner_id=None, resource_owner_account=None, resource_owner_id=None,
                 uid=None):
        self.only_check = only_check  # type: bool
        self.owner_id = owner_id  # type: long
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long
        self.uid = uid  # type: long

    def validate(self):
        pass

    def to_map(self):
        _map = super(VerifyAuthenticationRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.only_check is not None:
            result['OnlyCheck'] = self.only_check
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        if self.uid is not None:
            result['Uid'] = self.uid
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OnlyCheck') is not None:
            self.only_check = m.get('OnlyCheck')
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        if m.get('Uid') is not None:
            self.uid = m.get('Uid')
        return self


class VerifyAuthenticationResponseBody(TeaModel):
    def __init__(self, request_id=None):
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(VerifyAuthenticationResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class VerifyAuthenticationResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: VerifyAuthenticationResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(VerifyAuthenticationResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = VerifyAuthenticationResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


class VerifyUserRequest(TeaModel):
    def __init__(self, owner_id=None, region_id=None, resource_owner_account=None, resource_owner_id=None):
        self.owner_id = owner_id  # type: long
        self.region_id = region_id  # type: str
        self.resource_owner_account = resource_owner_account  # type: str
        self.resource_owner_id = resource_owner_id  # type: long

    def validate(self):
        pass

    def to_map(self):
        _map = super(VerifyUserRequest, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.owner_id is not None:
            result['OwnerId'] = self.owner_id
        if self.region_id is not None:
            result['RegionId'] = self.region_id
        if self.resource_owner_account is not None:
            result['ResourceOwnerAccount'] = self.resource_owner_account
        if self.resource_owner_id is not None:
            result['ResourceOwnerId'] = self.resource_owner_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('OwnerId') is not None:
            self.owner_id = m.get('OwnerId')
        if m.get('RegionId') is not None:
            self.region_id = m.get('RegionId')
        if m.get('ResourceOwnerAccount') is not None:
            self.resource_owner_account = m.get('ResourceOwnerAccount')
        if m.get('ResourceOwnerId') is not None:
            self.resource_owner_id = m.get('ResourceOwnerId')
        return self


class VerifyUserResponseBody(TeaModel):
    def __init__(self, request_id=None):
        self.request_id = request_id  # type: str

    def validate(self):
        pass

    def to_map(self):
        _map = super(VerifyUserResponseBody, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.request_id is not None:
            result['RequestId'] = self.request_id
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('RequestId') is not None:
            self.request_id = m.get('RequestId')
        return self


class VerifyUserResponse(TeaModel):
    def __init__(self, headers=None, status_code=None, body=None):
        self.headers = headers  # type: dict[str, str]
        self.status_code = status_code  # type: int
        self.body = body  # type: VerifyUserResponseBody

    def validate(self):
        if self.body:
            self.body.validate()

    def to_map(self):
        _map = super(VerifyUserResponse, self).to_map()
        if _map is not None:
            return _map

        result = dict()
        if self.headers is not None:
            result['headers'] = self.headers
        if self.status_code is not None:
            result['statusCode'] = self.status_code
        if self.body is not None:
            result['body'] = self.body.to_map()
        return result

    def from_map(self, m=None):
        m = m or dict()
        if m.get('headers') is not None:
            self.headers = m.get('headers')
        if m.get('statusCode') is not None:
            self.status_code = m.get('statusCode')
        if m.get('body') is not None:
            temp_model = VerifyUserResponseBody()
            self.body = temp_model.from_map(m['body'])
        return self


